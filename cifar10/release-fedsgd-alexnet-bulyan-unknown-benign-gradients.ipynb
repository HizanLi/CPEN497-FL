{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The notebook contains\n",
    "### Code for _Bulyan_ aggregation algorithm, *when gradient updates of benign clients are unknown to adversary*\n",
    "### Evaluation of all of the attacks (Fang, LIE, and our SOTA AGR-tailored and AGR-agnstic) on Bulyan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse, os, sys, csv, shutil, time, random, operator, pickle, ast, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.optim import Optimizer\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import pickle\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "sys.path.insert(0,'./../utils/')\n",
    "from logger import *\n",
    "from eval import *\n",
    "from misc import *\n",
    "\n",
    "from cifar10_normal_train import *\n",
    "from cifar10_util import *\n",
    "from adam import Adam\n",
    "from sgd import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get cifar10 data and split it in IID fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "total data len:  60000\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "data_loc='/mnt/nfs/work1/amir/vshejwalkar/cifar10_data/'\n",
    "# load the train dataset\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "\n",
    "cifar10_train = datasets.CIFAR10(root=data_loc, train=True, download=True, transform=train_transform)\n",
    "\n",
    "cifar10_test = datasets.CIFAR10(root=data_loc, train=False, download=True, transform=train_transform)\n",
    "\n",
    "X=[]\n",
    "Y=[]\n",
    "for i in range(len(cifar10_train)):\n",
    "    X.append(cifar10_train[i][0].numpy())\n",
    "    Y.append(cifar10_train[i][1])\n",
    "\n",
    "for i in range(len(cifar10_test)):\n",
    "    X.append(cifar10_test[i][0].numpy())\n",
    "    Y.append(cifar10_test[i][1])\n",
    "\n",
    "X=np.array(X)\n",
    "Y=np.array(Y)\n",
    "\n",
    "print('total data len: ',len(X))\n",
    "\n",
    "if not os.path.isfile('./cifar10_shuffle.pkl'):\n",
    "    all_indices = np.arange(len(X))\n",
    "    np.random.shuffle(all_indices)\n",
    "    pickle.dump(all_indices,open('./cifar10_shuffle.pkl','wb'))\n",
    "else:\n",
    "    all_indices=pickle.load(open('./cifar10_shuffle.pkl','rb'))\n",
    "\n",
    "X=X[all_indices]\n",
    "Y=Y[all_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide cifar10 data among 50 clients in IID fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data len:  60000\n",
      "total tr len 50000 | val len 5000 | test len 5000\n",
      "user 0 tr len 1000\n",
      "user 1 tr len 1000\n",
      "user 2 tr len 1000\n",
      "user 3 tr len 1000\n",
      "user 4 tr len 1000\n",
      "user 5 tr len 1000\n",
      "user 6 tr len 1000\n",
      "user 7 tr len 1000\n",
      "user 8 tr len 1000\n",
      "user 9 tr len 1000\n",
      "user 10 tr len 1000\n",
      "user 11 tr len 1000\n",
      "user 12 tr len 1000\n",
      "user 13 tr len 1000\n",
      "user 14 tr len 1000\n",
      "user 15 tr len 1000\n",
      "user 16 tr len 1000\n",
      "user 17 tr len 1000\n",
      "user 18 tr len 1000\n",
      "user 19 tr len 1000\n",
      "user 20 tr len 1000\n",
      "user 21 tr len 1000\n",
      "user 22 tr len 1000\n",
      "user 23 tr len 1000\n",
      "user 24 tr len 1000\n",
      "user 25 tr len 1000\n",
      "user 26 tr len 1000\n",
      "user 27 tr len 1000\n",
      "user 28 tr len 1000\n",
      "user 29 tr len 1000\n",
      "user 30 tr len 1000\n",
      "user 31 tr len 1000\n",
      "user 32 tr len 1000\n",
      "user 33 tr len 1000\n",
      "user 34 tr len 1000\n",
      "user 35 tr len 1000\n",
      "user 36 tr len 1000\n",
      "user 37 tr len 1000\n",
      "user 38 tr len 1000\n",
      "user 39 tr len 1000\n",
      "user 40 tr len 1000\n",
      "user 41 tr len 1000\n",
      "user 42 tr len 1000\n",
      "user 43 tr len 1000\n",
      "user 44 tr len 1000\n",
      "user 45 tr len 1000\n",
      "user 46 tr len 1000\n",
      "user 47 tr len 1000\n",
      "user 48 tr len 1000\n",
      "user 49 tr len 1000\n"
     ]
    }
   ],
   "source": [
    "# data loading\n",
    "\n",
    "nusers=50\n",
    "user_tr_len=1000\n",
    "\n",
    "total_tr_len=user_tr_len*nusers\n",
    "val_len=5000\n",
    "te_len=5000\n",
    "\n",
    "print('total data len: ',len(X))\n",
    "\n",
    "if not os.path.isfile('./cifar10_shuffle.pkl'):\n",
    "    all_indices = np.arange(len(X))\n",
    "    np.random.shuffle(all_indices)\n",
    "    pickle.dump(all_indices,open('./cifar10_shuffle.pkl','wb'))\n",
    "else:\n",
    "    all_indices=pickle.load(open('./cifar10_shuffle.pkl','rb'))\n",
    "\n",
    "total_tr_data=X[:total_tr_len]\n",
    "total_tr_label=Y[:total_tr_len]\n",
    "\n",
    "val_data=X[total_tr_len:(total_tr_len+val_len)]\n",
    "val_label=Y[total_tr_len:(total_tr_len+val_len)]\n",
    "\n",
    "te_data=X[(total_tr_len+val_len):(total_tr_len+val_len+te_len)]\n",
    "te_label=Y[(total_tr_len+val_len):(total_tr_len+val_len+te_len)]\n",
    "\n",
    "total_tr_data_tensor=torch.from_numpy(total_tr_data).type(torch.FloatTensor)\n",
    "total_tr_label_tensor=torch.from_numpy(total_tr_label).type(torch.LongTensor)\n",
    "\n",
    "val_data_tensor=torch.from_numpy(val_data).type(torch.FloatTensor)\n",
    "val_label_tensor=torch.from_numpy(val_label).type(torch.LongTensor)\n",
    "\n",
    "te_data_tensor=torch.from_numpy(te_data).type(torch.FloatTensor)\n",
    "te_label_tensor=torch.from_numpy(te_label).type(torch.LongTensor)\n",
    "\n",
    "print('total tr len %d | val len %d | test len %d'%(len(total_tr_data_tensor),len(val_data_tensor),len(te_data_tensor)))\n",
    "\n",
    "#==============================================================================================================\n",
    "\n",
    "user_tr_data_tensors=[]\n",
    "user_tr_label_tensors=[]\n",
    "\n",
    "for i in range(nusers):\n",
    "    \n",
    "    user_tr_data_tensor=torch.from_numpy(total_tr_data[user_tr_len*i:user_tr_len*(i+1)]).type(torch.FloatTensor)\n",
    "    user_tr_label_tensor=torch.from_numpy(total_tr_label[user_tr_len*i:user_tr_len*(i+1)]).type(torch.LongTensor)\n",
    "\n",
    "    user_tr_data_tensors.append(user_tr_data_tensor)\n",
    "    user_tr_label_tensors.append(user_tr_label_tensor)\n",
    "    print('user %d tr len %d'%(i,len(user_tr_data_tensor)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for Multi-krum aggregation algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_krum(all_updates, n_attackers, multi_k=False):\n",
    "\n",
    "    candidates = []\n",
    "    candidate_indices = []\n",
    "    remaining_updates = all_updates\n",
    "    all_indices = np.arange(len(all_updates))\n",
    "\n",
    "    while len(remaining_updates) > 2 * n_attackers + 2:\n",
    "        torch.cuda.empty_cache()\n",
    "        distances = []\n",
    "        for update in remaining_updates:\n",
    "            distance = []\n",
    "            for update_ in remaining_updates:\n",
    "                distance.append(torch.norm((update - update_)) ** 2)\n",
    "            distance = torch.Tensor(distance).float()\n",
    "            distances = distance[None, :] if not len(distances) else torch.cat((distances, distance[None, :]), 0)\n",
    "\n",
    "        distances = torch.sort(distances, dim=1)[0]\n",
    "        scores = torch.sum(distances[:, :len(remaining_updates) - 2 - n_attackers], dim=1)\n",
    "        indices = torch.argsort(scores)[:len(remaining_updates) - 2 - n_attackers]\n",
    "\n",
    "        candidate_indices.append(all_indices[indices[0].cpu().numpy()])\n",
    "        all_indices = np.delete(all_indices, indices[0].cpu().numpy())\n",
    "        candidates = remaining_updates[indices[0]][None, :] if not len(candidates) else torch.cat((candidates, remaining_updates[indices[0]][None, :]), 0)\n",
    "        remaining_updates = torch.cat((remaining_updates[:indices[0]], remaining_updates[indices[0] + 1:]), 0)\n",
    "        if not multi_k:\n",
    "            break\n",
    "    # print(len(remaining_updates))\n",
    "\n",
    "    aggregate = torch.mean(candidates, dim=0)\n",
    "\n",
    "    return aggregate, np.array(candidate_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for Bulyan aggregation algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bulyan(all_updates, n_attackers):\n",
    "    nusers = all_updates.shape[0]\n",
    "    bulyan_cluster = []\n",
    "    candidate_indices = []\n",
    "    remaining_updates = all_updates\n",
    "    all_indices = np.arange(len(all_updates))\n",
    "\n",
    "    while len(bulyan_cluster) < (nusers - 2 * n_attackers):\n",
    "        torch.cuda.empty_cache()\n",
    "        distances = []\n",
    "        for update in remaining_updates:\n",
    "            distance = []\n",
    "            for update_ in remaining_updates:\n",
    "                distance.append(torch.norm((update - update_)) ** 2)\n",
    "            distance = torch.Tensor(distance).float()\n",
    "            distances = distance[None, :] if not len(distances) else torch.cat((distances, distance[None, :]), 0)\n",
    "        # print(distances)\n",
    "\n",
    "        distances = torch.sort(distances, dim=1)[0]\n",
    "\n",
    "        scores = torch.sum(distances[:, :len(remaining_updates) - 2 - n_attackers], dim=1)\n",
    "        indices = torch.argsort(scores)[:len(remaining_updates) - 2 - n_attackers]\n",
    "        if not len(indices):\n",
    "            break\n",
    "        candidate_indices.append(all_indices[indices[0].cpu().numpy()])\n",
    "        all_indices = np.delete(all_indices, indices[0].cpu().numpy())\n",
    "        bulyan_cluster = remaining_updates[indices[0]][None, :] if not len(bulyan_cluster) else torch.cat((bulyan_cluster, remaining_updates[indices[0]][None, :]), 0)\n",
    "        remaining_updates = torch.cat((remaining_updates[:indices[0]], remaining_updates[indices[0] + 1:]), 0)\n",
    "\n",
    "    # print('dim of bulyan cluster ', bulyan_cluster.shape)\n",
    "\n",
    "    n, d = bulyan_cluster.shape\n",
    "    param_med = torch.median(bulyan_cluster, dim=0)[0]\n",
    "    sort_idx = torch.argsort(torch.abs(bulyan_cluster - param_med), dim=0)\n",
    "    sorted_params = bulyan_cluster[sort_idx, torch.arange(d)[None, :]]\n",
    "\n",
    "    return torch.mean(sorted_params[:n - 2 * n_attackers], dim=0), np.array(candidate_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for fang attack on Bulyan\n",
    "### Note that Fang attacks on Multi-krum and Bulyan are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lambda_fang(all_updates, model_re, n_attackers):\n",
    "\n",
    "    distances = []\n",
    "    n_benign, d = all_updates.shape\n",
    "    for update in all_updates:\n",
    "        distance = torch.norm((all_updates - update), dim=1)\n",
    "        distances = distance[None, :] if not len(distances) else torch.cat((distances, distance[None, :]), 0)\n",
    "\n",
    "    distances[distances == 0] = 10000\n",
    "    distances = torch.sort(distances, dim=1)[0]\n",
    "    scores = torch.sum(distances[:, :n_benign - 2 - n_attackers], dim=1)\n",
    "    min_score = torch.min(scores)\n",
    "    term_1 = min_score / ((n_benign - n_attackers - 1) * torch.sqrt(torch.Tensor([d]))[0])\n",
    "    max_wre_dist = torch.max(torch.norm((all_updates - model_re), dim=1)) / (torch.sqrt(torch.Tensor([d]))[0])\n",
    "    # print(term_1 + max_wre_dist) # tensor(0.0001, device='cuda:0')\n",
    "    return (term_1 + max_wre_dist)\n",
    "\n",
    "\n",
    "def get_malicious_updates_fang(all_updates, model_re, deviation, n_attackers):\n",
    "    # deviation = torch.sign(agg_grads)\n",
    "    # print(\"all_updates.shape \", all_updates.shape) # all_updates.shape  torch.Size([10, 2472266])\n",
    "    # print(\"n_attackers \", n_attackers) # n_attackers  2\n",
    "    # print(\"model_re.shape \", model_re.shape) # model_re.shape torch.Size([2472266])\n",
    "    \n",
    "    lamda = compute_lambda_fang(all_updates, model_re, n_attackers) # tensor(0.0001, device='cuda:0')\n",
    "    \n",
    "    threshold = 1e-5\n",
    "\n",
    "    mal_updates = []\n",
    "    while lamda > threshold:\n",
    "        print(\"lamda: \", lamda)\n",
    "        mal_update = (- lamda * deviation) # torch.Size([2472266])\n",
    "        mal_updates = torch.stack([mal_update] * n_attackers)   # torch.Size([2, 2472266])\n",
    "        mal_updates = torch.cat((mal_updates, all_updates), 0)  # torch.Size([12, 2472266])\n",
    "\n",
    "        agg_grads, krum_candidate = multi_krum(mal_updates, n_attackers, multi_k=False) # agg_grads.shape torch.Size([2472266]) # krum_candidate.shape torch.Size(1,)\n",
    "        print(\"krum_candidate: \", krum_candidate)\n",
    "        if krum_candidate < n_attackers:\n",
    "            return mal_update\n",
    "        \n",
    "        lamda *= 0.5\n",
    "\n",
    "    if not len(mal_updates):\n",
    "        print(lamda, threshold)\n",
    "        mal_update = (model_re - lamda * deviation)\n",
    "    return mal_update  # len(mal_update) 2472266"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute Fang attack on Bulyan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, bulyan: at fang n_at 10 n_mal_sel 10 e 0 | val loss 2.3026 val acc 10.2476 best val_acc 10.247565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hizan\\AppData\\Local\\Temp\\ipykernel_15060\\1308321397.py:135: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, bulyan: at fang n_at 10 n_mal_sel 10 e 1 | val loss 2.3022 val acc 10.2679 best val_acc 10.267857\n",
      "epoch: 2, bulyan: at fang n_at 10 n_mal_sel 10 e 2 | val loss 2.3017 val acc 10.9172 best val_acc 10.917208\n",
      "epoch: 3, bulyan: at fang n_at 10 n_mal_sel 10 e 3 | val loss 2.3013 val acc 13.3117 best val_acc 13.311688\n",
      "epoch: 4, bulyan: at fang n_at 10 n_mal_sel 9 e 4 | val loss 2.3008 val acc 11.9115 best val_acc 13.311688\n",
      "epoch: 5, bulyan: at fang n_at 10 n_mal_sel 10 e 5 | val loss 2.3003 val acc 17.9586 best val_acc 17.958604\n",
      "epoch: 6, bulyan: at fang n_at 10 n_mal_sel 10 e 6 | val loss 2.2998 val acc 19.4399 best val_acc 19.439935\n",
      "epoch: 7, bulyan: at fang n_at 10 n_mal_sel 10 e 7 | val loss 2.2993 val acc 19.1761 best val_acc 19.439935\n",
      "epoch: 8, bulyan: at fang n_at 10 n_mal_sel 10 e 8 | val loss 2.2986 val acc 17.2890 best val_acc 19.439935\n",
      "epoch: 9, bulyan: at fang n_at 10 n_mal_sel 10 e 9 | val loss 2.2979 val acc 21.6721 best val_acc 21.672078\n",
      "epoch: 10, bulyan: at fang n_at 10 n_mal_sel 10 e 10 | val loss 2.2971 val acc 19.5008 best val_acc 21.672078\n",
      "epoch: 11, bulyan: at fang n_at 10 n_mal_sel 10 e 11 | val loss 2.2962 val acc 17.6339 best val_acc 21.672078\n",
      "epoch: 12, bulyan: at fang n_at 10 n_mal_sel 10 e 12 | val loss 2.2950 val acc 17.5528 best val_acc 21.672078\n",
      "epoch: 13, bulyan: at fang n_at 10 n_mal_sel 10 e 13 | val loss 2.2936 val acc 19.8052 best val_acc 21.672078\n",
      "epoch: 14, bulyan: at fang n_at 10 n_mal_sel 10 e 14 | val loss 2.2919 val acc 18.2021 best val_acc 21.672078\n",
      "epoch: 15, bulyan: at fang n_at 10 n_mal_sel 10 e 15 | val loss 2.2897 val acc 16.2541 best val_acc 21.672078\n",
      "epoch: 16, bulyan: at fang n_at 10 n_mal_sel 10 e 16 | val loss 2.2868 val acc 17.5325 best val_acc 21.672078\n",
      "epoch: 17, bulyan: at fang n_at 10 n_mal_sel 10 e 17 | val loss 2.2830 val acc 19.5211 best val_acc 21.672078\n",
      "epoch: 18, bulyan: at fang n_at 10 n_mal_sel 10 e 18 | val loss 2.2778 val acc 18.0804 best val_acc 21.672078\n",
      "epoch: 19, bulyan: at fang n_at 10 n_mal_sel 10 e 19 | val loss 2.2704 val acc 18.2427 best val_acc 21.672078\n",
      "epoch: 20, bulyan: at fang n_at 10 n_mal_sel 10 e 20 | val loss 2.2600 val acc 18.4456 best val_acc 21.672078\n",
      "epoch: 21, bulyan: at fang n_at 10 n_mal_sel 10 e 21 | val loss 2.2454 val acc 19.9472 best val_acc 21.672078\n",
      "epoch: 22, bulyan: at fang n_at 10 n_mal_sel 10 e 22 | val loss 2.2265 val acc 19.6023 best val_acc 21.672078\n",
      "epoch: 23, bulyan: at fang n_at 10 n_mal_sel 9 e 23 | val loss 2.2035 val acc 20.9213 best val_acc 21.672078\n",
      "epoch: 24, bulyan: at fang n_at 10 n_mal_sel 10 e 24 | val loss 2.2060 val acc 20.1096 best val_acc 21.672078\n",
      "epoch: 25, bulyan: at fang n_at 10 n_mal_sel 10 e 25 | val loss 2.4019 val acc 9.7200 best val_acc 21.672078\n",
      "epoch: 26, bulyan: at fang n_at 10 n_mal_sel 10 e 26 | val loss 2.2734 val acc 19.2776 best val_acc 21.672078\n",
      "epoch: 27, bulyan: at fang n_at 10 n_mal_sel 10 e 27 | val loss 2.2424 val acc 20.5966 best val_acc 21.672078\n",
      "epoch: 28, bulyan: at fang n_at 10 n_mal_sel 10 e 28 | val loss 2.2015 val acc 18.5065 best val_acc 21.672078\n",
      "epoch: 29, bulyan: at fang n_at 10 n_mal_sel 10 e 29 | val loss 2.1708 val acc 21.1648 best val_acc 21.672078\n",
      "epoch: 30, bulyan: at fang n_at 10 n_mal_sel 10 e 30 | val loss 2.1441 val acc 23.6810 best val_acc 23.681006\n",
      "epoch: 31, bulyan: at fang n_at 10 n_mal_sel 9 e 31 | val loss 2.2241 val acc 19.3994 best val_acc 23.681006\n",
      "epoch: 32, bulyan: at fang n_at 10 n_mal_sel 9 e 32 | val loss 2.4262 val acc 9.8011 best val_acc 23.681006\n",
      "epoch: 33, bulyan: at fang n_at 10 n_mal_sel 10 e 33 | val loss 2.2980 val acc 12.7841 best val_acc 23.681006\n",
      "epoch: 34, bulyan: at fang n_at 10 n_mal_sel 10 e 34 | val loss 2.2949 val acc 11.1810 best val_acc 23.681006\n",
      "epoch: 35, bulyan: at fang n_at 10 n_mal_sel 10 e 35 | val loss 2.2920 val acc 12.0130 best val_acc 23.681006\n",
      "epoch: 36, bulyan: at fang n_at 10 n_mal_sel 10 e 36 | val loss 2.2887 val acc 10.9984 best val_acc 23.681006\n",
      "epoch: 37, bulyan: at fang n_at 10 n_mal_sel 10 e 37 | val loss 2.2853 val acc 11.4448 best val_acc 23.681006\n",
      "epoch: 38, bulyan: at fang n_at 10 n_mal_sel 10 e 38 | val loss 2.2816 val acc 11.1810 best val_acc 23.681006\n",
      "epoch: 39, bulyan: at fang n_at 10 n_mal_sel 10 e 39 | val loss 2.2775 val acc 12.2971 best val_acc 23.681006\n",
      "epoch: 40, bulyan: at fang n_at 10 n_mal_sel 10 e 40 | val loss 2.2730 val acc 11.2419 best val_acc 23.681006\n",
      "epoch: 41, bulyan: at fang n_at 10 n_mal_sel 10 e 41 | val loss 2.2676 val acc 12.6420 best val_acc 23.681006\n",
      "epoch: 42, bulyan: at fang n_at 10 n_mal_sel 10 e 42 | val loss 2.2620 val acc 12.5609 best val_acc 23.681006\n",
      "epoch: 43, bulyan: at fang n_at 10 n_mal_sel 10 e 43 | val loss 2.2557 val acc 12.5406 best val_acc 23.681006\n",
      "epoch: 44, bulyan: at fang n_at 10 n_mal_sel 10 e 44 | val loss 2.2492 val acc 11.0593 best val_acc 23.681006\n",
      "epoch: 45, bulyan: at fang n_at 10 n_mal_sel 10 e 45 | val loss 2.2417 val acc 12.8450 best val_acc 23.681006\n",
      "epoch: 46, bulyan: at fang n_at 10 n_mal_sel 10 e 46 | val loss 2.2339 val acc 14.6104 best val_acc 23.681006\n",
      "epoch: 47, bulyan: at fang n_at 10 n_mal_sel 10 e 47 | val loss 2.2253 val acc 15.0365 best val_acc 23.681006\n",
      "epoch: 48, bulyan: at fang n_at 10 n_mal_sel 10 e 48 | val loss 2.2166 val acc 15.9091 best val_acc 23.681006\n",
      "epoch: 49, bulyan: at fang n_at 10 n_mal_sel 10 e 49 | val loss 2.2082 val acc 16.2946 best val_acc 23.681006\n",
      "epoch: 50, bulyan: at fang n_at 10 n_mal_sel 10 e 50 | val loss 2.1992 val acc 18.0195 best val_acc 23.681006\n",
      "epoch: 51, bulyan: at fang n_at 10 n_mal_sel 10 e 51 | val loss 2.1916 val acc 18.9935 best val_acc 23.681006\n",
      "epoch: 52, bulyan: at fang n_at 10 n_mal_sel 10 e 52 | val loss 2.1928 val acc 19.4805 best val_acc 23.681006\n",
      "epoch: 53, bulyan: at fang n_at 10 n_mal_sel 10 e 53 | val loss 2.2221 val acc 19.5820 best val_acc 23.681006\n",
      "epoch: 54, bulyan: at fang n_at 10 n_mal_sel 10 e 54 | val loss 2.2814 val acc 13.9610 best val_acc 23.681006\n",
      "epoch: 55, bulyan: at fang n_at 10 n_mal_sel 10 e 55 | val loss 2.2235 val acc 19.2979 best val_acc 23.681006\n",
      "epoch: 56, bulyan: at fang n_at 10 n_mal_sel 10 e 56 | val loss 2.1723 val acc 21.1039 best val_acc 23.681006\n",
      "epoch: 57, bulyan: at fang n_at 10 n_mal_sel 10 e 57 | val loss 2.1453 val acc 21.8750 best val_acc 23.681006\n",
      "epoch: 58, bulyan: at fang n_at 10 n_mal_sel 10 e 58 | val loss 2.1319 val acc 21.5706 best val_acc 23.681006\n",
      "epoch: 59, bulyan: at fang n_at 10 n_mal_sel 10 e 59 | val loss 2.1595 val acc 19.5617 best val_acc 23.681006\n",
      "epoch: 60, bulyan: at fang n_at 10 n_mal_sel 10 e 60 | val loss 2.3095 val acc 18.5674 best val_acc 23.681006\n",
      "epoch: 61, bulyan: at fang n_at 10 n_mal_sel 10 e 61 | val loss 2.3061 val acc 10.6534 best val_acc 23.681006\n",
      "epoch: 62, bulyan: at fang n_at 10 n_mal_sel 10 e 62 | val loss 2.2745 val acc 11.7289 best val_acc 23.681006\n",
      "epoch: 63, bulyan: at fang n_at 10 n_mal_sel 10 e 63 | val loss 2.2253 val acc 15.2800 best val_acc 23.681006\n",
      "epoch: 64, bulyan: at fang n_at 10 n_mal_sel 10 e 64 | val loss 2.1532 val acc 19.6023 best val_acc 23.681006\n",
      "epoch: 65, bulyan: at fang n_at 10 n_mal_sel 10 e 65 | val loss 2.1034 val acc 20.7183 best val_acc 23.681006\n",
      "epoch: 66, bulyan: at fang n_at 10 n_mal_sel 10 e 66 | val loss 2.0864 val acc 22.4838 best val_acc 23.681006\n",
      "epoch: 67, bulyan: at fang n_at 10 n_mal_sel 10 e 67 | val loss 2.2016 val acc 18.3442 best val_acc 23.681006\n",
      "epoch: 68, bulyan: at fang n_at 10 n_mal_sel 10 e 68 | val loss 2.4048 val acc 10.6331 best val_acc 23.681006\n",
      "epoch: 69, bulyan: at fang n_at 10 n_mal_sel 10 e 69 | val loss 2.2694 val acc 14.0625 best val_acc 23.681006\n",
      "epoch: 70, bulyan: at fang n_at 10 n_mal_sel 10 e 70 | val loss 2.2306 val acc 17.7151 best val_acc 23.681006\n",
      "epoch: 71, bulyan: at fang n_at 10 n_mal_sel 10 e 71 | val loss 2.1824 val acc 19.1558 best val_acc 23.681006\n",
      "epoch: 72, bulyan: at fang n_at 10 n_mal_sel 10 e 72 | val loss 2.1412 val acc 21.4692 best val_acc 23.681006\n",
      "epoch: 73, bulyan: at fang n_at 10 n_mal_sel 10 e 73 | val loss 2.1164 val acc 20.8198 best val_acc 23.681006\n",
      "epoch: 74, bulyan: at fang n_at 10 n_mal_sel 10 e 74 | val loss 2.1016 val acc 23.4375 best val_acc 23.681006\n",
      "epoch: 75, bulyan: at fang n_at 10 n_mal_sel 10 e 75 | val loss 2.1072 val acc 20.7995 best val_acc 23.681006\n",
      "epoch: 76, bulyan: at fang n_at 10 n_mal_sel 10 e 76 | val loss 2.1953 val acc 17.3093 best val_acc 23.681006\n",
      "epoch: 77, bulyan: at fang n_at 10 n_mal_sel 10 e 77 | val loss 2.1991 val acc 19.2573 best val_acc 23.681006\n",
      "epoch: 78, bulyan: at fang n_at 10 n_mal_sel 10 e 78 | val loss 2.1751 val acc 15.7062 best val_acc 23.681006\n",
      "epoch: 79, bulyan: at fang n_at 10 n_mal_sel 10 e 79 | val loss 2.1162 val acc 18.3644 best val_acc 23.681006\n",
      "epoch: 80, bulyan: at fang n_at 10 n_mal_sel 10 e 80 | val loss 2.0773 val acc 19.1558 best val_acc 23.681006\n",
      "epoch: 81, bulyan: at fang n_at 10 n_mal_sel 10 e 81 | val loss 2.0454 val acc 20.4545 best val_acc 23.681006\n",
      "epoch: 82, bulyan: at fang n_at 10 n_mal_sel 10 e 82 | val loss 2.0215 val acc 24.3101 best val_acc 24.310065\n",
      "epoch: 83, bulyan: at fang n_at 10 n_mal_sel 10 e 83 | val loss 2.0058 val acc 23.1534 best val_acc 24.310065\n",
      "epoch: 84, bulyan: at fang n_at 10 n_mal_sel 9 e 84 | val loss 1.9994 val acc 23.3766 best val_acc 24.310065\n",
      "epoch: 85, bulyan: at fang n_at 10 n_mal_sel 10 e 85 | val loss 2.0141 val acc 21.8953 best val_acc 24.310065\n",
      "epoch: 86, bulyan: at fang n_at 10 n_mal_sel 10 e 86 | val loss 2.2384 val acc 18.1209 best val_acc 24.310065\n",
      "epoch: 87, bulyan: at fang n_at 10 n_mal_sel 9 e 87 | val loss 2.1764 val acc 17.6745 best val_acc 24.310065\n",
      "epoch: 88, bulyan: at fang n_at 10 n_mal_sel 10 e 88 | val loss 2.1150 val acc 19.5617 best val_acc 24.310065\n",
      "epoch: 89, bulyan: at fang n_at 10 n_mal_sel 10 e 89 | val loss 2.0941 val acc 18.7906 best val_acc 24.310065\n",
      "epoch: 90, bulyan: at fang n_at 10 n_mal_sel 10 e 90 | val loss 2.0806 val acc 20.7792 best val_acc 24.310065\n",
      "epoch: 91, bulyan: at fang n_at 10 n_mal_sel 10 e 91 | val loss 2.0774 val acc 19.0138 best val_acc 24.310065\n",
      "epoch: 92, bulyan: at fang n_at 10 n_mal_sel 10 e 92 | val loss 2.1080 val acc 17.6745 best val_acc 24.310065\n",
      "epoch: 93, bulyan: at fang n_at 10 n_mal_sel 10 e 93 | val loss 2.0885 val acc 20.9821 best val_acc 24.310065\n",
      "epoch: 94, bulyan: at fang n_at 10 n_mal_sel 10 e 94 | val loss 2.1204 val acc 18.1818 best val_acc 24.310065\n",
      "epoch: 95, bulyan: at fang n_at 10 n_mal_sel 10 e 95 | val loss 2.0791 val acc 21.9765 best val_acc 24.310065\n",
      "epoch: 96, bulyan: at fang n_at 10 n_mal_sel 10 e 96 | val loss 2.0541 val acc 22.3620 best val_acc 24.310065\n",
      "epoch: 97, bulyan: at fang n_at 10 n_mal_sel 10 e 97 | val loss 2.0280 val acc 23.3360 best val_acc 24.310065\n",
      "epoch: 98, bulyan: at fang n_at 10 n_mal_sel 10 e 98 | val loss 2.0208 val acc 21.7532 best val_acc 24.310065\n",
      "epoch: 99, bulyan: at fang n_at 10 n_mal_sel 10 e 99 | val loss 2.0184 val acc 23.5593 best val_acc 24.310065\n",
      "epoch: 100, bulyan: at fang n_at 10 n_mal_sel 10 e 100 | val loss 2.0729 val acc 22.0170 best val_acc 24.310065\n",
      "epoch: 101, bulyan: at fang n_at 10 n_mal_sel 10 e 101 | val loss 2.0265 val acc 25.2232 best val_acc 25.223214\n",
      "epoch: 102, bulyan: at fang n_at 10 n_mal_sel 10 e 102 | val loss 2.0703 val acc 20.9213 best val_acc 25.223214\n",
      "epoch: 103, bulyan: at fang n_at 10 n_mal_sel 10 e 103 | val loss 2.0522 val acc 21.8547 best val_acc 25.223214\n",
      "epoch: 104, bulyan: at fang n_at 10 n_mal_sel 10 e 104 | val loss 2.1892 val acc 19.7443 best val_acc 25.223214\n",
      "epoch: 105, bulyan: at fang n_at 10 n_mal_sel 10 e 105 | val loss 2.2120 val acc 12.1144 best val_acc 25.223214\n",
      "epoch: 106, bulyan: at fang n_at 10 n_mal_sel 10 e 106 | val loss 2.1154 val acc 21.7938 best val_acc 25.223214\n",
      "epoch: 107, bulyan: at fang n_at 10 n_mal_sel 10 e 107 | val loss 2.0128 val acc 23.1737 best val_acc 25.223214\n",
      "epoch: 108, bulyan: at fang n_at 10 n_mal_sel 10 e 108 | val loss 1.9791 val acc 26.0755 best val_acc 26.075487\n",
      "epoch: 109, bulyan: at fang n_at 10 n_mal_sel 10 e 109 | val loss 1.9858 val acc 25.5682 best val_acc 26.075487\n",
      "epoch: 110, bulyan: at fang n_at 10 n_mal_sel 9 e 110 | val loss 2.0613 val acc 24.6144 best val_acc 26.075487\n",
      "epoch: 111, bulyan: at fang n_at 10 n_mal_sel 10 e 111 | val loss 2.0200 val acc 22.6055 best val_acc 26.075487\n",
      "epoch: 112, bulyan: at fang n_at 10 n_mal_sel 9 e 112 | val loss 1.9733 val acc 25.2435 best val_acc 26.075487\n",
      "epoch: 113, bulyan: at fang n_at 10 n_mal_sel 10 e 113 | val loss 2.0157 val acc 22.4229 best val_acc 26.075487\n",
      "epoch: 114, bulyan: at fang n_at 10 n_mal_sel 10 e 114 | val loss 2.1537 val acc 22.8287 best val_acc 26.075487\n",
      "epoch: 115, bulyan: at fang n_at 10 n_mal_sel 10 e 115 | val loss 2.2201 val acc 15.7062 best val_acc 26.075487\n",
      "epoch: 116, bulyan: at fang n_at 10 n_mal_sel 9 e 116 | val loss 2.1401 val acc 26.0958 best val_acc 26.095779\n",
      "epoch: 117, bulyan: at fang n_at 10 n_mal_sel 10 e 117 | val loss 2.0528 val acc 25.0609 best val_acc 26.095779\n",
      "epoch: 118, bulyan: at fang n_at 10 n_mal_sel 10 e 118 | val loss 2.0021 val acc 25.4058 best val_acc 26.095779\n",
      "epoch: 119, bulyan: at fang n_at 10 n_mal_sel 10 e 119 | val loss 1.9792 val acc 25.8523 best val_acc 26.095779\n",
      "epoch: 120, bulyan: at fang n_at 10 n_mal_sel 10 e 120 | val loss 2.1022 val acc 20.5966 best val_acc 26.095779\n",
      "epoch: 121, bulyan: at fang n_at 10 n_mal_sel 10 e 121 | val loss 2.5223 val acc 14.5901 best val_acc 26.095779\n",
      "epoch: 122, bulyan: at fang n_at 10 n_mal_sel 10 e 122 | val loss 2.2758 val acc 16.9034 best val_acc 26.095779\n",
      "epoch: 123, bulyan: at fang n_at 10 n_mal_sel 10 e 123 | val loss 2.2370 val acc 18.3442 best val_acc 26.095779\n",
      "epoch: 124, bulyan: at fang n_at 10 n_mal_sel 10 e 124 | val loss 2.1939 val acc 19.3588 best val_acc 26.095779\n",
      "epoch: 125, bulyan: at fang n_at 10 n_mal_sel 10 e 125 | val loss 2.1479 val acc 20.2516 best val_acc 26.095779\n",
      "epoch: 126, bulyan: at fang n_at 10 n_mal_sel 10 e 126 | val loss 2.1129 val acc 22.2808 best val_acc 26.095779\n",
      "epoch: 127, bulyan: at fang n_at 10 n_mal_sel 10 e 127 | val loss 2.0873 val acc 23.2346 best val_acc 26.095779\n",
      "epoch: 128, bulyan: at fang n_at 10 n_mal_sel 10 e 128 | val loss 2.0729 val acc 25.3247 best val_acc 26.095779\n",
      "epoch: 129, bulyan: at fang n_at 10 n_mal_sel 10 e 129 | val loss 2.0908 val acc 22.0373 best val_acc 26.095779\n",
      "epoch: 130, bulyan: at fang n_at 10 n_mal_sel 10 e 130 | val loss 2.1876 val acc 17.2078 best val_acc 26.095779\n",
      "epoch: 131, bulyan: at fang n_at 10 n_mal_sel 10 e 131 | val loss 2.1176 val acc 22.6461 best val_acc 26.095779\n",
      "epoch: 132, bulyan: at fang n_at 10 n_mal_sel 10 e 132 | val loss 2.0827 val acc 22.7273 best val_acc 26.095779\n",
      "epoch: 133, bulyan: at fang n_at 10 n_mal_sel 10 e 133 | val loss 2.0701 val acc 22.7273 best val_acc 26.095779\n",
      "epoch: 134, bulyan: at fang n_at 10 n_mal_sel 10 e 134 | val loss 2.1224 val acc 23.6607 best val_acc 26.095779\n",
      "epoch: 135, bulyan: at fang n_at 10 n_mal_sel 10 e 135 | val loss 2.2856 val acc 16.6396 best val_acc 26.095779\n",
      "epoch: 136, bulyan: at fang n_at 10 n_mal_sel 10 e 136 | val loss 2.1381 val acc 23.5795 best val_acc 26.095779\n",
      "epoch: 137, bulyan: at fang n_at 10 n_mal_sel 10 e 137 | val loss 2.0328 val acc 26.2784 best val_acc 26.278409\n",
      "epoch: 138, bulyan: at fang n_at 10 n_mal_sel 10 e 138 | val loss 1.9758 val acc 28.1047 best val_acc 28.104708\n",
      "epoch: 139, bulyan: at fang n_at 10 n_mal_sel 10 e 139 | val loss 1.9457 val acc 27.3336 best val_acc 28.104708\n",
      "epoch: 140, bulyan: at fang n_at 10 n_mal_sel 10 e 140 | val loss 1.9209 val acc 28.3685 best val_acc 28.368506\n",
      "epoch: 141, bulyan: at fang n_at 10 n_mal_sel 10 e 141 | val loss 1.9212 val acc 28.3076 best val_acc 28.368506\n",
      "epoch: 142, bulyan: at fang n_at 10 n_mal_sel 10 e 142 | val loss 2.0096 val acc 24.6347 best val_acc 28.368506\n",
      "epoch: 143, bulyan: at fang n_at 10 n_mal_sel 10 e 143 | val loss 1.9883 val acc 24.2492 best val_acc 28.368506\n",
      "epoch: 144, bulyan: at fang n_at 10 n_mal_sel 10 e 144 | val loss 1.9388 val acc 25.9943 best val_acc 28.368506\n",
      "epoch: 145, bulyan: at fang n_at 10 n_mal_sel 10 e 145 | val loss 2.1281 val acc 20.6575 best val_acc 28.368506\n",
      "epoch: 146, bulyan: at fang n_at 10 n_mal_sel 10 e 146 | val loss 2.0594 val acc 19.7443 best val_acc 28.368506\n",
      "epoch: 147, bulyan: at fang n_at 10 n_mal_sel 10 e 147 | val loss 2.0086 val acc 24.8580 best val_acc 28.368506\n",
      "epoch: 148, bulyan: at fang n_at 10 n_mal_sel 10 e 148 | val loss 2.1992 val acc 21.0633 best val_acc 28.368506\n",
      "epoch: 149, bulyan: at fang n_at 10 n_mal_sel 10 e 149 | val loss 2.0124 val acc 23.5998 best val_acc 28.368506\n",
      "epoch: 150, bulyan: at fang n_at 10 n_mal_sel 9 e 150 | val loss 1.9645 val acc 24.2898 best val_acc 28.368506\n",
      "epoch: 151, bulyan: at fang n_at 10 n_mal_sel 10 e 151 | val loss 1.9389 val acc 28.2873 best val_acc 28.368506\n",
      "epoch: 152, bulyan: at fang n_at 10 n_mal_sel 10 e 152 | val loss 1.9065 val acc 27.2321 best val_acc 28.368506\n",
      "epoch: 153, bulyan: at fang n_at 10 n_mal_sel 10 e 153 | val loss 1.8721 val acc 30.2963 best val_acc 30.296266\n",
      "epoch: 154, bulyan: at fang n_at 10 n_mal_sel 10 e 154 | val loss 1.8446 val acc 29.9919 best val_acc 30.296266\n",
      "epoch: 155, bulyan: at fang n_at 10 n_mal_sel 10 e 155 | val loss 2.0140 val acc 22.6461 best val_acc 30.296266\n",
      "epoch: 156, bulyan: at fang n_at 10 n_mal_sel 10 e 156 | val loss 2.0822 val acc 25.8523 best val_acc 30.296266\n",
      "epoch: 157, bulyan: at fang n_at 10 n_mal_sel 10 e 157 | val loss 2.3154 val acc 16.8628 best val_acc 30.296266\n",
      "epoch: 158, bulyan: at fang n_at 10 n_mal_sel 10 e 158 | val loss 2.4352 val acc 17.0252 best val_acc 30.296266\n",
      "epoch: 159, bulyan: at fang n_at 10 n_mal_sel 9 e 159 | val loss 2.2830 val acc 11.0593 best val_acc 30.296266\n",
      "epoch: 160, bulyan: at fang n_at 10 n_mal_sel 9 e 160 | val loss 2.2159 val acc 15.9903 best val_acc 30.296266\n",
      "epoch: 161, bulyan: at fang n_at 10 n_mal_sel 10 e 161 | val loss 2.1251 val acc 21.9765 best val_acc 30.296266\n",
      "epoch: 162, bulyan: at fang n_at 10 n_mal_sel 10 e 162 | val loss 2.0550 val acc 23.3563 best val_acc 30.296266\n",
      "epoch: 163, bulyan: at fang n_at 10 n_mal_sel 10 e 163 | val loss 2.0049 val acc 23.2143 best val_acc 30.296266\n",
      "epoch: 164, bulyan: at fang n_at 10 n_mal_sel 10 e 164 | val loss 1.9672 val acc 25.3044 best val_acc 30.296266\n",
      "epoch: 165, bulyan: at fang n_at 10 n_mal_sel 10 e 165 | val loss 2.0212 val acc 24.3506 best val_acc 30.296266\n",
      "epoch: 166, bulyan: at fang n_at 10 n_mal_sel 10 e 166 | val loss 1.9882 val acc 25.1218 best val_acc 30.296266\n",
      "epoch: 167, bulyan: at fang n_at 10 n_mal_sel 10 e 167 | val loss 2.0874 val acc 23.9042 best val_acc 30.296266\n",
      "epoch: 168, bulyan: at fang n_at 10 n_mal_sel 10 e 168 | val loss 1.9511 val acc 28.3888 best val_acc 30.296266\n",
      "epoch: 169, bulyan: at fang n_at 10 n_mal_sel 10 e 169 | val loss 1.8640 val acc 29.5252 best val_acc 30.296266\n",
      "epoch: 170, bulyan: at fang n_at 10 n_mal_sel 10 e 170 | val loss 1.8424 val acc 30.2151 best val_acc 30.296266\n",
      "epoch: 171, bulyan: at fang n_at 10 n_mal_sel 10 e 171 | val loss 1.8466 val acc 28.9773 best val_acc 30.296266\n",
      "epoch: 172, bulyan: at fang n_at 10 n_mal_sel 10 e 172 | val loss 2.0985 val acc 23.0925 best val_acc 30.296266\n",
      "epoch: 173, bulyan: at fang n_at 10 n_mal_sel 10 e 173 | val loss 2.3006 val acc 17.8977 best val_acc 30.296266\n",
      "epoch: 174, bulyan: at fang n_at 10 n_mal_sel 10 e 174 | val loss 2.2307 val acc 12.7841 best val_acc 30.296266\n",
      "epoch: 175, bulyan: at fang n_at 10 n_mal_sel 10 e 175 | val loss 2.1632 val acc 20.2313 best val_acc 30.296266\n",
      "epoch: 176, bulyan: at fang n_at 10 n_mal_sel 10 e 176 | val loss 2.0666 val acc 20.3125 best val_acc 30.296266\n",
      "epoch: 177, bulyan: at fang n_at 10 n_mal_sel 10 e 177 | val loss 2.0265 val acc 20.5763 best val_acc 30.296266\n",
      "epoch: 178, bulyan: at fang n_at 10 n_mal_sel 10 e 178 | val loss 1.9994 val acc 24.3912 best val_acc 30.296266\n",
      "epoch: 179, bulyan: at fang n_at 10 n_mal_sel 10 e 179 | val loss 1.9696 val acc 23.4984 best val_acc 30.296266\n",
      "epoch: 180, bulyan: at fang n_at 10 n_mal_sel 10 e 180 | val loss 1.9567 val acc 24.3506 best val_acc 30.296266\n",
      "epoch: 181, bulyan: at fang n_at 10 n_mal_sel 9 e 181 | val loss 1.9492 val acc 24.1883 best val_acc 30.296266\n",
      "epoch: 182, bulyan: at fang n_at 10 n_mal_sel 9 e 182 | val loss 1.9988 val acc 20.2719 best val_acc 30.296266\n",
      "epoch: 183, bulyan: at fang n_at 10 n_mal_sel 10 e 183 | val loss 1.9260 val acc 26.8669 best val_acc 30.296266\n",
      "epoch: 184, bulyan: at fang n_at 10 n_mal_sel 10 e 184 | val loss 1.9043 val acc 27.8206 best val_acc 30.296266\n",
      "epoch: 185, bulyan: at fang n_at 10 n_mal_sel 10 e 185 | val loss 1.9328 val acc 26.7045 best val_acc 30.296266\n",
      "epoch: 186, bulyan: at fang n_at 10 n_mal_sel 10 e 186 | val loss 2.0538 val acc 23.5795 best val_acc 30.296266\n",
      "epoch: 187, bulyan: at fang n_at 10 n_mal_sel 10 e 187 | val loss 2.0071 val acc 25.5682 best val_acc 30.296266\n",
      "epoch: 188, bulyan: at fang n_at 10 n_mal_sel 10 e 188 | val loss 1.9400 val acc 26.4813 best val_acc 30.296266\n",
      "epoch: 189, bulyan: at fang n_at 10 n_mal_sel 10 e 189 | val loss 1.9028 val acc 26.7857 best val_acc 30.296266\n",
      "epoch: 190, bulyan: at fang n_at 10 n_mal_sel 9 e 190 | val loss 1.8599 val acc 29.4237 best val_acc 30.296266\n",
      "epoch: 191, bulyan: at fang n_at 10 n_mal_sel 10 e 191 | val loss 1.9101 val acc 27.6177 best val_acc 30.296266\n",
      "epoch: 192, bulyan: at fang n_at 10 n_mal_sel 10 e 192 | val loss 1.8382 val acc 30.4992 best val_acc 30.499188\n",
      "epoch: 193, bulyan: at fang n_at 10 n_mal_sel 10 e 193 | val loss 1.8165 val acc 31.6761 best val_acc 31.676136\n",
      "epoch: 194, bulyan: at fang n_at 10 n_mal_sel 10 e 194 | val loss 1.8997 val acc 29.9919 best val_acc 31.676136\n",
      "epoch: 195, bulyan: at fang n_at 10 n_mal_sel 10 e 195 | val loss 2.1523 val acc 21.9359 best val_acc 31.676136\n",
      "epoch: 196, bulyan: at fang n_at 10 n_mal_sel 10 e 196 | val loss 2.0854 val acc 21.2865 best val_acc 31.676136\n",
      "epoch: 197, bulyan: at fang n_at 10 n_mal_sel 10 e 197 | val loss 1.9517 val acc 27.7597 best val_acc 31.676136\n",
      "epoch: 198, bulyan: at fang n_at 10 n_mal_sel 10 e 198 | val loss 1.8721 val acc 31.0268 best val_acc 31.676136\n",
      "epoch: 199, bulyan: at fang n_at 10 n_mal_sel 10 e 199 | val loss 1.8459 val acc 30.5804 best val_acc 31.676136\n",
      "epoch: 200, bulyan: at fang n_at 10 n_mal_sel 10 e 200 | val loss 2.0044 val acc 26.7654 best val_acc 31.676136\n",
      "epoch: 201, bulyan: at fang n_at 10 n_mal_sel 10 e 201 | val loss 1.9214 val acc 27.0698 best val_acc 31.676136\n",
      "epoch: 202, bulyan: at fang n_at 10 n_mal_sel 10 e 202 | val loss 1.8590 val acc 27.9221 best val_acc 31.676136\n",
      "epoch: 203, bulyan: at fang n_at 10 n_mal_sel 10 e 203 | val loss 1.8485 val acc 31.9196 best val_acc 31.919643\n",
      "epoch: 204, bulyan: at fang n_at 10 n_mal_sel 10 e 204 | val loss 1.8436 val acc 31.6356 best val_acc 31.919643\n",
      "epoch: 205, bulyan: at fang n_at 10 n_mal_sel 10 e 205 | val loss 1.9030 val acc 29.2005 best val_acc 31.919643\n",
      "epoch: 206, bulyan: at fang n_at 10 n_mal_sel 10 e 206 | val loss 1.8679 val acc 32.6299 best val_acc 32.629870\n",
      "epoch: 207, bulyan: at fang n_at 10 n_mal_sel 10 e 207 | val loss 1.8641 val acc 31.8588 best val_acc 32.629870\n",
      "epoch: 208, bulyan: at fang n_at 10 n_mal_sel 10 e 208 | val loss 1.9484 val acc 29.1396 best val_acc 32.629870\n",
      "epoch: 209, bulyan: at fang n_at 10 n_mal_sel 10 e 209 | val loss 2.1339 val acc 26.1567 best val_acc 32.629870\n",
      "epoch: 210, bulyan: at fang n_at 10 n_mal_sel 10 e 210 | val loss 2.0538 val acc 25.6494 best val_acc 32.629870\n",
      "epoch: 211, bulyan: at fang n_at 10 n_mal_sel 10 e 211 | val loss 1.8718 val acc 30.6006 best val_acc 32.629870\n",
      "epoch: 212, bulyan: at fang n_at 10 n_mal_sel 10 e 212 | val loss 1.8116 val acc 31.6761 best val_acc 32.629870\n",
      "epoch: 213, bulyan: at fang n_at 10 n_mal_sel 10 e 213 | val loss 1.7712 val acc 33.9286 best val_acc 33.928571\n",
      "epoch: 214, bulyan: at fang n_at 10 n_mal_sel 10 e 214 | val loss 1.7660 val acc 34.0909 best val_acc 34.090909\n",
      "epoch: 215, bulyan: at fang n_at 10 n_mal_sel 10 e 215 | val loss 1.8881 val acc 29.1599 best val_acc 34.090909\n",
      "epoch: 216, bulyan: at fang n_at 10 n_mal_sel 10 e 216 | val loss 2.0293 val acc 24.4521 best val_acc 34.090909\n",
      "epoch: 217, bulyan: at fang n_at 10 n_mal_sel 10 e 217 | val loss 2.0126 val acc 25.9334 best val_acc 34.090909\n",
      "epoch: 218, bulyan: at fang n_at 10 n_mal_sel 10 e 218 | val loss 1.8884 val acc 28.6729 best val_acc 34.090909\n",
      "epoch: 219, bulyan: at fang n_at 10 n_mal_sel 10 e 219 | val loss 1.8741 val acc 34.4359 best val_acc 34.435877\n",
      "epoch: 220, bulyan: at fang n_at 10 n_mal_sel 10 e 220 | val loss 1.8516 val acc 33.1575 best val_acc 34.435877\n",
      "epoch: 221, bulyan: at fang n_at 10 n_mal_sel 10 e 221 | val loss 1.8748 val acc 30.2151 best val_acc 34.435877\n",
      "epoch: 222, bulyan: at fang n_at 10 n_mal_sel 10 e 222 | val loss 1.7839 val acc 35.7549 best val_acc 35.754870\n",
      "epoch: 223, bulyan: at fang n_at 10 n_mal_sel 10 e 223 | val loss 1.7254 val acc 36.0390 best val_acc 36.038961\n",
      "epoch: 224, bulyan: at fang n_at 10 n_mal_sel 10 e 224 | val loss 1.7616 val acc 34.9229 best val_acc 36.038961\n",
      "epoch: 225, bulyan: at fang n_at 10 n_mal_sel 10 e 225 | val loss 1.8895 val acc 30.0731 best val_acc 36.038961\n",
      "epoch: 226, bulyan: at fang n_at 10 n_mal_sel 10 e 226 | val loss 1.9468 val acc 26.2581 best val_acc 36.038961\n",
      "epoch: 227, bulyan: at fang n_at 10 n_mal_sel 10 e 227 | val loss 1.9285 val acc 26.3393 best val_acc 36.038961\n",
      "epoch: 228, bulyan: at fang n_at 10 n_mal_sel 10 e 228 | val loss 1.8493 val acc 29.6469 best val_acc 36.038961\n",
      "epoch: 229, bulyan: at fang n_at 10 n_mal_sel 10 e 229 | val loss 1.7658 val acc 36.3839 best val_acc 36.383929\n",
      "epoch: 230, bulyan: at fang n_at 10 n_mal_sel 10 e 230 | val loss 1.7275 val acc 36.3839 best val_acc 36.383929\n",
      "epoch: 231, bulyan: at fang n_at 10 n_mal_sel 10 e 231 | val loss 1.7655 val acc 34.5576 best val_acc 36.383929\n",
      "epoch: 232, bulyan: at fang n_at 10 n_mal_sel 10 e 232 | val loss 1.8116 val acc 34.4562 best val_acc 36.383929\n",
      "epoch: 233, bulyan: at fang n_at 10 n_mal_sel 10 e 233 | val loss 1.9438 val acc 29.4440 best val_acc 36.383929\n",
      "epoch: 234, bulyan: at fang n_at 10 n_mal_sel 10 e 234 | val loss 1.7914 val acc 36.1607 best val_acc 36.383929\n",
      "epoch: 235, bulyan: at fang n_at 10 n_mal_sel 10 e 235 | val loss 1.7002 val acc 37.6015 best val_acc 37.601461\n",
      "epoch: 236, bulyan: at fang n_at 10 n_mal_sel 10 e 236 | val loss 1.7384 val acc 35.9781 best val_acc 37.601461\n",
      "epoch: 237, bulyan: at fang n_at 10 n_mal_sel 10 e 237 | val loss 1.8171 val acc 34.4562 best val_acc 37.601461\n",
      "epoch: 238, bulyan: at fang n_at 10 n_mal_sel 10 e 238 | val loss 1.8664 val acc 29.4237 best val_acc 37.601461\n",
      "epoch: 239, bulyan: at fang n_at 10 n_mal_sel 10 e 239 | val loss 1.7403 val acc 37.6826 best val_acc 37.682630\n",
      "epoch: 240, bulyan: at fang n_at 10 n_mal_sel 10 e 240 | val loss 1.6546 val acc 39.5089 best val_acc 39.508929\n",
      "epoch: 241, bulyan: at fang n_at 10 n_mal_sel 9 e 241 | val loss 1.6525 val acc 38.9610 best val_acc 39.508929\n",
      "epoch: 242, bulyan: at fang n_at 10 n_mal_sel 10 e 242 | val loss 1.7335 val acc 36.4651 best val_acc 39.508929\n",
      "epoch: 243, bulyan: at fang n_at 10 n_mal_sel 10 e 243 | val loss 1.8392 val acc 30.2963 best val_acc 39.508929\n",
      "epoch: 244, bulyan: at fang n_at 10 n_mal_sel 10 e 244 | val loss 1.8424 val acc 32.8734 best val_acc 39.508929\n",
      "epoch: 245, bulyan: at fang n_at 10 n_mal_sel 10 e 245 | val loss 1.7590 val acc 33.4010 best val_acc 39.508929\n",
      "epoch: 246, bulyan: at fang n_at 10 n_mal_sel 10 e 246 | val loss 1.7282 val acc 36.7086 best val_acc 39.508929\n",
      "epoch: 247, bulyan: at fang n_at 10 n_mal_sel 10 e 247 | val loss 1.6632 val acc 37.8653 best val_acc 39.508929\n",
      "epoch: 248, bulyan: at fang n_at 10 n_mal_sel 10 e 248 | val loss 1.7169 val acc 36.6071 best val_acc 39.508929\n",
      "epoch: 249, bulyan: at fang n_at 10 n_mal_sel 10 e 249 | val loss 1.8136 val acc 32.2646 best val_acc 39.508929\n",
      "epoch: 250, bulyan: at fang n_at 10 n_mal_sel 10 e 250 | val loss 1.7922 val acc 33.1778 best val_acc 39.508929\n",
      "epoch: 251, bulyan: at fang n_at 10 n_mal_sel 10 e 251 | val loss 1.7325 val acc 35.9375 best val_acc 39.508929\n",
      "epoch: 252, bulyan: at fang n_at 10 n_mal_sel 10 e 252 | val loss 1.8332 val acc 30.5804 best val_acc 39.508929\n",
      "epoch: 253, bulyan: at fang n_at 10 n_mal_sel 9 e 253 | val loss 1.8362 val acc 33.7865 best val_acc 39.508929\n",
      "epoch: 254, bulyan: at fang n_at 10 n_mal_sel 10 e 254 | val loss 1.8274 val acc 31.9602 best val_acc 39.508929\n",
      "epoch: 255, bulyan: at fang n_at 10 n_mal_sel 10 e 255 | val loss 1.7501 val acc 35.3287 best val_acc 39.508929\n",
      "epoch: 256, bulyan: at fang n_at 10 n_mal_sel 10 e 256 | val loss 1.6896 val acc 37.6218 best val_acc 39.508929\n",
      "epoch: 257, bulyan: at fang n_at 10 n_mal_sel 10 e 257 | val loss 1.7534 val acc 34.5779 best val_acc 39.508929\n",
      "epoch: 258, bulyan: at fang n_at 10 n_mal_sel 10 e 258 | val loss 1.8993 val acc 29.6875 best val_acc 39.508929\n",
      "epoch: 259, bulyan: at fang n_at 10 n_mal_sel 10 e 259 | val loss 1.8497 val acc 30.0731 best val_acc 39.508929\n",
      "epoch: 260, bulyan: at fang n_at 10 n_mal_sel 10 e 260 | val loss 1.7194 val acc 37.8247 best val_acc 39.508929\n",
      "epoch: 261, bulyan: at fang n_at 10 n_mal_sel 10 e 261 | val loss 1.6420 val acc 39.5901 best val_acc 39.590097\n",
      "epoch: 262, bulyan: at fang n_at 10 n_mal_sel 10 e 262 | val loss 1.6235 val acc 39.9351 best val_acc 39.935065\n",
      "epoch: 263, bulyan: at fang n_at 10 n_mal_sel 10 e 263 | val loss 1.6534 val acc 39.9554 best val_acc 39.955357\n",
      "epoch: 264, bulyan: at fang n_at 10 n_mal_sel 10 e 264 | val loss 1.7426 val acc 35.9172 best val_acc 39.955357\n",
      "epoch: 265, bulyan: at fang n_at 10 n_mal_sel 10 e 265 | val loss 1.7344 val acc 35.5519 best val_acc 39.955357\n",
      "epoch: 266, bulyan: at fang n_at 10 n_mal_sel 10 e 266 | val loss 1.6339 val acc 40.7670 best val_acc 40.767045\n",
      "epoch: 267, bulyan: at fang n_at 10 n_mal_sel 10 e 267 | val loss 1.6229 val acc 40.9091 best val_acc 40.909091\n",
      "epoch: 268, bulyan: at fang n_at 10 n_mal_sel 10 e 268 | val loss 1.7392 val acc 36.0795 best val_acc 40.909091\n",
      "epoch: 269, bulyan: at fang n_at 10 n_mal_sel 10 e 269 | val loss 1.8375 val acc 32.5487 best val_acc 40.909091\n",
      "epoch: 270, bulyan: at fang n_at 10 n_mal_sel 10 e 270 | val loss 1.8288 val acc 32.2646 best val_acc 40.909091\n",
      "epoch: 271, bulyan: at fang n_at 10 n_mal_sel 10 e 271 | val loss 1.6890 val acc 36.4245 best val_acc 40.909091\n",
      "epoch: 272, bulyan: at fang n_at 10 n_mal_sel 10 e 272 | val loss 1.6953 val acc 38.2711 best val_acc 40.909091\n",
      "epoch: 273, bulyan: at fang n_at 10 n_mal_sel 10 e 273 | val loss 1.6549 val acc 38.5349 best val_acc 40.909091\n",
      "epoch: 274, bulyan: at fang n_at 10 n_mal_sel 10 e 274 | val loss 1.8202 val acc 33.7865 best val_acc 40.909091\n",
      "epoch: 275, bulyan: at fang n_at 10 n_mal_sel 10 e 275 | val loss 1.7381 val acc 35.4911 best val_acc 40.909091\n",
      "epoch: 276, bulyan: at fang n_at 10 n_mal_sel 10 e 276 | val loss 1.7838 val acc 36.3433 best val_acc 40.909091\n",
      "epoch: 277, bulyan: at fang n_at 10 n_mal_sel 10 e 277 | val loss 1.7850 val acc 32.5690 best val_acc 40.909091\n",
      "epoch: 278, bulyan: at fang n_at 10 n_mal_sel 10 e 278 | val loss 1.6713 val acc 39.1031 best val_acc 40.909091\n",
      "epoch: 279, bulyan: at fang n_at 10 n_mal_sel 10 e 279 | val loss 1.6698 val acc 39.8945 best val_acc 40.909091\n",
      "epoch: 280, bulyan: at fang n_at 10 n_mal_sel 10 e 280 | val loss 1.7565 val acc 38.3320 best val_acc 40.909091\n",
      "epoch: 281, bulyan: at fang n_at 10 n_mal_sel 10 e 281 | val loss 1.7150 val acc 38.9610 best val_acc 40.909091\n",
      "epoch: 282, bulyan: at fang n_at 10 n_mal_sel 10 e 282 | val loss 1.6430 val acc 40.7873 best val_acc 40.909091\n",
      "epoch: 283, bulyan: at fang n_at 10 n_mal_sel 10 e 283 | val loss 1.5856 val acc 42.6542 best val_acc 42.654221\n",
      "epoch: 284, bulyan: at fang n_at 10 n_mal_sel 10 e 284 | val loss 1.6726 val acc 40.3206 best val_acc 42.654221\n",
      "epoch: 285, bulyan: at fang n_at 10 n_mal_sel 10 e 285 | val loss 1.7826 val acc 36.7492 best val_acc 42.654221\n",
      "epoch: 286, bulyan: at fang n_at 10 n_mal_sel 10 e 286 | val loss 1.8196 val acc 33.9489 best val_acc 42.654221\n",
      "epoch: 287, bulyan: at fang n_at 10 n_mal_sel 10 e 287 | val loss 1.6879 val acc 38.2102 best val_acc 42.654221\n",
      "epoch: 288, bulyan: at fang n_at 10 n_mal_sel 10 e 288 | val loss 1.6111 val acc 41.6193 best val_acc 42.654221\n",
      "epoch: 289, bulyan: at fang n_at 10 n_mal_sel 10 e 289 | val loss 1.6770 val acc 39.0422 best val_acc 42.654221\n",
      "epoch: 290, bulyan: at fang n_at 10 n_mal_sel 10 e 290 | val loss 1.7817 val acc 33.0763 best val_acc 42.654221\n",
      "epoch: 291, bulyan: at fang n_at 10 n_mal_sel 10 e 291 | val loss 1.6473 val acc 39.8336 best val_acc 42.654221\n",
      "epoch: 292, bulyan: at fang n_at 10 n_mal_sel 10 e 292 | val loss 1.5783 val acc 40.8076 best val_acc 42.654221\n",
      "epoch: 293, bulyan: at fang n_at 10 n_mal_sel 10 e 293 | val loss 1.5883 val acc 41.5584 best val_acc 42.654221\n",
      "epoch: 294, bulyan: at fang n_at 10 n_mal_sel 10 e 294 | val loss 1.5963 val acc 42.3295 best val_acc 42.654221\n",
      "epoch: 295, bulyan: at fang n_at 10 n_mal_sel 10 e 295 | val loss 1.7326 val acc 34.6794 best val_acc 42.654221\n",
      "epoch: 296, bulyan: at fang n_at 10 n_mal_sel 10 e 296 | val loss 1.7841 val acc 35.0244 best val_acc 42.654221\n",
      "epoch: 297, bulyan: at fang n_at 10 n_mal_sel 10 e 297 | val loss 1.7926 val acc 33.2792 best val_acc 42.654221\n",
      "epoch: 298, bulyan: at fang n_at 10 n_mal_sel 10 e 298 | val loss 1.7393 val acc 35.0649 best val_acc 42.654221\n",
      "epoch: 299, bulyan: at fang n_at 10 n_mal_sel 10 e 299 | val loss 1.6533 val acc 39.4481 best val_acc 42.654221\n",
      "epoch: 300, bulyan: at fang n_at 10 n_mal_sel 10 e 300 | val loss 1.7350 val acc 37.6623 best val_acc 42.654221\n",
      "epoch: 301, bulyan: at fang n_at 10 n_mal_sel 10 e 301 | val loss 1.7118 val acc 37.1550 best val_acc 42.654221\n",
      "epoch: 302, bulyan: at fang n_at 10 n_mal_sel 10 e 302 | val loss 1.6633 val acc 39.0625 best val_acc 42.654221\n",
      "epoch: 303, bulyan: at fang n_at 10 n_mal_sel 10 e 303 | val loss 1.6140 val acc 40.3003 best val_acc 42.654221\n",
      "epoch: 304, bulyan: at fang n_at 10 n_mal_sel 10 e 304 | val loss 1.6944 val acc 39.9351 best val_acc 42.654221\n",
      "epoch: 305, bulyan: at fang n_at 10 n_mal_sel 10 e 305 | val loss 1.6986 val acc 38.6161 best val_acc 42.654221\n",
      "epoch: 306, bulyan: at fang n_at 10 n_mal_sel 10 e 306 | val loss 1.6820 val acc 39.0219 best val_acc 42.654221\n",
      "epoch: 307, bulyan: at fang n_at 10 n_mal_sel 10 e 307 | val loss 1.6027 val acc 41.5990 best val_acc 42.654221\n",
      "epoch: 308, bulyan: at fang n_at 10 n_mal_sel 10 e 308 | val loss 1.5674 val acc 43.5877 best val_acc 43.587662\n",
      "epoch: 309, bulyan: at fang n_at 10 n_mal_sel 10 e 309 | val loss 1.5868 val acc 41.5381 best val_acc 43.587662\n",
      "epoch: 310, bulyan: at fang n_at 10 n_mal_sel 10 e 310 | val loss 1.6371 val acc 40.1177 best val_acc 43.587662\n",
      "epoch: 311, bulyan: at fang n_at 10 n_mal_sel 10 e 311 | val loss 1.6993 val acc 35.3287 best val_acc 43.587662\n",
      "epoch: 312, bulyan: at fang n_at 10 n_mal_sel 10 e 312 | val loss 1.5427 val acc 43.9529 best val_acc 43.952922\n",
      "epoch: 313, bulyan: at fang n_at 10 n_mal_sel 10 e 313 | val loss 1.5676 val acc 42.8369 best val_acc 43.952922\n",
      "epoch: 314, bulyan: at fang n_at 10 n_mal_sel 10 e 314 | val loss 1.5886 val acc 42.4107 best val_acc 43.952922\n",
      "epoch: 315, bulyan: at fang n_at 10 n_mal_sel 10 e 315 | val loss 1.6680 val acc 40.7670 best val_acc 43.952922\n",
      "epoch: 316, bulyan: at fang n_at 10 n_mal_sel 10 e 316 | val loss 1.6848 val acc 38.3117 best val_acc 43.952922\n",
      "epoch: 317, bulyan: at fang n_at 10 n_mal_sel 10 e 317 | val loss 1.7735 val acc 33.9286 best val_acc 43.952922\n",
      "epoch: 318, bulyan: at fang n_at 10 n_mal_sel 10 e 318 | val loss 1.6261 val acc 38.1899 best val_acc 43.952922\n",
      "epoch: 319, bulyan: at fang n_at 10 n_mal_sel 10 e 319 | val loss 1.5491 val acc 44.5008 best val_acc 44.500812\n",
      "epoch: 320, bulyan: at fang n_at 10 n_mal_sel 10 e 320 | val loss 1.5448 val acc 43.6282 best val_acc 44.500812\n",
      "epoch: 321, bulyan: at fang n_at 10 n_mal_sel 10 e 321 | val loss 1.5704 val acc 42.2687 best val_acc 44.500812\n",
      "epoch: 322, bulyan: at fang n_at 10 n_mal_sel 10 e 322 | val loss 1.6776 val acc 40.6453 best val_acc 44.500812\n",
      "epoch: 323, bulyan: at fang n_at 10 n_mal_sel 10 e 323 | val loss 1.8400 val acc 35.6331 best val_acc 44.500812\n",
      "epoch: 324, bulyan: at fang n_at 10 n_mal_sel 10 e 324 | val loss 1.8103 val acc 35.7752 best val_acc 44.500812\n",
      "epoch: 325, bulyan: at fang n_at 10 n_mal_sel 10 e 325 | val loss 1.7756 val acc 36.7086 best val_acc 44.500812\n",
      "epoch: 326, bulyan: at fang n_at 10 n_mal_sel 10 e 326 | val loss 1.6917 val acc 37.5203 best val_acc 44.500812\n",
      "epoch: 327, bulyan: at fang n_at 10 n_mal_sel 10 e 327 | val loss 1.7162 val acc 38.4740 best val_acc 44.500812\n",
      "epoch: 328, bulyan: at fang n_at 10 n_mal_sel 10 e 328 | val loss 1.7052 val acc 35.3693 best val_acc 44.500812\n",
      "epoch: 329, bulyan: at fang n_at 10 n_mal_sel 9 e 329 | val loss 1.5998 val acc 40.1583 best val_acc 44.500812\n",
      "epoch: 330, bulyan: at fang n_at 10 n_mal_sel 10 e 330 | val loss 1.5624 val acc 42.4716 best val_acc 44.500812\n",
      "epoch: 331, bulyan: at fang n_at 10 n_mal_sel 10 e 331 | val loss 1.5744 val acc 42.2078 best val_acc 44.500812\n",
      "epoch: 332, bulyan: at fang n_at 10 n_mal_sel 10 e 332 | val loss 1.6190 val acc 42.3701 best val_acc 44.500812\n",
      "epoch: 333, bulyan: at fang n_at 10 n_mal_sel 10 e 333 | val loss 1.6016 val acc 40.7468 best val_acc 44.500812\n",
      "epoch: 334, bulyan: at fang n_at 10 n_mal_sel 10 e 334 | val loss 1.5438 val acc 44.6023 best val_acc 44.602273\n",
      "epoch: 335, bulyan: at fang n_at 10 n_mal_sel 10 e 335 | val loss 1.5224 val acc 44.8052 best val_acc 44.805195\n",
      "epoch: 336, bulyan: at fang n_at 10 n_mal_sel 10 e 336 | val loss 1.6078 val acc 43.4050 best val_acc 44.805195\n",
      "epoch: 337, bulyan: at fang n_at 10 n_mal_sel 10 e 337 | val loss 1.6324 val acc 40.8279 best val_acc 44.805195\n",
      "epoch: 338, bulyan: at fang n_at 10 n_mal_sel 10 e 338 | val loss 1.5743 val acc 43.0804 best val_acc 44.805195\n",
      "epoch: 339, bulyan: at fang n_at 10 n_mal_sel 10 e 339 | val loss 1.7181 val acc 37.4594 best val_acc 44.805195\n",
      "epoch: 340, bulyan: at fang n_at 10 n_mal_sel 10 e 340 | val loss 1.7604 val acc 37.3174 best val_acc 44.805195\n",
      "epoch: 341, bulyan: at fang n_at 10 n_mal_sel 10 e 341 | val loss 1.6873 val acc 37.9667 best val_acc 44.805195\n",
      "epoch: 342, bulyan: at fang n_at 10 n_mal_sel 10 e 342 | val loss 1.6583 val acc 38.4131 best val_acc 44.805195\n",
      "epoch: 343, bulyan: at fang n_at 10 n_mal_sel 10 e 343 | val loss 1.6346 val acc 40.6656 best val_acc 44.805195\n",
      "epoch: 344, bulyan: at fang n_at 10 n_mal_sel 10 e 344 | val loss 1.5723 val acc 43.1412 best val_acc 44.805195\n",
      "epoch: 345, bulyan: at fang n_at 10 n_mal_sel 9 e 345 | val loss 1.7874 val acc 37.7841 best val_acc 44.805195\n",
      "epoch: 346, bulyan: at fang n_at 10 n_mal_sel 10 e 346 | val loss 1.6256 val acc 41.6802 best val_acc 44.805195\n",
      "epoch: 347, bulyan: at fang n_at 10 n_mal_sel 10 e 347 | val loss 1.5546 val acc 45.0893 best val_acc 45.089286\n",
      "epoch: 348, bulyan: at fang n_at 10 n_mal_sel 10 e 348 | val loss 1.5009 val acc 45.7183 best val_acc 45.718344\n",
      "epoch: 349, bulyan: at fang n_at 10 n_mal_sel 10 e 349 | val loss 1.5088 val acc 45.9010 best val_acc 45.900974\n",
      "epoch: 350, bulyan: at fang n_at 10 n_mal_sel 10 e 350 | val loss 1.5768 val acc 43.8920 best val_acc 45.900974\n",
      "epoch: 351, bulyan: at fang n_at 10 n_mal_sel 10 e 351 | val loss 1.6462 val acc 40.4627 best val_acc 45.900974\n",
      "epoch: 352, bulyan: at fang n_at 10 n_mal_sel 10 e 352 | val loss 1.4956 val acc 45.6169 best val_acc 45.900974\n",
      "epoch: 353, bulyan: at fang n_at 10 n_mal_sel 10 e 353 | val loss 1.4850 val acc 45.9619 best val_acc 45.961851\n",
      "epoch: 354, bulyan: at fang n_at 10 n_mal_sel 10 e 354 | val loss 1.5118 val acc 45.8401 best val_acc 45.961851\n",
      "epoch: 355, bulyan: at fang n_at 10 n_mal_sel 10 e 355 | val loss 1.6364 val acc 40.4221 best val_acc 45.961851\n",
      "epoch: 356, bulyan: at fang n_at 10 n_mal_sel 10 e 356 | val loss 1.5421 val acc 43.2630 best val_acc 45.961851\n",
      "epoch: 357, bulyan: at fang n_at 10 n_mal_sel 10 e 357 | val loss 1.5334 val acc 44.6226 best val_acc 45.961851\n",
      "epoch: 358, bulyan: at fang n_at 10 n_mal_sel 10 e 358 | val loss 1.4897 val acc 45.8807 best val_acc 45.961851\n",
      "epoch: 359, bulyan: at fang n_at 10 n_mal_sel 10 e 359 | val loss 1.6242 val acc 42.8369 best val_acc 45.961851\n",
      "epoch: 360, bulyan: at fang n_at 10 n_mal_sel 10 e 360 | val loss 1.8751 val acc 33.5430 best val_acc 45.961851\n",
      "epoch: 361, bulyan: at fang n_at 10 n_mal_sel 10 e 361 | val loss 1.8660 val acc 31.8791 best val_acc 45.961851\n",
      "epoch: 362, bulyan: at fang n_at 10 n_mal_sel 10 e 362 | val loss 1.6950 val acc 39.2451 best val_acc 45.961851\n",
      "epoch: 363, bulyan: at fang n_at 10 n_mal_sel 10 e 363 | val loss 1.6351 val acc 43.0804 best val_acc 45.961851\n",
      "epoch: 364, bulyan: at fang n_at 10 n_mal_sel 10 e 364 | val loss 1.5978 val acc 42.1266 best val_acc 45.961851\n",
      "epoch: 365, bulyan: at fang n_at 10 n_mal_sel 10 e 365 | val loss 1.5986 val acc 42.1875 best val_acc 45.961851\n",
      "epoch: 366, bulyan: at fang n_at 10 n_mal_sel 10 e 366 | val loss 1.5398 val acc 45.0284 best val_acc 45.961851\n",
      "epoch: 367, bulyan: at fang n_at 10 n_mal_sel 10 e 367 | val loss 1.5488 val acc 44.4805 best val_acc 45.961851\n",
      "epoch: 368, bulyan: at fang n_at 10 n_mal_sel 10 e 368 | val loss 1.5348 val acc 44.3182 best val_acc 45.961851\n",
      "epoch: 369, bulyan: at fang n_at 10 n_mal_sel 10 e 369 | val loss 1.6502 val acc 39.8945 best val_acc 45.961851\n",
      "epoch: 370, bulyan: at fang n_at 10 n_mal_sel 10 e 370 | val loss 1.5654 val acc 43.0398 best val_acc 45.961851\n",
      "epoch: 371, bulyan: at fang n_at 10 n_mal_sel 10 e 371 | val loss 1.5422 val acc 43.0398 best val_acc 45.961851\n",
      "epoch: 372, bulyan: at fang n_at 10 n_mal_sel 10 e 372 | val loss 1.4591 val acc 46.9359 best val_acc 46.935877\n",
      "epoch: 373, bulyan: at fang n_at 10 n_mal_sel 10 e 373 | val loss 1.5010 val acc 45.0081 best val_acc 46.935877\n",
      "epoch: 374, bulyan: at fang n_at 10 n_mal_sel 10 e 374 | val loss 1.4821 val acc 45.8198 best val_acc 46.935877\n",
      "epoch: 375, bulyan: at fang n_at 10 n_mal_sel 10 e 375 | val loss 1.5638 val acc 42.1063 best val_acc 46.935877\n",
      "epoch: 376, bulyan: at fang n_at 10 n_mal_sel 10 e 376 | val loss 1.4342 val acc 47.8693 best val_acc 47.869318\n",
      "epoch: 377, bulyan: at fang n_at 10 n_mal_sel 10 e 377 | val loss 1.4467 val acc 48.0519 best val_acc 48.051948\n",
      "epoch: 378, bulyan: at fang n_at 10 n_mal_sel 10 e 378 | val loss 1.4619 val acc 47.3011 best val_acc 48.051948\n",
      "epoch: 379, bulyan: at fang n_at 10 n_mal_sel 10 e 379 | val loss 1.5570 val acc 44.0950 best val_acc 48.051948\n",
      "epoch: 380, bulyan: at fang n_at 10 n_mal_sel 10 e 380 | val loss 1.5561 val acc 43.7297 best val_acc 48.051948\n",
      "epoch: 381, bulyan: at fang n_at 10 n_mal_sel 10 e 381 | val loss 1.5270 val acc 45.5560 best val_acc 48.051948\n",
      "epoch: 382, bulyan: at fang n_at 10 n_mal_sel 10 e 382 | val loss 1.4738 val acc 46.6315 best val_acc 48.051948\n",
      "epoch: 383, bulyan: at fang n_at 10 n_mal_sel 10 e 383 | val loss 1.5075 val acc 44.5820 best val_acc 48.051948\n",
      "epoch: 384, bulyan: at fang n_at 10 n_mal_sel 10 e 384 | val loss 1.5367 val acc 45.5154 best val_acc 48.051948\n",
      "epoch: 385, bulyan: at fang n_at 10 n_mal_sel 10 e 385 | val loss 1.4723 val acc 47.3011 best val_acc 48.051948\n",
      "epoch: 386, bulyan: at fang n_at 10 n_mal_sel 10 e 386 | val loss 1.5145 val acc 46.7127 best val_acc 48.051948\n",
      "epoch: 387, bulyan: at fang n_at 10 n_mal_sel 10 e 387 | val loss 1.6974 val acc 39.2248 best val_acc 48.051948\n",
      "epoch: 388, bulyan: at fang n_at 10 n_mal_sel 10 e 388 | val loss 1.6094 val acc 42.1266 best val_acc 48.051948\n",
      "epoch: 389, bulyan: at fang n_at 10 n_mal_sel 10 e 389 | val loss 1.5909 val acc 43.5674 best val_acc 48.051948\n",
      "epoch: 390, bulyan: at fang n_at 10 n_mal_sel 10 e 390 | val loss 1.4478 val acc 47.5041 best val_acc 48.051948\n",
      "epoch: 391, bulyan: at fang n_at 10 n_mal_sel 10 e 391 | val loss 1.4616 val acc 46.5503 best val_acc 48.051948\n",
      "epoch: 392, bulyan: at fang n_at 10 n_mal_sel 10 e 392 | val loss 1.5093 val acc 44.2776 best val_acc 48.051948\n",
      "epoch: 393, bulyan: at fang n_at 10 n_mal_sel 10 e 393 | val loss 1.5895 val acc 42.0860 best val_acc 48.051948\n",
      "epoch: 394, bulyan: at fang n_at 10 n_mal_sel 10 e 394 | val loss 1.5544 val acc 41.8425 best val_acc 48.051948\n",
      "epoch: 395, bulyan: at fang n_at 10 n_mal_sel 10 e 395 | val loss 1.4530 val acc 48.5795 best val_acc 48.579545\n",
      "epoch: 396, bulyan: at fang n_at 10 n_mal_sel 10 e 396 | val loss 1.4660 val acc 47.6461 best val_acc 48.579545\n",
      "epoch: 397, bulyan: at fang n_at 10 n_mal_sel 10 e 397 | val loss 1.5590 val acc 44.6023 best val_acc 48.579545\n",
      "epoch: 398, bulyan: at fang n_at 10 n_mal_sel 10 e 398 | val loss 1.5709 val acc 43.6485 best val_acc 48.579545\n",
      "epoch: 399, bulyan: at fang n_at 10 n_mal_sel 10 e 399 | val loss 1.4576 val acc 47.1997 best val_acc 48.579545\n",
      "epoch: 400, bulyan: at fang n_at 10 n_mal_sel 10 e 400 | val loss 1.4462 val acc 48.7825 best val_acc 48.782468\n",
      "epoch: 401, bulyan: at fang n_at 10 n_mal_sel 10 e 401 | val loss 1.4383 val acc 48.7825 best val_acc 48.782468\n",
      "epoch: 402, bulyan: at fang n_at 10 n_mal_sel 10 e 402 | val loss 1.5106 val acc 46.5706 best val_acc 48.782468\n",
      "epoch: 403, bulyan: at fang n_at 10 n_mal_sel 10 e 403 | val loss 1.5568 val acc 44.7849 best val_acc 48.782468\n",
      "epoch: 404, bulyan: at fang n_at 10 n_mal_sel 10 e 404 | val loss 1.5828 val acc 44.5414 best val_acc 48.782468\n",
      "epoch: 405, bulyan: at fang n_at 10 n_mal_sel 10 e 405 | val loss 1.4984 val acc 46.4286 best val_acc 48.782468\n",
      "epoch: 406, bulyan: at fang n_at 10 n_mal_sel 10 e 406 | val loss 1.4735 val acc 45.8401 best val_acc 48.782468\n",
      "epoch: 407, bulyan: at fang n_at 10 n_mal_sel 10 e 407 | val loss 1.4297 val acc 48.4375 best val_acc 48.782468\n",
      "epoch: 408, bulyan: at fang n_at 10 n_mal_sel 10 e 408 | val loss 1.4829 val acc 45.8807 best val_acc 48.782468\n",
      "epoch: 409, bulyan: at fang n_at 10 n_mal_sel 10 e 409 | val loss 1.5249 val acc 45.2922 best val_acc 48.782468\n",
      "epoch: 410, bulyan: at fang n_at 10 n_mal_sel 10 e 410 | val loss 1.4137 val acc 49.0463 best val_acc 49.046266\n",
      "epoch: 411, bulyan: at fang n_at 10 n_mal_sel 10 e 411 | val loss 1.4091 val acc 49.9594 best val_acc 49.959416\n",
      "epoch: 412, bulyan: at fang n_at 10 n_mal_sel 10 e 412 | val loss 1.4441 val acc 46.5097 best val_acc 49.959416\n",
      "epoch: 413, bulyan: at fang n_at 10 n_mal_sel 10 e 413 | val loss 1.5065 val acc 45.4343 best val_acc 49.959416\n",
      "epoch: 414, bulyan: at fang n_at 10 n_mal_sel 10 e 414 | val loss 1.5141 val acc 44.5414 best val_acc 49.959416\n",
      "epoch: 415, bulyan: at fang n_at 10 n_mal_sel 10 e 415 | val loss 1.6108 val acc 43.3442 best val_acc 49.959416\n",
      "epoch: 416, bulyan: at fang n_at 10 n_mal_sel 10 e 416 | val loss 1.5664 val acc 43.1615 best val_acc 49.959416\n",
      "epoch: 417, bulyan: at fang n_at 10 n_mal_sel 10 e 417 | val loss 1.5924 val acc 40.8076 best val_acc 49.959416\n",
      "epoch: 418, bulyan: at fang n_at 10 n_mal_sel 10 e 418 | val loss 1.6188 val acc 41.3961 best val_acc 49.959416\n",
      "epoch: 419, bulyan: at fang n_at 10 n_mal_sel 10 e 419 | val loss 1.4914 val acc 45.1907 best val_acc 49.959416\n",
      "epoch: 420, bulyan: at fang n_at 10 n_mal_sel 10 e 420 | val loss 1.4830 val acc 47.0779 best val_acc 49.959416\n",
      "epoch: 421, bulyan: at fang n_at 10 n_mal_sel 10 e 421 | val loss 1.4619 val acc 47.6055 best val_acc 49.959416\n",
      "epoch: 422, bulyan: at fang n_at 10 n_mal_sel 10 e 422 | val loss 1.4359 val acc 48.4375 best val_acc 49.959416\n",
      "epoch: 423, bulyan: at fang n_at 10 n_mal_sel 10 e 423 | val loss 1.4990 val acc 45.8807 best val_acc 49.959416\n",
      "epoch: 424, bulyan: at fang n_at 10 n_mal_sel 10 e 424 | val loss 1.4754 val acc 47.0779 best val_acc 49.959416\n",
      "epoch: 425, bulyan: at fang n_at 10 n_mal_sel 10 e 425 | val loss 1.3930 val acc 50.4667 best val_acc 50.466721\n",
      "epoch: 426, bulyan: at fang n_at 10 n_mal_sel 10 e 426 | val loss 1.3850 val acc 51.3596 best val_acc 51.359578\n",
      "epoch: 427, bulyan: at fang n_at 10 n_mal_sel 10 e 427 | val loss 1.3761 val acc 50.4870 best val_acc 51.359578\n",
      "epoch: 428, bulyan: at fang n_at 10 n_mal_sel 10 e 428 | val loss 1.4860 val acc 48.5795 best val_acc 51.359578\n",
      "epoch: 429, bulyan: at fang n_at 10 n_mal_sel 10 e 429 | val loss 1.4262 val acc 49.8377 best val_acc 51.359578\n",
      "epoch: 430, bulyan: at fang n_at 10 n_mal_sel 10 e 430 | val loss 1.5305 val acc 47.1794 best val_acc 51.359578\n",
      "epoch: 431, bulyan: at fang n_at 10 n_mal_sel 10 e 431 | val loss 1.6223 val acc 45.0690 best val_acc 51.359578\n",
      "epoch: 432, bulyan: at fang n_at 10 n_mal_sel 10 e 432 | val loss 1.6046 val acc 41.5584 best val_acc 51.359578\n",
      "epoch: 433, bulyan: at fang n_at 10 n_mal_sel 10 e 433 | val loss 1.5290 val acc 45.5357 best val_acc 51.359578\n",
      "epoch: 434, bulyan: at fang n_at 10 n_mal_sel 10 e 434 | val loss 1.5465 val acc 43.2630 best val_acc 51.359578\n",
      "epoch: 435, bulyan: at fang n_at 10 n_mal_sel 10 e 435 | val loss 1.4616 val acc 47.3620 best val_acc 51.359578\n",
      "epoch: 436, bulyan: at fang n_at 10 n_mal_sel 10 e 436 | val loss 1.4530 val acc 46.9968 best val_acc 51.359578\n",
      "epoch: 437, bulyan: at fang n_at 10 n_mal_sel 10 e 437 | val loss 1.4541 val acc 47.7070 best val_acc 51.359578\n",
      "epoch: 438, bulyan: at fang n_at 10 n_mal_sel 10 e 438 | val loss 1.4800 val acc 47.5852 best val_acc 51.359578\n",
      "epoch: 439, bulyan: at fang n_at 10 n_mal_sel 10 e 439 | val loss 1.5418 val acc 42.0252 best val_acc 51.359578\n",
      "epoch: 440, bulyan: at fang n_at 10 n_mal_sel 10 e 440 | val loss 1.4243 val acc 48.8231 best val_acc 51.359578\n",
      "epoch: 441, bulyan: at fang n_at 10 n_mal_sel 10 e 441 | val loss 1.4130 val acc 49.8377 best val_acc 51.359578\n",
      "epoch: 442, bulyan: at fang n_at 10 n_mal_sel 10 e 442 | val loss 1.4902 val acc 47.2403 best val_acc 51.359578\n",
      "epoch: 443, bulyan: at fang n_at 10 n_mal_sel 10 e 443 | val loss 1.6008 val acc 41.9643 best val_acc 51.359578\n",
      "epoch: 444, bulyan: at fang n_at 10 n_mal_sel 10 e 444 | val loss 1.5775 val acc 41.5990 best val_acc 51.359578\n",
      "epoch: 445, bulyan: at fang n_at 10 n_mal_sel 10 e 445 | val loss 1.4251 val acc 48.5593 best val_acc 51.359578\n",
      "epoch: 446, bulyan: at fang n_at 10 n_mal_sel 10 e 446 | val loss 1.3694 val acc 50.7711 best val_acc 51.359578\n",
      "epoch: 447, bulyan: at fang n_at 10 n_mal_sel 10 e 447 | val loss 1.4010 val acc 50.8523 best val_acc 51.359578\n",
      "epoch: 448, bulyan: at fang n_at 10 n_mal_sel 10 e 448 | val loss 1.4174 val acc 48.6201 best val_acc 51.359578\n",
      "epoch: 449, bulyan: at fang n_at 10 n_mal_sel 10 e 449 | val loss 1.4007 val acc 50.5682 best val_acc 51.359578\n",
      "epoch: 450, bulyan: at fang n_at 10 n_mal_sel 10 e 450 | val loss 1.4112 val acc 48.8839 best val_acc 51.359578\n",
      "epoch: 451, bulyan: at fang n_at 10 n_mal_sel 10 e 451 | val loss 1.3877 val acc 50.1420 best val_acc 51.359578\n",
      "epoch: 452, bulyan: at fang n_at 10 n_mal_sel 10 e 452 | val loss 1.3977 val acc 48.1534 best val_acc 51.359578\n",
      "epoch: 453, bulyan: at fang n_at 10 n_mal_sel 10 e 453 | val loss 1.4992 val acc 46.1648 best val_acc 51.359578\n",
      "epoch: 454, bulyan: at fang n_at 10 n_mal_sel 10 e 454 | val loss 1.5215 val acc 42.0252 best val_acc 51.359578\n",
      "epoch: 455, bulyan: at fang n_at 10 n_mal_sel 10 e 455 | val loss 1.3922 val acc 49.4724 best val_acc 51.359578\n",
      "epoch: 456, bulyan: at fang n_at 10 n_mal_sel 10 e 456 | val loss 1.3265 val acc 52.0495 best val_acc 52.049513\n",
      "epoch: 457, bulyan: at fang n_at 10 n_mal_sel 10 e 457 | val loss 1.3344 val acc 51.7857 best val_acc 52.049513\n",
      "epoch: 458, bulyan: at fang n_at 10 n_mal_sel 10 e 458 | val loss 1.3865 val acc 50.2841 best val_acc 52.049513\n",
      "epoch: 459, bulyan: at fang n_at 10 n_mal_sel 10 e 459 | val loss 1.5754 val acc 43.1412 best val_acc 52.049513\n",
      "epoch: 460, bulyan: at fang n_at 10 n_mal_sel 10 e 460 | val loss 1.6662 val acc 42.5325 best val_acc 52.049513\n",
      "epoch: 461, bulyan: at fang n_at 10 n_mal_sel 10 e 461 | val loss 1.7792 val acc 37.6623 best val_acc 52.049513\n",
      "epoch: 462, bulyan: at fang n_at 10 n_mal_sel 10 e 462 | val loss 1.8892 val acc 31.2500 best val_acc 52.049513\n",
      "epoch: 463, bulyan: at fang n_at 10 n_mal_sel 9 e 463 | val loss 2.2227 val acc 28.0844 best val_acc 52.049513\n",
      "epoch: 464, bulyan: at fang n_at 10 n_mal_sel 10 e 464 | val loss 2.6760 val acc 17.4513 best val_acc 52.049513\n",
      "epoch: 465, bulyan: at fang n_at 10 n_mal_sel 10 e 465 | val loss 2.4831 val acc 14.7119 best val_acc 52.049513\n",
      "epoch: 466, bulyan: at fang n_at 10 n_mal_sel 10 e 466 | val loss 2.1177 val acc 21.1851 best val_acc 52.049513\n",
      "epoch: 467, bulyan: at fang n_at 10 n_mal_sel 10 e 467 | val loss 2.0569 val acc 21.7532 best val_acc 52.049513\n",
      "epoch: 468, bulyan: at fang n_at 10 n_mal_sel 10 e 468 | val loss 2.0552 val acc 26.7045 best val_acc 52.049513\n",
      "epoch: 469, bulyan: at fang n_at 10 n_mal_sel 10 e 469 | val loss 1.9611 val acc 28.7744 best val_acc 52.049513\n",
      "epoch: 470, bulyan: at fang n_at 10 n_mal_sel 10 e 470 | val loss 1.8323 val acc 33.9692 best val_acc 52.049513\n",
      "epoch: 471, bulyan: at fang n_at 10 n_mal_sel 10 e 471 | val loss 1.7431 val acc 39.6104 best val_acc 52.049513\n",
      "epoch: 472, bulyan: at fang n_at 10 n_mal_sel 10 e 472 | val loss 1.6893 val acc 39.2857 best val_acc 52.049513\n",
      "epoch: 473, bulyan: at fang n_at 10 n_mal_sel 10 e 473 | val loss 1.7337 val acc 37.6623 best val_acc 52.049513\n",
      "epoch: 474, bulyan: at fang n_at 10 n_mal_sel 10 e 474 | val loss 1.6321 val acc 41.7005 best val_acc 52.049513\n",
      "epoch: 475, bulyan: at fang n_at 10 n_mal_sel 10 e 475 | val loss 1.6974 val acc 37.9058 best val_acc 52.049513\n",
      "epoch: 476, bulyan: at fang n_at 10 n_mal_sel 10 e 476 | val loss 1.6960 val acc 39.2654 best val_acc 52.049513\n",
      "epoch: 477, bulyan: at fang n_at 10 n_mal_sel 10 e 477 | val loss 1.6714 val acc 40.8482 best val_acc 52.049513\n",
      "epoch: 478, bulyan: at fang n_at 10 n_mal_sel 10 e 478 | val loss 1.5999 val acc 41.8831 best val_acc 52.049513\n",
      "epoch: 479, bulyan: at fang n_at 10 n_mal_sel 10 e 479 | val loss 1.7123 val acc 40.0162 best val_acc 52.049513\n",
      "epoch: 480, bulyan: at fang n_at 10 n_mal_sel 10 e 480 | val loss 1.6600 val acc 40.8888 best val_acc 52.049513\n",
      "epoch: 481, bulyan: at fang n_at 10 n_mal_sel 10 e 481 | val loss 1.6163 val acc 43.7703 best val_acc 52.049513\n",
      "epoch: 482, bulyan: at fang n_at 10 n_mal_sel 10 e 482 | val loss 1.5029 val acc 46.4286 best val_acc 52.049513\n",
      "epoch: 483, bulyan: at fang n_at 10 n_mal_sel 10 e 483 | val loss 1.4768 val acc 48.1534 best val_acc 52.049513\n",
      "epoch: 484, bulyan: at fang n_at 10 n_mal_sel 10 e 484 | val loss 1.6181 val acc 42.6745 best val_acc 52.049513\n",
      "epoch: 485, bulyan: at fang n_at 10 n_mal_sel 10 e 485 | val loss 1.6603 val acc 41.3758 best val_acc 52.049513\n",
      "epoch: 486, bulyan: at fang n_at 10 n_mal_sel 10 e 486 | val loss 1.6324 val acc 39.2857 best val_acc 52.049513\n",
      "epoch: 487, bulyan: at fang n_at 10 n_mal_sel 10 e 487 | val loss 1.5663 val acc 43.0195 best val_acc 52.049513\n",
      "epoch: 488, bulyan: at fang n_at 10 n_mal_sel 10 e 488 | val loss 1.5449 val acc 41.9846 best val_acc 52.049513\n",
      "epoch: 489, bulyan: at fang n_at 10 n_mal_sel 10 e 489 | val loss 1.5606 val acc 43.8920 best val_acc 52.049513\n",
      "epoch: 490, bulyan: at fang n_at 10 n_mal_sel 10 e 490 | val loss 1.5394 val acc 43.2427 best val_acc 52.049513\n",
      "epoch: 491, bulyan: at fang n_at 10 n_mal_sel 10 e 491 | val loss 1.3968 val acc 50.3450 best val_acc 52.049513\n",
      "epoch: 492, bulyan: at fang n_at 10 n_mal_sel 10 e 492 | val loss 1.3776 val acc 50.9334 best val_acc 52.049513\n",
      "epoch: 493, bulyan: at fang n_at 10 n_mal_sel 10 e 493 | val loss 1.4440 val acc 48.2346 best val_acc 52.049513\n",
      "epoch: 494, bulyan: at fang n_at 10 n_mal_sel 10 e 494 | val loss 1.5885 val acc 41.3149 best val_acc 52.049513\n",
      "epoch: 495, bulyan: at fang n_at 10 n_mal_sel 10 e 495 | val loss 1.6102 val acc 40.5235 best val_acc 52.049513\n",
      "epoch: 496, bulyan: at fang n_at 10 n_mal_sel 10 e 496 | val loss 1.4810 val acc 46.0836 best val_acc 52.049513\n",
      "epoch: 497, bulyan: at fang n_at 10 n_mal_sel 10 e 497 | val loss 1.4966 val acc 45.8198 best val_acc 52.049513\n",
      "epoch: 498, bulyan: at fang n_at 10 n_mal_sel 10 e 498 | val loss 1.4689 val acc 46.9562 best val_acc 52.049513\n",
      "epoch: 499, bulyan: at fang n_at 10 n_mal_sel 10 e 499 | val loss 1.4964 val acc 45.2922 best val_acc 52.049513\n",
      "epoch: 500, bulyan: at fang n_at 10 n_mal_sel 10 e 500 | val loss 1.4018 val acc 50.5885 best val_acc 52.049513\n",
      "epoch: 501, bulyan: at fang n_at 10 n_mal_sel 10 e 501 | val loss 1.3557 val acc 51.2784 best val_acc 52.049513\n",
      "epoch: 502, bulyan: at fang n_at 10 n_mal_sel 10 e 502 | val loss 1.3926 val acc 50.8117 best val_acc 52.049513\n",
      "epoch: 503, bulyan: at fang n_at 10 n_mal_sel 10 e 503 | val loss 1.4367 val acc 49.1274 best val_acc 52.049513\n",
      "epoch: 504, bulyan: at fang n_at 10 n_mal_sel 10 e 504 | val loss 1.4710 val acc 49.1274 best val_acc 52.049513\n",
      "epoch: 505, bulyan: at fang n_at 10 n_mal_sel 10 e 505 | val loss 1.4648 val acc 47.5446 best val_acc 52.049513\n",
      "epoch: 506, bulyan: at fang n_at 10 n_mal_sel 10 e 506 | val loss 1.4155 val acc 50.3044 best val_acc 52.049513\n",
      "epoch: 507, bulyan: at fang n_at 10 n_mal_sel 10 e 507 | val loss 1.4291 val acc 50.0000 best val_acc 52.049513\n",
      "epoch: 508, bulyan: at fang n_at 10 n_mal_sel 10 e 508 | val loss 1.5478 val acc 46.8750 best val_acc 52.049513\n",
      "epoch: 509, bulyan: at fang n_at 10 n_mal_sel 10 e 509 | val loss 1.3945 val acc 50.0609 best val_acc 52.049513\n",
      "epoch: 510, bulyan: at fang n_at 10 n_mal_sel 10 e 510 | val loss 1.3876 val acc 50.5885 best val_acc 52.049513\n",
      "epoch: 511, bulyan: at fang n_at 10 n_mal_sel 10 e 511 | val loss 1.4094 val acc 48.7622 best val_acc 52.049513\n",
      "epoch: 512, bulyan: at fang n_at 10 n_mal_sel 10 e 512 | val loss 1.4032 val acc 49.4724 best val_acc 52.049513\n",
      "epoch: 513, bulyan: at fang n_at 10 n_mal_sel 10 e 513 | val loss 1.3755 val acc 51.1161 best val_acc 52.049513\n",
      "epoch: 514, bulyan: at fang n_at 10 n_mal_sel 10 e 514 | val loss 1.4179 val acc 49.6144 best val_acc 52.049513\n",
      "epoch: 515, bulyan: at fang n_at 10 n_mal_sel 10 e 515 | val loss 1.3610 val acc 51.0349 best val_acc 52.049513\n",
      "epoch: 516, bulyan: at fang n_at 10 n_mal_sel 10 e 516 | val loss 1.4051 val acc 48.0925 best val_acc 52.049513\n",
      "epoch: 517, bulyan: at fang n_at 10 n_mal_sel 10 e 517 | val loss 1.4481 val acc 48.4984 best val_acc 52.049513\n",
      "epoch: 518, bulyan: at fang n_at 10 n_mal_sel 10 e 518 | val loss 1.5327 val acc 43.1209 best val_acc 52.049513\n",
      "epoch: 519, bulyan: at fang n_at 10 n_mal_sel 10 e 519 | val loss 1.4594 val acc 47.8287 best val_acc 52.049513\n",
      "epoch: 520, bulyan: at fang n_at 10 n_mal_sel 10 e 520 | val loss 1.3913 val acc 50.4261 best val_acc 52.049513\n",
      "epoch: 521, bulyan: at fang n_at 10 n_mal_sel 10 e 521 | val loss 1.4190 val acc 49.5739 best val_acc 52.049513\n",
      "epoch: 522, bulyan: at fang n_at 10 n_mal_sel 10 e 522 | val loss 1.4559 val acc 46.9359 best val_acc 52.049513\n",
      "epoch: 523, bulyan: at fang n_at 10 n_mal_sel 10 e 523 | val loss 1.3686 val acc 51.1364 best val_acc 52.049513\n",
      "epoch: 524, bulyan: at fang n_at 10 n_mal_sel 10 e 524 | val loss 1.3056 val acc 53.1453 best val_acc 53.145292\n",
      "epoch: 525, bulyan: at fang n_at 10 n_mal_sel 10 e 525 | val loss 1.3577 val acc 52.1713 best val_acc 53.145292\n",
      "epoch: 526, bulyan: at fang n_at 10 n_mal_sel 10 e 526 | val loss 1.4214 val acc 48.8433 best val_acc 53.145292\n",
      "epoch: 527, bulyan: at fang n_at 10 n_mal_sel 10 e 527 | val loss 1.5057 val acc 45.7995 best val_acc 53.145292\n",
      "epoch: 528, bulyan: at fang n_at 10 n_mal_sel 10 e 528 | val loss 1.4081 val acc 48.5187 best val_acc 53.145292\n",
      "epoch: 529, bulyan: at fang n_at 10 n_mal_sel 10 e 529 | val loss 1.3956 val acc 50.0406 best val_acc 53.145292\n",
      "epoch: 530, bulyan: at fang n_at 10 n_mal_sel 10 e 530 | val loss 1.3379 val acc 51.2378 best val_acc 53.145292\n",
      "epoch: 531, bulyan: at fang n_at 10 n_mal_sel 10 e 531 | val loss 1.3841 val acc 50.9334 best val_acc 53.145292\n",
      "epoch: 532, bulyan: at fang n_at 10 n_mal_sel 10 e 532 | val loss 1.3310 val acc 52.5568 best val_acc 53.145292\n",
      "epoch: 533, bulyan: at fang n_at 10 n_mal_sel 10 e 533 | val loss 1.4377 val acc 48.9651 best val_acc 53.145292\n",
      "epoch: 534, bulyan: at fang n_at 10 n_mal_sel 10 e 534 | val loss 1.3513 val acc 52.2524 best val_acc 53.145292\n",
      "epoch: 535, bulyan: at fang n_at 10 n_mal_sel 10 e 535 | val loss 1.3165 val acc 52.3336 best val_acc 53.145292\n",
      "epoch: 536, bulyan: at fang n_at 10 n_mal_sel 10 e 536 | val loss 1.2998 val acc 53.1859 best val_acc 53.185877\n",
      "epoch: 537, bulyan: at fang n_at 10 n_mal_sel 10 e 537 | val loss 1.3932 val acc 50.5885 best val_acc 53.185877\n",
      "epoch: 538, bulyan: at fang n_at 10 n_mal_sel 10 e 538 | val loss 1.5185 val acc 45.3125 best val_acc 53.185877\n",
      "epoch: 539, bulyan: at fang n_at 10 n_mal_sel 10 e 539 | val loss 1.5104 val acc 45.0081 best val_acc 53.185877\n",
      "epoch: 540, bulyan: at fang n_at 10 n_mal_sel 10 e 540 | val loss 1.4979 val acc 45.7589 best val_acc 53.185877\n",
      "epoch: 541, bulyan: at fang n_at 10 n_mal_sel 10 e 541 | val loss 1.6012 val acc 44.4805 best val_acc 53.185877\n",
      "epoch: 542, bulyan: at fang n_at 10 n_mal_sel 10 e 542 | val loss 1.6680 val acc 43.4050 best val_acc 53.185877\n",
      "epoch: 543, bulyan: at fang n_at 10 n_mal_sel 10 e 543 | val loss 1.6035 val acc 43.3442 best val_acc 53.185877\n",
      "epoch: 544, bulyan: at fang n_at 10 n_mal_sel 10 e 544 | val loss 1.4242 val acc 49.4318 best val_acc 53.185877\n",
      "epoch: 545, bulyan: at fang n_at 10 n_mal_sel 10 e 545 | val loss 1.4075 val acc 48.9651 best val_acc 53.185877\n",
      "epoch: 546, bulyan: at fang n_at 10 n_mal_sel 10 e 546 | val loss 1.3169 val acc 52.1916 best val_acc 53.185877\n",
      "epoch: 547, bulyan: at fang n_at 10 n_mal_sel 10 e 547 | val loss 1.3424 val acc 52.1104 best val_acc 53.185877\n",
      "epoch: 548, bulyan: at fang n_at 10 n_mal_sel 10 e 548 | val loss 1.4243 val acc 47.1794 best val_acc 53.185877\n",
      "epoch: 549, bulyan: at fang n_at 10 n_mal_sel 10 e 549 | val loss 1.3748 val acc 50.4667 best val_acc 53.185877\n",
      "epoch: 550, bulyan: at fang n_at 10 n_mal_sel 10 e 550 | val loss 1.3227 val acc 52.0698 best val_acc 53.185877\n",
      "epoch: 551, bulyan: at fang n_at 10 n_mal_sel 10 e 551 | val loss 1.3068 val acc 53.1047 best val_acc 53.185877\n",
      "epoch: 552, bulyan: at fang n_at 10 n_mal_sel 10 e 552 | val loss 1.4083 val acc 49.5739 best val_acc 53.185877\n",
      "epoch: 553, bulyan: at fang n_at 10 n_mal_sel 10 e 553 | val loss 1.4829 val acc 48.4375 best val_acc 53.185877\n",
      "epoch: 554, bulyan: at fang n_at 10 n_mal_sel 10 e 554 | val loss 1.4505 val acc 47.6867 best val_acc 53.185877\n",
      "epoch: 555, bulyan: at fang n_at 10 n_mal_sel 10 e 555 | val loss 1.3198 val acc 52.8612 best val_acc 53.185877\n",
      "epoch: 556, bulyan: at fang n_at 10 n_mal_sel 10 e 556 | val loss 1.2980 val acc 53.4700 best val_acc 53.469968\n",
      "epoch: 557, bulyan: at fang n_at 10 n_mal_sel 10 e 557 | val loss 1.3291 val acc 52.9221 best val_acc 53.469968\n",
      "epoch: 558, bulyan: at fang n_at 10 n_mal_sel 10 e 558 | val loss 1.3536 val acc 51.4002 best val_acc 53.469968\n",
      "epoch: 559, bulyan: at fang n_at 10 n_mal_sel 10 e 559 | val loss 1.3963 val acc 50.2029 best val_acc 53.469968\n",
      "epoch: 560, bulyan: at fang n_at 10 n_mal_sel 10 e 560 | val loss 1.3853 val acc 51.0958 best val_acc 53.469968\n",
      "epoch: 561, bulyan: at fang n_at 10 n_mal_sel 10 e 561 | val loss 1.3306 val acc 51.9481 best val_acc 53.469968\n",
      "epoch: 562, bulyan: at fang n_at 10 n_mal_sel 10 e 562 | val loss 1.3622 val acc 50.9334 best val_acc 53.469968\n",
      "epoch: 563, bulyan: at fang n_at 10 n_mal_sel 10 e 563 | val loss 1.4342 val acc 49.3304 best val_acc 53.469968\n",
      "epoch: 564, bulyan: at fang n_at 10 n_mal_sel 10 e 564 | val loss 1.5009 val acc 45.2313 best val_acc 53.469968\n",
      "epoch: 565, bulyan: at fang n_at 10 n_mal_sel 10 e 565 | val loss 1.3034 val acc 53.2062 best val_acc 53.469968\n",
      "epoch: 566, bulyan: at fang n_at 10 n_mal_sel 10 e 566 | val loss 1.3130 val acc 52.3133 best val_acc 53.469968\n",
      "epoch: 567, bulyan: at fang n_at 10 n_mal_sel 10 e 567 | val loss 1.3486 val acc 51.5016 best val_acc 53.469968\n",
      "epoch: 568, bulyan: at fang n_at 10 n_mal_sel 10 e 568 | val loss 1.4436 val acc 48.9651 best val_acc 53.469968\n",
      "epoch: 569, bulyan: at fang n_at 10 n_mal_sel 10 e 569 | val loss 1.4183 val acc 49.2086 best val_acc 53.469968\n",
      "epoch: 570, bulyan: at fang n_at 10 n_mal_sel 10 e 570 | val loss 1.3145 val acc 52.8815 best val_acc 53.469968\n",
      "epoch: 571, bulyan: at fang n_at 10 n_mal_sel 10 e 571 | val loss 1.3351 val acc 52.6989 best val_acc 53.469968\n",
      "epoch: 572, bulyan: at fang n_at 10 n_mal_sel 10 e 572 | val loss 1.4459 val acc 49.7565 best val_acc 53.469968\n",
      "epoch: 573, bulyan: at fang n_at 10 n_mal_sel 9 e 573 | val loss 1.3840 val acc 50.2232 best val_acc 53.469968\n",
      "epoch: 574, bulyan: at fang n_at 10 n_mal_sel 10 e 574 | val loss 1.3444 val acc 51.4407 best val_acc 53.469968\n",
      "epoch: 575, bulyan: at fang n_at 10 n_mal_sel 10 e 575 | val loss 1.2877 val acc 53.3279 best val_acc 53.469968\n",
      "epoch: 576, bulyan: at fang n_at 10 n_mal_sel 10 e 576 | val loss 1.2515 val acc 55.0731 best val_acc 55.073052\n",
      "epoch: 577, bulyan: at fang n_at 10 n_mal_sel 10 e 577 | val loss 1.3093 val acc 51.6437 best val_acc 55.073052\n",
      "epoch: 578, bulyan: at fang n_at 10 n_mal_sel 10 e 578 | val loss 1.4230 val acc 50.7711 best val_acc 55.073052\n",
      "epoch: 579, bulyan: at fang n_at 10 n_mal_sel 10 e 579 | val loss 1.5281 val acc 44.8864 best val_acc 55.073052\n",
      "epoch: 580, bulyan: at fang n_at 10 n_mal_sel 10 e 580 | val loss 1.4522 val acc 48.5593 best val_acc 55.073052\n",
      "epoch: 581, bulyan: at fang n_at 10 n_mal_sel 10 e 581 | val loss 1.2936 val acc 53.9773 best val_acc 55.073052\n",
      "epoch: 582, bulyan: at fang n_at 10 n_mal_sel 10 e 582 | val loss 1.2986 val acc 53.4497 best val_acc 55.073052\n",
      "epoch: 583, bulyan: at fang n_at 10 n_mal_sel 10 e 583 | val loss 1.3498 val acc 51.8263 best val_acc 55.073052\n",
      "epoch: 584, bulyan: at fang n_at 10 n_mal_sel 10 e 584 | val loss 1.3832 val acc 50.8320 best val_acc 55.073052\n",
      "epoch: 585, bulyan: at fang n_at 10 n_mal_sel 10 e 585 | val loss 1.3498 val acc 51.4610 best val_acc 55.073052\n",
      "epoch: 586, bulyan: at fang n_at 10 n_mal_sel 10 e 586 | val loss 1.2652 val acc 54.3425 best val_acc 55.073052\n",
      "epoch: 587, bulyan: at fang n_at 10 n_mal_sel 10 e 587 | val loss 1.2501 val acc 55.2760 best val_acc 55.275974\n",
      "epoch: 588, bulyan: at fang n_at 10 n_mal_sel 10 e 588 | val loss 1.3020 val acc 54.2208 best val_acc 55.275974\n",
      "epoch: 589, bulyan: at fang n_at 10 n_mal_sel 10 e 589 | val loss 1.3641 val acc 51.6234 best val_acc 55.275974\n",
      "epoch: 590, bulyan: at fang n_at 10 n_mal_sel 10 e 590 | val loss 1.3800 val acc 50.8929 best val_acc 55.275974\n",
      "epoch: 591, bulyan: at fang n_at 10 n_mal_sel 10 e 591 | val loss 1.3532 val acc 51.7045 best val_acc 55.275974\n",
      "epoch: 592, bulyan: at fang n_at 10 n_mal_sel 10 e 592 | val loss 1.4318 val acc 47.4432 best val_acc 55.275974\n",
      "epoch: 593, bulyan: at fang n_at 10 n_mal_sel 10 e 593 | val loss 1.3351 val acc 52.7800 best val_acc 55.275974\n",
      "epoch: 594, bulyan: at fang n_at 10 n_mal_sel 10 e 594 | val loss 1.3374 val acc 51.7654 best val_acc 55.275974\n",
      "epoch: 595, bulyan: at fang n_at 10 n_mal_sel 10 e 595 | val loss 1.2512 val acc 54.9919 best val_acc 55.275974\n",
      "epoch: 596, bulyan: at fang n_at 10 n_mal_sel 10 e 596 | val loss 1.2864 val acc 52.8206 best val_acc 55.275974\n",
      "epoch: 597, bulyan: at fang n_at 10 n_mal_sel 10 e 597 | val loss 1.3958 val acc 51.4205 best val_acc 55.275974\n",
      "epoch: 598, bulyan: at fang n_at 10 n_mal_sel 10 e 598 | val loss 1.4191 val acc 48.8028 best val_acc 55.275974\n",
      "epoch: 599, bulyan: at fang n_at 10 n_mal_sel 10 e 599 | val loss 1.4281 val acc 48.9245 best val_acc 55.275974\n",
      "epoch: 600, bulyan: at fang n_at 10 n_mal_sel 10 e 600 | val loss 1.3505 val acc 53.7541 best val_acc 55.275974\n",
      "epoch: 601, bulyan: at fang n_at 10 n_mal_sel 10 e 601 | val loss 1.4205 val acc 51.6031 best val_acc 55.275974\n",
      "epoch: 602, bulyan: at fang n_at 10 n_mal_sel 10 e 602 | val loss 1.3104 val acc 53.4294 best val_acc 55.275974\n",
      "epoch: 603, bulyan: at fang n_at 10 n_mal_sel 10 e 603 | val loss 1.2850 val acc 55.3571 best val_acc 55.357143\n",
      "epoch: 604, bulyan: at fang n_at 10 n_mal_sel 10 e 604 | val loss 1.3208 val acc 53.3482 best val_acc 55.357143\n",
      "epoch: 605, bulyan: at fang n_at 10 n_mal_sel 10 e 605 | val loss 1.4252 val acc 49.7971 best val_acc 55.357143\n",
      "epoch: 606, bulyan: at fang n_at 10 n_mal_sel 10 e 606 | val loss 1.3595 val acc 50.8523 best val_acc 55.357143\n",
      "epoch: 607, bulyan: at fang n_at 10 n_mal_sel 10 e 607 | val loss 1.2852 val acc 53.7946 best val_acc 55.357143\n",
      "epoch: 608, bulyan: at fang n_at 10 n_mal_sel 10 e 608 | val loss 1.2470 val acc 55.2760 best val_acc 55.357143\n",
      "epoch: 609, bulyan: at fang n_at 10 n_mal_sel 10 e 609 | val loss 1.2601 val acc 54.8904 best val_acc 55.357143\n",
      "epoch: 610, bulyan: at fang n_at 10 n_mal_sel 10 e 610 | val loss 1.3535 val acc 52.1510 best val_acc 55.357143\n",
      "epoch: 611, bulyan: at fang n_at 10 n_mal_sel 10 e 611 | val loss 1.3595 val acc 51.7451 best val_acc 55.357143\n",
      "epoch: 612, bulyan: at fang n_at 10 n_mal_sel 10 e 612 | val loss 1.3835 val acc 50.3450 best val_acc 55.357143\n",
      "epoch: 613, bulyan: at fang n_at 10 n_mal_sel 10 e 613 | val loss 1.3225 val acc 52.7597 best val_acc 55.357143\n",
      "epoch: 614, bulyan: at fang n_at 10 n_mal_sel 10 e 614 | val loss 1.2821 val acc 53.3076 best val_acc 55.357143\n",
      "epoch: 615, bulyan: at fang n_at 10 n_mal_sel 10 e 615 | val loss 1.2130 val acc 56.4732 best val_acc 56.473214\n",
      "epoch: 616, bulyan: at fang n_at 10 n_mal_sel 10 e 616 | val loss 1.2316 val acc 55.7427 best val_acc 56.473214\n",
      "epoch: 617, bulyan: at fang n_at 10 n_mal_sel 10 e 617 | val loss 1.3124 val acc 52.9627 best val_acc 56.473214\n",
      "epoch: 618, bulyan: at fang n_at 10 n_mal_sel 10 e 618 | val loss 1.4004 val acc 48.5795 best val_acc 56.473214\n",
      "epoch: 619, bulyan: at fang n_at 10 n_mal_sel 10 e 619 | val loss 1.3447 val acc 51.4610 best val_acc 56.473214\n",
      "epoch: 620, bulyan: at fang n_at 10 n_mal_sel 10 e 620 | val loss 1.2419 val acc 55.2760 best val_acc 56.473214\n",
      "epoch: 621, bulyan: at fang n_at 10 n_mal_sel 10 e 621 | val loss 1.2202 val acc 56.2297 best val_acc 56.473214\n",
      "epoch: 622, bulyan: at fang n_at 10 n_mal_sel 10 e 622 | val loss 1.3658 val acc 52.3742 best val_acc 56.473214\n",
      "epoch: 623, bulyan: at fang n_at 10 n_mal_sel 10 e 623 | val loss 1.4109 val acc 50.8320 best val_acc 56.473214\n",
      "epoch: 624, bulyan: at fang n_at 10 n_mal_sel 10 e 624 | val loss 1.3574 val acc 52.5365 best val_acc 56.473214\n",
      "epoch: 625, bulyan: at fang n_at 10 n_mal_sel 10 e 625 | val loss 1.3238 val acc 53.1859 best val_acc 56.473214\n",
      "epoch: 626, bulyan: at fang n_at 10 n_mal_sel 10 e 626 | val loss 1.4059 val acc 51.0755 best val_acc 56.473214\n",
      "epoch: 627, bulyan: at fang n_at 10 n_mal_sel 10 e 627 | val loss 1.3171 val acc 53.2062 best val_acc 56.473214\n",
      "epoch: 628, bulyan: at fang n_at 10 n_mal_sel 10 e 628 | val loss 1.2485 val acc 55.3774 best val_acc 56.473214\n",
      "epoch: 629, bulyan: at fang n_at 10 n_mal_sel 10 e 629 | val loss 1.2653 val acc 54.6266 best val_acc 56.473214\n",
      "epoch: 630, bulyan: at fang n_at 10 n_mal_sel 10 e 630 | val loss 1.3581 val acc 51.7451 best val_acc 56.473214\n",
      "epoch: 631, bulyan: at fang n_at 10 n_mal_sel 10 e 631 | val loss 1.3311 val acc 52.0089 best val_acc 56.473214\n",
      "epoch: 632, bulyan: at fang n_at 10 n_mal_sel 10 e 632 | val loss 1.2833 val acc 53.7541 best val_acc 56.473214\n",
      "epoch: 633, bulyan: at fang n_at 10 n_mal_sel 10 e 633 | val loss 1.2304 val acc 55.7833 best val_acc 56.473214\n",
      "epoch: 634, bulyan: at fang n_at 10 n_mal_sel 10 e 634 | val loss 1.2400 val acc 55.4383 best val_acc 56.473214\n",
      "epoch: 635, bulyan: at fang n_at 10 n_mal_sel 10 e 635 | val loss 1.3802 val acc 50.5479 best val_acc 56.473214\n",
      "epoch: 636, bulyan: at fang n_at 10 n_mal_sel 10 e 636 | val loss 1.3660 val acc 49.6347 best val_acc 56.473214\n",
      "epoch: 637, bulyan: at fang n_at 10 n_mal_sel 10 e 637 | val loss 1.3220 val acc 52.4148 best val_acc 56.473214\n",
      "epoch: 638, bulyan: at fang n_at 10 n_mal_sel 10 e 638 | val loss 1.3165 val acc 53.1047 best val_acc 56.473214\n",
      "epoch: 639, bulyan: at fang n_at 10 n_mal_sel 10 e 639 | val loss 1.3969 val acc 51.0552 best val_acc 56.473214\n",
      "epoch: 640, bulyan: at fang n_at 10 n_mal_sel 10 e 640 | val loss 1.4695 val acc 48.6201 best val_acc 56.473214\n",
      "epoch: 641, bulyan: at fang n_at 10 n_mal_sel 10 e 641 | val loss 1.4104 val acc 50.5682 best val_acc 56.473214\n",
      "epoch: 642, bulyan: at fang n_at 10 n_mal_sel 10 e 642 | val loss 1.2508 val acc 56.1080 best val_acc 56.473214\n",
      "epoch: 643, bulyan: at fang n_at 10 n_mal_sel 10 e 643 | val loss 1.2133 val acc 56.4732 best val_acc 56.473214\n",
      "epoch: 644, bulyan: at fang n_at 10 n_mal_sel 10 e 644 | val loss 1.2592 val acc 55.5601 best val_acc 56.473214\n",
      "epoch: 645, bulyan: at fang n_at 10 n_mal_sel 10 e 645 | val loss 1.3217 val acc 52.8409 best val_acc 56.473214\n",
      "epoch: 646, bulyan: at fang n_at 10 n_mal_sel 10 e 646 | val loss 1.3059 val acc 53.3482 best val_acc 56.473214\n",
      "epoch: 647, bulyan: at fang n_at 10 n_mal_sel 10 e 647 | val loss 1.2454 val acc 55.2151 best val_acc 56.473214\n",
      "epoch: 648, bulyan: at fang n_at 10 n_mal_sel 10 e 648 | val loss 1.2484 val acc 55.6615 best val_acc 56.473214\n",
      "epoch: 649, bulyan: at fang n_at 10 n_mal_sel 10 e 649 | val loss 1.3123 val acc 52.5771 best val_acc 56.473214\n",
      "epoch: 650, bulyan: at fang n_at 10 n_mal_sel 10 e 650 | val loss 1.3430 val acc 51.9278 best val_acc 56.473214\n",
      "epoch: 651, bulyan: at fang n_at 10 n_mal_sel 10 e 651 | val loss 1.3705 val acc 50.9334 best val_acc 56.473214\n",
      "epoch: 652, bulyan: at fang n_at 10 n_mal_sel 10 e 652 | val loss 1.2224 val acc 56.1485 best val_acc 56.473214\n",
      "epoch: 653, bulyan: at fang n_at 10 n_mal_sel 10 e 653 | val loss 1.2013 val acc 56.1891 best val_acc 56.473214\n",
      "epoch: 654, bulyan: at fang n_at 10 n_mal_sel 10 e 654 | val loss 1.2742 val acc 53.8758 best val_acc 56.473214\n",
      "epoch: 655, bulyan: at fang n_at 10 n_mal_sel 10 e 655 | val loss 1.3196 val acc 52.2524 best val_acc 56.473214\n",
      "epoch: 656, bulyan: at fang n_at 10 n_mal_sel 10 e 656 | val loss 1.3322 val acc 52.2930 best val_acc 56.473214\n",
      "epoch: 657, bulyan: at fang n_at 10 n_mal_sel 10 e 657 | val loss 1.3295 val acc 52.9221 best val_acc 56.473214\n",
      "epoch: 658, bulyan: at fang n_at 10 n_mal_sel 10 e 658 | val loss 1.3265 val acc 54.2817 best val_acc 56.473214\n",
      "epoch: 659, bulyan: at fang n_at 10 n_mal_sel 10 e 659 | val loss 1.4052 val acc 51.8872 best val_acc 56.473214\n",
      "epoch: 660, bulyan: at fang n_at 10 n_mal_sel 10 e 660 | val loss 1.3416 val acc 52.0698 best val_acc 56.473214\n",
      "epoch: 661, bulyan: at fang n_at 10 n_mal_sel 10 e 661 | val loss 1.3438 val acc 53.0032 best val_acc 56.473214\n",
      "epoch: 662, bulyan: at fang n_at 10 n_mal_sel 10 e 662 | val loss 1.2770 val acc 54.2817 best val_acc 56.473214\n",
      "epoch: 663, bulyan: at fang n_at 10 n_mal_sel 10 e 663 | val loss 1.2118 val acc 56.7370 best val_acc 56.737013\n",
      "epoch: 664, bulyan: at fang n_at 10 n_mal_sel 10 e 664 | val loss 1.1996 val acc 57.3255 best val_acc 57.325487\n",
      "epoch: 665, bulyan: at fang n_at 10 n_mal_sel 10 e 665 | val loss 1.2392 val acc 55.5601 best val_acc 57.325487\n",
      "epoch: 666, bulyan: at fang n_at 10 n_mal_sel 10 e 666 | val loss 1.3210 val acc 53.2873 best val_acc 57.325487\n",
      "epoch: 667, bulyan: at fang n_at 10 n_mal_sel 10 e 667 | val loss 1.2642 val acc 55.1542 best val_acc 57.325487\n",
      "epoch: 668, bulyan: at fang n_at 10 n_mal_sel 10 e 668 | val loss 1.3429 val acc 53.8352 best val_acc 57.325487\n",
      "epoch: 669, bulyan: at fang n_at 10 n_mal_sel 10 e 669 | val loss 1.4125 val acc 51.3190 best val_acc 57.325487\n",
      "epoch: 670, bulyan: at fang n_at 10 n_mal_sel 10 e 670 | val loss 1.4390 val acc 49.9188 best val_acc 57.325487\n",
      "epoch: 671, bulyan: at fang n_at 10 n_mal_sel 10 e 671 | val loss 1.2516 val acc 55.9253 best val_acc 57.325487\n",
      "epoch: 672, bulyan: at fang n_at 10 n_mal_sel 10 e 672 | val loss 1.2187 val acc 57.2443 best val_acc 57.325487\n",
      "epoch: 673, bulyan: at fang n_at 10 n_mal_sel 10 e 673 | val loss 1.2705 val acc 54.7078 best val_acc 57.325487\n",
      "epoch: 674, bulyan: at fang n_at 10 n_mal_sel 10 e 674 | val loss 1.2738 val acc 55.0122 best val_acc 57.325487\n",
      "epoch: 675, bulyan: at fang n_at 10 n_mal_sel 10 e 675 | val loss 1.3525 val acc 52.1307 best val_acc 57.325487\n",
      "epoch: 676, bulyan: at fang n_at 10 n_mal_sel 10 e 676 | val loss 1.3005 val acc 53.8149 best val_acc 57.325487\n",
      "epoch: 677, bulyan: at fang n_at 10 n_mal_sel 10 e 677 | val loss 1.2892 val acc 54.4440 best val_acc 57.325487\n",
      "epoch: 678, bulyan: at fang n_at 10 n_mal_sel 10 e 678 | val loss 1.2134 val acc 57.3052 best val_acc 57.325487\n",
      "epoch: 679, bulyan: at fang n_at 10 n_mal_sel 10 e 679 | val loss 1.2099 val acc 56.8385 best val_acc 57.325487\n",
      "epoch: 680, bulyan: at fang n_at 10 n_mal_sel 10 e 680 | val loss 1.1967 val acc 57.4878 best val_acc 57.487825\n",
      "epoch: 681, bulyan: at fang n_at 10 n_mal_sel 10 e 681 | val loss 1.3388 val acc 52.3539 best val_acc 57.487825\n",
      "epoch: 682, bulyan: at fang n_at 10 n_mal_sel 10 e 682 | val loss 1.5418 val acc 46.5706 best val_acc 57.487825\n",
      "epoch: 683, bulyan: at fang n_at 10 n_mal_sel 10 e 683 | val loss 1.3445 val acc 53.4903 best val_acc 57.487825\n",
      "epoch: 684, bulyan: at fang n_at 10 n_mal_sel 10 e 684 | val loss 1.2664 val acc 54.9513 best val_acc 57.487825\n",
      "epoch: 685, bulyan: at fang n_at 10 n_mal_sel 10 e 685 | val loss 1.2665 val acc 55.9456 best val_acc 57.487825\n",
      "epoch: 686, bulyan: at fang n_at 10 n_mal_sel 10 e 686 | val loss 1.4527 val acc 51.9481 best val_acc 57.487825\n",
      "epoch: 687, bulyan: at fang n_at 10 n_mal_sel 10 e 687 | val loss 1.3978 val acc 51.0958 best val_acc 57.487825\n",
      "epoch: 688, bulyan: at fang n_at 10 n_mal_sel 10 e 688 | val loss 1.4054 val acc 50.4667 best val_acc 57.487825\n",
      "epoch: 689, bulyan: at fang n_at 10 n_mal_sel 10 e 689 | val loss 1.2437 val acc 55.8239 best val_acc 57.487825\n",
      "epoch: 690, bulyan: at fang n_at 10 n_mal_sel 10 e 690 | val loss 1.2204 val acc 57.7516 best val_acc 57.751623\n",
      "epoch: 691, bulyan: at fang n_at 10 n_mal_sel 10 e 691 | val loss 1.1946 val acc 57.9343 best val_acc 57.934253\n",
      "epoch: 692, bulyan: at fang n_at 10 n_mal_sel 10 e 692 | val loss 1.3014 val acc 54.9310 best val_acc 57.934253\n",
      "epoch: 693, bulyan: at fang n_at 10 n_mal_sel 10 e 693 | val loss 1.2232 val acc 57.5284 best val_acc 57.934253\n",
      "epoch: 694, bulyan: at fang n_at 10 n_mal_sel 10 e 694 | val loss 1.2008 val acc 56.8588 best val_acc 57.934253\n",
      "epoch: 695, bulyan: at fang n_at 10 n_mal_sel 10 e 695 | val loss 1.2210 val acc 56.3920 best val_acc 57.934253\n",
      "epoch: 696, bulyan: at fang n_at 10 n_mal_sel 10 e 696 | val loss 1.3288 val acc 53.4091 best val_acc 57.934253\n",
      "epoch: 697, bulyan: at fang n_at 10 n_mal_sel 10 e 697 | val loss 1.2876 val acc 53.7338 best val_acc 57.934253\n",
      "epoch: 698, bulyan: at fang n_at 10 n_mal_sel 10 e 698 | val loss 1.2643 val acc 54.9513 best val_acc 57.934253\n",
      "epoch: 699, bulyan: at fang n_at 10 n_mal_sel 10 e 699 | val loss 1.3075 val acc 54.2817 best val_acc 57.934253\n",
      "epoch: 700, bulyan: at fang n_at 10 n_mal_sel 10 e 700 | val loss 1.3681 val acc 51.3393 best val_acc 57.934253\n",
      "epoch: 701, bulyan: at fang n_at 10 n_mal_sel 10 e 701 | val loss 1.3004 val acc 53.6323 best val_acc 57.934253\n",
      "epoch: 702, bulyan: at fang n_at 10 n_mal_sel 10 e 702 | val loss 1.2986 val acc 54.3425 best val_acc 57.934253\n",
      "epoch: 703, bulyan: at fang n_at 10 n_mal_sel 10 e 703 | val loss 1.3446 val acc 53.0032 best val_acc 57.934253\n",
      "epoch: 704, bulyan: at fang n_at 10 n_mal_sel 10 e 704 | val loss 1.3199 val acc 52.1510 best val_acc 57.934253\n",
      "epoch: 705, bulyan: at fang n_at 10 n_mal_sel 10 e 705 | val loss 1.2909 val acc 54.5252 best val_acc 57.934253\n",
      "epoch: 706, bulyan: at fang n_at 10 n_mal_sel 10 e 706 | val loss 1.2578 val acc 55.5804 best val_acc 57.934253\n",
      "epoch: 707, bulyan: at fang n_at 10 n_mal_sel 10 e 707 | val loss 1.3002 val acc 53.8961 best val_acc 57.934253\n",
      "epoch: 708, bulyan: at fang n_at 10 n_mal_sel 10 e 708 | val loss 1.2516 val acc 54.5252 best val_acc 57.934253\n",
      "epoch: 709, bulyan: at fang n_at 10 n_mal_sel 10 e 709 | val loss 1.1666 val acc 58.3401 best val_acc 58.340097\n",
      "epoch: 710, bulyan: at fang n_at 10 n_mal_sel 10 e 710 | val loss 1.1525 val acc 59.8417 best val_acc 59.841721\n",
      "epoch: 711, bulyan: at fang n_at 10 n_mal_sel 10 e 711 | val loss 1.2474 val acc 56.5341 best val_acc 59.841721\n",
      "epoch: 712, bulyan: at fang n_at 10 n_mal_sel 10 e 712 | val loss 1.4000 val acc 52.5974 best val_acc 59.841721\n",
      "epoch: 713, bulyan: at fang n_at 10 n_mal_sel 10 e 713 | val loss 1.4600 val acc 50.0609 best val_acc 59.841721\n",
      "epoch: 714, bulyan: at fang n_at 10 n_mal_sel 10 e 714 | val loss 1.2657 val acc 55.6209 best val_acc 59.841721\n",
      "epoch: 715, bulyan: at fang n_at 10 n_mal_sel 10 e 715 | val loss 1.2697 val acc 55.3774 best val_acc 59.841721\n",
      "epoch: 716, bulyan: at fang n_at 10 n_mal_sel 10 e 716 | val loss 1.3570 val acc 53.0641 best val_acc 59.841721\n",
      "epoch: 717, bulyan: at fang n_at 10 n_mal_sel 10 e 717 | val loss 1.4914 val acc 49.4521 best val_acc 59.841721\n",
      "epoch: 718, bulyan: at fang n_at 10 n_mal_sel 10 e 718 | val loss 1.4185 val acc 51.0958 best val_acc 59.841721\n",
      "epoch: 719, bulyan: at fang n_at 10 n_mal_sel 10 e 719 | val loss 1.3820 val acc 50.9740 best val_acc 59.841721\n",
      "epoch: 720, bulyan: at fang n_at 10 n_mal_sel 10 e 720 | val loss 1.2473 val acc 55.8847 best val_acc 59.841721\n",
      "epoch: 721, bulyan: at fang n_at 10 n_mal_sel 10 e 721 | val loss 1.2105 val acc 56.5544 best val_acc 59.841721\n",
      "epoch: 722, bulyan: at fang n_at 10 n_mal_sel 10 e 722 | val loss 1.1997 val acc 57.9545 best val_acc 59.841721\n",
      "epoch: 723, bulyan: at fang n_at 10 n_mal_sel 10 e 723 | val loss 1.2740 val acc 54.3222 best val_acc 59.841721\n",
      "epoch: 724, bulyan: at fang n_at 10 n_mal_sel 10 e 724 | val loss 1.3073 val acc 53.0438 best val_acc 59.841721\n",
      "epoch: 725, bulyan: at fang n_at 10 n_mal_sel 10 e 725 | val loss 1.2231 val acc 56.0674 best val_acc 59.841721\n",
      "epoch: 726, bulyan: at fang n_at 10 n_mal_sel 10 e 726 | val loss 1.1396 val acc 59.5170 best val_acc 59.841721\n",
      "epoch: 727, bulyan: at fang n_at 10 n_mal_sel 10 e 727 | val loss 1.1657 val acc 58.4821 best val_acc 59.841721\n",
      "epoch: 728, bulyan: at fang n_at 10 n_mal_sel 10 e 728 | val loss 1.2463 val acc 56.3312 best val_acc 59.841721\n",
      "epoch: 729, bulyan: at fang n_at 10 n_mal_sel 10 e 729 | val loss 1.3194 val acc 53.6729 best val_acc 59.841721\n",
      "epoch: 730, bulyan: at fang n_at 10 n_mal_sel 10 e 730 | val loss 1.4416 val acc 49.8985 best val_acc 59.841721\n",
      "epoch: 731, bulyan: at fang n_at 10 n_mal_sel 10 e 731 | val loss 1.4995 val acc 49.1680 best val_acc 59.841721\n",
      "epoch: 732, bulyan: at fang n_at 10 n_mal_sel 10 e 732 | val loss 1.4320 val acc 50.4058 best val_acc 59.841721\n",
      "epoch: 733, bulyan: at fang n_at 10 n_mal_sel 10 e 733 | val loss 1.3467 val acc 51.8669 best val_acc 59.841721\n",
      "epoch: 734, bulyan: at fang n_at 10 n_mal_sel 10 e 734 | val loss 1.2607 val acc 55.7630 best val_acc 59.841721\n",
      "epoch: 735, bulyan: at fang n_at 10 n_mal_sel 10 e 735 | val loss 1.2370 val acc 57.0414 best val_acc 59.841721\n",
      "epoch: 736, bulyan: at fang n_at 10 n_mal_sel 10 e 736 | val loss 1.2364 val acc 57.2240 best val_acc 59.841721\n",
      "epoch: 737, bulyan: at fang n_at 10 n_mal_sel 10 e 737 | val loss 1.2704 val acc 54.8295 best val_acc 59.841721\n",
      "epoch: 738, bulyan: at fang n_at 10 n_mal_sel 10 e 738 | val loss 1.2614 val acc 55.4586 best val_acc 59.841721\n",
      "epoch: 739, bulyan: at fang n_at 10 n_mal_sel 10 e 739 | val loss 1.2620 val acc 53.9773 best val_acc 59.841721\n",
      "epoch: 740, bulyan: at fang n_at 10 n_mal_sel 10 e 740 | val loss 1.2318 val acc 56.7370 best val_acc 59.841721\n",
      "epoch: 741, bulyan: at fang n_at 10 n_mal_sel 10 e 741 | val loss 1.2557 val acc 55.4383 best val_acc 59.841721\n",
      "epoch: 742, bulyan: at fang n_at 10 n_mal_sel 10 e 742 | val loss 1.2016 val acc 57.3864 best val_acc 59.841721\n",
      "epoch: 743, bulyan: at fang n_at 10 n_mal_sel 10 e 743 | val loss 1.2256 val acc 56.7370 best val_acc 59.841721\n",
      "epoch: 744, bulyan: at fang n_at 10 n_mal_sel 10 e 744 | val loss 1.2279 val acc 56.2094 best val_acc 59.841721\n",
      "epoch: 745, bulyan: at fang n_at 10 n_mal_sel 10 e 745 | val loss 1.1767 val acc 58.1778 best val_acc 59.841721\n",
      "epoch: 746, bulyan: at fang n_at 10 n_mal_sel 10 e 746 | val loss 1.2171 val acc 57.7922 best val_acc 59.841721\n",
      "epoch: 747, bulyan: at fang n_at 10 n_mal_sel 10 e 747 | val loss 1.2649 val acc 55.2963 best val_acc 59.841721\n",
      "epoch: 748, bulyan: at fang n_at 10 n_mal_sel 10 e 748 | val loss 1.2893 val acc 55.7427 best val_acc 59.841721\n",
      "epoch: 749, bulyan: at fang n_at 10 n_mal_sel 10 e 749 | val loss 1.2227 val acc 57.7922 best val_acc 59.841721\n",
      "epoch: 750, bulyan: at fang n_at 10 n_mal_sel 10 e 750 | val loss 1.2767 val acc 57.4067 best val_acc 59.841721\n",
      "epoch: 751, bulyan: at fang n_at 10 n_mal_sel 10 e 751 | val loss 1.3209 val acc 54.0787 best val_acc 59.841721\n",
      "epoch: 752, bulyan: at fang n_at 10 n_mal_sel 10 e 752 | val loss 1.2667 val acc 55.1745 best val_acc 59.841721\n",
      "epoch: 753, bulyan: at fang n_at 10 n_mal_sel 10 e 753 | val loss 1.2225 val acc 57.5284 best val_acc 59.841721\n",
      "epoch: 754, bulyan: at fang n_at 10 n_mal_sel 10 e 754 | val loss 1.2790 val acc 54.3222 best val_acc 59.841721\n",
      "epoch: 755, bulyan: at fang n_at 10 n_mal_sel 10 e 755 | val loss 1.3975 val acc 51.5219 best val_acc 59.841721\n",
      "epoch: 756, bulyan: at fang n_at 10 n_mal_sel 10 e 756 | val loss 1.3047 val acc 53.2468 best val_acc 59.841721\n",
      "epoch: 757, bulyan: at fang n_at 10 n_mal_sel 10 e 757 | val loss 1.2020 val acc 57.1631 best val_acc 59.841721\n",
      "epoch: 758, bulyan: at fang n_at 10 n_mal_sel 10 e 758 | val loss 1.2024 val acc 57.8125 best val_acc 59.841721\n",
      "epoch: 759, bulyan: at fang n_at 10 n_mal_sel 10 e 759 | val loss 1.1959 val acc 57.8328 best val_acc 59.841721\n",
      "epoch: 760, bulyan: at fang n_at 10 n_mal_sel 10 e 760 | val loss 1.1898 val acc 58.2792 best val_acc 59.841721\n",
      "epoch: 761, bulyan: at fang n_at 10 n_mal_sel 10 e 761 | val loss 1.2342 val acc 56.3109 best val_acc 59.841721\n",
      "epoch: 762, bulyan: at fang n_at 10 n_mal_sel 10 e 762 | val loss 1.2418 val acc 55.7224 best val_acc 59.841721\n",
      "epoch: 763, bulyan: at fang n_at 10 n_mal_sel 10 e 763 | val loss 1.2924 val acc 54.0179 best val_acc 59.841721\n",
      "epoch: 764, bulyan: at fang n_at 10 n_mal_sel 10 e 764 | val loss 1.3299 val acc 53.4903 best val_acc 59.841721\n",
      "epoch: 765, bulyan: at fang n_at 10 n_mal_sel 10 e 765 | val loss 1.2371 val acc 56.4123 best val_acc 59.841721\n",
      "epoch: 766, bulyan: at fang n_at 10 n_mal_sel 10 e 766 | val loss 1.1650 val acc 58.6851 best val_acc 59.841721\n",
      "epoch: 767, bulyan: at fang n_at 10 n_mal_sel 10 e 767 | val loss 1.1882 val acc 58.1372 best val_acc 59.841721\n",
      "epoch: 768, bulyan: at fang n_at 10 n_mal_sel 10 e 768 | val loss 1.2724 val acc 55.4180 best val_acc 59.841721\n",
      "epoch: 769, bulyan: at fang n_at 10 n_mal_sel 10 e 769 | val loss 1.3306 val acc 53.0438 best val_acc 59.841721\n",
      "epoch: 770, bulyan: at fang n_at 10 n_mal_sel 10 e 770 | val loss 1.1825 val acc 58.0560 best val_acc 59.841721\n",
      "epoch: 771, bulyan: at fang n_at 10 n_mal_sel 10 e 771 | val loss 1.1878 val acc 57.6502 best val_acc 59.841721\n",
      "epoch: 772, bulyan: at fang n_at 10 n_mal_sel 10 e 772 | val loss 1.1901 val acc 58.5836 best val_acc 59.841721\n",
      "epoch: 773, bulyan: at fang n_at 10 n_mal_sel 10 e 773 | val loss 1.2032 val acc 56.7167 best val_acc 59.841721\n",
      "epoch: 774, bulyan: at fang n_at 10 n_mal_sel 10 e 774 | val loss 1.1754 val acc 58.9692 best val_acc 59.841721\n",
      "epoch: 775, bulyan: at fang n_at 10 n_mal_sel 10 e 775 | val loss 1.2190 val acc 57.4878 best val_acc 59.841721\n",
      "epoch: 776, bulyan: at fang n_at 10 n_mal_sel 10 e 776 | val loss 1.2139 val acc 58.0154 best val_acc 59.841721\n",
      "epoch: 777, bulyan: at fang n_at 10 n_mal_sel 10 e 777 | val loss 1.2612 val acc 56.6356 best val_acc 59.841721\n",
      "epoch: 778, bulyan: at fang n_at 10 n_mal_sel 10 e 778 | val loss 1.3152 val acc 55.3774 best val_acc 59.841721\n",
      "epoch: 779, bulyan: at fang n_at 10 n_mal_sel 10 e 779 | val loss 1.3498 val acc 51.8466 best val_acc 59.841721\n",
      "epoch: 780, bulyan: at fang n_at 10 n_mal_sel 10 e 780 | val loss 1.2822 val acc 56.3920 best val_acc 59.841721\n",
      "epoch: 781, bulyan: at fang n_at 10 n_mal_sel 10 e 781 | val loss 1.2326 val acc 55.8239 best val_acc 59.841721\n",
      "epoch: 782, bulyan: at fang n_at 10 n_mal_sel 10 e 782 | val loss 1.2308 val acc 55.7021 best val_acc 59.841721\n",
      "epoch: 783, bulyan: at fang n_at 10 n_mal_sel 10 e 783 | val loss 1.2108 val acc 57.7922 best val_acc 59.841721\n",
      "epoch: 784, bulyan: at fang n_at 10 n_mal_sel 10 e 784 | val loss 1.2362 val acc 56.3312 best val_acc 59.841721\n",
      "epoch: 785, bulyan: at fang n_at 10 n_mal_sel 10 e 785 | val loss 1.2436 val acc 56.2906 best val_acc 59.841721\n",
      "epoch: 786, bulyan: at fang n_at 10 n_mal_sel 10 e 786 | val loss 1.1991 val acc 57.1226 best val_acc 59.841721\n",
      "epoch: 787, bulyan: at fang n_at 10 n_mal_sel 10 e 787 | val loss 1.1905 val acc 58.5836 best val_acc 59.841721\n",
      "epoch: 788, bulyan: at fang n_at 10 n_mal_sel 10 e 788 | val loss 1.1941 val acc 58.2386 best val_acc 59.841721\n",
      "epoch: 789, bulyan: at fang n_at 10 n_mal_sel 10 e 789 | val loss 1.2709 val acc 56.3312 best val_acc 59.841721\n",
      "epoch: 790, bulyan: at fang n_at 10 n_mal_sel 10 e 790 | val loss 1.2519 val acc 57.6299 best val_acc 59.841721\n",
      "epoch: 791, bulyan: at fang n_at 10 n_mal_sel 10 e 791 | val loss 1.2569 val acc 57.2240 best val_acc 59.841721\n",
      "epoch: 792, bulyan: at fang n_at 10 n_mal_sel 10 e 792 | val loss 1.3480 val acc 55.0731 best val_acc 59.841721\n",
      "epoch: 793, bulyan: at fang n_at 10 n_mal_sel 10 e 793 | val loss 1.4083 val acc 51.9683 best val_acc 59.841721\n",
      "epoch: 794, bulyan: at fang n_at 10 n_mal_sel 10 e 794 | val loss 1.3930 val acc 52.1713 best val_acc 59.841721\n",
      "epoch: 795, bulyan: at fang n_at 10 n_mal_sel 10 e 795 | val loss 1.4306 val acc 50.7305 best val_acc 59.841721\n",
      "epoch: 796, bulyan: at fang n_at 10 n_mal_sel 10 e 796 | val loss 1.3674 val acc 53.1656 best val_acc 59.841721\n",
      "epoch: 797, bulyan: at fang n_at 10 n_mal_sel 10 e 797 | val loss 1.4436 val acc 50.4667 best val_acc 59.841721\n",
      "epoch: 798, bulyan: at fang n_at 10 n_mal_sel 10 e 798 | val loss 1.4006 val acc 51.7654 best val_acc 59.841721\n",
      "epoch: 799, bulyan: at fang n_at 10 n_mal_sel 10 e 799 | val loss 1.4569 val acc 50.2029 best val_acc 59.841721\n",
      "epoch: 800, bulyan: at fang n_at 10 n_mal_sel 10 e 800 | val loss 1.3584 val acc 51.8872 best val_acc 59.841721\n",
      "epoch: 801, bulyan: at fang n_at 10 n_mal_sel 10 e 801 | val loss 1.3955 val acc 52.8409 best val_acc 59.841721\n",
      "epoch: 802, bulyan: at fang n_at 10 n_mal_sel 10 e 802 | val loss 1.3410 val acc 53.0032 best val_acc 59.841721\n",
      "epoch: 803, bulyan: at fang n_at 10 n_mal_sel 10 e 803 | val loss 1.3284 val acc 54.1193 best val_acc 59.841721\n",
      "epoch: 804, bulyan: at fang n_at 10 n_mal_sel 10 e 804 | val loss 1.2093 val acc 56.9399 best val_acc 59.841721\n",
      "epoch: 805, bulyan: at fang n_at 10 n_mal_sel 10 e 805 | val loss 1.1638 val acc 59.0706 best val_acc 59.841721\n",
      "epoch: 806, bulyan: at fang n_at 10 n_mal_sel 10 e 806 | val loss 1.1288 val acc 60.1867 best val_acc 60.186688\n",
      "epoch: 807, bulyan: at fang n_at 10 n_mal_sel 10 e 807 | val loss 1.1671 val acc 59.5373 best val_acc 60.186688\n",
      "epoch: 808, bulyan: at fang n_at 10 n_mal_sel 10 e 808 | val loss 1.2492 val acc 57.2240 best val_acc 60.186688\n",
      "epoch: 809, bulyan: at fang n_at 10 n_mal_sel 10 e 809 | val loss 1.1883 val acc 58.2995 best val_acc 60.186688\n",
      "epoch: 810, bulyan: at fang n_at 10 n_mal_sel 10 e 810 | val loss 1.2044 val acc 58.4010 best val_acc 60.186688\n",
      "epoch: 811, bulyan: at fang n_at 10 n_mal_sel 10 e 811 | val loss 1.1980 val acc 58.5430 best val_acc 60.186688\n",
      "epoch: 812, bulyan: at fang n_at 10 n_mal_sel 10 e 812 | val loss 1.1657 val acc 58.7662 best val_acc 60.186688\n",
      "epoch: 813, bulyan: at fang n_at 10 n_mal_sel 10 e 813 | val loss 1.1280 val acc 60.0041 best val_acc 60.186688\n",
      "epoch: 814, bulyan: at fang n_at 10 n_mal_sel 10 e 814 | val loss 1.1454 val acc 59.7606 best val_acc 60.186688\n",
      "epoch: 815, bulyan: at fang n_at 10 n_mal_sel 10 e 815 | val loss 1.2419 val acc 57.3052 best val_acc 60.186688\n",
      "epoch: 816, bulyan: at fang n_at 10 n_mal_sel 10 e 816 | val loss 1.3423 val acc 54.3425 best val_acc 60.186688\n",
      "epoch: 817, bulyan: at fang n_at 10 n_mal_sel 10 e 817 | val loss 1.2843 val acc 54.3831 best val_acc 60.186688\n",
      "epoch: 818, bulyan: at fang n_at 10 n_mal_sel 10 e 818 | val loss 1.2040 val acc 58.8271 best val_acc 60.186688\n",
      "epoch: 819, bulyan: at fang n_at 10 n_mal_sel 10 e 819 | val loss 1.1468 val acc 60.1055 best val_acc 60.186688\n",
      "epoch: 820, bulyan: at fang n_at 10 n_mal_sel 10 e 820 | val loss 1.2751 val acc 55.7630 best val_acc 60.186688\n",
      "epoch: 821, bulyan: at fang n_at 10 n_mal_sel 10 e 821 | val loss 1.3238 val acc 55.1542 best val_acc 60.186688\n",
      "epoch: 822, bulyan: at fang n_at 10 n_mal_sel 10 e 822 | val loss 1.4331 val acc 50.7102 best val_acc 60.186688\n",
      "epoch: 823, bulyan: at fang n_at 10 n_mal_sel 10 e 823 | val loss 1.2813 val acc 55.1339 best val_acc 60.186688\n",
      "epoch: 824, bulyan: at fang n_at 10 n_mal_sel 10 e 824 | val loss 1.1837 val acc 57.8937 best val_acc 60.186688\n",
      "epoch: 825, bulyan: at fang n_at 10 n_mal_sel 10 e 825 | val loss 1.1221 val acc 60.5317 best val_acc 60.531656\n",
      "epoch: 826, bulyan: at fang n_at 10 n_mal_sel 10 e 826 | val loss 1.1537 val acc 59.5779 best val_acc 60.531656\n",
      "epoch: 827, bulyan: at fang n_at 10 n_mal_sel 10 e 827 | val loss 1.2036 val acc 58.5024 best val_acc 60.531656\n",
      "epoch: 828, bulyan: at fang n_at 10 n_mal_sel 10 e 828 | val loss 1.2638 val acc 54.6672 best val_acc 60.531656\n",
      "epoch: 829, bulyan: at fang n_at 10 n_mal_sel 10 e 829 | val loss 1.2572 val acc 55.6209 best val_acc 60.531656\n",
      "epoch: 830, bulyan: at fang n_at 10 n_mal_sel 10 e 830 | val loss 1.2486 val acc 55.4789 best val_acc 60.531656\n",
      "epoch: 831, bulyan: at fang n_at 10 n_mal_sel 10 e 831 | val loss 1.3157 val acc 54.4237 best val_acc 60.531656\n",
      "epoch: 832, bulyan: at fang n_at 10 n_mal_sel 10 e 832 | val loss 1.2214 val acc 56.5341 best val_acc 60.531656\n",
      "epoch: 833, bulyan: at fang n_at 10 n_mal_sel 10 e 833 | val loss 1.1865 val acc 59.6794 best val_acc 60.531656\n",
      "epoch: 834, bulyan: at fang n_at 10 n_mal_sel 10 e 834 | val loss 1.2111 val acc 58.6242 best val_acc 60.531656\n",
      "epoch: 835, bulyan: at fang n_at 10 n_mal_sel 10 e 835 | val loss 1.2948 val acc 57.2443 best val_acc 60.531656\n",
      "epoch: 836, bulyan: at fang n_at 10 n_mal_sel 10 e 836 | val loss 1.3821 val acc 53.3685 best val_acc 60.531656\n",
      "epoch: 837, bulyan: at fang n_at 10 n_mal_sel 10 e 837 | val loss 1.2741 val acc 56.8385 best val_acc 60.531656\n",
      "epoch: 838, bulyan: at fang n_at 10 n_mal_sel 10 e 838 | val loss 1.2441 val acc 58.2792 best val_acc 60.531656\n",
      "epoch: 839, bulyan: at fang n_at 10 n_mal_sel 10 e 839 | val loss 1.1716 val acc 60.3693 best val_acc 60.531656\n",
      "epoch: 840, bulyan: at fang n_at 10 n_mal_sel 10 e 840 | val loss 1.2635 val acc 58.3198 best val_acc 60.531656\n",
      "epoch: 841, bulyan: at fang n_at 10 n_mal_sel 10 e 841 | val loss 1.2131 val acc 58.4619 best val_acc 60.531656\n",
      "epoch: 842, bulyan: at fang n_at 10 n_mal_sel 10 e 842 | val loss 1.1679 val acc 59.4765 best val_acc 60.531656\n",
      "epoch: 843, bulyan: at fang n_at 10 n_mal_sel 10 e 843 | val loss 1.2052 val acc 57.9343 best val_acc 60.531656\n",
      "epoch: 844, bulyan: at fang n_at 10 n_mal_sel 10 e 844 | val loss 1.3776 val acc 52.1713 best val_acc 60.531656\n",
      "epoch: 845, bulyan: at fang n_at 10 n_mal_sel 10 e 845 | val loss 1.3453 val acc 53.3482 best val_acc 60.531656\n",
      "epoch: 846, bulyan: at fang n_at 10 n_mal_sel 10 e 846 | val loss 1.3039 val acc 55.0528 best val_acc 60.531656\n",
      "epoch: 847, bulyan: at fang n_at 10 n_mal_sel 10 e 847 | val loss 1.4150 val acc 51.2987 best val_acc 60.531656\n",
      "epoch: 848, bulyan: at fang n_at 10 n_mal_sel 10 e 848 | val loss 1.3360 val acc 54.0381 best val_acc 60.531656\n",
      "epoch: 849, bulyan: at fang n_at 10 n_mal_sel 10 e 849 | val loss 1.2821 val acc 53.8352 best val_acc 60.531656\n",
      "epoch: 850, bulyan: at fang n_at 10 n_mal_sel 10 e 850 | val loss 1.2453 val acc 55.4586 best val_acc 60.531656\n",
      "epoch: 851, bulyan: at fang n_at 10 n_mal_sel 10 e 851 | val loss 1.1918 val acc 58.2386 best val_acc 60.531656\n",
      "epoch: 852, bulyan: at fang n_at 10 n_mal_sel 10 e 852 | val loss 1.1993 val acc 57.5893 best val_acc 60.531656\n",
      "epoch: 853, bulyan: at fang n_at 10 n_mal_sel 10 e 853 | val loss 1.1605 val acc 59.5373 best val_acc 60.531656\n",
      "epoch: 854, bulyan: at fang n_at 10 n_mal_sel 10 e 854 | val loss 1.1492 val acc 60.1664 best val_acc 60.531656\n",
      "epoch: 855, bulyan: at fang n_at 10 n_mal_sel 10 e 855 | val loss 1.1765 val acc 59.4359 best val_acc 60.531656\n",
      "epoch: 856, bulyan: at fang n_at 10 n_mal_sel 10 e 856 | val loss 1.2558 val acc 57.0617 best val_acc 60.531656\n",
      "epoch: 857, bulyan: at fang n_at 10 n_mal_sel 10 e 857 | val loss 1.3485 val acc 54.0584 best val_acc 60.531656\n",
      "epoch: 858, bulyan: at fang n_at 10 n_mal_sel 10 e 858 | val loss 1.1979 val acc 57.3661 best val_acc 60.531656\n",
      "epoch: 859, bulyan: at fang n_at 10 n_mal_sel 10 e 859 | val loss 1.1268 val acc 61.1810 best val_acc 61.181006\n",
      "epoch: 860, bulyan: at fang n_at 10 n_mal_sel 10 e 860 | val loss 1.1651 val acc 59.7403 best val_acc 61.181006\n",
      "epoch: 861, bulyan: at fang n_at 10 n_mal_sel 10 e 861 | val loss 1.2545 val acc 57.6299 best val_acc 61.181006\n",
      "epoch: 862, bulyan: at fang n_at 10 n_mal_sel 10 e 862 | val loss 1.2922 val acc 55.2151 best val_acc 61.181006\n",
      "epoch: 863, bulyan: at fang n_at 10 n_mal_sel 10 e 863 | val loss 1.1624 val acc 59.3953 best val_acc 61.181006\n",
      "epoch: 864, bulyan: at fang n_at 10 n_mal_sel 10 e 864 | val loss 1.1679 val acc 59.6388 best val_acc 61.181006\n",
      "epoch: 865, bulyan: at fang n_at 10 n_mal_sel 10 e 865 | val loss 1.3179 val acc 55.6006 best val_acc 61.181006\n",
      "epoch: 866, bulyan: at fang n_at 10 n_mal_sel 10 e 866 | val loss 1.2883 val acc 54.4846 best val_acc 61.181006\n",
      "epoch: 867, bulyan: at fang n_at 10 n_mal_sel 10 e 867 | val loss 1.2032 val acc 57.6907 best val_acc 61.181006\n",
      "epoch: 868, bulyan: at fang n_at 10 n_mal_sel 10 e 868 | val loss 1.1204 val acc 61.4042 best val_acc 61.404221\n",
      "epoch: 869, bulyan: at fang n_at 10 n_mal_sel 10 e 869 | val loss 1.1409 val acc 60.5114 best val_acc 61.404221\n",
      "epoch: 870, bulyan: at fang n_at 10 n_mal_sel 10 e 870 | val loss 1.1672 val acc 59.5576 best val_acc 61.404221\n",
      "epoch: 871, bulyan: at fang n_at 10 n_mal_sel 10 e 871 | val loss 1.1938 val acc 57.8328 best val_acc 61.404221\n",
      "epoch: 872, bulyan: at fang n_at 10 n_mal_sel 10 e 872 | val loss 1.1830 val acc 59.1112 best val_acc 61.404221\n",
      "epoch: 873, bulyan: at fang n_at 10 n_mal_sel 10 e 873 | val loss 1.1827 val acc 59.4359 best val_acc 61.404221\n",
      "epoch: 874, bulyan: at fang n_at 10 n_mal_sel 10 e 874 | val loss 1.1841 val acc 58.5430 best val_acc 61.404221\n",
      "epoch: 875, bulyan: at fang n_at 10 n_mal_sel 10 e 875 | val loss 1.2005 val acc 59.1315 best val_acc 61.404221\n",
      "epoch: 876, bulyan: at fang n_at 10 n_mal_sel 10 e 876 | val loss 1.2734 val acc 56.2297 best val_acc 61.404221\n",
      "epoch: 877, bulyan: at fang n_at 10 n_mal_sel 10 e 877 | val loss 1.4015 val acc 55.5804 best val_acc 61.404221\n",
      "epoch: 878, bulyan: at fang n_at 10 n_mal_sel 10 e 878 | val loss 1.2346 val acc 56.2703 best val_acc 61.404221\n",
      "epoch: 879, bulyan: at fang n_at 10 n_mal_sel 10 e 879 | val loss 1.1669 val acc 59.5576 best val_acc 61.404221\n",
      "epoch: 880, bulyan: at fang n_at 10 n_mal_sel 10 e 880 | val loss 1.1504 val acc 60.5722 best val_acc 61.404221\n",
      "epoch: 881, bulyan: at fang n_at 10 n_mal_sel 10 e 881 | val loss 1.1822 val acc 59.0909 best val_acc 61.404221\n",
      "epoch: 882, bulyan: at fang n_at 10 n_mal_sel 10 e 882 | val loss 1.2318 val acc 57.5487 best val_acc 61.404221\n",
      "epoch: 883, bulyan: at fang n_at 10 n_mal_sel 10 e 883 | val loss 1.3295 val acc 55.8036 best val_acc 61.404221\n",
      "epoch: 884, bulyan: at fang n_at 10 n_mal_sel 10 e 884 | val loss 1.2702 val acc 55.3774 best val_acc 61.404221\n",
      "epoch: 885, bulyan: at fang n_at 10 n_mal_sel 10 e 885 | val loss 1.1289 val acc 60.9375 best val_acc 61.404221\n",
      "epoch: 886, bulyan: at fang n_at 10 n_mal_sel 10 e 886 | val loss 1.1626 val acc 60.2273 best val_acc 61.404221\n",
      "epoch: 887, bulyan: at fang n_at 10 n_mal_sel 10 e 887 | val loss 1.2792 val acc 55.9456 best val_acc 61.404221\n",
      "epoch: 888, bulyan: at fang n_at 10 n_mal_sel 10 e 888 | val loss 1.3874 val acc 53.3685 best val_acc 61.404221\n",
      "epoch: 889, bulyan: at fang n_at 10 n_mal_sel 10 e 889 | val loss 1.2972 val acc 57.2037 best val_acc 61.404221\n",
      "epoch: 890, bulyan: at fang n_at 10 n_mal_sel 10 e 890 | val loss 1.2268 val acc 58.2589 best val_acc 61.404221\n",
      "epoch: 891, bulyan: at fang n_at 10 n_mal_sel 10 e 891 | val loss 1.2390 val acc 58.3198 best val_acc 61.404221\n",
      "epoch: 892, bulyan: at fang n_at 10 n_mal_sel 10 e 892 | val loss 1.2870 val acc 56.8791 best val_acc 61.404221\n",
      "epoch: 893, bulyan: at fang n_at 10 n_mal_sel 10 e 893 | val loss 1.3633 val acc 55.9862 best val_acc 61.404221\n",
      "epoch: 894, bulyan: at fang n_at 10 n_mal_sel 10 e 894 | val loss 1.2375 val acc 56.1080 best val_acc 61.404221\n",
      "epoch: 895, bulyan: at fang n_at 10 n_mal_sel 10 e 895 | val loss 1.2186 val acc 57.2646 best val_acc 61.404221\n",
      "epoch: 896, bulyan: at fang n_at 10 n_mal_sel 10 e 896 | val loss 1.1460 val acc 59.6997 best val_acc 61.404221\n",
      "epoch: 897, bulyan: at fang n_at 10 n_mal_sel 10 e 897 | val loss 1.2607 val acc 56.4326 best val_acc 61.404221\n",
      "epoch: 898, bulyan: at fang n_at 10 n_mal_sel 10 e 898 | val loss 1.2233 val acc 57.1631 best val_acc 61.404221\n",
      "epoch: 899, bulyan: at fang n_at 10 n_mal_sel 10 e 899 | val loss 1.2486 val acc 57.7719 best val_acc 61.404221\n",
      "epoch: 900, bulyan: at fang n_at 10 n_mal_sel 10 e 900 | val loss 1.1038 val acc 61.5463 best val_acc 61.546266\n",
      "epoch: 901, bulyan: at fang n_at 10 n_mal_sel 10 e 901 | val loss 1.0943 val acc 62.3377 best val_acc 62.337662\n",
      "epoch: 902, bulyan: at fang n_at 10 n_mal_sel 10 e 902 | val loss 1.1138 val acc 61.7695 best val_acc 62.337662\n",
      "epoch: 903, bulyan: at fang n_at 10 n_mal_sel 10 e 903 | val loss 1.2169 val acc 59.1315 best val_acc 62.337662\n",
      "epoch: 904, bulyan: at fang n_at 10 n_mal_sel 10 e 904 | val loss 1.3478 val acc 56.0268 best val_acc 62.337662\n",
      "epoch: 905, bulyan: at fang n_at 10 n_mal_sel 10 e 905 | val loss 1.3506 val acc 54.6469 best val_acc 62.337662\n",
      "epoch: 906, bulyan: at fang n_at 10 n_mal_sel 10 e 906 | val loss 1.3614 val acc 54.8295 best val_acc 62.337662\n",
      "epoch: 907, bulyan: at fang n_at 10 n_mal_sel 10 e 907 | val loss 1.3192 val acc 55.7224 best val_acc 62.337662\n",
      "epoch: 908, bulyan: at fang n_at 10 n_mal_sel 10 e 908 | val loss 1.2030 val acc 58.7865 best val_acc 62.337662\n",
      "epoch: 909, bulyan: at fang n_at 10 n_mal_sel 10 e 909 | val loss 1.2377 val acc 58.5024 best val_acc 62.337662\n",
      "epoch: 910, bulyan: at fang n_at 10 n_mal_sel 10 e 910 | val loss 1.3480 val acc 56.7979 best val_acc 62.337662\n",
      "epoch: 911, bulyan: at fang n_at 10 n_mal_sel 10 e 911 | val loss 1.4493 val acc 52.3539 best val_acc 62.337662\n",
      "epoch: 912, bulyan: at fang n_at 10 n_mal_sel 10 e 912 | val loss 1.2758 val acc 55.9456 best val_acc 62.337662\n",
      "epoch: 913, bulyan: at fang n_at 10 n_mal_sel 10 e 913 | val loss 1.1933 val acc 58.5430 best val_acc 62.337662\n",
      "epoch: 914, bulyan: at fang n_at 10 n_mal_sel 10 e 914 | val loss 1.1991 val acc 58.8474 best val_acc 62.337662\n",
      "epoch: 915, bulyan: at fang n_at 10 n_mal_sel 10 e 915 | val loss 1.2294 val acc 58.1169 best val_acc 62.337662\n",
      "epoch: 916, bulyan: at fang n_at 10 n_mal_sel 10 e 916 | val loss 1.2577 val acc 56.4935 best val_acc 62.337662\n",
      "epoch: 917, bulyan: at fang n_at 10 n_mal_sel 10 e 917 | val loss 1.2697 val acc 56.5544 best val_acc 62.337662\n",
      "epoch: 918, bulyan: at fang n_at 10 n_mal_sel 10 e 918 | val loss 1.1882 val acc 58.3807 best val_acc 62.337662\n",
      "epoch: 919, bulyan: at fang n_at 10 n_mal_sel 10 e 919 | val loss 1.1608 val acc 59.7606 best val_acc 62.337662\n",
      "epoch: 920, bulyan: at fang n_at 10 n_mal_sel 10 e 920 | val loss 1.1465 val acc 61.4042 best val_acc 62.337662\n",
      "epoch: 921, bulyan: at fang n_at 10 n_mal_sel 10 e 921 | val loss 1.1660 val acc 59.9838 best val_acc 62.337662\n",
      "epoch: 922, bulyan: at fang n_at 10 n_mal_sel 10 e 922 | val loss 1.1607 val acc 59.6185 best val_acc 62.337662\n",
      "epoch: 923, bulyan: at fang n_at 10 n_mal_sel 10 e 923 | val loss 1.2048 val acc 59.2127 best val_acc 62.337662\n",
      "epoch: 924, bulyan: at fang n_at 10 n_mal_sel 10 e 924 | val loss 1.2661 val acc 57.4472 best val_acc 62.337662\n",
      "epoch: 925, bulyan: at fang n_at 10 n_mal_sel 10 e 925 | val loss 1.2532 val acc 56.8994 best val_acc 62.337662\n",
      "epoch: 926, bulyan: at fang n_at 10 n_mal_sel 10 e 926 | val loss 1.2076 val acc 57.9951 best val_acc 62.337662\n",
      "epoch: 927, bulyan: at fang n_at 10 n_mal_sel 10 e 927 | val loss 1.1993 val acc 58.6648 best val_acc 62.337662\n",
      "epoch: 928, bulyan: at fang n_at 10 n_mal_sel 10 e 928 | val loss 1.2405 val acc 57.2443 best val_acc 62.337662\n",
      "epoch: 929, bulyan: at fang n_at 10 n_mal_sel 10 e 929 | val loss 1.1268 val acc 60.8563 best val_acc 62.337662\n",
      "epoch: 930, bulyan: at fang n_at 10 n_mal_sel 10 e 930 | val loss 1.1799 val acc 60.4099 best val_acc 62.337662\n",
      "epoch: 931, bulyan: at fang n_at 10 n_mal_sel 10 e 931 | val loss 1.2305 val acc 57.8734 best val_acc 62.337662\n",
      "epoch: 932, bulyan: at fang n_at 10 n_mal_sel 10 e 932 | val loss 1.2694 val acc 57.3864 best val_acc 62.337662\n",
      "epoch: 933, bulyan: at fang n_at 10 n_mal_sel 10 e 933 | val loss 1.2283 val acc 57.9748 best val_acc 62.337662\n",
      "epoch: 934, bulyan: at fang n_at 10 n_mal_sel 10 e 934 | val loss 1.1691 val acc 59.7403 best val_acc 62.337662\n",
      "epoch: 935, bulyan: at fang n_at 10 n_mal_sel 10 e 935 | val loss 1.2149 val acc 58.9083 best val_acc 62.337662\n",
      "epoch: 936, bulyan: at fang n_at 10 n_mal_sel 10 e 936 | val loss 1.1857 val acc 59.1721 best val_acc 62.337662\n",
      "epoch: 937, bulyan: at fang n_at 10 n_mal_sel 10 e 937 | val loss 1.1732 val acc 60.1664 best val_acc 62.337662\n",
      "epoch: 938, bulyan: at fang n_at 10 n_mal_sel 10 e 938 | val loss 1.2160 val acc 58.8068 best val_acc 62.337662\n",
      "epoch: 939, bulyan: at fang n_at 10 n_mal_sel 10 e 939 | val loss 1.2624 val acc 56.6356 best val_acc 62.337662\n",
      "epoch: 940, bulyan: at fang n_at 10 n_mal_sel 10 e 940 | val loss 1.1665 val acc 59.0909 best val_acc 62.337662\n",
      "epoch: 941, bulyan: at fang n_at 10 n_mal_sel 10 e 941 | val loss 1.2510 val acc 58.8068 best val_acc 62.337662\n",
      "epoch: 942, bulyan: at fang n_at 10 n_mal_sel 10 e 942 | val loss 1.3991 val acc 53.7338 best val_acc 62.337662\n",
      "epoch: 943, bulyan: at fang n_at 10 n_mal_sel 10 e 943 | val loss 1.2605 val acc 56.1080 best val_acc 62.337662\n",
      "epoch: 944, bulyan: at fang n_at 10 n_mal_sel 10 e 944 | val loss 1.1756 val acc 59.1721 best val_acc 62.337662\n",
      "epoch: 945, bulyan: at fang n_at 10 n_mal_sel 10 e 945 | val loss 1.1723 val acc 59.6591 best val_acc 62.337662\n",
      "epoch: 946, bulyan: at fang n_at 10 n_mal_sel 10 e 946 | val loss 1.2615 val acc 58.0763 best val_acc 62.337662\n",
      "epoch: 947, bulyan: at fang n_at 10 n_mal_sel 10 e 947 | val loss 1.3166 val acc 57.6096 best val_acc 62.337662\n",
      "epoch: 948, bulyan: at fang n_at 10 n_mal_sel 10 e 948 | val loss 1.2174 val acc 59.0909 best val_acc 62.337662\n",
      "epoch: 949, bulyan: at fang n_at 10 n_mal_sel 10 e 949 | val loss 1.1245 val acc 61.4854 best val_acc 62.337662\n",
      "epoch: 950, bulyan: at fang n_at 10 n_mal_sel 10 e 950 | val loss 1.1925 val acc 60.6737 best val_acc 62.337662\n",
      "epoch: 951, bulyan: at fang n_at 10 n_mal_sel 10 e 951 | val loss 1.3360 val acc 57.3864 best val_acc 62.337662\n",
      "epoch: 952, bulyan: at fang n_at 10 n_mal_sel 10 e 952 | val loss 1.2133 val acc 59.0300 best val_acc 62.337662\n",
      "epoch: 953, bulyan: at fang n_at 10 n_mal_sel 10 e 953 | val loss 1.1920 val acc 59.5982 best val_acc 62.337662\n",
      "epoch: 954, bulyan: at fang n_at 10 n_mal_sel 10 e 954 | val loss 1.2213 val acc 59.5576 best val_acc 62.337662\n",
      "epoch: 955, bulyan: at fang n_at 10 n_mal_sel 10 e 955 | val loss 1.3226 val acc 56.4935 best val_acc 62.337662\n",
      "epoch: 956, bulyan: at fang n_at 10 n_mal_sel 10 e 956 | val loss 1.4901 val acc 53.3888 best val_acc 62.337662\n",
      "epoch: 957, bulyan: at fang n_at 10 n_mal_sel 10 e 957 | val loss 1.4084 val acc 52.8815 best val_acc 62.337662\n",
      "epoch: 958, bulyan: at fang n_at 10 n_mal_sel 10 e 958 | val loss 1.4553 val acc 52.2321 best val_acc 62.337662\n",
      "epoch: 959, bulyan: at fang n_at 10 n_mal_sel 10 e 959 | val loss 1.4888 val acc 52.3336 best val_acc 62.337662\n",
      "epoch: 960, bulyan: at fang n_at 10 n_mal_sel 10 e 960 | val loss 1.5041 val acc 51.2987 best val_acc 62.337662\n",
      "epoch: 961, bulyan: at fang n_at 10 n_mal_sel 10 e 961 | val loss 1.6098 val acc 46.2662 best val_acc 62.337662\n",
      "epoch: 962, bulyan: at fang n_at 10 n_mal_sel 10 e 962 | val loss 1.5788 val acc 50.3247 best val_acc 62.337662\n",
      "epoch: 963, bulyan: at fang n_at 10 n_mal_sel 10 e 963 | val loss 1.8194 val acc 40.8685 best val_acc 62.337662\n",
      "epoch: 964, bulyan: at fang n_at 10 n_mal_sel 10 e 964 | val loss 1.7278 val acc 39.4278 best val_acc 62.337662\n",
      "epoch: 965, bulyan: at fang n_at 10 n_mal_sel 10 e 965 | val loss 1.6106 val acc 47.5852 best val_acc 62.337662\n",
      "epoch: 966, bulyan: at fang n_at 10 n_mal_sel 10 e 966 | val loss 1.5706 val acc 46.3271 best val_acc 62.337662\n",
      "epoch: 967, bulyan: at fang n_at 10 n_mal_sel 10 e 967 | val loss 1.3401 val acc 52.7597 best val_acc 62.337662\n",
      "epoch: 968, bulyan: at fang n_at 10 n_mal_sel 10 e 968 | val loss 1.2968 val acc 56.8385 best val_acc 62.337662\n",
      "epoch: 969, bulyan: at fang n_at 10 n_mal_sel 10 e 969 | val loss 1.2584 val acc 55.5195 best val_acc 62.337662\n",
      "epoch: 970, bulyan: at fang n_at 10 n_mal_sel 10 e 970 | val loss 1.2328 val acc 58.9286 best val_acc 62.337662\n",
      "epoch: 971, bulyan: at fang n_at 10 n_mal_sel 10 e 971 | val loss 1.2560 val acc 56.9399 best val_acc 62.337662\n",
      "epoch: 972, bulyan: at fang n_at 10 n_mal_sel 10 e 972 | val loss 1.2410 val acc 57.7110 best val_acc 62.337662\n",
      "epoch: 973, bulyan: at fang n_at 10 n_mal_sel 10 e 973 | val loss 1.1257 val acc 60.6940 best val_acc 62.337662\n",
      "epoch: 974, bulyan: at fang n_at 10 n_mal_sel 10 e 974 | val loss 1.1369 val acc 61.4651 best val_acc 62.337662\n",
      "epoch: 975, bulyan: at fang n_at 10 n_mal_sel 10 e 975 | val loss 1.1209 val acc 61.3839 best val_acc 62.337662\n",
      "epoch: 976, bulyan: at fang n_at 10 n_mal_sel 10 e 976 | val loss 1.1482 val acc 60.8969 best val_acc 62.337662\n",
      "epoch: 977, bulyan: at fang n_at 10 n_mal_sel 10 e 977 | val loss 1.2145 val acc 59.2127 best val_acc 62.337662\n",
      "epoch: 978, bulyan: at fang n_at 10 n_mal_sel 10 e 978 | val loss 1.3196 val acc 57.5487 best val_acc 62.337662\n",
      "epoch: 979, bulyan: at fang n_at 10 n_mal_sel 10 e 979 | val loss 1.1316 val acc 60.8969 best val_acc 62.337662\n",
      "epoch: 980, bulyan: at fang n_at 10 n_mal_sel 10 e 980 | val loss 1.1653 val acc 60.5114 best val_acc 62.337662\n",
      "epoch: 981, bulyan: at fang n_at 10 n_mal_sel 10 e 981 | val loss 1.2126 val acc 58.4213 best val_acc 62.337662\n",
      "epoch: 982, bulyan: at fang n_at 10 n_mal_sel 10 e 982 | val loss 1.2663 val acc 58.2995 best val_acc 62.337662\n",
      "epoch: 983, bulyan: at fang n_at 10 n_mal_sel 10 e 983 | val loss 1.1751 val acc 60.1461 best val_acc 62.337662\n",
      "epoch: 984, bulyan: at fang n_at 10 n_mal_sel 10 e 984 | val loss 1.2345 val acc 58.0966 best val_acc 62.337662\n",
      "epoch: 985, bulyan: at fang n_at 10 n_mal_sel 10 e 985 | val loss 1.1634 val acc 59.9432 best val_acc 62.337662\n",
      "epoch: 986, bulyan: at fang n_at 10 n_mal_sel 10 e 986 | val loss 1.1772 val acc 60.3896 best val_acc 62.337662\n",
      "epoch: 987, bulyan: at fang n_at 10 n_mal_sel 10 e 987 | val loss 1.1281 val acc 61.8709 best val_acc 62.337662\n",
      "epoch: 988, bulyan: at fang n_at 10 n_mal_sel 10 e 988 | val loss 1.1380 val acc 61.1607 best val_acc 62.337662\n",
      "epoch: 989, bulyan: at fang n_at 10 n_mal_sel 10 e 989 | val loss 1.2040 val acc 59.1518 best val_acc 62.337662\n",
      "epoch: 990, bulyan: at fang n_at 10 n_mal_sel 10 e 990 | val loss 1.2522 val acc 58.2792 best val_acc 62.337662\n",
      "epoch: 991, bulyan: at fang n_at 10 n_mal_sel 10 e 991 | val loss 1.1823 val acc 58.9286 best val_acc 62.337662\n",
      "epoch: 992, bulyan: at fang n_at 10 n_mal_sel 10 e 992 | val loss 1.1617 val acc 60.5317 best val_acc 62.337662\n",
      "epoch: 993, bulyan: at fang n_at 10 n_mal_sel 10 e 993 | val loss 1.2202 val acc 59.8417 best val_acc 62.337662\n",
      "epoch: 994, bulyan: at fang n_at 10 n_mal_sel 10 e 994 | val loss 1.2399 val acc 58.1575 best val_acc 62.337662\n",
      "epoch: 995, bulyan: at fang n_at 10 n_mal_sel 10 e 995 | val loss 1.1951 val acc 59.2330 best val_acc 62.337662\n",
      "epoch: 996, bulyan: at fang n_at 10 n_mal_sel 10 e 996 | val loss 1.1598 val acc 61.4245 best val_acc 62.337662\n",
      "epoch: 997, bulyan: at fang n_at 10 n_mal_sel 10 e 997 | val loss 1.1545 val acc 61.2825 best val_acc 62.337662\n",
      "epoch: 998, bulyan: at fang n_at 10 n_mal_sel 10 e 998 | val loss 1.2125 val acc 59.9635 best val_acc 62.337662\n",
      "epoch: 999, bulyan: at fang n_at 10 n_mal_sel 10 e 999 | val loss 1.1907 val acc 60.0446 best val_acc 62.337662\n",
      "New learnin rate  0.25\n",
      "epoch: 1000, bulyan: at fang n_at 10 n_mal_sel 10 e 1000 | val loss 1.0383 val acc 65.1786 best val_acc 65.178571\n"
     ]
    }
   ],
   "source": [
    "batch_size=250\n",
    "resume=0\n",
    "nepochs=1000\n",
    "schedule=[1000]\n",
    "nbatches = user_tr_len//batch_size\n",
    "\n",
    "gamma=.5\n",
    "opt = 'sgd'\n",
    "fed_lr=0.5\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "aggregation='bulyan'\n",
    "multi_k = False\n",
    "candidates = []\n",
    "\n",
    "at_type='fang'\n",
    "n_attackers=[10]\n",
    "\n",
    "arch='alexnet'\n",
    "chkpt='./'+aggregation\n",
    "\n",
    "for n_attacker in n_attackers:\n",
    "    epoch_num = 0\n",
    "    best_global_acc = 0\n",
    "    best_global_te_acc = 0\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    r=np.arange(user_tr_len)\n",
    "\n",
    "    fed_model, _ = return_model(arch, 0.1, 0.9, parallel=False)\n",
    "    optimizer_fed = SGD(fed_model.parameters(), lr=fed_lr)\n",
    "\n",
    "    df = pd.DataFrame(columns = ['epoch', 'loss', 'validation accuracy', 'best validation accuracy'])\n",
    "    while epoch_num <= nepochs:\n",
    "        user_grads=[]\n",
    "        if not epoch_num and epoch_num%nbatches == 0:\n",
    "            np.random.shuffle(r)\n",
    "            for i in range(nusers):\n",
    "                user_tr_data_tensors[i]=user_tr_data_tensors[i][r]\n",
    "                user_tr_label_tensors[i]=user_tr_label_tensors[i][r]\n",
    "\n",
    "        # for i in range(n_attacker, nusers):\n",
    "        for i in range(nusers):\n",
    "\n",
    "            inputs = user_tr_data_tensors[i][(epoch_num%nbatches)*batch_size:((epoch_num%nbatches) + 1) * batch_size]\n",
    "            targets = user_tr_label_tensors[i][(epoch_num%nbatches)*batch_size:((epoch_num%nbatches) + 1) * batch_size]\n",
    "            targets = targets.type(torch.LongTensor)   \n",
    "            \n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "\n",
    "            outputs = fed_model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            fed_model.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "\n",
    "            param_grad=[]\n",
    "            for param in fed_model.parameters():\n",
    "                param_grad=param.grad.data.view(-1) if not len(param_grad) else torch.cat((param_grad,param.grad.view(-1)))\n",
    "\n",
    "            user_grads=param_grad[None, :] if len(user_grads)==0 else torch.cat((user_grads,param_grad[None,:]), 0)\n",
    "\n",
    "        if epoch_num in schedule:\n",
    "            for param_group in optimizer_fed.param_groups:\n",
    "                param_group['lr'] *= gamma\n",
    "                print('New learnin rate ', param_group['lr'])\n",
    "\n",
    "        if n_attacker > 0:\n",
    "            n_attacker_ = max(1, n_attacker**2//nusers)\n",
    "            # if at_type == 'lie':\n",
    "            #     mal_update = lie_attack(user_grads[:n_attacker], z_values[n_attacker])\n",
    "            # elif at_type == 'fang':\n",
    "            #     agg_grads = torch.mean(user_grads[:n_attacker], 0)\n",
    "            #     deviation = torch.sign(agg_grads)\n",
    "            #     mal_update = get_malicious_updates_fang(user_grads[:n_attacker], agg_grads, deviation, n_attacker_)\n",
    "            # elif at_type == 'our-agr':\n",
    "            #     agg_grads = torch.mean(user_grads[:n_attacker], 0)\n",
    "            #     mal_update = our_attack_median(user_grads[:n_attacker], agg_grads, n_attacker_, dev_type)\n",
    "            # elif at_type == 'min-max':\n",
    "            #     agg_grads = torch.mean(user_grads[:n_attacker], 0)\n",
    "            #     mal_update = our_attack_dist(user_grads[:n_attacker], agg_grads, n_attacker_, dev_type)\n",
    "            # elif at_type == 'min-sum':\n",
    "            #     agg_grads = torch.mean(user_grads[:n_attacker], 0)\n",
    "            #     mal_update = our_attack_score(user_grads[:n_attacker], agg_grads, n_attacker_, dev_type)\n",
    "\n",
    "            # mal_updates = torch.stack([mal_update] * n_attacker)\n",
    "            # malicious_grads = torch.cat((mal_updates, user_grads[n_attacker:]), 0)\n",
    "        \n",
    "        # mal_updates = torch.stack([mal_update] * n_attacker)\n",
    "        # malicious_grads = torch.cat((mal_updates, user_grads), 0)\n",
    "            \n",
    "        malicious_grads = user_grads\n",
    "        \n",
    "        if not (malicious_grads.shape[0]==50):\n",
    "            print(malicious_grads.shape)\n",
    "            sys.exit()\n",
    "            \n",
    "        agg_grads, krum_candidate=bulyan(malicious_grads, 0)\n",
    "\n",
    "        del user_grads\n",
    "\n",
    "        start_idx=0\n",
    "\n",
    "        optimizer_fed.zero_grad()\n",
    "\n",
    "        model_grads=[]\n",
    "\n",
    "        for i, param in enumerate(fed_model.parameters()):\n",
    "            param_=agg_grads[start_idx:start_idx+len(param.data.view(-1))].reshape(param.data.shape)\n",
    "            start_idx=start_idx+len(param.data.view(-1))\n",
    "            param_=param_.cuda()\n",
    "            model_grads.append(param_)\n",
    "\n",
    "        optimizer_fed.step(model_grads)\n",
    "\n",
    "        val_loss, val_acc = test(val_data_tensor,val_label_tensor,fed_model,criterion,use_cuda)\n",
    "        te_loss, te_acc = test(te_data_tensor,te_label_tensor, fed_model, criterion, use_cuda)\n",
    "\n",
    "        is_best = best_global_acc < val_acc\n",
    "\n",
    "        best_global_acc = max(best_global_acc, val_acc)\n",
    "\n",
    "        if is_best:\n",
    "            best_global_te_acc = te_acc\n",
    "\n",
    "        \n",
    "        print('epoch: %d, %s: at %s n_at %d n_mal_sel %d e %d | val loss %.4f val acc %.4f best val_acc %f'%(epoch_num, aggregation, at_type, n_attacker, np.sum(krum_candidate < n_attacker), epoch_num, val_loss, val_acc, best_global_acc))\n",
    "        new_row = pd.DataFrame([{\n",
    "            'epoch': epoch_num, \n",
    "            'loss': val_loss, \n",
    "            'validation accuracy': val_acc, \n",
    "            'best validation accuracy': best_global_acc\n",
    "            }])\n",
    "        df = pd.concat([df, new_row], ignore_index=True)\n",
    "        df.to_csv('./no_attack.csv', index=False)        \n",
    "        epoch_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGzCAYAAACPa3XZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAACQ90lEQVR4nO2dd5wTZf7HP+nbK1soS+9NlLogoIiihwXFeqjYG3a9wtmwop6nnvdDbBzoKaJ4yllRBBULIEVUQJDedynL9t1syvz+yM7kmclM2mZL2M/79eJFMvNk5skkm+cz32qSJEkCIYQQQkgTYW7uCRBCCCGkdUHxQQghhJAmheKDEEIIIU0KxQchhBBCmhSKD0IIIYQ0KRQfhBBCCGlSKD4IIYQQ0qRQfBBCCCGkSaH4IIQQQkiTQvFBSAtm165dMJlMeOaZZ5p7KgF07twZV111lfL866+/hslkwtdffx3ytaeccgpOOeWUmM5nxowZMJlMMT0mIaRxoPggJAibNm3CjBkzsGvXroB9L774IubNm9fkc2rNVFdXY8aMGWEJHEJIy4Xig5AgbNq0CQ8//DDFRxiMGTMGNTU1GDNmTKOdo7q6Gg8//LCu+Lj//vtRU1PTaOcmhMQOig9CSEwwm81ISEiA2dw8PytWqxUJCQnNcu54ora2Fl6vt7mnQVo5FB+k2ZF99du2bcNVV12FjIwMpKen4+qrr0Z1dbVqrNvtxqOPPopu3brB4XCgc+fO+Nvf/gan0xnROXfv3o1bbrkFvXr1QmJiIrKzs3HRRRepLBzz5s3DRRddBAA49dRTYTKZlJiGzp07Y+PGjfjmm2+U7XIMQ0lJCe69914MGDAAKSkpSEtLw1lnnYWff/45YB61tbWYMWMGevbsiYSEBLRt2xYXXHABtm/fbjh3SZJwww03wG634/333w/r/fbv3x+nnnpqwHav14v27dvjwgsvVLY988wzGDlyJLKzs5GYmIjBgwfjvffeC3kOo5iPV155Bd26dUNiYiKGDRuGb7/9NuC1dXV1ePDBBzF48GCkp6cjOTkZo0ePxldffaWM2bVrF3JycgAADz/8sHLdZ8yYAUA/5iPc70vnzp1x9tln47vvvsOwYcOQkJCArl274o033gj5voHIrtmbb76JYcOGISkpCZmZmRgzZgy++OIL1ZjPPvsMY8eORWpqKtLS0jB06FDMnz9fNV8x3kZGG0sjfyYLFizA/fffj/bt2yMpKQnl5eUx+55KkoTOnTvjvPPO031deno6brzxxrCuI2k9WJt7AoTIXHzxxejSpQtmzpyJdevW4bXXXkNubi6eeuopZcx1112H119/HRdeeCHuuecerFq1CjNnzsRvv/2GDz74IOxzrV69Gj/88AMuvfRSdOjQAbt27cLs2bNxyimnYNOmTUhKSsKYMWNw++2344UXXsDf/vY39OnTBwDQp08fPP/887jtttuQkpKC++67DwCQl5cHANixYwcWLVqEiy66CF26dEFxcTFefvlljB07Fps2bUK7du0AAB6PB2effTaWLl2KSy+9FHfccQcqKiqwZMkSbNiwAd26dQuYt8fjwTXXXIN33nkHH3zwASZOnBjW+73kkkswY8YMFBUVIT8/X9n+3Xff4cCBA7j00kuVbf/85z9x7rnnYsqUKairq8OCBQtw0UUX4eOPPw77fDJz5szBjTfeiJEjR+LOO+/Ejh07cO655yIrKwsFBQXKuPLycrz22mu47LLLcP3116OiogJz5szBhAkT8OOPP2LQoEHIycnB7NmzcfPNN+P888/HBRdcAAAYOHCg4fkj+b5s27YNF154Ia699lpMnToV//73v3HVVVdh8ODB6NevX9D3Ge41e/jhhzFjxgyMHDkSjzzyCOx2O1atWoVly5bhjDPOAOATvddccw369euH6dOnIyMjAz/99BMWL16MP/7xjxFdf5lHH30Udrsd9957L5xOJ+x2OzZt2hSz7+nll1+Op59+GiUlJcjKylLO+9FHH6G8vByXX355VPMmxzESIc3MQw89JAGQrrnmGtX2888/X8rOzlaer1+/XgIgXXfddapx9957rwRAWrZsWdjnrK6uDti2YsUKCYD0xhtvKNsWLlwoAZC++uqrgPH9+vWTxo4dG7C9trZW8ng8qm07d+6UHA6H9Mgjjyjb/v3vf0sApGeffTbgGF6vV3kdAOnvf/+75HK5pEsuuURKTEyUPv/883DfqiRJkrRlyxYJgPSvf/1Ltf2WW26RUlJSVNdDe23q6uqk/v37S+PGjVNt79SpkzR16lTl+VdffaW6VnV1dVJubq40aNAgyel0KuNeeeUVCYDq2rndbtUYSZKkY8eOSXl5earvxeHDhyUA0kMPPRTwHuXvkUwk35dOnTpJAKTly5cr2w4dOiQ5HA7pnnvuCTiXlnCu2datWyWz2Sydf/75Ad8P+fMuLS2VUlNTpeHDh0s1NTW6Y+T5itdeZuzYsarrKn8mXbt2DZhjLL+n8vdr9uzZqv3nnnuu1LlzZ9XcCZEkSaLbhbQYbrrpJtXz0aNH4+jRoygvLwcAfPrppwCAu+++WzXunnvuAQB88sknYZ8rMTFReexyuXD06FF0794dGRkZWLduXVTzl3E4HErcg8fjwdGjR5GSkoJevXqpjv3f//4Xbdq0wW233RZwDK37oK6uTrmT/vTTT5W75HDp2bMnBg0ahHfeeUfZ5vF48N577+Gcc85RXQ/x8bFjx1BWVobRo0dHfF3WrFmDQ4cO4aabboLdble2X3XVVUhPT1eNtVgsyhiv14uSkhK43W4MGTIk6s8j0u9L3759MXr0aOV5Tk4OevXqhR07doQ8VzjXbNGiRfB6vXjwwQcD4mLkz3vJkiWoqKjAX//614D4lYakEU+dOlU1RyC239OePXti+PDheOutt5R9JSUl+OyzzzBlyhSmQJMAKD5Ii6Fjx46q55mZmQB8P+aAL07DbDaje/fuqnH5+fnIyMjA7t27wz5XTU0NHnzwQRQUFMDhcKBNmzbIyclBaWkpysrKGvQ+vF4vnnvuOfTo0UN17F9++UV17O3bt6NXr16wWkN7P2fOnIlFixbhvffei7o+xiWXXILvv/8e+/fvB+CLBzh06BAuueQS1biPP/4YI0aMQEJCArKyshR3R6TXRf48evToodpus9nQtWvXgPGvv/46Bg4ciISEBGRnZyMnJweffPJJ1J9HpN8X7fcP8H0H5e9fMMK5Ztu3b4fZbEbfvn0NjyPH+vTv3z/kOSOhS5cuAdti/T298sor8f333yvXdeHChXC5XLjiiiti+l7I8QHFB2kxWCwW3e2SJKmex+Iu6rbbbsPjjz+Oiy++GO+++y6++OILLFmyBNnZ2Q3OBHjiiSdw9913Y8yYMXjzzTfx+eefY8mSJejXr1/Ux54wYQKSk5Px9NNPo7a2NqpjXHLJJZAkCQsXLgQAvPvuu0hPT8eZZ56pjPn2229x7rnnIiEhAS+++CI+/fRTLFmyBH/84x8DPodY8uabb+Kqq65Ct27dMGfOHCxevBhLlizBuHHjGvx5hPt9Cff7p6U5rpnRe/J4PLrbtVYPIPbf00svvRQ2m02xfrz55psYMmQIevXqFfGxyPEPA05J3NCpUyd4vV5s3bpVCf4EgOLiYpSWlqJTp05hH+u9997D1KlT8Y9//EPZVltbi9LSUtW4YAuX0b733nsPp556KubMmaPaXlpaijZt2ijPu3XrhlWrVsHlcsFmswWd74gRI3DTTTfh7LPPxkUXXYQPPvggLIuJSJcuXTBs2DC88847uPXWW/H+++9j0qRJcDgcypj//ve/SEhIwOeff67aPnfu3IjOBUD5PLZu3Ypx48Yp210uF3bu3IkTTjhB2fbee++ha9eueP/991XX9aGHHlIdMxLhGcvvSzDCvWbdunWD1+vFpk2bMGjQIN1jyUHGGzZsCLDYiGRmZgZ8VwGftUfPqqRHrL+nWVlZmDhxIt566y1MmTIF33//PZ5//vmw5kJaH7R8kLjhD3/4AwAE/KA9++yzABBRJobFYgm4K/3Xv/4VcOeYnJwMALo/9MnJybrb9Y69cOFCxd0hM3nyZBw5cgT/93//F3AMvTvm8ePHY8GCBVi8eDGuuOKKqO5OL7nkEqxcuRL//ve/ceTIkQCXi8VigclkUl2HXbt2YdGiRRGfa8iQIcjJycFLL72Euro6Zfu8efMCrptsdRDf96pVq7BixQrVuKSkJAD6n4eWWH5fghHuNZs0aRLMZjMeeeSRgM9Oft9nnHEGUlNTMXPmzAALl3htunXrhpUrV6qu68cff4y9e/dGNO9Yf0+vuOIKbNq0CX/6059gsVhUWVSEiNDyQeKGE044AVOnTsUrr7yC0tJSjB07Fj/++CNef/11TJo0SbeOhRFnn302/vOf/yA9PR19+/bFihUr8OWXXyI7O1s1btCgQbBYLHjqqadQVlYGh8OBcePGITc3F4MHD8bs2bPx2GOPoXv37sjNzcW4ceNw9tln45FHHsHVV1+NkSNH4tdff8Vbb70VcEd65ZVX4o033sDdd9+NH3/8EaNHj0ZVVRW+/PJL3HLLLbp1EyZNmoS5c+fiyiuvRFpaGl5++eWIruHFF1+Me++9F/feey+ysrIwfvx41f6JEyfi2WefxZlnnok//vGPOHToEGbNmoXu3bvjl19+iehcNpsNjz32GG688UaMGzcOl1xyCXbu3Im5c+cGXIuzzz4b77//Ps4//3xMnDgRO3fuxEsvvYS+ffuisrJSGZeYmIi+ffvinXfeQc+ePZGVlYX+/fvrxkjE8vsSjHCvWffu3XHffffh0UcfxejRo3HBBRfA4XBg9erVaNeuHWbOnIm0tDQ899xzuO666zB06FD88Y9/RGZmJn7++WdUV1fj9ddfB+BLIX7vvfdw5pln4uKLL8b27dvx5ptv6qZnG9EY39OJEyciOzsbCxcuxFlnnYXc3NwGXl1y3NIsOTaECMgpkocPH1Ztnzt3rgRA2rlzp7LN5XJJDz/8sNSlSxfJZrNJBQUF0vTp06Xa2tqIznns2DHp6quvltq0aSOlpKRIEyZMkDZv3qybwvjqq69KXbt2lSwWiyqVtKioSJo4caKUmpqqSh2tra2V7rnnHqlt27ZSYmKiNGrUKGnFihUBaZCS5EvRvO+++5T3k5+fL1144YXS9u3bJUlSp9qKvPjiixIA6d57743ofUuSJI0aNUo3BVVmzpw5Uo8ePSSHwyH17t1bmjt3bkAaqySFTrUV59qlSxfJ4XBIQ4YMkZYvXx5wLbxer/TEE09InTp1khwOh3TiiSdKH3/8sTR16lSpU6dOquP98MMP0uDBgyW73a5Ku9WbY7jfl06dOkkTJ04MuBZ6n1lDrpkk+VJXTzzxRMnhcEiZmZnS2LFjpSVLlqjGfPjhh9LIkSOlxMREKS0tTRo2bJj09ttvq8b84x//kNq3by85HA5p1KhR0po1awxTbRcuXBgwj1h+T0VuueUWCYA0f/78kNeNtF5MktSIUWSEEEJaFXfddRfmzJmDoqIixU1GiBbGfBBCCIkJtbW1ePPNNzF58mQKDxIUxnyQ44rKykpVjIAeOTk5hmmV8UhRUVHQ/YmJiQFFvQiJJYcOHcKXX36J9957D0ePHsUdd9zR3FMiLRyKD3Jc8cwzz+Dhhx8OOmbnzp3o3Llz00yoCWjbtm3Q/VOnTsW8efOaZjKkVbJp0yZMmTIFubm5eOGFFwxTiQmRYcwHOa7YsWNHyHLYJ5988nHVev3LL78Mur9du3ZBq2oSQkhTQ/FBCCGEkCaFAaeEEEIIaVJaXMyH1+vFgQMHkJqayk6IhBBCSJwgSRIqKirQrl27gM7NWlqc+Dhw4AAKCgqaexqEEEIIiYK9e/eiQ4cOQce0OPGRmpoKwDf5tLS0Zp4NIYQQQsKhvLwcBQUFyjoejBYnPmRXS1paGsUHIYQQEmeEEzLBgFNCCCGENCkUH4QQQghpUig+CCGEENKkUHwQQgghpEmh+CCEEEJIk0LxQQghhJAmheKDEEIIIU0KxQchhBBCmhSKD0IIIYQ0KRQfhBBCCGlSKD4IIYQQ0qRQfBBCCCGkSWlxjeUIIYQQ0jjsPlqFud/vQk6qA9NO7d5s86DlgxBCCGklHCyrxbwfduG/6/Y16zwoPgghhJBWgtcrAQCs5tBt7xsTig9CCCGkleCuFx8Wc/Mu/xQfhBBCSCvBo4iP5p0HxQchhBDSSvDQ8kEIIYSQpsTNmA9CCCGENCV+ywfFByGEEEKaALfXCwCwmCg+CCGEENIEeKV6t4uF4oMQQgghTYDbQ7cLIYQQQpoQDwNOCSGEENKUeOrdLmbGfBBCCCGkKVAsH4z5IIQQQkhT4I/5YJExQgghhDQBSrYLYz4IIYQQ0hTIFU4Z80EIIYTEKUVltfh5b2lzTyNsmO1CCCGExDmnPvM1zpv1PTYXlTf3VMJCiflgwCkhhBASf0iShBqXBwDw3dYjzTyb8JBTbVlenRBCCIlDKp1u5XFNnacZZ6LP4g0H8cM2tSjyyL1dmtntYm3WsxNCCCFxyuEKp/L4kPC4JVBUVoub3lwHANjxxB9grhcbbsZ8EEIIIfGLKD5KqupieuxjVXVwe7xhjZUkSQkklSmrcSmPjwpz83oZ80EIIYQ0Oz9sO4IHFm2I2HUiCo46A6FQ6/Lgwf9twPfbwo8J2XesGic+ugQXvrQirPFT567GKc98hT1Hq1XnlSkurwUAPLV4M179dicAxnwQQgghTUpJVR3WC+mxf3xtFf6zcjdeWLY1ouOIgqPOrS8+Xl2+A2+s2I0pr60K+7iLNxQBgGqORjjdHiz//TD2ltTg+S9/V7ZXCfEoRWW1qHS6Mfvr7co2ul0IIYSQJuSUv3+FSbO+x8odR1XbNx6ILF3W5ZGEx/riY5dgjQiXtASb8jiU6+VIpd/6crCsVnlcJVhxiitqA6w6LK9OCCGENCHltT6rwJJNxartFbWugLGSJOH2t3/Cox9vCtjnCsPyoWdgWLnjKIoEoaAl2eHPBSmpDh5Lcqjcf5wVO47i6cWbUVPnUVk+KmvdKjcM0PyN5ZjtQgghpFXidKsX5Ipad8CYvSU1+PDnAwCAP03ohQSbRdknWiWMYj60Zcx/2nMMl76yEgCw68mJuq9xe/3HOlJRh9zUBMP3oM2yefHr7ThW7UK/dmnKtlqXN+C9srw6IYQQEiE/7izBtkOVDTqG06UWDKLlo7rOjcc/2YRf9pcq2w6Vqxd60e1iaPkQVllJklSuHSOXijivw5XBU3iP6Oz/cP1+leVj2+FKfPnbIdWYuIv52L9/Py6//HJkZ2cjMTERAwYMwJo1a5T9kiThwQcfRNu2bZGYmIjx48dj69bIgngIIYQQI/aWVOPil1dg/LPf6O77avMhnVcF4nRrxYd/wf7n0q149duduHX+T8q2onK1q0S0UBhZPkyChaHW5UVemt+KsadEPx5EtFJo3SVaal2B563SuF0++vkAnvxss2pMcxcZi0h8HDt2DKNGjYLNZsNnn32GTZs24R//+AcyMzOVMU8//TReeOEFvPTSS1i1ahWSk5MxYcIE1NYa+7cIIYQQmSqnGz/tOQZJknT3i4u2tr7F6Ke/wtXzVgdU9gSA8lqXalHWuiKqhaDMX/eVBby+WCM+wrF8iG+hwulSzXdPSTUkSVLFbfjm5T+WUSBrqPMeCVF3JK5iPp566ikUFBRg7ty5yrYuXboojyVJwvPPP4/7778f5513HgDgjTfeQF5eHhYtWoRLL700RtMmhBByvHLd62uwYsdR/PPSQThnYDscqXQiNy0B/1m5G9/+fhjXnOxfd8prXMhMtgccY/WuYxjZvY3yvNblwYgnlqqCOY0WbqN9hzXxFe4wsl1q6vxip8rpUVlLnG4vHvl4E+Z+vwuzp5yEswa0VbaHOm6o/fNX7Qn6uriK+fjwww8xZMgQXHTRRcjNzcWJJ56IV199Vdm/c+dOFBUVYfz48cq29PR0DB8+HCtW6BdLcTqdKC8vV/0jhBASW8prXTGvwtlYrKhPgZ33wy68s2Yvhj2xFPO+34kHFm3AF5uKsein/crY0prADBU9dh6pQnWdRyUgtG4XAIq1Rc+Nol3oVW4XAyEjWlMqa92qYzjdXsz9fhcA4MnFfreIU3C1uNz61p9Q5w1Fkt0SelAjEpH42LFjB2bPno0ePXrg888/x80334zbb78dr7/+OgCgqMhXGCUvL0/1ury8PGWflpkzZyI9PV35V1BQEM37IIQQYoAkSRg44wuc9OiSkDEELYlqpwePfORLcZ3xkT/VVYzNOFZdB0mSsP1wpaGbBtDvvSKLDzH8QU7D1VvU3YLL5Nd9ZdhxpEp5Ho742Hm0SuWq+e/afcpjOQDU5fGiQnANubzRWT6C0adtGsb3zQs9sBGJSHx4vV6cdNJJeOKJJ3DiiSfihhtuwPXXX4+XXnop6glMnz4dZWVlyr+9e/dGfSxCCCGBiAugXn2JWpcHO4WFtKVQVedG15zkgO1mQS2UVtfhhaXbcNo/vsGzS/wVPiWohciB0pqA46zdfQyDH10CMWxEtg7pWT5kN8uB0hqc83/f4ZNfDir7RFGhfQ8yG/eXqVw13/x+WHlss5jh9nhxxnPLFWsIANz3wQYsXGO8LhoFuhoxtmcOPr7tZFUhs+YgIvHRtm1b9O3bV7WtT58+2LPH51vKz88HABQXqwu3FBcXK/u0OBwOpKWlqf4RQgiJHeICqBdoePHLK3DqM1/jx50lTTktXUTrhVGvFTFN9FiVC8/VlxX/17Jtyvbnv9yq1OcAgIM64gNQN10DfNdig0YkyMjt6LfqpPjWeby6lhfxPWw8UK5y1ajek8WEXUerdEXgn977BaUGxcYidbukJlibPdMFiFB8jBo1Clu2bFFt+/3339GpUycAvuDT/Px8LF26VNlfXl6OVatWobCwMAbTJYQQEinVTv8CqM0OAYBf6jM73g1yh91U1AhuIavFpBuXIb6HY0EqgN7+tj9NttIZnrvpcIUTt739k24dDNnt4jVw7+hZP0Tht+FAmaFYsJrN2B2kFLteATTfOSMTH2KRtOYkomyXu+66CyNHjsQTTzyBiy++GD/++CNeeeUVvPLKKwB8+cx33nknHnvsMfTo0QNdunTBAw88gHbt2mHSpEmNMX9CCCEhqBRjCIIsVmIaanMhtoK3ms26MSqiG6msxgWH1awrUkRq3eHHuhi5oGTxYRRbUufxwm5V39OLwq+02oUDpfplJ9bvLcXrK3YbzsnoczNy9xiRYGsZtUUjEh9Dhw7FBx98gOnTp+ORRx5Bly5d8Pzzz2PKlCnKmD//+c+oqqrCDTfcgNLSUpx88slYvHgxEhKMy8MSQghpPERRURcke6IyhuLD5fFiyqur0LttKh45r3/YrxPv8LV1OGRqXOqA02SHFU538EyeWgMXTiTIrhijGNA6txdw+B5XOt0wQW35AICSKuOKpcuFGBAteiLj+21H8EF95o/JpK4pYkR6YvPGeshE3Nvl7LPPxtlnn22432Qy4ZFHHsEjjzzSoIkRQgiJDaKlIJjlo7qBC7TL48WhCifaZyRi1Y4S/LjL9y8S8SFaOpwur25ApTjPY9UuJNktKAkRL1sTgywfOV7DY7DK/2/9fizZVIxnLjoBF7+8Al6vpFQgla0z2hiTcNH73Ka8tkp5nJ5oQ2l16LTjjMTAmijNQcuwvxBCCGk0msrtcueC9Rj15DL8sP0I3l/nTyMVe5i4PF78a+lWrN2tH9wquk8qnG5dd4ralVGHZHvo++jYiA/Z8qEvPh7+aBN+2H4UZzy3HPuO1eCAkFnUJsVnEvl2a2Dl1XAIldUSrkWjpVg+KD4IIeQ4p1ow/QdbxLQugkj55Fdf6umjH/+G94VCYNXCwv/ZhiL8Y8nvmDxbv/BkONkb1aLbpcqFxDAKZhllzkSCuz6jJZQQ0LqvzCYgM1l/0U9LCM8BEeq6hCPAAIR1rZqCiN0uhBBC4gsx0yNYgGKwBa7S6UaizRKQprnvWDUe/+Q3XD+mq7Ltt4PqStVVTrdSV6JE6MJaVuMKuBM3ivMQEYVErcuDFIMFXJ5qTZ0Hq2KQRvzpr0VYtvkQ2mUkRvS6ZLsVSTb9OWYl25XCZsEIldUSbsVSm6Vl2BxaxiwIIYQ0GuKCbtTGHTAOWDxUUYthj3+Jq+b+GLDvhjfW4rMNRbhCiD/QUl7jX1wdQqrnlqKKwLlqurS2S09Ax6wk1bYqUUx5vTCqWiFnnrywLDad1SudbhyprFNSk8MlyWFBgoE4yEgKLwYjlPgQe9aInNgxQ/XcYW0Zy37LmAUhhJCo2VtSjYc/2hjQdVXGqAHa+r2luO711cpzg1AGfL/tCKrrPPh265EA68imeitHVRC3hihaxLgSvRgTrUuja05KwIIpxm+4PVLAwtw7PxWAr928xythZX2vmObCZ/nQFx+ZSeHFYATLUgKAZIf/+BcO7gAAOKljBt64ZhgWTRuF8X1y0Tk7CYXdssOcdeNCtwshhMQ5o5/+CoBvsZ15wYCA/aK1o04QIpNmfa8aZ1S/QnSNjHpqGZ656ASM7ZmDXUI9DJvFZOjSOVhWC0mS8MD/NuDNlf5uq3pBoFrLR4LNElA7Q8TlkQLOm5uWgM31VpUalwfZyQ7D1zcFSQ6LoVskLy28MhSh3S7+5fzx8/vjtN65GNmtDVITbBhUkIFXrxwCSVKXpm9OaPkghJA4RlyUftlXqj9GMGm4gsR1GKWQioLgcIUTU//9Iw6U1uDbrf66FL3qrQ1G7D5arRIeAHDLW+sC3EDamI8Emzmo+HB7vQELsyiWPB4JOanhuTayk+3o3z72LT6S7FbDQM9O2YG9a/QI6XYRju+wWnDWgLZIF6wqJpOpxQgPgOKDEELiiu+2HsGoJ5cpBamqNb1DPv7lQMBrtKmuRuilkNa6PFi6+VDA9pFPLsNzX/pjKSzm4MuJ0Xm//E3dC0ybWptgs8AeJEjS7QnMPklP9FsBPJIUVhO1XnmpWHP/eFw9skvIsVpCBXsm24NZPsKzyoTKdumeF1z8tTQoPgghpIXxyvLtOPmpZdhb4uv18cXGIqzbcww7j1Th8jmrsL+0Bte9sQYAAsqPP/7JbwHHcxnEfGgRtcf6vaU4UunEwx9twntC63eREqFgVqgKokbVU7cWq5u0acVHYki3S6DlI1UQGx5v6NRYwNdHxmQyBT2XEdqAWC1JDqtqTiJy/Q+RG8d0xR8GqJuxhrJ8TBrUDleN7KzrdmuJMOaDEEJaGE98uhkA8MryHZg6sjNu+M9aAMDpffOUMbIBXVu/Qq+CpthJtS6MVNv/rd+POxasx9ieOaq278EQa2/ocbhCv6y4WIgLCBQfXdok42CZfkdawFf4y6UJxkxxWGE1m+D2Sj7xUX/MU3vl4Kst+u9HTkGNRnzkpDqUGBM9ku0WdMhUp+fmpTlwVv+2OLl7m4Dxgztl4rbTeiDFYcXS3w7haFVd0M8N8AmuGef2i3juzQUtH4QQ0kKxWczYcdhvGRDdJ3KgojZoU888L2a7BEu1rfN44fVKmPHhRgAIW3gAQFmI0t6HK/XFh9Ng/l3aJOOKEZ1w+YhOQQWBnmUjxWFV4hs8kl98GFkfAF/ALICgLh4jQr0myW5VWUeuGNEJX997Kmac2083DsNmNSPFYcXTF56AU3vnAgi0fOh1J44naPkghJAWhLiIZyXbVAtrgbCAZSb7gijDKRsertsF8AmQY2H0CNESqlCWkeVD221WDjg9q38+/nxmbwChF/dqTWXWZIcVFpNvUfcK4sSoFgbQMMtHqNck2S3okOn/7O6b2Cdoa3uH8H7leWkDhed+vzPiebYkKD4IIaQFsb/U72KQJLUlQ6xO2a2NL0tCL9bC45VUlUj13C5GabXaVNdYccTQ8qHNdpEbsfkX51CLe21Aeq4ZVtny4fXXAUlxGC/41vprG2kFUJsldJxIssOK/PQEPHh2X1gtpqDCA/BZPmTs9RYZrWh8TIjt+eZPp0Q055YA3S6EEBIl81ftwQ1vrAkI+jSi1uXBTf9Zi3lB7lrFdvHVLo9KfFQK1gVT/Z29nuVj37Fq1XO9ImPaBVsmnPLm4XJ63zwloHLxhmLdMVrLh/x+HTZhAY7QGmGzmBV3hluI+UhxGLtd5EU+0nNlJztCCpaUeovLNSd3wZWFnQP2DyrIUD236Vg+gsV8FGQGD3htiVB8EEJIlPztg1/xxaZi/GfFbvx2sDxg0dey4Mc9WLyxCDM+2qTaLi74YsBlTZ1HJWzEjBFvveVCT3zsOKzuLy/eNcvm+0MV+tVQ9brIRsurVw7BwA7pAIwtH1oRJJ9fdLXYLZE1Q7NbzIrlxytJyjGTg1k+zLLlI7JaGOcNahdUsLTPSMRZmswVLQtuGKFcJ+0cZCtIsFTbllS/I1woPgghpIGs2HEUZ/3zW5z81FdBx2084G+4JtUHQl780goMmPGFUiBMKz5EwVEhPJbbu+tZMLTdad3eQMvHgVJ98dHQzrZaUoLEWQCBqcJyAGpDLB9Wiwlmk9/t4rd8BIn5qD+H6O4JVb/jtnHdcfcZPQ1jUuZfPxzf/OkU5KYGr2KaYLOgl1CnQy286mM+wkgXjicoPgghpIF8vSWwCJceYiBnhdONPSVV+HFXCercXkWYiDEQ1S6PSnBU1vpfX+f24Pkvf1eKjYloFyqXTnn1onL99NWjlYGpug0hVdNxtkNmIr7986mYd/VQAIHiQw4OjSTmQ4vNoo75CCvgtH58mxR/NdS26cFFw7RTu8NhNa5DkpZgU2JJQmEVrR2WQOFF8UEIIUSFUdbj+r2lmPnpb0otDtE6XlJZp8pCkRdh0QVTU+dWNV8TrSCfbyzG819uxYc/B1Y01Zro9VJtD5bpWz6M3COXDCnQ3Q4AnbONYw607e6Hds5CQVaS0s01wO1S/1xc0CPtxGqzmBS3S9iWj/oFXyzNridWZFFz7cldlMDRRIMA0kjmLVtqAKgCUmUXTDiF0uIJZrsQQkgMkSRJCQa9cPYPcHslVDrdePz8AUqcBgDcvuAnFAkCQHa3iMKhus6jEg6VIdJZZcTgxAOlNVghdHVduHYfxvfNM6xIamT5SA/SfbVzm2TsOqof76ItbS4LMXlh1ga4ys8d1kDXQ7j4Ak59jz2SP9slmBiQLQ8mk74FQua8Qe3xpwm9VGXRtdadYK83Qjitap5Kqm2IImPxBi0fhBASBuEWdXJ5JNS6PKiodSmxFrJ1QjzGL/vKcEiofSHf8Ts14kN8TUWY4kOsCTHyyWUB+2/8z1rD+iBGZdCDBWLm6JQIl9FaG6452dc7Rb6711o+6nSEQsQxH2azEkDqFSwfwY6jJxQGtE/XGWdCfnqCSqQYWVSsEQSvioYNMd7FqM5HvEPxQQghAMpqXHjx6226GStHKp0Y9viXeGDRBnyxsQj/W7/f8Dhurxfjn/0GA2Z8oWyTRYM7iICR7/hF8eF0e1WdZisMhIGWcEz0K3eU6G6vMjhHiU7ZdplglUNFq8D1o7tgWJcsAL5aHIBewGnDYz7sVpPi4nJ7/dkuoSqlyiyaNgpXjeyMu8/oGTBOT1AYxZJEYvnwCLVY7DoxH9rPNL++wm2XNuF1xW1pUHwQQlodHq+E1btKVJUxH/zfBjy9eAumvLYqYPwbK3bjaFUd/rNyN274z1rcsWC9quy5iMstYd8x/WBOr0FhL8BvARDdEL8dLMeSjfr1MYIRzl2yUcyHnuXjDwPycVrvPJ3RPtISjT34oogQO98m1G93eyVVyXc9oRCp28Vq9qfa7j9Wo3T+TbIbz1PM8hlUkIEZ5/ZDWoIN79wwAu2EwFOLKVB8aONaZCIRH6J7zRpGtktSfdrwk3HSSE4LxQchpNUx9/uduOilFbixvmEbACz9zZexsrs+dmHu9ztx7bzVcLo9utVA1+0p1T12ZZBUVXcQv70sOrTBouFaO0T+seR3bDtUETRDQluSXEbP8nFW/7Y4rU8u3rhmGLrmBN5pi0GaWkR3jdWsH1RZK7xnpchYQ9wuFpMidO5Z+DPKanxZQmKdjw6ZiariXtoGfTLDu2bji7vHKs/1jFepMXC7GFnFlCJjBkHE4WbTtDTic9aEENIA5n6/CwDw7dYjyjZtTMfDH23C0s2H8N7afdAzWGw+WB64EcGDQoNZPuQ7/lgV+Trz+W+VRVePaoPFttIZuN1uNcNkMmFMzxzd2hfaoFIR8e5fLPkuCgqXytXkO39CA+p8+IqMBW4XLR89clOwaNoo5XmVwfUA1EJI7zM0tHyYI3G7GIkP/fLqsrUo0qJoLQWKD0JIq0PsdSJjJAzKalyQELjPKCW10hm44IvxB0Yo4iPK3iqZSTZ0z01Rnru9EkqjaBCnZxERF/9qHXFitPgC2lLh/oXSYvbHZbj03C6W6GM+rBazrnskWNGwmiAWK9Fioys+DGM+IrF86H/uNqXOh/q8rvrvkiUOq5sCFB+EkFaI3l2mkfgwMlboWQiMtssLsDeY+NCp8xEJV4zohIkD2qq2ldVEXjBMtgBkJfuLbYkxF1qLic1iCrqoW1WCQ73k+PuW6LhdBMuHw8C1MKZnju52m8UUUHLcbjGrhJD2k6gy+DwBdfqtnkZok+JAWr0AK+yarWyPRBgYueSMYj7k73CkjfBaCvE5a0IIaQB6NRNEXSDGeHi8kq4AMcoK0dsuLyDBLB9Hq+rw2rc7lJiTSLGYzQEWgsmzV0R8HHn+uan+9FmxAJa2/LrVbA4ayGkU8wGIC6vvurg9XuUahRPz8e+pQ3CC0BPFf05zwLmSNH1d5I9CFjCXj+hk+B7Urwv8DBNsFnxy+2j88NdxqrgSk471xQij74bdoLeLLEa07zNeYJExQkirw60TiGkxmeBBYLM2j1fP6WJcD0Mv5sNi8VfbNGLt7mNYu/tYsGkHxWKOjf9fFh9pQhCp6BLQWj6s5uCWD6OYD6B+YXX6F1LRAiIKjk7ZyUi0WZDssKrcXVaLGXOuGooXlm6Fw2rGq9/uVM5p1iz8yQYC6ZUrBuP34grdmh56eAxMYQVZviqvQcJ6gh83VMBpQMxHfcBpBHElLYn4nDUhhDQAl/BD/9Tizfjf+v2qhVFcYL2SpJu6amT50MtOkd0t4RYqiwaL2RxxSqoesqgSBYVo8teWUreGcrsIi6M2+0ObySEWHBNTdHNSHVg5/TR8/9dTA47fJsWBR87rj175aco2i9kUIHSKytWpxbKbJMFmwcAOGWFbKUKJi2g/YcOYD4OAU/m7FElGTUuC4oMQ0uoQLR+zv96OOxasV/24i2mX1XUefKXTOM6o+6ue5UNeKIzummOBxewPTmwIsqgSRUP3HH/H1ZevGIIRXbOE85qRKcSHaFG7XTQxH1b1wloup8TaLQHiIT3JphIkWrTp0NrXy5/B85cMwokdM3DfxD6GxwpGsIwlvXmES+iYD23AaXy7XSg+CCGtDj0DhOhzF4XFnO92YvvhqoDxRgGKetku8rGDBZw2lFCWj1tO6RbWceQp2iwmLP/TqfjglpHoKFg7uuem4NUrhwivkMJOtdUulNq+JXJqcLC6IUZor6xWA3Ssd4tMOrE9PrhlFNqmJ0Z8DiC09Sraj1hutKdFr7y6GIfEOh+EENICOFZVhyc/24xth/QrkIZDsMwHGcOYDz23S/1KESzgNFyMBIbFFFiqXOacE9rhwsEdIjqP1WJGx+wknNgxM2CfKChCvSWrJr1WxK5xu8jiIy0K8aFFG6A5M0aVQBvLePXwef0wvEsWXrlisGq7Xnl10UVDtwshhLQAHv1kE176ZjsueukHZVukpnCjeI5w0Gv+FkvLh1FnVovFHNCkTXxNpCmZtiDmfFEAydf25O5tQo41ivmQ3S6lDbB8aNGmLBv1X4mUUJaPaD/h9hmJeOfGQpzRL1+1XQw4la+1qhQ73S6EEBI7vtxUjGe/2KISDr8dLMcf/vktlm0O7HdytNKJJZuKsfz3wwCAY/UFtrYUVWDwY19iznc7wz63kVUjHD7+5WDANkkCPvv1oDKnhiDWvxCxmk24aEgHnNorsPaFwxqYhhuKYDUqzKqiW77/X7lyMN67qRA9hEJngNotoA3qlONBbp2/Du+u2dsgt8tZ/fORk+rA2QN9tU60XXsbGox7+2k9kOKw4k9n9go6LtqYDyPSE20wm3zfocP1XZDV4iM+l/H4nDUh5LjnujfW4IVl2/D5xiJl2/VvrMGmg+W4Zt6agPHnzfoe17+xBkcq1YW1nlq8GSVVdXj0400AwlscGiI+jLj5rXWGbez1WHDDCN3tRkGXFpMJGUl2zL16GJI12ScOqyViy0e4sQSySEmyWzGkc1aAOArmFpDnVFXnwZ/f+0UJOI1GfKQm2LDir+Pwr8tO9B1T4zqLVHxpufv0nlj/4OnolpMSenAMsVvN6JDpi1fZccQXe+QS3S60fBBCSOzZecRfdMuoW6zRvrIaFxKFBmYTnluOq+auDnnOrcUVEc4yttitZozomq1bQMvQ7aJjjVBeYzMb1gAZ1iULGUk23Di2q2p7uDVDtIvfU5MHIiPJhofP7QdA30UjoxUE32/z9dppnxldMKjVYlasK1oBaXTdIj1+KBojJqRLG18zv5314kN2/ZhNCKjkGi+wyBghpEUjWwu0AYThUFbtQkaS/y56S3EFtoQhLORiVc1FVn3mg56Vw2EzsHwE6T/ilSRDy8f1o7tifJ9cfPKr2l0UrjlfKz76tUvHTw+crogAcb92Yda6QlbuOAoAmDSofVjnDoY2bqehlo9wCZWKGw1yps6+Yz4hrlQ3jdNMF4CWD0JIC0S8Q651eXCgtAYDZnwe8XEqnC5Vj5KWwtyrh+Lak7sY7pfnrBffEY7lQ7v+Vda6DcWH1WyCyWQKrMERruVD57hibIdqXppwTO2cZItNtJYPEW1mUSwKsIVDY1g+2mX4rsfBUl+hNNnrotc8L16g+CCEtDjqNAW//v3dTlWrea2l2SiOo7LWHZPMiVjTIzcFbdMTDPfL4kNvwQzP7aK+HpVOt2EAqbxdKzbCTeEMNU4UItqPSa8oWmqCtVGapTWV5UO/GH/DaJfh+668/9N+VNS6lGJ18drRFqD4IISEINbR++FQWyeID5cnoK9Ffpp/4X5q8WZc+spK3eM0RuBoLLCYTcrdrB6yq0jX8hGF20Wv6qqM7BbRWjCidbsEQ/tV0nttY1mqmkp83DjGV8xtQr+8mB1TLIi2eEORKuYjXqH4IIQYsmxzMQY9sgSLNxSFHhxDaoUaDTV1noC+FmI579lfb8eqnSW6x/nyt2IlSK8lYTGbVJYPu9WMEwoylOcp9TUp9CwfJwrjVMc0GQecju6hX4NDngsQWNcj/IDT8JcRrSjS+15lGlT6jJRLhhSonjdVVsipvXOxYvo4vDhlcOjBYTJQCDwurXYp15GWD0LIccljH/+GshoXbnpzbZOeV+ytUufxos6tXrTCDT59+8e9eGvVnpjOLRZYTCa0Fywflw4twHs3FSrPe+X7eqmIAadPTR6A+yf2MWz9bjEQC/+67MSg7eJlt0mA5SNM10cknXS1NrRROoXJYmX5eHRSf0wc0FZ5Hkl7+4bSNj0xpsIgwWbB1ELfZ1hW41IsHxQfhJDjktw0h/K4MfuSaBEtHy6PN8DtIsd/NGaX2HCJ5vffYjapFtnKWjesZhPG9c7FwA7puGxYRwBqt8uA9hm4bnTXIOXV9SdyzgntggoJS73lQhu7EW6AZjgLoDxkWOcs1fbHJvUPGCt3m20odqsZJ3bMiMmxWgLp9Rah0po6we0Sv+KDqbaEEEPapPjFR43LE7MS1aEQLR8ujzegpb1s+dC6Y5qKrGQ7Sqp8xcwcVoth8bDJJ3XARz8fCBBPFrNJJQjKa90wmUz491VDIUmScpcuCgB5kTeycETrVrAqbhe12EgNUwSEYyH56YEzUFJdh8719Spk8nWCbhPtsfuONUbaa3ORWR8HRLcLISRukCQJf/vgVzzy0aaIXif+uBm1kI+UdXuO4VBFbdAxYo8Sl1sKOLe8mDeX+MgUaocYlTt//Pz++MfFJyiZCSLaRaO81l92XXQPiMeW13gjC0e0C5FFCThVvz6U+Dilvoz7NaM6hzxHepJNKZQVCm111obQAgxjMSNDEB/Hg+WD4oOQVkBReS3mr9qDf3+/ExW14fcXERf3cDq9huLXfWW44MUfcObz36q2H6qoxZpd/qBRsTtrSXUdvt16RDXeWb/f5Wm61UUM+hO7roZKC9VzDQWIjxr9z0SM+ZAXmlApswBw1cjOAIBzT2gXdG7i67SxGymO4CnKr145BMvuGYsz+7cNOi5SkmIoPjpnJ8XsWM2NnDJeVnN8WD7odiGkFVAmLG4lVXVITQiv9oUY2Bltp9edR6rQNj0BCTYLlm89rMzB45WUH89RTy6DyyMhM8mGNfefrhIf2w5VBs6rkSwfeWkOFJc7dfclCEIgWXANGHV/1boxRLTWC71OuIC6E6ucVRKO+PjbH/pgfJ88DOmcaTgH7eu0WSuhLB82ixldG6HPSSzdLhP65eMvZ/bGCQWBZerjDbvF9/1zebyQv/bxLD5o+SCkFXBUaLambbwmsmL7UUx7ax12H/WlpzobKD5W7jiKU5/5GlfX91MR4xL2lvh7tsgWjGPVLqzccRSuEPZyl0eC1ytFVXI9GNnJDsN9ogsk2eEXInqFsvq2TcM5QawO2kWjTYp+hkeKcB5ZGxitN+Ix7VYzTu7RBgkGNUFEUusFjvZ9pMQo8DNSYmn5MJlMuPmUbhjZzTjVOF6QP1+PV2KdD0JIfHC0yi84jlbq39m7PV5c9upKfPLrQby3dh8AjfiIIuZDbmO/or5nx6EK/7l31Qucco0byCtJcIdh0ajzeGNu+bj9tB6G+8QGdaEsR5/eMRqJQRZROa7j3RsLMbpHGzx7ySDdcaLrQ158jFJGo70Lzq0v2Ka14KQ2UXCxlnhtlNbYiOLjeHC7UHwQ0gooEQRHSZW+5UOsBvqvZduw8UCZxu0SecyHKDYAX+yJeLxD5bUYOOML1RibxWzo+hBxurwNivkQf7iHdMrEK1cMxpn983G1EEApVsUUK4vmpPotJGJMx5ypQ/D1vaeEPYdhXbLwn2uHG7ZpF60PeoGmucI8orkWYkyINmulqSwfD53TV70hRIbKzAsGAADuPaNnY02pRSJ/X90qy0crER8zZsyAyWRS/evdu7eyv7a2FtOmTUN2djZSUlIwefJkFBcXx3zShJDIKKn2WxeOGogPMcMEAB5YtKHBbpdD5eqslmrhGD9sP4K/ffBrwGue+PQ3PLV4c8hju70Ns3yIlTQ7t0nGGf3yAagFh+gCEK0xYgqyuFae1icvIJ20IajdLoELjRiXEU2qrRgsq812SQzDZRMLrh6lbrAXSkJdNqwj1j1wOm4dZ2ylOh6RP989JdX4vb4zc6uyfPTr1w8HDx5U/n333XfKvrvuugsfffQRFi5ciG+++QYHDhzABRdcENMJE0IixykU7ao1qEmh3b5uT6nqdVV1kVs+yjRZHGKn0bdW7cGXvx0KeM0v+8rCOrbHKzVQfPhdGuLCLQaKJgkLsHh9CrtmK49D1ZKIpAKolkRbcMsHAMyechL+NKEX+rVLi/j4otAS37fc6bapePdGf3XXcEpztMROxY2NKDQe++S3gG3xRsR2NavVivz8/IDtZWVlmDNnDubPn49x48YBAObOnYs+ffpg5cqVGDFihO7xnE4nnE6/ibW8vDzSKRFC6jlc4cSekmoM7qTOcnAJ5clrDESEUyd4c8dhf1+UcOIwtGgXzFgWffJIUoPcLnlpCdhan0kjWhXEH3QxbkO0DPVtl4aFNxUiPy0Bk2f/EPQ8KQ4rjlWHn94sIp7fqLjYWQOiT3W1C8cULR/hBKrGkmFdspCfloCi8lqM7ZnTpOeOF/S6B7catwsAbN26Fe3atUPXrl0xZcoU7Nnj65uwdu1auFwujB8/Xhnbu3dvdOzYEStWrDA83syZM5Genq78KygoMBxLCAnOqCeXYfLsH7B2t7rRmtvrXzhf+26nyoXi8njx3JLf8cN2dS0NLXrFskKhXTDdMazL4fYYWz5SE6z48b7TcOOYroav75mXqjwWLR9WA/EhWoEAYGjnLBRkJYUsZNWQ2AnR7SPpvNVIr+afJvRSPVe5XYT37WiiDrAiy+4di+//Oi6mbqvjCT3LVzxbPiL6hg0fPhzz5s3D4sWLMXv2bOzcuROjR49GRUUFioqKYLfbkZGRoXpNXl4eioqMO2JOnz4dZWVlyr+9e/dG9UYIIf76F9our9pF+l/LtimPX/9hF/65dCseDlH9NBqjhTYOIZaWD68kBZQtF8+bm5qgW75bJk/oWyPeQYpWkCTB7dExS79glRTiPYUq1hWM3FQHTuudi3G9c5GWqCNiIryc007tjs2Pnqk8F90uopulOQqDJtmtqmZ7RI2e0DByxcUDEUnys846S3k8cOBADB8+HJ06dcK7776LxMTovjQOhwMOh3FuPSEkPMRFME2TCqp1T/x20O/eXL+3NKzjR9PETSxcJUmSKuajobi9EmoNXEjyD3WyQcGqW07ppvoxNwrWFC0ft5/WA0kOK84ZqK7fEcoiNKggXXW9I8FkMmHOVUMN90dzNUWXilF11uoYldInsUNbBA7w136JRxo09YyMDPTs2RPbtm1Dfn4+6urqUFpaqhpTXFysGyNCCIkt5UKVTG11Sq3lQzSrG8WAaIlGfIgLvJgiGAs8Xgk3v7Uu6HmTHIGxCzeO7Yo/n9lbNTcj87WY8ZGRZMcT5w9AYbds1ZhQ3X6n/6EPrgjS0r45EVOGRbSZT6T50Yv5aTVuFy2VlZXYvn072rZti8GDB8Nms2Hp0qXK/i1btmDPnj0oLCwMchRCSCwQ63doA9G04kO8+60OU3yEci/oIQbJ1bm9MRcfhuetvyXUq5Zp0ylTLj4WL53oljD6oQ91WdISbHhUp3V8LIjmMwGApycPxNkD2+LiIYyxixf0rHPxHHAakdvl3nvvxTnnnINOnTrhwIEDeOihh2CxWHDZZZchPT0d1157Le6++25kZWUhLS0Nt912GwoLCw0zXQghsaOkyp81JgaYAoFulwShVHi4JvaoAk6FH0xnE4oPGT23gmwVEn+4VeID6jLlMkaumeZs2x7tmS8eWoCLhwYKjzE9c7D898M4tRczTloaekIjni0fEYmPffv24bLLLsPRo0eRk5ODk08+GStXrkROju+L+txzz8FsNmPy5MlwOp2YMGECXnzxxUaZOCGtHZfHi80HK9CnbSqsFrPK7SKm1spjRcRuqeFaPhpayTzWlo9g8SM19TU59H6cT+7h6/NhDcPyIaYXG/3QN2fb9ljrnn9eMggf/nwgaF8a0jzoid9WE3C6YMGCoPsTEhIwa9YszJo1q0GTIoSE5s531uOTXw7iwsEd8MxFJ8Al1OlwaSwf2hRX8Y6+xqDomJZoTPziSxoqPu6f2Adbiirw7dYjKCqvhccrwWzSX/zlUvGi5SPFYcW1J3dB37a+Ylyq2h4m0fLhJ0toNGeUfhqNRailkplsx9SRnZt7GkQHvZiPeO6D0zydgwghUSFJEq7894+QJOC7bb66HO+t3YdnLjpBVU1UFCJerxRQaVQUAeH6jaMRDuJr6jyeoAv1uN65WLY5sOKpzEVDCpCeaMOpz3ytHDszya5bLl7uSSPeLd45vgeuG+2v+yEKDvGHXbwcV4/qjLIaF64b3cWw4me4osxk8okxsTR7Q5GaJSmWNAfHm+UjjhN1CGl9VDrd+HbrEUV4yPzfsq3403u/KM9Fl8TUuT/i1/3qkuVifQy9yol6Ld6jucMXxYfT7TUsMvbfmwuRE2JRTq4PHhW7e4ZK3RXTE7VuE6NUWzHmoyArCf+4+AT0aWtcuvyVK4fAYjbhyfqGZ0b89+aRGNktG29cMyzouEg4jowuJAS6dT7i2PJB8UFIHGG01jzzxe+q56K4+HarX6jIZdfFbrU2TbGAqYWd8OcJvaElVEop4BMESzYV40h9F13RKhDM7WKzmLHjSGXQY8tdV62C+Ag1J1FYaS08avEhFtsKesgATu2Vi82PnolLh3UMOu6kjpmYf/0I9I2iB4sRFB+tB/06HxQfhJAYUOf24r4PfsXrP+zS3R+OAAD8MR7aQNP0RJtyHhnt3ZPJZILDFvjTEM6p56/ajevfWINz/+VrOClaS9xeydB6YrOYUV4TXtaNLCLcXm9Ia4xo0dD+TovvuyHN33yv508paVz0dEYDv7bNCv9iCGlBzF+1G2+t2oOHPtyoG0sQbtyFLDqOVqrjIZIdvjCvOp0mcjIWs0m3nXo4bpePfzkIADhQVls/X+H1QYqM2SxmPHRu35DHB/zWDK8UumiZVRAF2rtE0RJipXggLRy9mCNaPgghMUEsdV7pDLQE6AkAPTeBXNdDdn/IyHETsjiZ9dU2bNKU/raYTbpdTcOxumg744oCKphYsFvMGNmtTcjjy/MDfNYdbY0NbcVOteUjzJiPOArii7bIGDk+YMApISQmWAS/bnG5Xzh4vRIW/bRf1eJeRm/9kcXFYa34kC0fHi/2l9bg759vCXit2WRS9TRR5hDGQqe1qIhiyes1ttzYrOH/iMo/uHpi5rz6+hQp9e9TjPnQ/lCLxg5Vg7WwZ9L8UHq0blpNhVNCSOMiLvCHKmrRLScZ2w9XYdPBctz5zvqwjyMXx9p/rEa1XbZ8ON1evPjVtoDXAT7fsq7bJYwiY9q286I48EiSUnn1smEd8faPe5R9kcRMyBYLl0cKiEO5YWxX9MhLQWFXuZCYcNyAmA+xeqn/sa0Z2skTEg37SqubewpRQ/FBSAtCXKwPVzjx4tfbda0Toaird7vsPqq2lMiWD6fbi7dW7Ql4HSC7XfQCTsOwfHi0bhfh9V4Jcu2zaad2Q4/cFDzy8SYA0YkPbQl5wOe+uWSoP+skWCCpRRXz4X88+aT2mL9qD8b0CM8N1JzQ69K6CbcpZEuE4oOQFoKkcSPU1HmiEh6A3+2y84j6zkgWH9U68SQyZpNBzEcYK51T0w1VZfnwSoo4sVvMqu6w9ijEh17QrFg2XhwLBMZHiEYRUaQk2a347I7RYc+HkOYi3NYILRGKD0JaABv2l2HKa6vUVUo9Xjis5oAgznBwG8R8yE3Vgv1oGQWchpNpo7V8iDEf/ye4eSxmkypQNpJUV6uO+Hj6woFIS7AGxKqIFhXt9FWWD50aCvEAK5y2bmrDbI3QEqH4IKQF8Nf3fwkogV7p9ERdwVDOdqnViAy5imhVkE62RjEf0Vg+RGuDmMljMZuQl5qgeq4lO1m/dLo8VhRl5wxspxskK2axaOcvulr0qrzGA3S7tG5qXZHfmLQUKD4IaQGYdHIsnlq8OerjyW4XbdO41ARfkbFglg+zYapt6PMGCzgVsZhNSE2w4f1bRiLRZtFNb11933h0/dunuq8F1FYWI8OFKGq0qcJipkAkbp+WBLVH66Y6yE1ESyc+/+IIOc6I9Z23bBXQig85pTRokTGTSdcSEU6RMXF9l6TAbBTlHPXHP6ljpmHfFKMCSrKLxOX2H9yo3oEoagLcLmKdjzgTHxec1B4AcNu47s08E9Kc0PJBCGkQ2v4qDaWi1ufC0bpd7GGkkRq5esIt7S4TTKs0pCGWWbF8+N9bOMfTul1UFU7jrFLk3y88AdNO7Y6ubZKbeyqkGemem9LcU4ia+JL7hMQpHq8UNDgs1t0pS+vjR4wsH8EwqvAZTsyHSDBLSUMCPLUBp2ZTeFVJg1k+4q03i8VsQreclLiqxkoaTu/8VNXz2Zef1EwzaTi0fBDSiHy+sQhfbCzGr/tLUVbjwmOTBmDN7hLccVoPJNn9f36xdruUVbvg8ngDWs6HE9tgNBVPhAEGwbJjGqK1xCJj4vNQaC03VnP8B5yS1sXzlw7Cmc9/C8CXIdYpO34tXxQfhDQStS4PbvzPWtW2699YA8AXo/DnM/1t62N9511a40K1U2316JqT3GLcLuHesdut5oD4FDm+Y159599wS0wHuF1Ey0ecptqS1oUY2xTPpdUBul0IaTTW7TlmuG/boUrV81jHHHi8kqrGx6w/noSFNxbCEYb4MAr0jKXbJVzmXzccPfNSMP+64co2i8ZKEbblI0idj0h6yxDSXJiOI/FBywchjYS2r4qIw2ZcDCtWFNW3tU9xWDFxYFsA4VkvjDJHwiky1pDxegzpnIUv7hqr2hbQIC5Ky4e6qy3vw0jLR9TZcRYjHQD/4ghpJA6U1hruS9BYIBoj5uBgmU/8iDU7zGZTSCuL0R1VpJaPxmr3rrV0GFlqtGjnIz6NpMIqIc2F+LcZ7ve+pULxQUgjcaA0mOXD96e3bHMx1u05FpNsl3G9c9E2PUFpCidbPrRN4kLFfRj9qIWyZGj3G42Xa1RES4fMRNXzcF1Ww7tmq56Lpcnjrc4HaZ2Y6XYhhIg43R7YLWaVT1avNLiMw2pBcXktrpnnC0CdNKhdg+dw67juOKljJi55eQVW7SxRYj60GS4+F0+wtF/97aG8KNrAUL2YjztO64G7Tu8Z/EAhGFSQoXoe6g7wx7+dhj0l1RjSOUu1XXw/8Vbng7RORL0R6/T8poZyn5AGUlHrwunPLscFs39QbXd5jKsP2q1mlAu9XA6UGbtowkXux5KR5CuhfqRefGhdOiEtH1G6XbTiQ294LH4wB3fKRLccf4phqJiP3LSEAOEBAJn11wmIvzofpHUiCu041x4UH4SEy9biCt1eCu+s3os9JdX4aU+pagF2B2mGIknqO+8dh6uimlPHrCTlsSI+Eu0AgMMV9eJDE0wZqtaHkfgI5XZxetTWFG2NESA24sNkMuGR8/o3+JgZSXa8ff0IvH/LyLi/iyStA/FrGu8F5ig+CAmDlTuO4vTnluO8//s+YN8+IaulyukXJ64gVbnq3F6VUDkipMVGwrjeucrj1ASfF9Vv+fC5fbTBlKESOwzrfETodtHrHxOrRT490W+1aEiiSmG3bJzUMTMGMyKk8RFvDMLN8mqpMOaDkDBYvKEIALBVU58DULsjKp1uZCb7LA/uIG4Xl8er6spqxKRB7fDhzwcMF3671Yx5Vw9FWY0L2SkOAEC6LD5ky4fG0hEqUE3ebzKpXSeh0nS1YkPP7RSr2Iq0BL/4iPcfYULCRfyqx7uxjuKDkDDIEOIDtIgWjsowLR8ujzdoZ1mZYV2y8cWmYlTX6QeIVtS6cUqvXNU22e1SUT8X7YIfarGWrRNmk0kVNBqqaJhWTOm9v1hF6Kcl+n+62FaetBbEvx+6XQg5Tvl5bynGPP0VPv31IDKT7Mp2rUVDfK4WH8bios4dnuUj0W4OKhbk7rUiWqGkDTAN9ZslaxXtnVWkAae/F1cEjIlVPZMUh198iK4uQo5n1OKjGScSAyg+CDHgrnfWY09JNW55a50STwEAJdXqFFoxsFIUH3oBlzJ1Hi9cYVg+yqpdQVNJK2oDF96MRLX40Fo+QrpdzLLbRT0ulNtFK7bufvfnwGPH6BdTdCVVUnyQVkK8u1pEKD4I0VDr8uCed3/GjiP+DBTxpv9IRRDxIYiBWMR8dMlJCfqDo7eWp2ssH5HGfMiWFu15Q7ldnGGIqcaop1HrCn1eQo4H4t3VIsKYD0I0vLlyN/67bp9qm7jwltWoXR2iyAg328XlkYLGfMy7eijKa90Y06ONYYZIlzbJeODsvgHbMwQXERCY7RLq90uM+RAJkjkMQD/GQ0u8l4QmpDkRfwviXYdQfBCi4VBFYNqr6HLQ1vrQCziVJCmoZSNUzEe3nBQU1Nfw0LvbGd8nF69NHar72kC3S2SWD5NJf1ykMR96xDIzJS/NgeJyJ3rnp8bsmIS0ZI4n7U63CyEa9P6+jeI6fPv8i+5jn/yGKqcbF760Qinypce+Y9WY/v6vhvvFwEy9BTuYgEh2WNGvXZrusYAw6nwIqbYioYqMheNGimUDvQU3FGJ8nzxMO7V7zI5JSEsm3vu5iFB8EKJF5+9bvOuvcmoqeWrcK499sglrdx8LeopdR6uDLuai4NC72wn1IzRCaKJmC2L50HPbGLldSmtcQYNOjSwfbdMTdM+tx/SzegMAnr5wYNBxgM/t9NrUITjnhIb3xSEkHhD/fEy6t0nxA90upNXgdHvgsFpCjtP7oxb7sGhTO7VZHtsPRVcqXUTVw0FHfYSqFCp2stVaG0Q3jl3HEmFWxIewzeQTF0eqnMhNTQh4DWAsPvq1S8PB+t41oQJObxzbDZcO66iqYEoI8UHLByFxxv/W70ev+xfjf+v3hxyr9/e9Xei9UlWndbvEpsxVbqpDeSwu0iFCLXQRRZa2aVooz4fZFGj5yEvzCY79Qil5LUZulyS7/x4nnIBTCg9C9KH4ICTOuGPBetX/MnqN4vT+vDcdKFcey5aPXUeqMHLm0gAXS6jATCMsBtaOGldgddNgBcwAwCEUFgta50Pnx8wf8+Hf1y4jEQAUC4YeRpaPZKEgGFvXExI95uB/unEFxQdptcz5bif6Pvi50rdFRu+Petthf0+XyvqYj/fW7sMBncU4VD0MI0TxIcZ81OiUVo9IfETa28Usj/NvS7L7LCm1OkJIxsjykeLwW2GYaktI9BxPdT4oPkir5dGPNwEA7n53vWq7NoAUUGd6yJaPNin2gHFA6EqgRqgsH6ZQlo/g53DYRLeLcZ0PvZ8yvYBT2WIRtGorLR+EkDCh+CCtnjYpDtXzYHf3gN9VY7QMR2v5EGM+tIJBy8Ey49gLQOt20cR8CAJAL75CFh0d6+uM+F7jO4ZRhk5ZjQsfrj+guy9REELsQEtIbIj3vySKD9LqydZYMEKVCZfrfBiNC6PchcK0U7spjxPtVnz3l1OxYvq4AFeJllBzFANOA7Nd/I/P6p+P809sj0IhNVcWH89ecgLG98nDOzeMMLR8eL0SftpzDFfMWaUqRy9iFMtCCGm9UHyQVse181bjv2v95dOzk9WWj1ALu1znw8hCEonbJS3Bb3kwm4AOmUlom55oOH7RtFHonZ+KJ84fEPS4ouVDa0VRuVMsZjx3ySDMvMB/PKnectMhMwmvTR2C4V2zYak/hkejrP6zcjfOf/EH/LKvTHcez1x0gkp80O1CCAFY54O0QpZuPoSlmw8pz7OT1ZaPUG6XqlCWjwjcLqKFI5xleVBBBhbfOSbkOIfN2O3Sv306vt16RLWtU7bfxZKZHBjLIosGbajJGyt2BZ2HzWKi5YOQRiDeg08pPkirJyVB/WcQ0vJRH/PhNOimGonlQ7RKxDKHX1Xnw6oWH7eP6wGr2YQJ/fKVbSaTCV/fewrKalwBMTCA33XiCdVdDr44Ern5ntVsVv1I0vJBCAEoPggJqMvhdIeyfNS7XQzG6WWnGCFaJWJ5JyO6XfLT1BVJE+0W3HNGr4DXdG6TbHg8o5gPvTlnJAniw2JCsl1ItY3zuzVCWgrx/pfEmA9y3LD7aBXmr9oTcaqrdnytgUVDpqrODUmSDC0f1Tp1OYwQg0FjuS6LbpeCLOMYknBRsl1CpPgC6jgWm8WEHLFyawwbyxFC4hdaPshxgcvjxdi/fw0A6JCZiDE9c8J+rVarhLJ8SJJPYBiN06uaaoTa7RL2y0LicvvfVPuMhouPcOp8yKQlinU9zCrxwVRbQmJDbJo6NB8UH+S4YEtRhfK4SFN1NFQreG2AqJFFQ6Sqzm0YGxKqAJiI6HaJpUuie24KUhxWpCfakJrQ8F4p/pgPjdtFZ2ye4OaxWczIEWJI4v0Hk5CWglFRv3ihQW6XJ598EiaTCXfeeaeyrba2FtOmTUN2djZSUlIwefJkFBcXN3SehARFtELYNQGWoWIwJI34MIrlUI2p8ypZMZMGtcOLU07CdSd3CXe6CrZGcrsk2i1YMX0clt07NibHs0Rg+eggWFpsFhMyk/zZM6EyiQgh4RGJhbUlErX4WL16NV5++WUMHDhQtf2uu+7CRx99hIULF+Kbb77BgQMHcMEFFzR4ooQEQyw/oV0g9XqjqF/rG79hfxkufWUF9pYErx4K+KwlsuXj9L75+MOAtoaFwVITjA2MkQScWiL0y6Qm2FRZLw3BGkG2S/tMv/iwWswwm024fnQXnNY7F/3bpcdkPoS0diKJLWuJROV2qaysxJQpU/Dqq6/iscceU7aXlZVhzpw5mD9/PsaNGwcAmDt3Lvr06YOVK1dixIgRsZk1IRrcwqKoXSBDiQ9Zq9y78GdsFtw3wfB4vYr4kDNLjNJIV04/Dceq6/B7cQUOltXivg82KPusEaTaRio+Ykkklo/2Gf6aIfI1uW9i38aZGCGtlFAlAVo6UVk+pk2bhokTJ2L8+PGq7WvXroXL5VJt7927Nzp27IgVK1boHsvpdKK8vFz1j5BIWPDjHtw2/yflubhASpKELzYV6b1MQc52Ka12hX1Ot1eCq/6PX66jYVRAK9lhRYfMJIzrnYdR3dqo9tkiKDLWnDUyrEYxHzpTyhKKlNlClIknhLROIrZ8LFiwAOvWrcPq1asD9hUVFcFutyMjI0O1PS8vD0VF+gvAzJkz8fDDD0c6DUIA+Bqa/fX9X1XbxAXy/XX78dgnvwU9hlznoyArEUXltUHHiueQz2OrX5jDyeTQWjdEQdFZqDKqR/NaPnwiIpTlY8rwjkgQq6sytZYQokNEtyV79+7FHXfcgbfeegsJCQmhXxAG06dPR1lZmfJv7969MTkuiX8kSQpZs+PnvaUB29xCtsl/1+0L2K9FHh7J4u7xSoqrR35dOAutVp9YLWa8dd1wXDGiE24+pXvQ1zar5UPp7eK/tit3HMXvxZXK8xFds/D4+QOQIHSxtZlp+SCEBBKR5WPt2rU4dOgQTjrpJGWbx+PB8uXL8X//93/4/PPPUVdXh9LSUpX1o7i4GPn5+TpHBBwOBxyOwHLOhEybvw6bDpTj0ztGI8mu/1XdXBTophMtH1VhBGVVO9149ONNWLmjJOy5uQXLh7wwh5Mqq3XN2CwmDO7UBqO6tzF4hR9LMy7kejEfl76yUjUmxeFL6RXFB7UHIUSPiMTHaaedhl9/VZu4r776avTu3Rt/+ctfUFBQAJvNhqVLl2Ly5MkAgC1btmDPnj0oLCyM3axJq+DTX32uui82FmPSie11x1TWBqabiQuk3AQuGGKTuXDxWT5855FFQTiWCe0QbdO3YLSMmA/jILe0+qwe0e0SqsYKISQyJg5si09+OYheeanNPZUGEZH4SE1NRf/+/VXbkpOTkZ2drWy/9tprcffddyMrKwtpaWm47bbbUFhYyEwXEhFi7Y3iIHEYeulm4gJZHYb4iAa3R7B81C/M4XRsDYj5iCAmomuOce+VxiacbBe5QZ+Y3qvXIZcQEj1PXjAAQzpl4g8D2jb3VBpEzCucPvfcczCbzZg8eTKcTicmTJiAF198MdanIcc5YhrZ4Qqn4bhqnaJV4gJZ52mcdDS15UMOOA39Oq1nJpw4k//eXIi53+/CfRP7RDzPWCHPU9uET0SuZ2Ixm/DFXWNQ5/aq+rwQQhpOaoINV4+KvKBhS6PB4uPrr79WPU9ISMCsWbMwa9ashh6atGJEi4bcIVUPvRoeoqnf3kipnh4p0PJhCeNcWstHOHEigztlYXCnrChmGTsUy0eQ0vHJDv/PSc84NwkTQhoX9nYhLRKxJHowU7+e+HB7JTjdHkiSOvgxlni8Xrg96myXaFJt46XRmlGdD5Fkg6BgQgjRwl8L0iKpEfoWBOsyq+d2qXa6Mfbpr5HksETdL6VfuzRsPGBc8O7rLYdRXh/sam1AwGmcaA/dOh9mk7ojsBhoSgghweCvBWmR1NT5YzWCdW+s0Wmu9PXvh1FUXosdh6ui6n/w/CWD8ODZwcuBv7Fit/LYYgk/4FTbv6U5C4dFgp7lQ9s3prGsTISQ4w+KD9IiqVZZPozFh5642H20WnksCpfc1ND1ZOwWMyad2F4VvxDKoqHEfITx16Q9VLyID3+2i/96OjSWDooPQki4UHyQFokY8+F0+RY8l07mSqimcbL4eP2aYapuq0ZIUGewAIDdGvzPRIn5CKNmhzbmI17cLnqWD23fFooPQki4UHyQFokoKpweLx77eBMGPfwFdh+tUo0L5VZx1guWjERbWE3O5ExSawTiwxpBwKnW0hEvAad6dT4kTdptNmt6EELChOKDtDgWbziINbuPKc+dLg9e+24nquo8mPXVNgDApgPleG7J70HTcAG/tcRiNoWVdisvp6JIEEWLngvGb/kI3HfOCe1Uz7VaI5xU25aA0ttFEB+iEEm2W9CvXVqTz4sQEp8w24W0KH7eW4qb3lyn2qYXcPqHF74N63jyzbnZZIItjCpg/todfsEhipYEmwWVmqqp8lhRfNw0ths6ZyfhbI34CKjzEScxH/K8xTofohBZfOeYgGBaQggxguKDtCi2FFUEbBMDTqO1FFjMprDcLsp4i77bxWE1o1JTcFUWHSlCkGrv/FTdfjQBdT7iRHzoVTiVxcd7NxWiICupWeZFCIlP6HYhLQoJgUWsxODTaO+uLWbAFiJ2Q0QV82FRiw+jsUM7ZyI/LQFmEzCgQ7rucbVaI060hxKbIlo75MdtM0IH8hJCiAgtH6RFodc6pKSqTnkcrWXfbAov5uP8emuFaKGwWf2PHToZHbLrxGoxY/Gdo1Fc7kS3nBTd42vFU7zEfMjv0aNj+YiXoFlCSMuB4oO0KEJ1YA+VWmuEz+0SfJEc1zsXT04eAEBt+RBTaPUsHyIZSXZkJIWf9REv4kNxu+gEnMaL64gQ0nKg24W0KKp1KpaKVNQGz24xwmwywRrC8nFSxwylaqcY8yGurXqWj4YQLwu3LJJky4coQuLlPRBCWg60fJAWgSRJOFbtCsgk0SL3U4mUcFJtRQuHyvIhWCdCWT4iJV7Wbb/lw/fcTfFBCGkAFB+kRXDzm+uweGNRyMXYrVPlNBzCcbuoXS2i5aPxxEe8pKdqA07FrBeKD0JIpNDtQpoVuUrm4o1FAELHfARr6R4MkymwHLgWqyBOxDofYtX01lpCXL4GsttFtHyE082XEEJEKD5Is/HBT/sw6JEl+GH7kbBf89vBCqzeVRLxuSym0HU+rGb9OA/xzj7Wlo94QRtwKorAeAmaJYS0HOh2Ic3GXe/8DAB4avGWsF9T5/HiopdWRHwui9kUukeLIE5Ed4gJovhonZYPiybg1EPLByGkAbTO2zjS7Igl09MSGl8Dm8OI+TCKXRALn+0vrY7pvOIFpc6HxvJhMsVPiXhCSMuB4oM0C7Vuf72OJHvjWxMidbuIiIXPhnbOiuW04gbZ8iFfCxYYI4Q0BIoP0ix4hAZlodJrw+HBs/sG3W8xm0JmZRjVAREzO64s7IxHJ/XH1MJOkU8yjrFoLR8SC4wRQqKH4oM0C2KZ7sooa3eIXD6iExZNG2W432wSIzf0MbJ89GnrbxWfmWTDFSM64cax3QAAZ/XPj3iu8Yi2vLosHik+CCHRwIBT0iyIAYtlNdFVLRUxmxA0psNiNoVsDKNdSL//6zgcrXTipz2lAWPaZSRi86NntprsF9m94qXlgxASA1rHLydpccRafPiKiBl/nc0mhLR8aIVE+4xEDOyQodQiAdRZMAk2S9wUCWso2jofnvpSpxQfhJBooPggzYIoPpzu6KqWiphCBJSaTKaQHXGT7DQEGiEGnEqSBLnQLNNsCSHRQPFBmhxJkrB+b6ny3BVlyXQZ+e471EIYKuojsZVWLw0H0cLh8Upw11s+WGCMEBINFB+kyXlv7T7c9vZPynOXJ7qS6TLyuhgqlVZvnTyjb57yOLEJUn7jFbGWh0eSlAZztHwQQqKB4oM0GZIkoaisFm//uCemx5XvvkMVEdPbK2ayNEW9kXhFrOfh9cJv+aD4IIREAZ3cpMn4y39/wbtr9oWMvYgUWXwY1emQ0Tuvw+Z/DcWHMRat5aM+8JSWD0JINNDyQZqESqcb767ZB0BdMTQWyAtjKMtHmxRHwDYxDsSoY22ygxpdjO3weCW4611ltHwQQqKB4oM0CSWVdY12bFOYMR+n9srFNaO6GO43qtlx3qD2GN8nF/dP7BP1HOMd0fLh9UpKyi0tH4SQaOAtHWkSnEIvl1gTbraL2WzCg+f0xbo9x1TZNjJGNTvsVjNemzq0wfOMZ8RL65EkJVWa2S6EkGig5YM0CbWuhtfyMEJeAEXxkJVsxw1juoZ8LdfO8DCZTIoA8Xr94sMawtVFCCF6UHyQJqExLR96d9+SJIUlLLKS7I0wo+MTi9DfhV1tCSENgW4X0iQ0ruUjcJsEY5eAGJh6/knt8cP2IxjVvU0jze74wXc9fcJDER+M+SCERAEtH6RJaIqYDxFJ0hclAPD4+QOQm+rAI+f1g81ixvOXnoiLhhQ02vy0xGuQpllpLgeKD0JIg6DlgzQqa3aVoGN2Ukz6txhh5HYxsnz0zEvFqr+d1mxN4RJsFlQ63c1y7oagcruwqy0hpAHQ8kEajTW7SnDhSysw6sllqHU1YsyHwbc4WCZGc3ajNUrpbenIOoNuF0JIQ4nPX0ESF6zaWQLA17ulMS0fepTXujFleEck2iyYfFKHJj13KIyKmbV0ZKHhlfxFxixGyo8QQoJAtwtpNLKS/ZkkVY3oZvAKuqZdegIOlNUCAHLTEvDLjDNCFh9rasSS7vGE4nYRiowx05YQEg3x+StI4gKxLPmB0toGH++2cd1Djnnj2mHonpuCf146CEDoqqfNQYI1Pi0fshtL7XZpedeXENLy4S8HaRTeXb0Xt7/9k/J877HqBh/znjN66cZLeIVmMd1zU/Hl3WNx3qD2DT5fY5EQ55YPr1jnIz7fCiGkmeFPB4kJ76zeg2Wbi5Xnf/7vL6r9B8tqYnIer05Xulg3qmtsrj3ZV3l1dI/4qi2iZ/mw0vJBCIkCxnyQBrPtUAX+8t9fAQC7npwIAMhJdeBwhVMZU1bjism5vDpCQ0+QtGQmDmyLXvlj0TErqbmnEhF6lg92tSWERANvW0iDEeM55EUpN1Xdvl4UIg1B1/IRkyM3Ld1zU2CPs5Rbv/iAYPmg+CCERE58/fqRFolbSDepqa/noa3/EKvy6npGjjgzfMQtqjofLDJGCGkAdLuQBuMUhMUnvxzAgdJaNO2SRPXRFMiZQ24PG8sRQhoGxQdpMBW1/hoecuxHU6IXB0Jijyw+XF6vX3yw0AchJArodiENJlbBpNEi0e/SJMjdgOvcXrhp+SCENACKD9JgymubV3zQ8tE0KJYPjxde9nYhhDSAiMTH7NmzMXDgQKSlpSEtLQ2FhYX47LPPlP21tbWYNm0asrOzkZKSgsmTJ6O4uDjIEUlzc6iitsEdVkW3S2Pzj4tOAAA8el4/ZRstH02DnJ3j8giWD4oPQkgURCQ+OnTogCeffBJr167FmjVrMG7cOJx33nnYuHEjAOCuu+7CRx99hIULF+Kbb77BgQMHcMEFFzTKxEnDKa2uw8iZy3DK37/S3b/naDXuXPATfjtYHvQ4TndsOtYGW8japPhSdycP7oCND0/AFYWdlX3UHk2DYvlwS0rKM1NtCSHREFHA6TnnnKN6/vjjj2P27NlYuXIlOnTogDlz5mD+/PkYN24cAGDu3Lno06cPVq5ciREjRsRu1iQm7DhSBbdXwpHKOuw7Vo0OmeqiVze+uRa/HSzHt1uPYO0DpxseJ1Yday1mkxLIKDOudy4qnW7MOMdv6RB7xgDMdWkqlJgPj1fpassiY4SQaIg65sPj8WDBggWoqqpCYWEh1q5dC5fLhfHjxytjevfujY4dO2LFihWGx3E6nSgvL1f9I02DeNf6057SgP2yxeNoVV3Q47g80S3/V4zohD8MyNedj8zgTpl498ZC9G2XZniceG1RH2+oYj5o+SCENICIxcevv/6KlJQUOBwO3HTTTfjggw/Qt29fFBUVwW63IyMjQzU+Ly8PRUVFhsebOXMm0tPTlX8FBQURvwkSHS6PUBysLnrXSV2UbpeR3bKRZPdbMfQyJ7xhRJP2yk+J6vwkMuwWMebD990xM9uFEBIFEYuPXr16Yf369Vi1ahVuvvlmTJ06FZs2bYp6AtOnT0dZWZnyb+/evVEfi0SG6C7xNCBwIlrLh8VsUkz5gL4JP5wjnz2wXVTnJ5Hht3xIkHUrLR+EkGiIuMiY3W5H9+7dAQCDBw/G6tWr8c9//hOXXHIJ6urqUFpaqrJ+FBcXIz8/3+BogMPhgMPhMNxPGg9RNARrzhYsEPTnvaVYtvlQVOe3mE2qYzt0ep0E00Qf33Yy1u05hkuH0lrWFNis/jofHtnyQfFBCImCBtf58Hq9cDqdGDx4MGw2G5YuXars27JlC/bs2YPCwsKGnoY0Ai7B8qF1b4gumWCFpG5+c23U5zebTaqW7H3bpeGEDukY1zsXY3rmAAAuOKm94ev7t0/HlYWdYaLpv0kQYz5o+SCENISILB/Tp0/HWWedhY4dO6KiogLz58/H119/jc8//xzp6em49tprcffddyMrKwtpaWm47bbbUFhYyEyXFoooMLShFeVhVi1tSI0Pq9mkWrwcVjMWTRsFk8kESZJQXecJyGwhzYddJT583x3W+SCERENEv+yHDh3ClVdeiYMHDyI9PR0DBw7E559/jtNP96VhPvfcczCbzZg8eTKcTicmTJiAF198sVEmThpOnSA+tCmuYsn0Oo8XdW6vbgv4UGb3tukJOFhWq7vPYjKpeoPYLGbFimEymSg8WhiqmI/6rwvFByEkGiL6dZ8zZ07Q/QkJCZg1axZmzZrVoEmRpqFOdLtIxuID8N3t6omPUIvP1JGd8eRnm3X3mc0m2AS3i3xnTVomsvioo+WDENJA+GvfigkWcFqucae4DVJeQy0+SXbjGhzagFMbxUeLRg44dbm9qHP7vg/8zAgh0cBfjlbCkk3F+N/6/ao+KGJZdI+mSKnW8mFUbyNUwKFYx0OL3WJWpdpa2Z69RSPGfNS6fN+dBBt/QgghkUOneivA6fZg2lvrUOfxQpKASSe2h9cr4eGP/PVZtJaPyjAtH6GKTImWD5NJnTprt5phEdwuvItu2YgxH4r4sLK6LCEkcvhr3wq44+31SnDp5qIKAMDhSqdqjNayIVewVPYbFNwIZa0QxYe2jofdalZZTvRiSkjLQYz5qK23miUEcasRQogR/LVvBSze6C9vLwcKag0WWsOGW1O1VJsNc6iiFjV1nqA1QAC120UbUGq3mFXixUa3S4tG/qx8bhff94iWD0JINNDtcpwjSdriYb7nAeJCCi42xOdFZbUYMXMpCrIS4Qiy+JhNGsuHzQII7hyt5YNul5aN7GKTJH8vIMZ8EEKigb8cxznaviuyO0UrPgLdLsbiY/nvhwEAe0tqEMxWkZVsVy1OAW4XixlWC2M+4gX5s/ZKkhKszI7ChJBo4K/9cY62W60sOkLFdLg16S+iGBGtJMFSbdMTbbBb/IuTNqbDF3BKt0u8IMQG+90uFB+EkCig+DjOqXGpxYfidtFaNrTiQ7NfFCfiviOVdQCAAe3TA86dnmhTCQ6ti4Zul/hCdrt4JYmptoSQBsFfjuOc6jptyqzvjtWlsWxok1m0MR+im0bs+3KkPmtGr5hYWqJNZc2waywbVrOJbpc4Qi59X+f2KgI0kZYPQkgU8Nf+OCfQ8qEf8xEgNoJYPkqq6gLOk6gjPrKS7WpXiyYzxmQyaSwfdLu0ZOSPqlpw5dHtQgiJBoqP4xxtzIeh2yXA0mEc81FaHdjxVu8O+IQOGSrxoc28AUC3Sxxhqg85FQWtNoiYEELCgb8cxzlay4dbsXxo3S7hZ7toXTYAkJvqCNj2hwFtVY3jtAIHgKbOB7+OLRlZJ8qC1m71dyEmhJBIYJ2P45xqbbaLN7yAU61QEN0u2rHdcpLRJsUvPkZ0zcI/Lz0RORpBoic+WF49fpCFhiw+2YWYEBIt/PU4zqk1iPnQWi8CKpxqUnHFGBGtlaR3fhrMgvskK9mOvLSEgLnolWi3Ca+jCb9lI39UdW7fdyNUR2NCCDGCv/ZxxJFKJx79eBN+L/b1Z/nv2n246531ymKghzbm41iVCx6vFLrImHa/aPnQjM1KtqsazBk1mxOtLfKQdhmJAHyxH4M7Zxq+D9L8mBXLh+9zDNXRmBBCjKDbJY6Y+elm/HfdPsz5bid2PTkR9yz8GYCv8uTTFw5Upa3KyA3l7FYz6txebCmuwKWvrMC1J3dVjfutvuGcTLDsF23Ih098+J8b3REfqfA3s5N7wnRuk4xPbx+N9hmJSEuw6b6OtAxkwShbzWj5IIRECy0fccT2w5W629//aT+e/Gyz7j7ZKpIspMKu3nUswK3y895SrN5VojwPSLUVnmvdJ9kpdtVCZNRsrlzo6yKO79suDelJFB4tHdnyIX83KD4IIdFC8RFHtM9MVB5r4y5e+26n7mucsvhwqI1cWrcKAHy5qdi/Xxvz4Q3udhGzHsyaRUkvloP1IeIPraak+CCERAvFRxyRLwRxymXNZdIT/ZYDMcjUb/lQiw+9dFlxMQlWhExr+chMskOsD6a1fMy/fjiyk+147pITlG0syx1/aGN5GPNBCIkWrgAtnCOVTiz4cQ+qnG5VCfQHFm1QjeuakwwA+H7bEfR+YDFe+mY7AH/MR5JDbWnQrblhNqG6zo0znvsGXwhWEO147WuT7BaVtUNr+RjcKQtr7h+P80/soGyj5SP+0IoPWj4IIdHCgNMWzhVzfsRvB8uxZvcxlbVg8cYi1biCzCQAwJ/f+wUA8ORnm3HT2G7Glg8d8WE2m/D5xiL8XhwYW+IJku2SYLOo3C565R+0xaiYVht/aN0uVjM/Q0JIdPDXo4Xz28FyAMDiDUVwuQMFg4zsCtHGasjiQ9v4bfuhQIFhNZtURb9UxxcEh7ZcR6LNonK1GAWcitDyEX8w5oMQEisoPuIEk8nvQtFDFh9aq4QsPlI0AafzftgVcAyL2YwEA4uEKuBUoz4S7RZVqq3W7aJHgpXiI94IiPlgI0BCSJRQfMQJJiBoMTE5QDRAfHj0s130sJpNASm2Mt4gMR8JVotqYQrH8uFgwGncoRUfRsXkCCEkFIz5iBPMZlODLB96jd8AteCwmE0B5dhNJp+bxe2VsLW4AlsPVaK0Wp1pk2A3q6wd4Zjj6XaJP7QfK7NdCCHRQvHRjDjdHlz88kqcWJCBGef2Czo2pOWjXkBoDRdynY82BuLDIogPq8WEWpe2263vf48k4fTnlusew24xh+12Gdo5E6t3HcPlIzoZjiEtE8Z8EEJiBcVHM/L1lsP4eW8pft5bGlJ8mE0m3docMrLFw8jtYreYYbOYlL4cMnarWREoepYP5fhBzm0ymTS9XYzfx5vXDcf+YzXompNiPIi0SLQZS4z5IIRECx3vzYhN+PHWNnbTYjKZglo+FLeLpHW7+MSE3WrGJ7ePDnid2Pbeajah1m0gPoJPT+12CRIL4LBaKDzilMA6H/z5IIREB389wqCi1tUox020+Q1PFULfEz1CZbsYBpy6/Y3l2mckBrwuJ8UvPsymQLdLWoJvjqHEUaTZLiT+YMwHISRWUHyE4Pkvf8eAGV/gs18PxvzY4o1kuY7AEV0gZlPwmA+9gNOXvtmOdXtKAfjEh56PPlco2S5JgLP+nIMKMnD/xD44vW8+gMBGc1oizXYh8QcrnBJCYgXFRwie/3IrAOB+TTnzaPlh+xE89vEmON0eVf+UvceqA8bO+HCj8tiE4NkueuXSxU63dotZ9041O9muPPZKEspqfCJodI82uG50V8U1pO3nosUcpLEcOT6h5YMQEi0MOA2TWC2of3x1FQBfrEXP/FRl+w1vrMWGhycoz3/eW4oFq/f6z2/SbwYnoyc+RCxmk+6dql0oKlbj8qjOCfjft57V5YIT2+Pa0V2U+YnnIscfAXU++DkTQqKElo8wibUrYdfRKpXlo9Kpjvm4d+HPquehAk61gaZaLGZTQLaCvF3mQGmN8lheaOS7W6fOua8a1Rn92qUHHIdul+MTbXwpLR+EkGih+AiTxribdwexZFTXBRb70m5THyv8gFARcQEpr/ELoCkjOta/ThYfgedWp9fS7XK8w5gPQkisoPgIk8bIKhQ7yyZrGr9pLQ0mE1DlNM6I8UoSaoKIE6NS2KI1RA567ZaTjNxUXyCqvMBos2DEffL8lO1ck45LmO1CCIkVFB9hEntXggkeoQNtVZ1Hlc5ap7E01Lq8AdVLRTxeCcc0Zc9FjO5SxXPK6b4pCTZlm9/tEihsVK6WCMurk/hD67ZjnQ9CSLTw1yNMonUl7C2pxnn/9x0+/uWAZo8UUG20Wkit1Wa2VAexegA+8VFSZSw+jCwf5w1qpzyWLR+pQhM6c5CYD7pdWhfaT5WWD0JItFB8hEm0lo+/ffArft5Xhlvn/xSwTxunIbpVtG6OqnqXSmqCFX89q3fAsTxScMuHkfjokZeK0T3aAADK69Nskx1+F5Bi+dApuy6uPWq3Cxel4xHGfBBCYgXFR5hE2z78cIXTcJ/bqxYYcsaLnotDJtVhxY1jugZs93gklFYbV2INtlDIJdbLZbeLw+928QecBo/5sNDycdxD8UEIiRUUH2ESyYJ6oLRGqbsh1uZQZ7cENnmTLR9biysNj52SYIXJZFKsFTIeSUKNQVM4ALAE+aTlRUW2fKQm+N0uViXgNES2C1Ntj3u0HyvdLoSQaKH4CJNgi7fI5xuLMPLJZXj6c191UTF2Qx3HIQWk2sqWj3061U5lUurjMbTBfx6vvmtERq/Gh4y8hsgl1BNsfrdLsJgP8c7XyoDT4x6tAOfnTAiJllYrPrxeCZe+sgLT5q8La3y4d/P/rC/H/vI3OwAALrffuuHUxHFo+6XIlpC6IDU7EutTcrWz8Xi9wS0fQcWHep/YbTeY5UNcfPKEHjHk+CQg4DRcRU4IIRpa7a/HtsOVWLmjBJ/8cjBkaXIgfLdLO6FzbHmtS2Xt+HbbEeWx2yMFlEuXLSGiRUTMRgH86Y1aLeHxSrq1OPyvM56/1iqiahIXZrZLbqq/O26wrBsSv2hFatt0Ck5CSHS0WvEhrsV6d/WAWgSEa/kQg0grat1wCYv27W/7M17qPN6AbBfZ8iFvP7VXDq4a2Vl33trZeCUEtXwEE0/BikfJC04oy4d4F1xcUWt4LhK/aL8nBZlJzTMRQkjc02rFh1UokGQkPsS7/XAtH4fK/dkttS4PXF59a0Sd2xuwTxYu8narxRxgsZDFgNZa4fZ6Dd+H73XGcw44h0pUBIn5MBBkJ3TIMD4ZiVu037mCrESDkYQQEpxW29VWbMSmtRgcKK3Bhv1lGNo5S9kWbmzd0Sq/+Kip8xg2g3O6Ay0fsivmvg82APDFXlQ51XMzmofXayyigMhiPvQsH9p4FQAwaaTr938dh1/3leKMvvmG5yLxi/a7l5Vsb56JEELintYrPoQ4D22sxITnlqPC6cb9E/so20I0jVWoFsSC0+0xLIle5/YGZLvsL63BH/75rfLcajarCn4B/rtP7ULgs3wYx3zoWW7mXze8/pjq7XpZLLX1tUfMJijvSSto2mckon0G74aPVwLLqzPbhRASHa1WfIjBnlqLQUV9yuvMzzYr27SZKXpIkqQqkV5TZywGfG4X9TH//vkW1XOrxYQB7dORbLcoFU79v/fqH36vhKCN5fQsHyO7t6k/pvGiIosWWXzZrWZF5HDxaV1oP+5oC+8RQkhEMR8zZ87E0KFDkZqaitzcXEyaNAlbtqgXzNraWkybNg3Z2dlISUnB5MmTUVxcHNNJxwK15UN/0RbHhCM+XB4p6HE7Z/sD9FzeQMuHFpvZDJPJhLtO76lsMwWEmvqpqjPu/2I2sJjobTOq3wEADqtQA4SLT6uClg9CSKyISHx88803mDZtGlauXIklS5bA5XLhjDPOQFVVlTLmrrvuwkcffYSFCxfim2++wYEDB3DBBRfEfOINxR3E7aKHxyBwVERredDGkohBmy6PN6DCqRY52FNd9Mv3v966XxWk+Zz8urREW+C+IIuKdoHp1y7NcB85vgkQqRSfhJAoicjtsnjxYtXzefPmITc3F2vXrsWYMWNQVlaGOXPmYP78+Rg3bhwAYO7cuejTpw9WrlyJESNGxG7mDUQM9hRFgtfAwqENDtVDKzbkFvUyovhwe6SA/Vps9emroviQ7z71fvYrg4gPWShkJNoCesAE3NEadKsFgIuHFOCH7Ufr9wWdPjnO0H4X2MOHEBItDYr5KCsrAwBkZfmyQtauXQuXy4Xx48crY3r37o2OHTtixYoVuuLD6XTC6fRniJSXlzdkSmEj1uMQ3SO/FemfPxy3S7XG7VFc7q93kWAzq8qfuzxeVNS3sE+yW1CtE68h/9gn2MwB2/QIVtxLfl26ruVD/dzI7ZKb6sB5g9rB45WQ7LAGLdlOjj/4cRNCYkXUdT68Xi/uvPNOjBo1Cv379wcAFBUVwW63IyMjQzU2Ly8PRUVFuseZOXMm0tPTlX8FBQXRTikixNiMhz7ciB/qq49e+vJK3fGh4jOAQMuHKD68ktbtIimWiswk/ZRFCfW9VlRxFvL/gSvBkcrQ4kPP7aJ1n+gFnMrzNJlMmDy4A87sz3Ta1gZjfAghsSJq8TFt2jRs2LABCxYsaNAEpk+fjrKyMuXf3r17G3S8cBHdKCVVdfjja6sA+DNdAsaHYfn4ZV+Z6rkoPurcXtUx3B6v4nYxqpcgZ5ioYj6UImMhp6NCFhTdc1MC9gULJBQtH1x7Wjf8/AkhsSIqt8utt96Kjz/+GMuXL0eHDh2U7fn5+airq0NpaanK+lFcXIz8fP07ZYfDAYfDobuvsah1efDe2n0B28c987Xha0LFfLy7Zi+mv/+raluxUO1US51HQo3L53bJSAq0RgCAt159WCIQACaTfk0S+RB3n94TxeW1OPeE9gH7ZIwsHwwwbd3Q8kEIiRURWT4kScKtt96KDz74AMuWLUOXLl1U+wcPHgybzYalS5cq27Zs2YI9e/agsLAwNjOOAf9ZsRuf/HowYPuOI1U6o324Q2S7/E0jPAB1tVMtRyqdOFYf+Glk+dATH3qWD3F/ho5bxTfeNyY1wYYXpwxWuU0Csl1M+pYPLj6tG37+hJBYEZHlY9q0aZg/fz7+97//ITU1VYnjSE9PR2JiItLT03Httdfi7rvvRlZWFtLS0nDbbbehsLCwRWW6LN96OOLXhPK66LllDlcYiw8Rw5iP+kOKBgd/Yzm1RUKOYclMtiuiJlyCWT5UmS+0fLRq+OkTQmJFRJaP2bNno6ysDKeccgratm2r/HvnnXeUMc899xzOPvtsTJ48GWPGjEF+fj7ef//9mE+8IfTITY34Nd4g9dXlrJXA14Q+rsVs0s1AEV9vDmF9EAVCloGQCUawmA+11SXiQ5PjCBo+CCGxIiLLhxRGg5OEhATMmjULs2bNinpSjY3cpyQSjOp/AL6eLCJWs8kwQFW0UgBAdrIddqu+BpSvtyg4TDpuF9E1khlFs69wi4yxqFTrxqT6HjbjRAghcU/U2S7xTLBKoEYE013a+hrZKcYCIFMTXJqT6ggoYS6jxHyYAq0PJgN3SDSWj3ADTul2ITL8JhBCGgLFR5gEc7toK4a2STHO3snQiIOcVAesFv2PQTaQiHeZSsCpMM7SQMtHsDofVrpdiA4sMEcIaQitUnwEK0NuRLD4jWPVastHssPYm6XNRslJccBmCW75MOtYPkREsZCVrB8/Eoxwy6sz1ZbI8KtACGkIrVJ8VDmDx3yIdTey6y0JwSwfxzRuF7uBJcN3bLvmuQ1Ws8H4+lOq63zopNoKT4yCV4OhXUisghgSHzPVksgE665MCCGhaKXiI7jl49KhHZXH/dunAwge86FNbTWyZABAWqLaKuKwWuAwCDi9cIivgJs5ArdLiiMa8WEyfB6syRxpxfCrQAhpAK1SfOg1cZPpmpOMU3rlKM/lmIdglo+yGq34ML6sKRqXjN1qRsfspIBxmUk2jOzWBoA21db3v8nAHZLs8JdiD5cAy4dgiWGqLdGDXwVCSENoleIjWLXSZy8epAqytIQhPmo0YsZmYMkAAuNB7FYzeuj0W8lLS1Aem3UyW4wtH5FXzNfGfIheIKO0W0IIISRaWqX48ASJHk20WVSLsRzzECzgtLpO7cYJFvORaFNbJuwWsyoOpFtOMgBgynC/68eiV1/BoLx6SkLk4kPrTjG2fFB8EB/8LhBCGkJUjeXinWDiI8luUYkJi7AQS5Kkm2KodeMY1e0AAl0ycoGxVX87DaXVLnTMSsJvReUY1CFDGaOXaisiipNke+QfqVYric9FIcIFhxBCSCxolZYPUXv0ykvFGX3zlOepCVbVIisKCSPNUuNSi49g7gltMKosPvLSEtArPxWJdgtO6php2E1Wr7eLBP/EYuF2sRhYPuh2ITLB3JCEEBKKVik+5JiP0/vm4bWpQyD+jCY7rIYdY41+cLWWj2CVQG0WM56+cKDy3CjTRXU8nYwTcY61Ln8MS7LDiscm9QcQ3AJjdHxAbUlRCQ5qD1JPMOshIYSEolWKDzne9OFz+6EgKwluj3/xtlnMQSwf+j+42oDTYGu+1WLCsM5ZyvOwxIcwxKSTaitaXuxWMy4f0Qm/zDgDVxZ2DnlsILBOicViID643pB6jHoXEUJIOLRK8eGRe6bUL6zaH1Ijy4eRpblKE3AaLDbCZjarCncZNZUzOp4SbyqcwuUJzN5JSwi/3sfwrlmq55YIxRchhBASCa1TfHjVZcu1i6qR5cNo7dWrG2Jk/bBZTaqgU7sldF0OvW6yYsyH26M/sZ55gSm8egwUglsB4zgPag9CCCGxoNVlu3gFK4e8sLo8xuJDDL7Uu/P3eCXUuQMtD2aTSXe81WxWiQ9rkGqoevPRo07H8gEAFw0pQEl1HUZ0zQ55jvYZidhfWgMgiPig34UQQkgMaHXiwyMIAtmioM0QEa0WojjQExMVta6AbUB90KmOX9xmMamOGU4GiRjzIR9R1CNGwX8Wswm3nNI95PH1Xqc8NtHyQQghJLa0PvEhLNTyov7QOX2x/1gNbhjTFYBx6XK9NX5LUQUAoF16Ag6U1fqPbeR2sZhhE9REOAkkKstHvQIQ5xjrzANVaq/K8kEIIYQ0nFYnPkTrhbzIdspOxud3jVG2i2u9OuYjcPndeKAcANC3XboiPkzQj9MAAKvFrKr1oVe0TItFRwA0Zr0voxRdWj4IIYTEglYXcOrWifnQYo7A8iHHSchl0fWOIWIzmyIu3NUUhUVFYWUcY0L1QQghpOG0OvGhCjg1WGRFPSCO0Yv5OFrpBABkp9hV243Wb5vVrLJ2dNWIFj304i4mn9QeANA7PzXk6yPFyPLB0g6EEEJiQatzu3gitHyYzSbIsaO64qO+QFd2skO13ejY8sL+80NnwOn2hFWPQ88SMbhTFr7986nITXOg1/2LQx4jEoJVaCWEEEIaSusTH0rApnG8hbjZZPKnzerFPByprBcfGsuHodulPs02PdEGILxCYGaDdNeCrKSwXh8r9GJeCCGEkEhphW4X3/9GLhcgsJeKUTEywO92aZPit3yYTCZD64G2q208QbcLIYSQWBC/K2GUyJaPYK4FdQt7/3Pt4lvr8uBIvfjITVW7XYwOH05RsWA0lvEhnMNSexB2NiaExIJWJz7kgNOoLB8a9bHtUCW8ks+FkhMgPvRLtNvj2PJBtwuh+CCExIL4XQmjRE61DdZuXh3zYVKsGNq1d+shX4GxXvmpAfEjovgQm8c12PIRZJ+tgccmJBR3je8JALh4SIdmngkhJJ5pfQGn3tBuF7Xlw7gBXUmVr7R6flpC4DEEWWe3mpXmc1Zz7PXei1NOwoP/24B/XXZSzI8twq625KaxXXFq7xz0yI19ijchpPXQ6sSHvIAGMx9rW9j7Yz7Ui29NnRsAkGQP7Exr0bhuZBrqdtFb//8woC3O6p8fVrXUSI5LiBaTyYTe+WnNPQ1CSJzT6twuiuUjaMyH5rlZtnyot8vWjARboPjQWk9kGup2MaIhwiNcKFAIIYTEglYrPoIZIIziN7QBl7L40Fo+MpJsKreOKvi0wTEfzacA6HYhhBASC1qd+FDcLkEsBdpdZsXtot5e61KLj39cdALG98nF9aO7qqwdoviwNTTmoxnXf2oPQgghsaDVxXxEGnBqMpkUS4j2zl+2fCTafZdx8uAOmDy4Q8AxVEKkhaYqhmNRofYghBASC1qd5eNYta8cerBU24CYD4OAU0V8hIj5iGU8RrMKAKoPQgghMaDViY9r5q0BAOw6Wm04RhuM6o/5UI/Tul2MaIJY0CaBMR+EEEJiQasTH+EQGPNh5Hbxpdom6ogPcWywzJpIYZVRQggh8Q7Fhw5asSA/9XjDd7uoxUeMJ9gIhKNpKHsIIYTEAooPHbRa4UBpDQBg2lvrAAAujxfbDlWgJojbRdQpsbV8xOxQEeOw8utCCCGk4XA10UEdLOoXEgfKagEAf/98C8Y/uxy76+NGdN0ugvqIh5iPYJrmmYtOQNecZDw2qX+TzYcQQsjxS6tLtQ2HUGLhw/UHVM+T7IGXUXS7aOuDNITmMHxcOLgDLhzMRmKEEEJiAy0fOgRLjX3t2x0oKq9VbdOL+fAI4kMbK0IIIYS0ZlqV+HB7vA0+xmOf/BawTd/t4n8cS/ERBx4cQgghJCitSnzUxUB86KEfcCrpPo6W28Z1R7v0BNw4tluDj6UHM3gJIYQ0Fa0q5sPp8ouPk7u3idlxbTpd6rwxdrvcc0Yv3H16zybpXksIIYQ0Jq3K8uF0+8XH3KuHNuq5XJ7YWj6A2JZpJ4QQQpqLViY+/HU59KwVekS73FfUupTHDDglhBBC/LQq8VFXb/loimJZastHo58uBsTFJAkhhBwHtCrx4VTER/BGcLHGGx/qgxBCCGkSWpn48LldHLaGve0euSmYcU5fAEBqQuiYXU8cpJJcOLgAADC4U2Yzz4QQQsjxTqvKdimv8XWhTdapSBoulw0rwOOTBsBkAjq1SUa/tmlBxyfYzHER83H36T0xpFMmhnXNau6pEEIIOc5pVeLjQJmvQVzb9ISoXt87PxUzLxioPD+1V27I13TOTsb+0hpVpk1LxG41Y3zfvOaeBiGEkFZAxP6H5cuX45xzzkG7du1gMpmwaNEi1X5JkvDggw+ibdu2SExMxPjx47F169ZYzbdByN1p22Ukhv8iIb3Vagk/92Xe1UMxtHMmZl8+GHOvGoq26Ql46fLB4Z+XEEIIOU6JWHxUVVXhhBNOwKxZs3T3P/3003jhhRfw0ksvYdWqVUhOTsaECRNQW1urO76p+L24ArO+2g4AaJsRneXDYg7/cp3SKxcLbxqJLm2SMaRzFlZMPw1n9s+P6ryEEELI8UTEbpezzjoLZ511lu4+SZLw/PPP4/7778d5550HAHjjjTeQl5eHRYsW4dJLL23YbBuA2PxtUIeMqI5hNbPIFyGEENJQYhrzsXPnThQVFWH8+PHKtvT0dAwfPhwrVqzQFR9OpxNOp1N5Xl5eHsspKRRkJeGR8/phWJcs9M4PHiRqBMUHIYQQ0nBimmpbVFQEAMjLUwcu5uXlKfu0zJw5E+np6cq/goKCWE5JxZWFnaMWHoAvKJMQQgghDaPZV9Pp06ejrKxM+bd3797mnpKK7jkpuH9iH7RJseOhc/o193QIIYSQuCembpf8fF9AZXFxMdq2batsLy4uxqBBg3Rf43A44HA4YjmNmPDhraOw7VAlCrtlo7BbNq49uQsbuxFCCCExIKaWjy5duiA/Px9Lly5VtpWXl2PVqlUoLCyM5akanYEdMnDBSR2U5xQehBBCSGyI2PJRWVmJbdu2Kc937tyJ9evXIysrCx07dsSdd96Jxx57DD169ECXLl3wwAMPoF27dpg0aVIs500IIYSQOCVi8bFmzRqceuqpyvO7774bADB16lTMmzcPf/7zn1FVVYUbbrgBpaWlOPnkk7F48WIkJERXW4MQQgghxxcmSWpZXc/Ky8uRnp6OsrIypKVFn5lCCCGEkKYjkvW72bNdCCGEENK6oPgghBBCSJNC8UEIIYSQJoXigxBCCCFNCsUHIYQQQpoUig9CCCGENCkUH4QQQghpUig+CCGEENKkUHwQQgghpEmh+CCEEEJIkxJxb5fGRq72Xl5e3swzIYQQQki4yOt2OF1bWpz4qKioAAAUFBQ080wIIYQQEikVFRVIT08POqbFNZbzer04cOAAUlNTYTKZYnrs8vJyFBQUYO/evWxa14jwOjcNvM5NA69z08Fr3TQ01nWWJAkVFRVo164dzObgUR0tzvJhNpvRoUOHRj1HWloav9hNAK9z08Dr3DTwOjcdvNZNQ2Nc51AWDxkGnBJCCCGkSaH4IIQQQkiT0qrEh8PhwEMPPQSHw9HcUzmu4XVuGnidmwZe56aD17ppaAnXucUFnBJCCCHk+KZVWT4IIYQQ0vxQfBBCCCGkSaH4IIQQQkiTQvFBCCGEkCaF4oMQQgghTUqrER+zZs1C586dkZCQgOHDh+PHH39s7inFFTNnzsTQoUORmpqK3NxcTJo0CVu2bFGNqa2txbRp05CdnY2UlBRMnjwZxcXFqjF79uzBxIkTkZSUhNzcXPzpT3+C2+1uyrcSVzz55JMwmUy48847lW28zrFh//79uPzyy5GdnY3ExEQMGDAAa9asUfZLkoQHH3wQbdu2RWJiIsaPH4+tW7eqjlFSUoIpU6YgLS0NGRkZuPbaa1FZWdnUb6XF4vF48MADD6BLly5ITExEt27d8Oijj6oaj/E6R8fy5ctxzjnnoF27djCZTFi0aJFqf6yu6y+//ILRo0cjISEBBQUFePrpp2PzBqRWwIIFCyS73S79+9//ljZu3Chdf/31UkZGhlRcXNzcU4sbJkyYIM2dO1fasGGDtH79eukPf/iD1LFjR6myslIZc9NNN0kFBQXS0qVLpTVr1kgjRoyQRo4cqex3u91S//79pfHjx0s//fST9Omnn0pt2rSRpk+f3hxvqcXz448/Sp07d5YGDhwo3XHHHcp2XueGU1JSInXq1Em66qqrpFWrVkk7duyQPv/8c2nbtm3KmCeffFJKT0+XFi1aJP3888/SueeeK3Xp0kWqqalRxpx55pnSCSecIK1cuVL69ttvpe7du0uXXXZZc7ylFsnjjz8uZWdnSx9//LG0c+dOaeHChVJKSor0z3/+UxnD6xwdn376qXTfffdJ77//vgRA+uCDD1T7Y3Fdy8rKpLy8PGnKlCnShg0bpLfffltKTEyUXn755QbPv1WIj2HDhknTpk1Tnns8Hqldu3bSzJkzm3FW8c2hQ4ckANI333wjSZIklZaWSjabTVq4cKEy5rfffpMASCtWrJAkyffHYjabpaKiImXM7NmzpbS0NMnpdDbtG2jhVFRUSD169JCWLFkijR07VhEfvM6x4S9/+Yt08sknG+73er1Sfn6+9Pe//13ZVlpaKjkcDuntt9+WJEmSNm3aJAGQVq9erYz57LPPJJPJJO3fv7/xJh9HTJw4UbrmmmtU2y644AJpypQpkiTxOscKrfiI1XV98cUXpczMTNXvxl/+8hepV69eDZ7zce92qaurw9q1azF+/Hhlm9lsxvjx47FixYpmnFl8U1ZWBgDIysoCAKxduxYul0t1nXv37o2OHTsq13nFihUYMGAA8vLylDETJkxAeXk5Nm7c2ISzb/lMmzYNEydOVF1PgNc5Vnz44YcYMmQILrroIuTm5uLEE0/Eq6++quzfuXMnioqKVNc5PT0dw4cPV13njIwMDBkyRBkzfvx4mM1mrFq1quneTAtm5MiRWLp0KX7//XcAwM8//4zvvvsOZ511FgBe58YiVtd1xYoVGDNmDOx2uzJmwoQJ2LJlC44dO9agOba4rrax5siRI/B4PKofYgDIy8vD5s2bm2lW8Y3X68Wdd96JUaNGoX///gCAoqIi2O12ZGRkqMbm5eWhqKhIGaP3Ocj7iI8FCxZg3bp1WL16dcA+XufYsGPHDsyePRt33303/va3v2H16tW4/fbbYbfbMXXqVOU66V1H8Trn5uaq9lutVmRlZfE61/PXv/4V5eXl6N27NywWCzweDx5//HFMmTIFAHidG4lYXdeioiJ06dIl4BjyvszMzKjneNyLDxJ7pk2bhg0bNuC7775r7qkcd+zduxd33HEHlixZgoSEhOaeznGL1+vFkCFD8MQTTwAATjzxRGzYsAEvvfQSpk6d2syzO35499138dZbb2H+/Pno168f1q9fjzvvvBPt2rXjdW7lHPdulzZt2sBisQRkAxQXFyM/P7+ZZhW/3Hrrrfj444/x1VdfoUOHDsr2/Px81NXVobS0VDVevM75+fm6n4O8j/jcKocOHcJJJ50Eq9UKq9WKb775Bi+88AKsVivy8vJ4nWNA27Zt0bdvX9W2Pn36YM+ePQD81ynY70Z+fj4OHTqk2u92u1FSUsLrXM+f/vQn/PWvf8Wll16KAQMG4IorrsBdd92FmTNnAuB1bixidV0b87fkuBcfdrsdgwcPxtKlS5VtXq8XS5cuRWFhYTPOLL6QJAm33norPvjgAyxbtizAFDd48GDYbDbVdd6yZQv27NmjXOfCwkL8+uuvqi/8kiVLkJaWFrAQtFZOO+00/Prrr1i/fr3yb8iQIZgyZYrymNe54YwaNSogVfz3339Hp06dAABdunRBfn6+6jqXl5dj1apVqutcWlqKtWvXKmOWLVsGr9eL4cOHN8G7aPlUV1fDbFYvMxaLBV6vFwCvc2MRq+taWFiI5cuXw+VyKWOWLFmCXr16NcjlAqD1pNo6HA5p3rx50qZNm6QbbrhBysjIUGUDkODcfPPNUnp6uvT1119LBw8eVP5VV1crY2666SapY8eO0rJly6Q1a9ZIhYWFUmFhobJfTgE944wzpPXr10uLFy+WcnJymAIaAjHbRZJ4nWPBjz/+KFmtVunxxx+Xtm7dKr311ltSUlKS9OabbypjnnzySSkjI0P63//+J/3yyy/Seeedp5uqeOKJJ0qrVq2SvvvuO6lHjx6tPgVUZOrUqVL79u2VVNv3339fatOmjfTnP/9ZGcPrHB0VFRXSTz/9JP30008SAOnZZ5+VfvrpJ2n37t2SJMXmupaWlkp5eXnSFVdcIW3YsEFasGCBlJSUxFTbSPjXv/4ldezYUbLb7dKwYcOklStXNveU4goAuv/mzp2rjKmpqZFuueUWKTMzU0pKSpLOP/986eDBg6rj7Nq1SzrrrLOkxMREqU2bNtI999wjuVyuJn438YVWfPA6x4aPPvpI6t+/v+RwOKTevXtLr7zyimq/1+uVHnjgASkvL09yOBzSaaedJm3ZskU15ujRo9Jll10mpaSkSGlpadLVV18tVVRUNOXbaNGUl5dLd9xxh9SxY0cpISFB6tq1q3TfffepUjd5naPjq6++0v1Nnjp1qiRJsbuuP//8s3TyySdLDodDat++vfTkk0/GZP4mSRJKzRFCCCGENDLHfcwHIYQQQloWFB+EEEIIaVIoPgghhBDSpFB8EEIIIaRJofgghBBCSJNC8UEIIYSQJoXigxBCCCFNCsUHIYQQQpoUig9CCCGENCkUH4QQQghpUig+CCGEENKk/D8M+GdZSuUvsgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGzCAYAAACPa3XZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAABGAklEQVR4nO3deVxU5f4H8M8MMDOsw74pIKmBS6ZhKa5lXMnU3FOvJZldb4V7i5k3lzas7tWsq1T+Suua11JT00yvabkU4r4r7rugosywDjDz/P5ATo6sA8Ocgfm8Xy9eLzjncOY7DwPz4TnP8xyFEEKAiIiIyEaUchdAREREjoXhg4iIiGyK4YOIiIhsiuGDiIiIbIrhg4iIiGyK4YOIiIhsiuGDiIiIbIrhg4iIiGyK4YOIiIhsiuGDyErOnz8PhUKBf/7zn7U+l0KhwNixY61QVf3x3HPPoUmTJmbbFAoFZs6cWeX3zpw5EwqFwqr1/Pbbb1AoFPjtt9+sel4iYvigBuTYsWOYOXMmzp8/X2bfggULsHjxYpvXVJ/88ccfmDlzJrKysuQuxab42iCyPYYPajCOHTuGWbNmMXzU0B9//IFZs2bZVfjIz8/HP/7xjzp9jIpeG926dUN+fj66detWp49P5IgYPojIbmk0Gjg7O8vy2EqlEhqNBkol/0xWxmQyoaCgQO4yqJ7hbxVZpPTa+unTp/Hcc8/B29sbWq0Wo0aNQl5entmxxcXFeOedd9C0aVOo1Wo0adIEb775JgwGg0WPeeHCBbz88suIioqCq6sr/Pz8MGTIELMejsWLF2PIkCEAgMceewwKhUK6Xt+kSRMcPXoUW7dulbY/+uijAIBbt27h1VdfxQMPPAAPDw94eXmhV69eOHjwYJk6CgoKMHPmTNx///3QaDQICQnBwIEDcebMmQprF0JgzJgxUKlU+OGHHyx63gDw7bffIioqChqNBjExMdi2bVuZY65cuYLnn38eQUFBUKvVaNWqFb766qsyx3366ado1aoV3Nzc4OPjg/bt22Pp0qUASn6ur732GgAgMjJSaqfyepEAYOzYsfDw8CjzMweA4cOHIzg4GEajEQCwZs0a9O7dG6GhoVCr1WjatCneeecdaX9lyhvzsWPHDjz88MPQaDRo2rQpPv/883K/d9GiRejRowcCAwOhVqvRsmVLJCcnmx1T2WujojEfy5cvR0xMDFxdXeHv749nnnkGV65cMTvmueeeg4eHB65cuYL+/fvDw8MDAQEBePXVV6v1vC1ps9TUVDz55JPw8fGBu7s72rRpg3nz5pkdc+LECTz99NMICAiAq6sroqKiMG3aNLN67x1vA5Q/lqZ0PNK3336LVq1aQa1WY8OGDQCAf/7zn+jUqRP8/Pzg6uqKmJgYrFixotznuGTJEjzyyCPS67Fbt2743//+BwBISEiAv78/ioqKynxfz549ERUVVXkDkt2T518KqveefvppREZGIikpCfv27cP//d//ITAwEB988IF0zAsvvICvv/4agwcPxiuvvILU1FQkJSXh+PHjWLVqVbUfa/fu3fjjjz8wbNgwNG7cGOfPn0dycjIeffRRHDt2DG5ubujWrRvGjx+PTz75BG+++SZatGgBAGjRogU+/vhjjBs3Dh4eHtIf3KCgIADA2bNnsXr1agwZMgSRkZHIyMjA559/ju7du+PYsWMIDQ0FABiNRvTp0webN2/GsGHDMGHCBGRnZ2PTpk04cuQImjZtWqZuo9GI559/Ht999x1WrVqF3r17W9TGW7duxXfffYfx48dDrVZjwYIFeOKJJ7Br1y60bt0aAJCRkYGOHTtKbwgBAQH4+eefMXr0aOj1ekycOBEAsHDhQowfPx6DBw/GhAkTUFBQgEOHDiE1NRV//etfMXDgQJw8eRL//e9/MXfuXPj7+wMAAgICyq1t6NChmD9/Pn766Scp9AFAXl4e1q5di+eeew5OTk4ASoKhh4cHJk+eDA8PD2zZsgXTp0+HXq/HRx99ZFGbHD58GD179kRAQABmzpyJ4uJizJgxQ/p53i05ORmtWrXCU089BWdnZ6xduxYvv/wyTCYTEhMTAaDS10Z5Fi9ejFGjRuHhhx9GUlISMjIyMG/ePPz+++/Yv38/vL29pWONRiPi4+PRoUMH/POf/8Qvv/yCf/3rX2jatCleeumlSp9nddts06ZN6NOnD0JCQjBhwgQEBwfj+PHjWLduHSZMmAAAOHToELp27QoXFxeMGTMGTZo0wZkzZ7B27Vq899571W77u23ZsgXff/89xo4dC39/fym4zJs3D0899RRGjBiBwsJCLFu2DEOGDMG6devMXv+zZs3CzJkz0alTJ7z99ttQqVRITU3Fli1b0LNnTzz77LP45ptvsHHjRvTp00f6vvT0dGzZsgUzZsyoUd1kRwSRBWbMmCEAiOeff95s+4ABA4Sfn5/09YEDBwQA8cILL5gd9+qrrwoAYsuWLdV+zLy8vDLbUlJSBADxzTffSNuWL18uAIhff/21zPGtWrUS3bt3L7O9oKBAGI1Gs23nzp0TarVavP3229K2r776SgAQc+bMKXMOk8kkfR8A8dFHH4mioiIxdOhQ4erqKjZu3FjdpyoBIACIPXv2SNsuXLggNBqNGDBggLRt9OjRIiQkRNy8edPs+4cNGya0Wq3Udv369ROtWrWq9DE/+ugjAUCcO3euyvpMJpNo1KiRGDRokNn277//XgAQ27Ztk7aV9/P7+9//Ltzc3ERBQYG0LSEhQURERJgdB0DMmDFD+rp///5Co9GICxcuSNuOHTsmnJycxL1/zsp73Pj4eHHfffeZbavotfHrr7+avZ4KCwtFYGCgaN26tcjPz5eOW7dunQAgpk+fbvZcAJi9hoQQol27diImJqbMY92rOm1WXFwsIiMjRUREhLh9+7bZsaWvSSGE6Natm/D09DRrs3uPKa/thfjz9/1uAIRSqRRHjx6tsu7CwkLRunVr0aNHD2nbqVOnhFKpFAMGDCjzu1dak9FoFI0bNxZDhw412z9nzhyhUCjE2bNnyzw21S+87EI18uKLL5p93bVrV2RmZkKv1wMA1q9fDwCYPHmy2XGvvPIKAOCnn36q9mO5urpKnxcVFSEzMxPNmjWDt7c39u3bV6P6S6nVaumavtFoRGZmJjw8PBAVFWV27pUrV8Lf3x/jxo0rc457u6ULCwul//bWr1+Pnj171qi22NhYxMTESF+Hh4ejX79+2LhxI4xGI4QQWLlyJfr27QshBG7evCl9xMfHQ6fTSc/B29sbly9fxu7du2tUy70UCgWGDBmC9evXIycnR9r+3XffoVGjRujSpYu07e6fX3Z2Nm7evImuXbsiLy8PJ06cqPZjGo1GbNy4Ef3790d4eLi0vUWLFoiPjy9z/N2Pq9PpcPPmTXTv3h1nz56FTqer9uOW2rNnD65fv46XX34ZGo1G2t67d29ER0eX+5ou7/fk7NmzVT5Wddps//79OHfuHCZOnGjW4wL8+Zq8ceMGtm3bhueff96sze4+pia6d++Oli1bVlr37du3odPp0LVrV7PfpdWrV8NkMmH69OllxtOU1qRUKjFixAj8+OOPyM7OlvZ/++236NSpEyIjI2tcO9kHhg+qkXv/kPn4+AAo+YMDlIzTUCqVaNasmdlxwcHB8Pb2xoULF6r9WPn5+Zg+fTrCwsKgVqvh7++PgIAAZGVl1ehN5G4mkwlz585F8+bNzc596NAhs3OfOXMGUVFR1Rr8mJSUhNWrV2PFihXS+IGaaN68eZlt999/P/Ly8nDjxg3cuHEDWVlZ+OKLLxAQEGD2MWrUKADA9evXAQBTpkyBh4cHHnnkETRv3hyJiYn4/fffa1wbUHLpJT8/Hz/++CMAICcnB+vXr8eQIUPM3tiOHj2KAQMGQKvVwsvLCwEBAXjmmWcAwKKf340bN5Cfn19uu5Q3BuD3339HXFwc3N3d4e3tjYCAALz55psWP26p0tdseY8VHR1d5jWt0WjKXLby8fGRfkcqU502Kx1rVHoJrjylQaeyY2qiojf/devWoWPHjtBoNPD19UVAQACSk5PL/C4plcpyw8vdRo4cifz8fOkSbVpaGvbu3Ytnn33Wek+EZMMxH1Qjpdfz7yWEMPvaGgs/jRs3DosWLcLEiRMRGxsLrVYLhUKBYcOGwWQy1erc77//Pt566y08//zzeOedd+Dr6wulUomJEyfW+Nzx8fHYsGEDPvzwQzz66KNm/yVbU2l9zzzzDBISEso9pk2bNgBKegfS0tKwbt06bNiwAStXrsSCBQswffp0zJo1q0aP37FjRzRp0gTff/89/vrXv2Lt2rXIz8/H0KFDpWOysrLQvXt3eHl54e2330bTpk2h0Wiwb98+TJkypdY/v4qcOXMGjz/+OKKjozFnzhyEhYVBpVJh/fr1mDt3bp097t0q+h2pihxtVtHvaUWDY+/u4Si1fft2PPXUU+jWrRsWLFiAkJAQuLi4YNGiRdLAZku0bNkSMTExWLJkCUaOHIklS5ZApVLh6aeftvhcZH8YPqhOREREwGQy4dSpU9LgT6BkgGRWVhYiIiKqfa4VK1YgISEB//rXv6RtBQUFZdajqCzoVLRvxYoVeOyxx/Dll1+abc/KypIGXQJA06ZNkZqaiqKiIri4uFRab8eOHfHiiy+iT58+GDJkCFatWlWj6aKnTp0qs+3kyZNwc3OT/qP29PSE0WhEXFxcledzd3fH0KFDMXToUBQWFmLgwIF47733MHXqVGg0mhoFxaeffhrz5s2DXq/Hd999hyZNmqBjx47S/t9++w2ZmZn44YcfzNbLOHfunMWPVTpTo7x2SUtLM/t67dq1MBgM+PHHH8166X799dcy31vd5136mk1LS0OPHj3KPL4lr+nKVLfNSgc5HzlypMKf/3333ScdUxkfH59y13expIdy5cqV0Gg02LhxI9RqtbR90aJFZeo2mUw4duwY2rZtW+k5R44cicmTJ+PatWtYunQpevfuLfWyUv3Gyy5UJ5588kkAJbMJ7jZnzhwAsGjmh5OTU5kelU8//bTMf2Xu7u4AUO4fUXd393K3l3fu5cuXl5k6OWjQINy8eRP//ve/y5zj3u8HgLi4OCxbtgwbNmzAs88+W6P/VlNSUsyulV+6dAlr1qxBz5494eTkBCcnJwwaNAgrV64s983lxo0b0ueZmZlm+1QqFVq2bAkhhDSdsbL2q8jQoUNhMBjw9ddfY8OGDWX+Ky397//uNiosLMSCBQuq/Rh3nys+Ph6rV6/GxYsXpe3Hjx/Hxo0bq3xcnU5X5o0QqPi1ca/27dsjMDAQn332mdl08Z9//hnHjx+3eDZTRarbZg899BAiIyPx8ccfl6m/9HsDAgLQrVs3fPXVV2Ztdu/5mzZtCp1Oh0OHDknbrl27ZtGsNCcnJygUCrPfy/Pnz2P16tVmx/Xv3x9KpRJvv/12md+Le3+Xhg8fDoVCgQkTJuDs2bPSpSeq/9jzQXXiwQcfREJCAr744gupG3nXrl34+uuv0b9/fzz22GPVPlefPn3wn//8B1qtFi1btkRKSgp++eUX+Pn5mR3Xtm1bODk54YMPPoBOp4NarZbWeYiJiUFycjLeffddNGvWDIGBgejRowf69OmDt99+G6NGjUKnTp1w+PBhfPvtt9J/jKVGjhyJb775BpMnT8auXbvQtWtX5Obm4pdffsHLL7+Mfv36lam7f//+WLRoEUaOHAkvL68K16OoSOvWrREfH2821RaA2WWS2bNn49dff0WHDh3wt7/9DS1btsStW7ewb98+/PLLL7h16xaAkrURgoOD0blzZwQFBeH48eP497//jd69e8PT0xMApMGt06ZNw7Bhw+Di4oK+fftKoaQ8Dz30EJo1a4Zp06bBYDCYXXIBgE6dOsHHxwcJCQkYP348FAoF/vOf/5Qb2Kpj1qxZ2LBhA7p27YqXX34ZxcXF0vold79x9uzZEyqVCn379sXf//535OTkYOHChQgMDMS1a9fMzlnRa+NeLi4u+OCDDzBq1Ch0794dw4cPl6baNmnSBJMmTarRc7pXddtMqVQiOTkZffv2Rdu2bTFq1CiEhITgxIkTOHr0qBTIPvnkE3Tp0gUPPfQQxowZg8jISJw/fx4//fQTDhw4AAAYNmwYpkyZggEDBmD8+PHIy8tDcnIy7r///moP6u7duzfmzJmDJ554An/9619x/fp1zJ8/H82aNTP72ZS+Xt555x107doVAwcOhFqtxu7duxEaGoqkpCTp2ICAADzxxBNYvnw5vL29rRbwyA7IMMOG6rHSqXc3btww275o0aIy0zSLiorErFmzRGRkpHBxcRFhYWFi6tSpZtMrq+P27dti1KhRwt/fX3h4eIj4+Hhx4sQJERERIRISEsyOXbhwobjvvvukqZel0yTT09NF7969haenpwAgTa0sKCgQr7zyiggJCRGurq6ic+fOIiUlRXTv3r3M9Mu8vDwxbdo06fkEBweLwYMHizNnzgghzKfa3m3BggUCgHj11Ver/ZwBiMTERLFkyRLRvHlzoVarRbt27cqdRpyRkSESExNFWFiYVNfjjz8uvvjiC+mYzz//XHTr1k34+fkJtVotmjZtKl577TWh0+nMzvXOO++IRo0aCaVSWe1pt9OmTRMARLNmzcrd//vvv4uOHTsKV1dXERoaKl5//XWxcePGMtOiqzPVVgghtm7dKmJiYoRKpRL33Xef+Oyzz8qdEvrjjz+KNm3aCI1GI5o0aSI++OADacr03c+rotfGvVNtS3333XeiXbt2Qq1WC19fXzFixAhx+fJls2MSEhKEu7t7mbYor87atJkQQuzYsUP85S9/EZ6ensLd3V20adNGfPrpp2bHHDlyRAwYMEB4e3sLjUYjoqKixFtvvWV2zP/+9z/RunVroVKpRFRUlFiyZEmFU20TExPLrfvLL7+UXq/R0dFi0aJFFT7nr776SmpHHx8f0b17d7Fp06Yyx5VO3x4zZkyV7Ub1h0KIGv4LQkREVMfWrFmD/v37Y9u2bejatavc5ZCVMHwQEZHd6tOnD44fP47Tp09bZfYc2QeO+SDZ5OTkmC1QVZ6AgIAaT1m0R+np6ZXud3V1hVartVE1RPZr2bJlOHToEH766SfMmzePwaOBYc8HyWbmzJlVrjFx7ty5cm94VV9V9Qc0ISGh3Nu7EzkahUIBDw8PDB06FJ999plsdzemusHwQbI5e/ZslUtNd+nSpc4W6ZLDL7/8Uun+0NDQKld+JCKq7xg+iIiIyKa4yBgRERHZlN1dRDOZTLh69So8PT05wIiIiKieEEIgOzsboaGhZe5YfC+7Cx9Xr15FWFiY3GUQERFRDVy6dAmNGzeu9Bi7Cx+lSz1funQJXl5eMldDRERE1aHX6xEWFia9j1fG7sJH6aUWLy8vhg8iIqJ6pjpDJjjglIiIiGyK4YOIiIhsiuGDiIiIbIrhg4iIiGyK4YOIiIhsiuGDiIiIbIrhg4iIiGyK4YOIiIhsiuGDiIiIbIrhg4iIiGyK4YOIiIhsiuGDiIiIbMrubixHREREdePSrTz83/azCPTSIPGxZrLVwZ4PIiIiB3E1Kx9fp1zAyn2XZa2D4YOIiMhBFBpNAACVk7xv/wwfREREDqKoNHw4M3wQERGRDRQWs+eDiIiIbMhQzJ4PIiIisqEiowAAuLDng4iIiGyhkD0fREREZEuFxUYADB9ERERkI6WXXTjglIiIiGyC63wQERGRTXG2CxEREdkUFxkjIiIimyqd7cKptkRERGQTnGpLRERENlV62UXN8EFERES28OdlF4WsdTjL+uhERET1WGGxCaev50BAyF1KtdzIMQCQf6otwwcREVENPb94N3acvil3GRZTOTvJ+vgMH0RERDV04FIWAMDfQwWlQt5LGdXl56FG1+b+stbA8EFERFQDeYXFyDEUAwB+e+0xeKj5llpdHHBKRERUAzezCwEAri5OcFfJexmjvmH4ICIiqoEbOQUAgABPNRT15JKLvWAfERERObTzN3Px85F0mIRlM1Y2HEkHUBI+yDIMH0RE5FCEEMjQG6SwMX7Zfhy6rKvx+eJaBFmrNIfB8EFERA7ltRWHsGLvZbNtSgUwJCYMll498fdQ4/kuTaxXnINg+CAiIoey/dQNAICzUlEyPVYBDG0fhnf6t5a5MsfB8EFERA6jyGjC9eySVT7/mNoDgZ4amStyTAwfRERU7+QVFuO63mDx913PNkCIknub+LtzoKhcLA4fV65cwZQpU/Dzzz8jLy8PzZo1w6JFi9C+fXsAJQN5ZsyYgYULFyIrKwudO3dGcnIymjdvbvXiiYjI8ejyivDoP3/F7byiGp8jWKuBUsnpsXKxKHzcvn0bnTt3xmOPPYaff/4ZAQEBOHXqFHx8fKRjPvzwQ3zyySf4+uuvERkZibfeegvx8fE4duwYNBp2bxERUdUKi00VTn3948xN3M4rglIBuKks78BX3BnjQfJRCFH9ic1vvPEGfv/9d2zfvr3c/UIIhIaG4pVXXsGrr74KANDpdAgKCsLixYsxbNiwKh9Dr9dDq9VCp9PBy8uruqUREVEDseC30/hoYxqqencaEtMYHw150DZFUZUsef+2aIXTH3/8Ee3bt8eQIUMQGBiIdu3aYeHChdL+c+fOIT09HXFxcdI2rVaLDh06ICUlpdxzGgwG6PV6sw8iInJcK/ZcrjJ4qJyU6N0mxDYFkdVZ1F919uxZJCcnY/LkyXjzzTexe/dujB8/HiqVCgkJCUhPL1ntLSjIfMGVoKAgad+9kpKSMGvWrBqWT0RE1fHa8oPYfOK63GVUy63cknum7JjyGLSuLuUe4+KkhMaF91OprywKHyaTCe3bt8f7778PAGjXrh2OHDmCzz77DAkJCTUqYOrUqZg8ebL0tV6vR1gYr8UREVmLodiI5fcsqmXvYiJ80NjHTe4yqI5YFD5CQkLQsmVLs20tWrTAypUrAQDBwcEAgIyMDISE/NkdlpGRgbZt25Z7TrVaDbWa052IiOpKrsEofb5hYlc41YOboEX4uctdAtUhi8JH586dkZaWZrbt5MmTiIiIAABERkYiODgYmzdvlsKGXq9HamoqXnrpJetUTEREFsk1FAMA1M5KRAdzID/Jz6LwMWnSJHTq1Anvv/8+nn76aezatQtffPEFvvjiCwCAQqHAxIkT8e6776J58+bSVNvQ0FD079+/LuonIqIq5BaWhA8PNdeVJPtg0Svx4YcfxqpVqzB16lS8/fbbiIyMxMcff4wRI0ZIx7z++uvIzc3FmDFjkJWVhS5dumDDhg1c44OISCall13c1BygSfbBonU+bIHrfBARWde2kzcw8qtdiA72xIaJ3eQuhxqoOlvng4iI6p+8O5dd3HnZhewEwwcRUQOXc+eyC8MH2QuGDyKiBk7q+VBxzAfZB4YPIqIG7kZ2ya3nvd3KXy2UyNbYB0dEVM8VG004eFkHQ7Gx3P2p524BAO4P8rRlWUQVYvggIqrnPtl8Cp9sOV3lcS1COIOQ7APDBxFRPVZsNGFJ6kUAgEIBNAvwKPe4ZoEeiInwsWVpRBVi+CAiqkdu5Rbi250XUHDnEsut3CLcyi2E1tUFe/8RB2cnDuUj+8fwQURkZ05fz8GaA1dQbCq7BuRXO87BUGwqs73b/QEMHlRvMHwQEdmZWWuPYvupm5Ue06WZP5oHlVxiUTkr8WzHCFuURmQVDB9ERHbm7I1cAED/tqHw81CX2d8yxAuDYhrbuiwiq2H4ICKyI0VGE67p8gEAb/ZugUBP3pSTGh5eICQisiPXsgpgEoDaWYmAcno9iBoC9nwQEdVQVl4hdp27hXLGhdbYoctZAID7AjygUCisd2IiO8LwQURUQy8t2YeUs5l1cu5uzf3r5LxE9oDhg4iohs7ezAFQMgDU1Yo3bfPSOOPZWM5eoYaL4YOIqIZ0+UUAgM+fjUGYr5vM1RDVHxxwSkRUA4ZiIwqKShb78nLl3WKJLMHwQURUA6W9HgoF4KlmJzKRJRg+iIhqQH8nfHhpXKBUclYKkSUY14mIqmAyCaw9dBUXMvOkbdd0BQAALS+5EFmM4YOICMDOs5n429d7kFNYXGafqGQdjwBPLgRGZCmGDyJyOBn6AsxYcxS38wqlbRcy85BtKBs8Sqmdleja3B+BXn8ud+6kUPAeK0Q1wPBBRA5n/eFr2HA0vcx2J6UCK16MRWOfstNm3dVOcFPxTyaRNfA3iYgcTk5BSQ9Hl2b+GP5IuLQ9ws8NrRtp5SqLyGEwfBCRw8ktNAIAooI90btNiMzVEDkeTrUlIoeTd2dQqbsVl0Qnoupj+CAih5N3p+fDlWM4iGTB8EFEDkfq+VCz54NIDgwfRORwcg0lPR+cvUIkD4YPInI4+YWl4YM9H0RyYPggIoeTe+eyC8MHkTzY50hEDcrhyzqM+c8eZBdUvFpprjTmg38CieTA3zwiqjeEEDh9PUearVKeL3eck276VhlPtTOaBnhYszwiqiaGDyKyS0nrj+OblAsQ+POubsVGgWJTJXd5u8vsgQ8gtqlfhfv9PdTs+SCSCX/ziMgurdx3BflFZXs4nJQKBN91c7fy3Bfgjv7tGkHjwjEdRPaI4YOI7I4QAvr8IgDAypdiEej5Z9jwdVexx4KonuNvMBHZnfwiIwqNJgBAVLAXPBg2iBoUTrUlIruju9Pr4aRU8P4rRA0QwwcR2Z3S8KF1dYFCoZC5GiKyNvZlElGFTCaBQ1d0yDNUvGZGXUjLyAYAeLu62PRxicg2GD6IqEJLUi9g+pqjsj2+1o3hg6ghYvggogodvqwDULImhq+7bYOAk1KJUZ0jbfqYRGQbDB9EVKF0fclKoW/0isbgmMYyV0NEDQXDB5GDEELAUGyy6HtKlymvalEvIiJLMHwQOQCjSWDggt9x8M5lFEsFa9VWroiIHBmn2hI5gOvZBTUOHlFBngj3dbdyRUTkyNjzQeQAMnMKAZQMHN362qMWfa+rixOUSq61QUTWw/BB5AAyc0vDB++LQkTy42UXIgdwK9cAoOSmbEREcrMofMycORMKhcLsIzo6WtpfUFCAxMRE+Pn5wcPDA4MGDUJGRobViyYiy5RedmH4ICJ7YHHPR6tWrXDt2jXpY8eOHdK+SZMmYe3atVi+fDm2bt2Kq1evYuDAgVYtmIgsdyOnpOfD34OzVohIfhZf/HV2dkZwcHCZ7TqdDl9++SWWLl2KHj16AAAWLVqEFi1aYOfOnejYsWPtqyWiGjl/MxcAEO7rJnMlREQ1CB+nTp1CaGgoNBoNYmNjkZSUhPDwcOzduxdFRUWIi4uTjo2OjkZ4eDhSUlIqDB8GgwEGg0H6Wq/X1+BpEBEAnL6eg03HMmASwmz7wUsl02wjAzhllojkZ1H46NChAxYvXoyoqChcu3YNs2bNQteuXXHkyBGkp6dDpVLB29vb7HuCgoKQnp5e4TmTkpIwa9asGhVPROZeW3EQ+y9mVbi/WYCH7YohIqqAReGjV69e0udt2rRBhw4dEBERge+//x6urq41KmDq1KmYPHmy9LVer0dYWFiNzkXk6C7dygcAPNEqGF6u5r/eDzTSIoyXXYjIDtRqwr+3tzfuv/9+nD59Gn/5y19QWFiIrKwss96PjIyMcseIlFKr1VCrOQiOqLZMJoHbeSWzWmY+1QrBWt6PhYjsU63W+cjJycGZM2cQEhKCmJgYuLi4YPPmzdL+tLQ0XLx4EbGxsbUulIgqpy8ogtFUMtbDx91F5mqIiCpmUc/Hq6++ir59+yIiIgJXr17FjBkz4OTkhOHDh0Or1WL06NGYPHkyfH194eXlhXHjxiE2NpYzXYhs4NadVUw91c5QOzvJXA0RUcUsCh+XL1/G8OHDkZmZiYCAAHTp0gU7d+5EQEAAAGDu3LlQKpUYNGgQDAYD4uPjsWDBgjopnIjMlYYPHy4kRkR2TiHEPXPyZKbX66HVaqHT6eDl5SV3OUR2K8dQjAMXs6RptdtP3cDC7efQqakflv6NvY1EZFuWvH/zDlNE9YwQAoZiE15ashfbT90ss79Lc38ZqiIiqj6GD6J6xGQSGPzZH9h3Zy0PhQJoEfznfxi+7ioMjmksU3VERNXD8EFUj1zV5UvBAwAGtG2EOUPbylYPEVFNMHwQ1SMXMvMAAJH+7lg3rgvc1fwVJqL6h3+5iOxIYbEJr604iNPXc8rdn5VXBKAkfDB4EFF9xb9eRHbk5yPXsObA1SqPaxvmXffFEBHVEYYPIjtSOnvloXBvTIi7v9xjNM5KPBThY8uyiIisiuGDyI6ULhQ29OEwdL8/QOZqiIjqRq3u7UJE1iWtUurGVUqJqOFi+CCyI6Xhw5dLpBNRA8bwQWRHbvP+LETkABg+iOzAiXQ9HnpnE7INxQAAX152IaIGjOGDyA5sP3lTuuTSIsQLWlcXmSsiIqo7DB9EduB2Xknw6NU6GGvHdoZSqZC5IiKiusPwQWQHSsNHixAvODvx15KIGjb+lSOyA7dzS5ZN93Hj5RYiavi4yBiRjRQZTRXuu3Wn58ObA02JyAEwfBDVod9P38TyPZdw8LIO527mVnk81/cgIkfA8EFUR4qNJkz+/gAy9IZqHe/voUbLEK86roqISH4MH0R15MClLCl4TO/TEo9GBcDPQ13h8W4qJ7hwsCkROQCGD6I6cul2HgAg9j4/PN8lUuZqiIjsB//NIqojV7MKAACh3q4yV0JEZF8YPojqyJWsfABAI2+NzJUQEdkXhg+iOnI6IwcA0NjXTeZKiIjsC8d8ENVSYbEJI79KxZErerPtOXduEtch0leOsoiI7BbDB1E1FRQZkXsnUNztf8cysPPsrXK/58HGWoSz54OIyAzDB1E1nL+Zi96fbEduobHCY57tGIEXuprPagn1doVCwZvEERHdjeGDqBpSzmZWGjyigz3xanwUtK68NwsRUVUYPoiq4eKtkjU7RsZG4O1+rWWuhoiofmP4IKrAlax8vLvuGLILinEyIxsAOH6DiMgKGD6IKrBk5wX8fCTdbFvrRlqZqiEiajgYPojuIYTA8r2X8b+jJcFjRIdwPBLpiwBPNafNEhFZAcMH0T32XbyN11cckr4e0SECLUN5t1kiImvhCqdE97h8O1/6fNZTrRg8iIisjOGD6B63cgsBAL0fCEFCpybyFkNE1AAxfBDd4/ad8OHrrpK5EiKihonhg+get/JKwocPwwcRUZ3ggFNyCMev6fH22mPIKyx7b5Z7XbizoJivG1crJSKqCwwf5BB+2HcZKWczLfqe+4M866gaIiLHxvBBDiHHUHJflv5tQ9H3wdAqj/f3UKNNYy4oRkRUFxg+yCHk37nc0ipUi8dbBMlcDRGRY+OAU3IIeXfuSOuqcpK5EiIiYvggh5BfVBI+3Bg+iIhkx/BBDiG/kOGDiMheMHyQQ/jzsguHORERyY3hgxxC6WUXVxf2fBARyY3hgxxC6eJivOxCRCQ/9kFTgyGEQIbeAJMQZfblGTjbhYjIXjB8UIPx6vJDWLnvcqXHsOeDiEh+DB/UIFzMzDMLHirnslcUY8J9EOSpsWVZRERUDoYPahDOZeYCAKKCPLFxUjeZqyEiosrUasDp7NmzoVAoMHHiRGlbQUEBEhMT4efnBw8PDwwaNAgZGRm1rZOoUjeyDQCAQC+1zJUQEVFVahw+du/ejc8//xxt2rQx2z5p0iSsXbsWy5cvx9atW3H16lUMHDiw1oUSVeZmTkn4CPBg+CAisnc1Ch85OTkYMWIEFi5cCB8fH2m7TqfDl19+iTlz5qBHjx6IiYnBokWL8Mcff2Dnzp3lnstgMECv15t9EFkix1CMNQeuAgD8PRk+iIjsXY3CR2JiInr37o24uDiz7Xv37kVRUZHZ9ujoaISHhyMlJaXccyUlJUGr1UofYWFhNSmJHJTRJND7k+04fq0ktLLng4jI/lkcPpYtW4Z9+/YhKSmpzL709HSoVCp4e3ubbQ8KCkJ6enq555s6dSp0Op30cenSJUtLIgd25kYOLmTmAQA6NfXDk21CZK6IiIiqYtFsl0uXLmHChAnYtGkTNBrrTFlUq9VQq/nfKpWVciYTW05UPlh517lbAIAOkb5Y+reOtiiLiIhqyaLwsXfvXly/fh0PPfSQtM1oNGLbtm3497//jY0bN6KwsBBZWVlmvR8ZGRkIDg62WtHkGCZ9dwDp+oJqHdurNV9fRET1hUXh4/HHH8fhw4fNto0aNQrR0dGYMmUKwsLC4OLigs2bN2PQoEEAgLS0NFy8eBGxsbHWq5ocQmZuyQyWZztGwE1d8cqkUUGeGNCuka3KIiKiWrIofHh6eqJ169Zm29zd3eHn5ydtHz16NCZPngxfX194eXlh3LhxiI2NRceO7BKn6isymlBkLLlHyys974e3m0rmioiIyFqsvsLp3LlzoVQqMWjQIBgMBsTHx2PBggXWfhhq4AqKjNLnvBkcEVHDohCinFuAykiv10Or1UKn08HLy0vuckgm1/UFeOT9zVAqgDPvPwmFQiF3SUREVAlL3r9rtbw6UV3Jv9Pz4erixOBBRNTAMHyQXcorvBM+VLz3IRFRQ8PwQXZJ6vlQ8SVKRNTQ8C872aWCwj8vuxARUcPC8EF2iZddiIgaLoYPskt50oBTvkSJiBoa/ltJdqWw2ITRX+/G9lM3AQAeaheZKyIiImvjv5VkV45f00vBw8VJgREdw2WuiIiIrI09H2RX9AVF0ud/vPE4Ajx5x2MiooaGPR9kV/T5xQCAR5r4MngQETVQDB9kV7Lv9Hx4ubJTjoiooWL4ILtSetnFU8OBpkREDRXDB9mV7IKSyy5eGvZ8EBE1VPwLT3bhVEY2tp+6iV3nbgFgzwcRUUPG8EF2YfTXe3DxVp70ta+7SsZqiIioLjF8kGwKioz448xNZOYU4uKtPDgpFej9QAi0ri7o1zZU7vKIiKiOMHyQbOb+chKfbz0rfX1/kCc+Gd5OxoqIiMgWGD5INpuPXwcAtAjxgrerC17oGilzRUREZAsMHySLXEMxTl/PAQAsfaEDfDjGg4jIYXCqLcmidD0PFycFvN04s4WIyJEwfJAsStfz8FA7Q6FQyFwNERHZEsMHyaI0fHA9DyIix8PwQbLIMfzZ80FERI6F4YNkkVN62YXLqBMRORyGD5KFdPdahg8iIofD8EE2V1BkxNxfTgLgZRciIkfE8EE2t3LfZWToDQAAfw+1zNUQEZGt8d9OspnbuYX437F0rNl/FUDJGh8vdL1P5qqIiMjWGD7IZl5bcQi/HM+Qvl44sj2CtRoZKyIiIjkwfJBN3M4tlIJH+wgftAv3RtfmATJXRUREcmD4IJvIzC0Z46F1dcGKlzrJXA0REcmJA07JJvTSiqbMu0REjo7hg2wip4ArmhIRUQmGD7KJ0nu5ePFeLkREDo/hg2wix1CyoimXUyciIoYPsolsjvkgIqI7+E5AdUYIgR8PXsXl2/lIOZMJgGM+iIiI4YPq0L6LWZiw7IDZNj93lTzFEBGR3WD4oDpz/mYuACBEq0HX5v5wVztjRMcImasiIiK5MXxQnUnXFwAAOjX1x4eDH5S5GiIishcccEp15sgVHQAgWMs71xIR0Z8YPqhOfL71DH4+kg4ACPLizeOIiOhPvOxCVvHljnNSTwcAbD91Q/q8G28gR0REd2H4oFq7mpWPd9YdK7Nd46LErmlxXNWUiIjMMHxQrd3KLQRQsoDYhMebS9vbhXszeBARURkMH1Rr+vySpdODvTR4oet9MldDRET2jgNOqdb0BSXhw8uVvRxERFQ1hg+qNX1+yX1btAwfRERUDQwfVGtSzwdvGkdERNXA8EG1Vjrmg5ddiIioOiz6VzU5ORnJyck4f/48AKBVq1aYPn06evXqBQAoKCjAK6+8gmXLlsFgMCA+Ph4LFixAUFCQ1Qsn67idW4grWfm1OsfJjBwAvOxCRETVY1H4aNy4MWbPno3mzZtDCIGvv/4a/fr1w/79+9GqVStMmjQJP/30E5YvXw6tVouxY8di4MCB+P333+uqfqoFXX4RunywBbmFRqucr1NTf6uch4iIGjaFEELU5gS+vr746KOPMHjwYAQEBGDp0qUYPHgwAODEiRNo0aIFUlJS0LFjx2qdT6/XQ6vVQqfTwcvLqzalURWOXtWh9yc7oFTUfgn0h8J98OnwdlAqFVaqjoiI6hNL3r9rPELQaDRi+fLlyM3NRWxsLPbu3YuioiLExcVJx0RHRyM8PLzS8GEwGGAwGMyKJ9soKCrp8QjzdcPW1x6TuRoiInIUFg84PXz4MDw8PKBWq/Hiiy9i1apVaNmyJdLT06FSqeDt7W12fFBQENLT0ys8X1JSErRarfQRFhZm8ZOgmskvNAEAXF2cZK6EiIgcicXhIyoqCgcOHEBqaipeeuklJCQk4Nixsvf1qK6pU6dCp9NJH5cuXarxucgy+Xd6PjQMH0REZEMWX3ZRqVRo1qwZACAmJga7d+/GvHnzMHToUBQWFiIrK8us9yMjIwPBwcEVnk+tVkOtVlteOdVa6WUX9nwQEZEt1XqdD5PJBIPBgJiYGLi4uGDz5s3SvrS0NFy8eBGxsbG1fRiqA3/2fHC5FyIish2Lej6mTp2KXr16ITw8HNnZ2Vi6dCl+++03bNy4EVqtFqNHj8bkyZPh6+sLLy8vjBs3DrGxsdWe6UK2JfV8qNjzQUREtmNR+Lh+/TpGjhyJa9euQavVok2bNti4cSP+8pe/AADmzp0LpVKJQYMGmS0yRvYpv5BjPoiIyPYsCh9ffvllpfs1Gg3mz5+P+fPn16ooso2CopLZLgwfRERkS7zY78DyOeCUiIhkwNuQOojDl3U4eDnLbNvBSyVfM3wQEZEtMXw4gBxDMYZ+kYK8Cu7h4qnhy4CIiGyH7zoOYOoPh5FXaIS3mws6RPqa7dO6umBAu0YyVUZERI6I4cMBbDt5AwDQIzoQc55uK28xRETk8Djg1AHkFRYDACY83lzmSoiIiBg+GrwiowlFRgGg5BILERGR3Bg+GrjS6bQAVzIlIiL7wPDRwBXcmeGiVAAqJ/64iYhIfnw3auBKp9e6ujhBoVDIXA0RERHDR4MnrWKq4sQmIiKyDwwfDdyf4YM/aiIisg98R2rgSu9c6+bCng8iIrIPDB8NXGn40HCmCxER2QmGjwbuzzvX8kdNRET2gX3x9UiR0YQtJ65Dl18kfZ2hN1T6PUtTLwLgAmNERGQ/GD7qkdX7r+C1FYdq9L29WodYuRoiIqKaYfioR87ezAUAhPu6oVmgBxQAAr00cHGqfP2OYK0GfR8MtUGFREREVWP4qEduZpdcYhn6cBgSH2smczVEREQ1w1GI9UhmbiEAwM9dJXMlRERENceej3rgYmYeCoqNuJqVDwDw81DLXBEREVHNMXzYuf/bfhbv/nTcbJsvez6IiKgeY/iwc/svZgEA3FRO0Lg4oVmAB1o38pK3KCIiolpg+LBzmbklg0yTBj6Afm0byVwNERFR7XHAqZ27nVuyoJifO8d5EBFRw8DwYedKZ7j4uHOFUiIiahh42UVm36Scx6mMnAr3384rnV7Lng8iImoYGD5kdDIjG9PXHK3yOI2Lkj0fRETUYDB8yOhCZh4AIFSrweD2YRUe90gTX6idnWxVFhERUZ1i+JDRldsl4aNNY29M/sv9MldDRERkGwwfVTh8WYePfzmJgmKj1c998dadng9vV6ufm4iIyF4xfFThm5Tz2Hziep0+RosQzzo9PxERkT1h+KhCbmExAGBwTGN0be5v9fN7aVzq5LxERET2iuGjCvmFJZdbHmniyxVGiYiIrICLjFWhoMgEAFC7sKmIiIisge+oVcgvKun5cHXhVFciIiJrYPioQsGd8KFh+CAiIrIKho8qGIpLLru4qhg+iIiIrIHhowqlA041XGGUiIjIKhg+qlC6uJiGA06JiIisgu+oVZB6Pjjmg4iIyCoYPiohhJDGfDB8EBERWYdDLzK282wmjlzRVbi/2CSkzznglIiIyDocNnxkFxRh5Je7UGg0VXmsi5MCGmd2EhEREVmDw4aPrLwiFBpNcFIq8NSDoZUe27W5P5ydGD6IiIiswWHDR+lYDk+NM+YObStvMURERA7EYf+dL125VM3LKURERDblsO+8pT0fai4eRkREZFOOGz6KuHgYERGRHBz2nZc9H0RERPKwKHwkJSXh4YcfhqenJwIDA9G/f3+kpaWZHVNQUIDExET4+fnBw8MDgwYNQkZGhlWLtgaO+SAiIpKHRe+8W7duRWJiInbu3IlNmzahqKgIPXv2RG5urnTMpEmTsHbtWixfvhxbt27F1atXMXDgQKsXXltcuZSIiEgeFk213bBhg9nXixcvRmBgIPbu3Ytu3bpBp9Phyy+/xNKlS9GjRw8AwKJFi9CiRQvs3LkTHTt2tF7ltcSeDyIiInnU6p1XpytZmtzX1xcAsHfvXhQVFSEuLk46Jjo6GuHh4UhJSSn3HAaDAXq93uzDFtjzQUREJI8ahw+TyYSJEyeic+fOaN26NQAgPT0dKpUK3t7eZscGBQUhPT293PMkJSVBq9VKH2FhYTUtySLs+SAiIpJHjd95ExMTceTIESxbtqxWBUydOhU6nU76uHTpUq3OV13SbBdOtSUiIrKpGi2vPnbsWKxbtw7btm1D48aNpe3BwcEoLCxEVlaWWe9HRkYGgoODyz2XWq2GWq2uSRk1dulWHuZsOlny+JxqS0REZFMW/dsvhMDYsWOxatUqbNmyBZGRkWb7Y2Ji4OLigs2bN0vb0tLScPHiRcTGxlqnYiv4+cg16fMIPzcZKyEiInI8FvV8JCYmYunSpVizZg08PT2lcRxarRaurq7QarUYPXo0Jk+eDF9fX3h5eWHcuHGIjY21q5ku2QXFAIDoYE+MjG0ibzFEREQOxqLwkZycDAB49NFHzbYvWrQIzz33HABg7ty5UCqVGDRoEAwGA+Lj47FgwQKrFGstuYaSwaaPRQfCSamQuRoiIiLHYlH4EEJUeYxGo8H8+fMxf/78GhdV13INJT0fHuoaDXkhIiKiWnDIqR45hSXhw13FwaZERES25pDho7Tnw409H0RERDbnkOEj786YD152ISIisj2HDB85d3o+3Bk+iIiIbM4hw0cux3wQERHJxiHDR35hyWUXV4YPIiIim3PI8GE0lUwZdnFyyKdPREQkK4d89y0yltxUjguMERER2Z5Dho/Sng9nhg8iIiKbc8jwUXwnfLDng4iIyPYcMnz82fPhkE+fiIhIVg737iuEYM8HERGRjBwufJjuujcex3wQERHZnsOFj2KTSfrcyYnhg4iIyNYcLnwY7+r6cOGYDyIiIptzuHff4rvCB8d8EBER2Z7DhQ+j8c/wwTEfREREtudw4aO050OhAJQMH0RERDbncOGDq5sSERHJy+HCR+lsF473ICIikofDhQ+ubkpERCQvh3sH5uqmRERE8nK48MExH0RERPJyuPBRbGTPBxERkZwcLnyw54OIiEheDhc+pNkuvK8LERGRLBwufHC2CxERkbwc7h2Ys12IiIjk5XDhg2M+iIiI5OVw4YM9H0RERPJyvPBhLBlwyp4PIiIieThe+GDPBxERkawcLnzo8ooAcLYLERGRXBzuHXje5lNyl0BEROTQHC58eKidAQBtGmtlroSIiMgxOVz4MBQbAQBPtA6WuRIiIiLH5IDho2S2i9rZSeZKiIiIHJPDhY/C0vDh4nBPnYiIyC443Dtwac+HysnhnjoREZFdcLh34NIxH+z5ICIikodDvQMbTQJFxpJFxjjmg4iISB4OFT5Kx3sAgNrZoZ46ERGR3XCod+DSSy4AwwcREZFcHOoduHSwqZNSAWcOOCUiIpKFQ70DG4o404WIiEhuDvUuXGjkTBciIiK5OdS7cEFR6eqmDvW0iYiI7IpDvQtzaXUiIiL5OVT4yDUUAwBcXRg+iIiI5OJQ4eOaLh8AEKTVyFwJERGR47I4fGzbtg19+/ZFaGgoFAoFVq9ebbZfCIHp06cjJCQErq6uiIuLw6lTp6xVb61czSoAADTyZvggIiKSi8XhIzc3Fw8++CDmz59f7v4PP/wQn3zyCT777DOkpqbC3d0d8fHxKCgoqHWxtXE1Kx/JW88AAEK0rrLWQkRE5MicLf2GXr16oVevXuXuE0Lg448/xj/+8Q/069cPAPDNN98gKCgIq1evxrBhw2pXbS1k5RVJy6s3DfCQrQ4iIiJHZ9UxH+fOnUN6ejri4uKkbVqtFh06dEBKSkq532MwGKDX680+6kJ0sCeebt8Y/xryIJ5oHVwnj0FERERVs7jnozLp6ekAgKCgILPtQUFB0r57JSUlYdasWdYso1xKpQIfDn6wzh+HiIiIKif7bJepU6dCp9NJH5cuXZK7JCIiIqpDVg0fwcEllzMyMjLMtmdkZEj77qVWq+Hl5WX2QURERA2XVcNHZGQkgoODsXnzZmmbXq9HamoqYmNjrflQREREVE9ZPOYjJycHp0+flr4+d+4cDhw4AF9fX4SHh2PixIl499130bx5c0RGRuKtt95CaGgo+vfvb826iYiIqJ6yOHzs2bMHjz32mPT15MmTAQAJCQlYvHgxXn/9deTm5mLMmDHIyspCly5dsGHDBmg0XNiLiIiIAIUQQshdxN30ej20Wi10Oh3HfxAREdUTlrx/yz7bhYiIiBwLwwcRERHZFMMHERER2RTDBxEREdkUwwcRERHZFMMHERER2RTDBxEREdmUVe9qaw2ly47o9XqZKyEiIqLqKn3frs7yYXYXPrKzswEAYWFhMldCRERElsrOzoZWq630GLtb4dRkMuHq1avw9PSEQqGw6rn1ej3CwsJw6dIlrp5ah9jOtsF2tg22s+2wrW2jrtpZCIHs7GyEhoZCqax8VIfd9XwolUo0bty4Th/Dy8uLL2wbYDvbBtvZNtjOtsO2to26aOeqejxKccApERER2RTDBxEREdmUQ4UPtVqNGTNmQK1Wy11Kg8Z2tg22s22wnW2HbW0b9tDOdjfglIiIiBo2h+r5ICIiIvkxfBAREZFNMXwQERGRTTF8EBERkU0xfBAREZFNOUz4mD9/Ppo0aQKNRoMOHTpg165dcpdUryQlJeHhhx+Gp6cnAgMD0b9/f6SlpZkdU1BQgMTERPj5+cHDwwODBg1CRkaG2TEXL15E79694ebmhsDAQLz22msoLi625VOpV2bPng2FQoGJEydK29jO1nHlyhU888wz8PPzg6urKx544AHs2bNH2i+EwPTp0xESEgJXV1fExcXh1KlTZue4desWRowYAS8vL3h7e2P06NHIycmx9VOxW0ajEW+99RYiIyPh6uqKpk2b4p133jG78RjbuWa2bduGvn37IjQ0FAqFAqtXrzbbb612PXToELp27QqNRoOwsDB8+OGH1nkCwgEsW7ZMqFQq8dVXX4mjR4+Kv/3tb8Lb21tkZGTIXVq9ER8fLxYtWiSOHDkiDhw4IJ588kkRHh4ucnJypGNefPFFERYWJjZv3iz27NkjOnbsKDp16iTtLy4uFq1btxZxcXFi//79Yv369cLf319MnTpVjqdk93bt2iWaNGki2rRpIyZMmCBtZzvX3q1bt0RERIR47rnnRGpqqjh79qzYuHGjOH36tHTM7NmzhVarFatXrxYHDx4UTz31lIiMjBT5+fnSMU888YR48MEHxc6dO8X27dtFs2bNxPDhw+V4SnbpvffeE35+fmLdunXi3LlzYvny5cLDw0PMmzdPOobtXDPr168X06ZNEz/88IMAIFatWmW23xrtqtPpRFBQkBgxYoQ4cuSI+O9//ytcXV3F559/Xuv6HSJ8PPLIIyIxMVH62mg0itDQUJGUlCRjVfXb9evXBQCxdetWIYQQWVlZwsXFRSxfvlw65vjx4wKASElJEUKU/LIolUqRnp4uHZOcnCy8vLyEwWCw7ROwc9nZ2aJ58+Zi06ZNonv37lL4YDtbx5QpU0SXLl0q3G8ymURwcLD46KOPpG1ZWVlCrVaL//73v0IIIY4dOyYAiN27d0vH/Pzzz0KhUIgrV67UXfH1SO/evcXzzz9vtm3gwIFixIgRQgi2s7XcGz6s1a4LFiwQPj4+Zn83pkyZIqKiompdc4O/7FJYWIi9e/ciLi5O2qZUKhEXF4eUlBQZK6vfdDodAMDX1xcAsHfvXhQVFZm1c3R0NMLDw6V2TklJwQMPPICgoCDpmPj4eOj1ehw9etSG1du/xMRE9O7d26w9Abaztfz4449o3749hgwZgsDAQLRr1w4LFy6U9p87dw7p6elm7azVatGhQwezdvb29kb79u2lY+Li4qBUKpGammq7J2PHOnXqhM2bN+PkyZMAgIMHD2LHjh3o1asXALZzXbFWu6akpKBbt25QqVTSMfHx8UhLS8Pt27drVaPd3dXW2m7evAmj0Wj2hxgAgoKCcOLECZmqqt9MJhMmTpyIzp07o3Xr1gCA9PR0qFQqeHt7mx0bFBSE9PR06Zjyfg6l+6jEsmXLsG/fPuzevbvMPrazdZw9exbJycmYPHky3nzzTezevRvjx4+HSqVCQkKC1E7ltePd7RwYGGi239nZGb6+vmznO9544w3o9XpER0fDyckJRqMR7733HkaMGAEAbOc6Yq12TU9PR2RkZJlzlO7z8fGpcY0NPnyQ9SUmJuLIkSPYsWOH3KU0OJcuXcKECROwadMmaDQauctpsEwmE9q3b4/3338fANCuXTscOXIEn332GRISEmSuruH4/vvv8e2332Lp0qVo1aoVDhw4gIkTJyI0NJTt7OAa/GUXf39/ODk5lZkNkJGRgeDgYJmqqr/Gjh2LdevW4ddff0Xjxo2l7cHBwSgsLERWVpbZ8Xe3c3BwcLk/h9J9VHJZ5fr163jooYfg7OwMZ2dnbN26FZ988gmcnZ0RFBTEdraCkJAQtGzZ0mxbixYtcPHiRQB/tlNlfzeCg4Nx/fp1s/3FxcW4desW2/mO1157DW+88QaGDRuGBx54AM8++ywmTZqEpKQkAGznumKtdq3LvyUNPnyoVCrExMRg8+bN0jaTyYTNmzcjNjZWxsrqFyEExo4di1WrVmHLli1luuJiYmLg4uJi1s5paWm4ePGi1M6xsbE4fPiw2Qt+06ZN8PLyKvNG4Kgef/xxHD58GAcOHJA+2rdvjxEjRkifs51rr3PnzmWmip88eRIREREAgMjISAQHB5u1s16vR2pqqlk7Z2VlYe/evdIxW7ZsgclkQocOHWzwLOxfXl4elErztxknJyeYTCYAbOe6Yq12jY2NxbZt21BUVCQds2nTJkRFRdXqkgsAx5lqq1arxeLFi8WxY8fEmDFjhLe3t9lsAKrcSy+9JLRarfjtt9/EtWvXpI+8vDzpmBdffFGEh4eLLVu2iD179ojY2FgRGxsr7S+dAtqzZ09x4MABsWHDBhEQEMApoFW4e7aLEGxna9i1a5dwdnYW7733njh16pT49ttvhZubm1iyZIl0zOzZs4W3t7dYs2aNOHTokOjXr1+5UxXbtWsnUlNTxY4dO0Tz5s0dfgro3RISEkSjRo2kqbY//PCD8Pf3F6+//rp0DNu5ZrKzs8X+/fvF/v37BQAxZ84csX//fnHhwgUhhHXaNSsrSwQFBYlnn31WHDlyRCxbtky4ublxqq0lPv30UxEeHi5UKpV45JFHxM6dO+UuqV4BUO7HokWLpGPy8/PFyy+/LHx8fISbm5sYMGCAuHbtmtl5zp8/L3r16iVcXV2Fv7+/eOWVV0RRUZGNn039cm/4YDtbx9q1a0Xr1q2FWq0W0dHR4osvvjDbbzKZxFtvvSWCgoKEWq0Wjz/+uEhLSzM7JjMzUwwfPlx4eHgILy8vMWrUKJGdnW3Lp2HX9Hq9mDBhgggPDxcajUbcd999Ytq0aWZTN9nONfPrr7+W+zc5ISFBCGG9dj148KDo0qWLUKvVolGjRmL27NlWqV8hxF1LzRERERHVsQY/5oOIiIjsC8MHERER2RTDBxEREdkUwwcRERHZFMMHERER2RTDBxEREdkUwwcRERHZFMMHERER2RTDBxEREdkUwwcRERHZFMMHERER2dT/A3hjSux+1VwFAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting the data\n",
    "for col in ['loss', 'validation accuracy', 'best validation accuracy']:\n",
    "    plt.plot(df['epoch'].tolist(), df[col].tolist())\n",
    "    plt.title(\"no_attack_\"+col)\n",
    "    plt.savefig('./no_attack_' + col + '.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for LIE attack, followed by its execution on Bulyan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lie_attack(all_updates, z):\n",
    "    avg = torch.mean(all_updates, dim=0)\n",
    "    std = torch.std(all_updates, dim=0)\n",
    "    return avg + z * std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size=250\n",
    "resume=0\n",
    "nepochs=1200\n",
    "schedule=[1000]\n",
    "nbatches = user_tr_len//batch_size\n",
    "\n",
    "gamma=.5\n",
    "opt = 'sgd'\n",
    "fed_lr=0.5\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "aggregation='bulyan'\n",
    "multi_k = False\n",
    "candidates = []\n",
    "\n",
    "at_type='lie'\n",
    "z_values={3:0.69847, 5:0.7054, 8:0.71904, 10:0.72575, 12:0.73891}\n",
    "n_attackers=[10]\n",
    "\n",
    "arch='alexnet'\n",
    "chkpt='./'+aggregation\n",
    "\n",
    "for n_attacker in n_attackers:\n",
    "    epoch_num = 0\n",
    "    best_global_acc = 0\n",
    "    best_global_te_acc = 0\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    r=np.arange(user_tr_len)\n",
    "\n",
    "    fed_model, _ = return_model(arch, 0.1, 0.9, parallel=False)\n",
    "    optimizer_fed = SGD(fed_model.parameters(), lr=fed_lr)\n",
    "\n",
    "    while epoch_num <= nepochs:\n",
    "        user_grads=[]\n",
    "        if not epoch_num and epoch_num%nbatches == 0:\n",
    "            np.random.shuffle(r)\n",
    "            for i in range(nusers):\n",
    "                user_tr_data_tensors[i]=user_tr_data_tensors[i][r]\n",
    "                user_tr_label_tensors[i]=user_tr_label_tensors[i][r]\n",
    "\n",
    "        for i in range(n_attacker, nusers):\n",
    "\n",
    "            inputs = user_tr_data_tensors[i][(epoch_num%nbatches)*batch_size:((epoch_num%nbatches) + 1) * batch_size]\n",
    "            targets = user_tr_label_tensors[i][(epoch_num%nbatches)*batch_size:((epoch_num%nbatches) + 1) * batch_size]\n",
    "\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "\n",
    "            outputs = fed_model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            fed_model.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "\n",
    "            param_grad=[]\n",
    "            for param in fed_model.parameters():\n",
    "                param_grad=param.grad.data.view(-1) if not len(param_grad) else torch.cat((param_grad,param.grad.view(-1)))\n",
    "\n",
    "            user_grads=param_grad[None, :] if len(user_grads)==0 else torch.cat((user_grads,param_grad[None,:]), 0)\n",
    "\n",
    "        if epoch_num in schedule:\n",
    "            for param_group in optimizer_fed.param_groups:\n",
    "                param_group['lr'] *= gamma\n",
    "                print('New learnin rate ', param_group['lr'])\n",
    "\n",
    "        if n_attacker > 0:\n",
    "            n_attacker_ = max(1, n_attacker**2//nusers)\n",
    "            if at_type == 'lie':\n",
    "                mal_update = lie_attack(user_grads[:n_attacker], z_values[n_attacker])\n",
    "            \n",
    "        mal_updates = torch.stack([mal_update] * n_attacker)\n",
    "        malicious_grads = torch.cat((mal_updates, user_grads), 0)\n",
    "\n",
    "        if not (malicious_grads.shape[0]==50):\n",
    "            print(malicious_grads.shape)\n",
    "            sys.exit()\n",
    "            \n",
    "        agg_grads, krum_candidate=bulyan(malicious_grads, n_attacker)\n",
    "\n",
    "        del user_grads\n",
    "\n",
    "        start_idx=0\n",
    "\n",
    "        optimizer_fed.zero_grad()\n",
    "\n",
    "        model_grads=[]\n",
    "\n",
    "        for i, param in enumerate(fed_model.parameters()):\n",
    "            param_=agg_grads[start_idx:start_idx+len(param.data.view(-1))].reshape(param.data.shape)\n",
    "            start_idx=start_idx+len(param.data.view(-1))\n",
    "            param_=param_.cuda()\n",
    "            model_grads.append(param_)\n",
    "\n",
    "        optimizer_fed.step(model_grads)\n",
    "\n",
    "        val_loss, val_acc = test(val_data_tensor,val_label_tensor,fed_model,criterion,use_cuda)\n",
    "        te_loss, te_acc = test(te_data_tensor,te_label_tensor, fed_model, criterion, use_cuda)\n",
    "\n",
    "        is_best = best_global_acc < val_acc\n",
    "\n",
    "        best_global_acc = max(best_global_acc, val_acc)\n",
    "\n",
    "        if is_best:\n",
    "            best_global_te_acc = te_acc\n",
    "\n",
    "        if epoch_num%10==0 or epoch_num==nepochs-1:\n",
    "            print('%s: at %s n_at %d n_mal_sel %d e %d fed_model val loss %.4f val acc %.4f best val_acc %f te_acc %f'%(aggregation, at_type, n_attacker, np.sum(krum_candidate < n_attacker), epoch_num, val_loss, val_acc, best_global_acc,best_global_te_acc))\n",
    "\n",
    "        if val_loss > 10:\n",
    "            print('val loss %f too high'%val_loss)\n",
    "            break\n",
    "\n",
    "        epoch_num+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for our AGR-tailored attack on Bulyan\n",
    "* Note that our attacks on multi-krum and Bulyan aggregations are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def our_attack_mkrum(all_updates, model_re, n_attackers, dev_type='unit_vec'):\n",
    "\n",
    "    if dev_type == 'unit_vec':\n",
    "        deviation = model_re / torch.norm(model_re)\n",
    "    elif dev_type == 'sign':\n",
    "        deviation = torch.sign(model_re)\n",
    "    elif dev_type == 'std':\n",
    "        deviation = torch.std(all_updates, 0)\n",
    "\n",
    "    lamda = torch.Tensor([3.0]).cuda()\n",
    "\n",
    "    threshold_diff = 1e-5\n",
    "    lamda_fail = lamda\n",
    "    lamda_succ = 0\n",
    "\n",
    "    while torch.abs(lamda_succ - lamda) > threshold_diff:\n",
    "        mal_update = (model_re - lamda * deviation)\n",
    "        mal_updates = torch.stack([mal_update] * n_attackers)\n",
    "        mal_updates = torch.cat((mal_updates, all_updates), 0)\n",
    "\n",
    "        agg_grads, krum_candidate = multi_krum(mal_updates, n_attackers, multi_k=True)\n",
    "        if np.sum(krum_candidate < n_attackers) == n_attackers:\n",
    "            # print('successful lamda is ', lamda)\n",
    "            lamda_succ = lamda\n",
    "            lamda = lamda + lamda_fail / 2\n",
    "        else:\n",
    "            lamda = lamda - lamda_fail / 2\n",
    "\n",
    "        lamda_fail = lamda_fail / 2\n",
    "\n",
    "    mal_update = (model_re - lamda_succ * deviation)\n",
    "    return mal_update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute our AGR-tailored attack on Bulyan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=250\n",
    "resume=0\n",
    "nepochs=1200\n",
    "schedule=[1000]\n",
    "nbatches = user_tr_len//batch_size\n",
    "\n",
    "gamma=.5\n",
    "opt = 'sgd'\n",
    "fed_lr=0.5\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "aggregation='bulyan'\n",
    "multi_k = False\n",
    "candidates = []\n",
    "\n",
    "at_type='our-agr'\n",
    "dev_type ='std'\n",
    "n_attackers=[10]\n",
    "\n",
    "arch='alexnet'\n",
    "chkpt='./'+aggregation\n",
    "\n",
    "\n",
    "for n_attacker in n_attackers:\n",
    "    epoch_num = 0\n",
    "    best_global_acc = 0\n",
    "    best_global_te_acc = 0\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    r=np.arange(user_tr_len)\n",
    "\n",
    "    fed_model, _ = return_model(arch, 0.1, 0.9, parallel=False)\n",
    "    optimizer_fed = SGD(fed_model.parameters(), lr=fed_lr)\n",
    "\n",
    "    while epoch_num <= nepochs:\n",
    "        user_grads=[]\n",
    "        if not epoch_num and epoch_num%nbatches == 0:\n",
    "            np.random.shuffle(r)\n",
    "            for i in range(nusers):\n",
    "                user_tr_data_tensors[i]=user_tr_data_tensors[i][r]\n",
    "                user_tr_label_tensors[i]=user_tr_label_tensors[i][r]\n",
    "\n",
    "        for i in range(nusers):\n",
    "\n",
    "            inputs = user_tr_data_tensors[i][(epoch_num%nbatches)*batch_size:((epoch_num%nbatches) + 1) * batch_size]\n",
    "            targets = user_tr_label_tensors[i][(epoch_num%nbatches)*batch_size:((epoch_num%nbatches) + 1) * batch_size]\n",
    "\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "\n",
    "            outputs = fed_model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            fed_model.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "\n",
    "            param_grad=[]\n",
    "            for param in fed_model.parameters():\n",
    "                param_grad=param.grad.data.view(-1) if not len(param_grad) else torch.cat((param_grad,param.grad.view(-1)))\n",
    "\n",
    "            user_grads=param_grad[None, :] if len(user_grads)==0 else torch.cat((user_grads,param_grad[None,:]), 0)\n",
    "\n",
    "        if epoch_num in schedule:\n",
    "            for param_group in optimizer_fed.param_groups:\n",
    "                param_group['lr'] *= gamma\n",
    "                print('New learnin rate ', param_group['lr'])\n",
    "\n",
    "        if n_attacker > 0:\n",
    "            n_attacker_ = max(1, n_attacker**2//nusers)\n",
    "            if at_type == 'lie':\n",
    "                mal_update = lie_attack(user_grads[:n_attacker], z_values[n_attacker])\n",
    "            elif at_type == 'fang':\n",
    "                agg_grads = torch.mean(user_grads[:n_attacker], 0)\n",
    "                deviation = torch.sign(agg_grads)\n",
    "                mal_update = get_malicious_updates_fang(user_grads[:n_attacker], agg_grads, deviation, n_attacker_)\n",
    "            elif at_type == 'our-agr':\n",
    "                agg_grads = torch.mean(user_grads[:n_attacker], 0)\n",
    "                mal_update = our_attack_mkrum(user_grads[:n_attacker], agg_grads, n_attacker_, dev_type)\n",
    "            elif at_type == 'min-max':\n",
    "                agg_grads = torch.mean(user_grads[:n_attacker], 0)\n",
    "                mal_update = our_attack_dist(user_grads[:n_attacker], agg_grads, n_attacker_, dev_type)\n",
    "            elif at_type == 'min-sum':\n",
    "                agg_grads = torch.mean(user_grads[:n_attacker], 0)\n",
    "                mal_update = our_attack_score(user_grads[:n_attacker], agg_grads, n_attacker_, dev_type)\n",
    "\n",
    "            mal_updates = torch.stack([mal_update] * n_attacker)\n",
    "            malicious_grads = torch.cat((mal_updates, user_grads[n_attacker:]), 0)\n",
    "            \n",
    "        if not (malicious_grads.shape[0]==50):\n",
    "            print(malicious_grads.shape)\n",
    "            sys.exit()\n",
    "        \n",
    "        agg_grads, krum_candidate=bulyan(malicious_grads, n_attacker)\n",
    "\n",
    "        del user_grads\n",
    "\n",
    "        start_idx=0\n",
    "\n",
    "        optimizer_fed.zero_grad()\n",
    "\n",
    "        model_grads=[]\n",
    "\n",
    "        for i, param in enumerate(fed_model.parameters()):\n",
    "            param_=agg_grads[start_idx:start_idx+len(param.data.view(-1))].reshape(param.data.shape)\n",
    "            start_idx=start_idx+len(param.data.view(-1))\n",
    "            param_=param_.cuda()\n",
    "            model_grads.append(param_)\n",
    "\n",
    "        optimizer_fed.step(model_grads)\n",
    "\n",
    "        val_loss, val_acc = test(val_data_tensor,val_label_tensor,fed_model,criterion,use_cuda)\n",
    "        te_loss, te_acc = test(te_data_tensor,te_label_tensor, fed_model, criterion, use_cuda)\n",
    "\n",
    "        is_best = best_global_acc < val_acc\n",
    "\n",
    "        best_global_acc = max(best_global_acc, val_acc)\n",
    "\n",
    "        if is_best:\n",
    "            best_global_te_acc = te_acc\n",
    "\n",
    "        if epoch_num%25==0 or epoch_num==nepochs-1:\n",
    "            print('%s: at %s n_at %d n_mal_sel %d e %d | val loss %.4f val acc %.4f best val_acc %f'%(aggregation, at_type, n_attacker, np.sum(krum_candidate < n_attacker), epoch_num, val_loss, val_acc, best_global_acc))\n",
    "\n",
    "        if val_loss > 1000:\n",
    "            print('val loss %f too high'%val_loss)\n",
    "            break\n",
    "            \n",
    "        epoch_num+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for our first AGR-agnostic attack called Min-Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "MIN-MAX attack\n",
    "'''\n",
    "def our_attack_dist(all_updates, model_re, n_attackers, dev_type='unit_vec'):\n",
    "\n",
    "    if dev_type == 'unit_vec':\n",
    "        deviation = model_re / torch.norm(model_re)  # unit vector, dir opp to good dir\n",
    "    elif dev_type == 'sign':\n",
    "        deviation = torch.sign(model_re)\n",
    "    elif dev_type == 'std':\n",
    "        deviation = torch.std(all_updates, 0)\n",
    "\n",
    "    lamda = torch.Tensor([10.0]).float().cuda()\n",
    "    # print(lamda)\n",
    "    threshold_diff = 1e-5\n",
    "    lamda_fail = lamda\n",
    "    lamda_succ = 0\n",
    "    \n",
    "    distances = []\n",
    "    for update in all_updates:\n",
    "        distance = torch.norm((all_updates - update), dim=1) ** 2\n",
    "        distances = distance[None, :] if not len(distances) else torch.cat((distances, distance[None, :]), 0)\n",
    "    \n",
    "    max_distance = torch.max(distances)\n",
    "    del distances\n",
    "\n",
    "    while torch.abs(lamda_succ - lamda) > threshold_diff:\n",
    "        mal_update = (model_re - lamda * deviation)\n",
    "        distance = torch.norm((all_updates - mal_update), dim=1) ** 2\n",
    "        max_d = torch.max(distance)\n",
    "        \n",
    "        if max_d <= max_distance:\n",
    "            # print('successful lamda is ', lamda)\n",
    "            lamda_succ = lamda\n",
    "            lamda = lamda + lamda_fail / 2\n",
    "        else:\n",
    "            lamda = lamda - lamda_fail / 2\n",
    "\n",
    "        lamda_fail = lamda_fail / 2\n",
    "\n",
    "    mal_update = (model_re - lamda_succ * deviation)\n",
    "    \n",
    "    return mal_update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute Min-max attack on Bulyan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=250\n",
    "resume=0\n",
    "nepochs=1200\n",
    "schedule=[1000]\n",
    "nbatches = user_tr_len//batch_size\n",
    "\n",
    "gamma=.5\n",
    "opt = 'sgd'\n",
    "fed_lr=0.5\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "aggregation='bulyan'\n",
    "multi_k = False\n",
    "candidates = []\n",
    "\n",
    "at_type='min-max'\n",
    "dev_type ='std'\n",
    "n_attackers=[10]\n",
    "\n",
    "arch='alexnet'\n",
    "chkpt='./'+aggregation\n",
    "\n",
    "for n_attacker in n_attackers:\n",
    "    candidates = []\n",
    "\n",
    "    epoch_num = 0\n",
    "    best_global_acc = 0\n",
    "    best_global_te_acc = 0\n",
    "\n",
    "    fed_model, _ = return_model(arch, 0.1, 0.9, parallel=False)\n",
    "    optimizer_fed = SGD(fed_model.parameters(), lr=fed_lr)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    r=np.arange(user_tr_len)\n",
    "\n",
    "    while epoch_num <= nepochs:\n",
    "        user_grads=[]\n",
    "        if not epoch_num and epoch_num%nbatches == 0:\n",
    "            np.random.shuffle(r)\n",
    "            for i in range(nusers):\n",
    "                user_tr_data_tensors[i]=user_tr_data_tensors[i][r]\n",
    "                user_tr_label_tensors[i]=user_tr_label_tensors[i][r]\n",
    "\n",
    "        for i in range(nusers):\n",
    "\n",
    "            inputs = user_tr_data_tensors[i][(epoch_num%nbatches)*batch_size:((epoch_num%nbatches) + 1) * batch_size]\n",
    "            targets = user_tr_label_tensors[i][(epoch_num%nbatches)*batch_size:((epoch_num%nbatches) + 1) * batch_size]\n",
    "\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "\n",
    "            outputs = fed_model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            fed_model.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "\n",
    "            param_grad=[]\n",
    "            for param in fed_model.parameters():\n",
    "                param_grad=param.grad.data.view(-1) if not len(param_grad) else torch.cat((param_grad,param.grad.view(-1)))\n",
    "\n",
    "            user_grads=param_grad[None, :] if len(user_grads)==0 else torch.cat((user_grads,param_grad[None,:]), 0)\n",
    "\n",
    "        if epoch_num in schedule:\n",
    "            for param_group in optimizer_fed.param_groups:\n",
    "                param_group['lr'] *= gamma\n",
    "                print('New learnin rate ', param_group['lr'])\n",
    "\n",
    "        if n_attacker > 0:\n",
    "            n_attacker_ = max(1, n_attacker**2//nusers)\n",
    "            if at_type == 'lie':\n",
    "                mal_update = lie_attack(user_grads[:n_attacker], z_values[n_attacker])\n",
    "            elif at_type == 'fang':\n",
    "                agg_grads = torch.mean(user_grads[:n_attacker], 0)\n",
    "                deviation = torch.sign(agg_grads)\n",
    "                mal_update = get_malicious_updates_fang(user_grads[:n_attacker], agg_grads, deviation, n_attacker_)\n",
    "            elif at_type == 'our-agr':\n",
    "                agg_grads = torch.mean(user_grads[:n_attacker], 0)\n",
    "                mal_update = our_attack_mkrum(user_grads[:n_attacker], agg_grads, n_attacker_, dev_type)\n",
    "            elif at_type == 'min-max':\n",
    "                agg_grads = torch.mean(user_grads[:n_attacker], 0)\n",
    "                mal_update = our_attack_dist(user_grads[:n_attacker], agg_grads, n_attacker_, dev_type)\n",
    "            elif at_type == 'min-sum':\n",
    "                agg_grads = torch.mean(user_grads[:n_attacker], 0)\n",
    "                mal_update = our_attack_score(user_grads[:n_attacker], agg_grads, n_attacker_, dev_type)\n",
    "\n",
    "            mal_updates = torch.stack([mal_update] * n_attacker)\n",
    "            malicious_grads = torch.cat((mal_updates, user_grads[n_attacker:]), 0)\n",
    "\n",
    "        if not (malicious_grads.shape[0]==50):\n",
    "            print(malicious_grads.shape)\n",
    "            sys.exit()\n",
    "        \n",
    "        agg_grads, krum_candidate=bulyan(malicious_grads, n_attacker)\n",
    "\n",
    "        del user_grads\n",
    "\n",
    "        start_idx=0\n",
    "\n",
    "        optimizer_fed.zero_grad()\n",
    "\n",
    "        model_grads=[]\n",
    "\n",
    "        for i, param in enumerate(fed_model.parameters()):\n",
    "            param_=agg_grads[start_idx:start_idx+len(param.data.view(-1))].reshape(param.data.shape)\n",
    "            start_idx=start_idx+len(param.data.view(-1))\n",
    "            param_=param_.cuda()\n",
    "            model_grads.append(param_)\n",
    "\n",
    "        optimizer_fed.step(model_grads)\n",
    "\n",
    "        val_loss, val_acc = test(val_data_tensor,val_label_tensor,fed_model,criterion,use_cuda)\n",
    "        te_loss, te_acc = test(te_data_tensor,te_label_tensor, fed_model, criterion, use_cuda)\n",
    "\n",
    "        is_best = best_global_acc < val_acc\n",
    "\n",
    "        best_global_acc = max(best_global_acc, val_acc)\n",
    "\n",
    "        if is_best:\n",
    "            best_global_te_acc = te_acc\n",
    "\n",
    "        if epoch_num%25==0 or epoch_num==nepochs-1:\n",
    "            print('%s: at %s n_at %d n_mal_sel %d e %d | val loss %.4f val acc %.4f best val_acc %f'%(aggregation, at_type, n_attacker, np.sum(krum_candidate < n_attacker), epoch_num, val_loss, val_acc, best_global_acc))\n",
    "\n",
    "        if val_loss > 1000:\n",
    "            print('val loss %f too high'%val_loss)\n",
    "            break\n",
    "            \n",
    "        epoch_num+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for our second AGR-agnostic attack called Min-Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "MIN-SUM attack\n",
    "'''\n",
    "\n",
    "def our_attack_score(all_updates, model_re, n_attackers, dev_type='unit_vec'):\n",
    "\n",
    "    if dev_type == 'unit_vec':\n",
    "        deviation = model_re / torch.norm(model_re)  # unit vector, dir opp to good dir\n",
    "    elif dev_type == 'sign':\n",
    "        deviation = torch.sign(model_re)\n",
    "    elif dev_type == 'std':\n",
    "        deviation = torch.std(all_updates, 0)\n",
    "    \n",
    "    lamda = torch.Tensor([10.0]).float().cuda()\n",
    "    # print(lamda)\n",
    "    threshold_diff = 1e-5\n",
    "    lamda_fail = lamda\n",
    "    lamda_succ = 0\n",
    "    \n",
    "    distances = []\n",
    "    for update in all_updates:\n",
    "        distance = torch.norm((all_updates - update), dim=1) ** 2\n",
    "        distances = distance[None, :] if not len(distances) else torch.cat((distances, distance[None, :]), 0)\n",
    "    \n",
    "    scores = torch.sum(distances, dim=1)\n",
    "    min_score = torch.min(scores)\n",
    "    del distances\n",
    "\n",
    "    while torch.abs(lamda_succ - lamda) > threshold_diff:\n",
    "        mal_update = (model_re - lamda * deviation)\n",
    "        distance = torch.norm((all_updates - mal_update), dim=1) ** 2\n",
    "        score = torch.sum(distance)\n",
    "        \n",
    "        if score <= min_score:\n",
    "            # print('successful lamda is ', lamda)\n",
    "            lamda_succ = lamda\n",
    "            lamda = lamda + lamda_fail / 2\n",
    "        else:\n",
    "            lamda = lamda - lamda_fail / 2\n",
    "\n",
    "        lamda_fail = lamda_fail / 2\n",
    "\n",
    "    # print(lamda_succ)\n",
    "    mal_update = (model_re - lamda_succ * deviation)\n",
    "    \n",
    "    return mal_update\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute Min-Sum attack on Bulyan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=250\n",
    "resume=0\n",
    "nepochs=1200\n",
    "schedule=[1000]\n",
    "nbatches = user_tr_len//batch_size\n",
    "\n",
    "gamma=.5\n",
    "opt = 'sgd'\n",
    "fed_lr=0.5\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "aggregation='bulyan'\n",
    "multi_k = False\n",
    "candidates = []\n",
    "\n",
    "at_type='min-sum'\n",
    "dev_type ='std'\n",
    "z=0\n",
    "n_attackers=[10]\n",
    "\n",
    "arch='alexnet'\n",
    "chkpt='./'+aggregation\n",
    "\n",
    "for n_attacker in n_attackers:\n",
    "    candidates = []\n",
    "\n",
    "    epoch_num = 0\n",
    "    best_global_acc = 0\n",
    "    best_global_te_acc = 0\n",
    "\n",
    "    fed_model, _ = return_model(arch, 0.1, 0.9, parallel=False)\n",
    "    optimizer_fed = SGD(fed_model.parameters(), lr=fed_lr)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    r=np.arange(user_tr_len)\n",
    "\n",
    "    while epoch_num <= nepochs:\n",
    "        user_grads=[]\n",
    "        if not epoch_num and epoch_num%nbatches == 0:\n",
    "            np.random.shuffle(r)\n",
    "            for i in range(nusers):\n",
    "                user_tr_data_tensors[i]=user_tr_data_tensors[i][r]\n",
    "                user_tr_label_tensors[i]=user_tr_label_tensors[i][r]\n",
    "\n",
    "        for i in range(nusers):\n",
    "\n",
    "            inputs = user_tr_data_tensors[i][(epoch_num%nbatches)*batch_size:((epoch_num%nbatches) + 1) * batch_size]\n",
    "            targets = user_tr_label_tensors[i][(epoch_num%nbatches)*batch_size:((epoch_num%nbatches) + 1) * batch_size]\n",
    "\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "\n",
    "            outputs = fed_model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            fed_model.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "\n",
    "            param_grad=[]\n",
    "            for param in fed_model.parameters():\n",
    "                param_grad=param.grad.data.view(-1) if not len(param_grad) else torch.cat((param_grad,param.grad.view(-1)))\n",
    "\n",
    "            user_grads=param_grad[None, :] if len(user_grads)==0 else torch.cat((user_grads,param_grad[None,:]), 0)\n",
    "\n",
    "        if epoch_num in schedule:\n",
    "            for param_group in optimizer_fed.param_groups:\n",
    "                param_group['lr'] *= gamma\n",
    "                print('New learnin rate ', param_group['lr'])\n",
    "\n",
    "        if n_attacker > 0:\n",
    "            n_attacker_ = max(1, n_attacker**2//nusers)\n",
    "            if at_type == 'lie':\n",
    "                mal_update = lie_attack(user_grads[:n_attacker], z_values[n_attacker])\n",
    "            elif at_type == 'fang':\n",
    "                agg_grads = torch.mean(user_grads[:n_attacker], 0)\n",
    "                deviation = torch.sign(agg_grads)\n",
    "                mal_update = get_malicious_updates_fang(user_grads[:n_attacker], agg_grads, deviation, n_attacker_)\n",
    "            elif at_type == 'our-agr':\n",
    "                agg_grads = torch.mean(user_grads[:n_attacker], 0)\n",
    "                mal_update = our_attack_mkrum(user_grads[:n_attacker], agg_grads, n_attacker_, dev_type)\n",
    "            elif at_type == 'min-max':\n",
    "                agg_grads = torch.mean(user_grads[:n_attacker], 0)\n",
    "                mal_update = our_attack_dist(user_grads[:n_attacker], agg_grads, n_attacker_, dev_type)\n",
    "            elif at_type == 'min-sum':\n",
    "                agg_grads = torch.mean(user_grads[:n_attacker], 0)\n",
    "                mal_update = our_attack_score(user_grads[:n_attacker], agg_grads, n_attacker_, dev_type)\n",
    "\n",
    "            mal_updates = torch.stack([mal_update] * n_attacker)\n",
    "            malicious_grads = torch.cat((mal_updates, user_grads[n_attacker:]), 0)\n",
    "\n",
    "        if not (malicious_grads.shape[0]==50):\n",
    "            print(malicious_grads.shape)\n",
    "            sys.exit()\n",
    "        \n",
    "        agg_grads, krum_candidate=bulyan(malicious_grads, n_attacker)\n",
    "\n",
    "        del user_grads\n",
    "\n",
    "        start_idx=0\n",
    "\n",
    "        optimizer_fed.zero_grad()\n",
    "\n",
    "        model_grads=[]\n",
    "\n",
    "        for i, param in enumerate(fed_model.parameters()):\n",
    "            param_=agg_grads[start_idx:start_idx+len(param.data.view(-1))].reshape(param.data.shape)\n",
    "            start_idx=start_idx+len(param.data.view(-1))\n",
    "            param_=param_.cuda()\n",
    "            model_grads.append(param_)\n",
    "\n",
    "        optimizer_fed.step(model_grads)\n",
    "\n",
    "        val_loss, val_acc = test(val_data_tensor,val_label_tensor,fed_model,criterion,use_cuda)\n",
    "        te_loss, te_acc = test(te_data_tensor,te_label_tensor, fed_model, criterion, use_cuda)\n",
    "\n",
    "        is_best = best_global_acc < val_acc\n",
    "\n",
    "        best_global_acc = max(best_global_acc, val_acc)\n",
    "\n",
    "        if is_best:\n",
    "            best_global_te_acc = te_acc\n",
    "\n",
    "        if epoch_num%25==0 or epoch_num==nepochs-1:\n",
    "            print('%s: at %s n_at %d n_mal_sel %d e %d | val loss %.4f val acc %.4f best val_acc %f'%(aggregation, at_type, n_attacker, np.sum(krum_candidate < n_attacker), epoch_num, val_loss, val_acc, best_global_acc))\n",
    "\n",
    "        if val_loss > 1000:\n",
    "            print('val loss %f too high'%val_loss)\n",
    "            break\n",
    "            \n",
    "        epoch_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
