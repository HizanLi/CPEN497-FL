{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMUR8ODgnrc3"
      },
      "source": [
        "# The notebook contains\n",
        "### Code for _Bulyan_ aggregation algorithm, *when gradient updates of benign clients are unknown to adversary*\n",
        "### Evaluation of all of the attacks (Fang, LIE, and our SOTA AGR-tailored and AGR-agnstic) on Bulyan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJu2Edmbnrc5"
      },
      "source": [
        "## Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "wGSIzpf_nrc5",
        "outputId": "5563fc08-740b-4522-8ba9-41e940ec060e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>.container { width:90% !important; }</style>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import display, HTML\n",
        "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "AAU3fosynrc6"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import argparse, os, sys, csv, shutil, time, random, operator, pickle, ast, math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.optim import Optimizer\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import pickle\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torch.multiprocessing as mp\n",
        "import math\n",
        "sys.path.insert(0,'./../utils/')\n",
        "from logger import *\n",
        "from eval import *\n",
        "from misc import *\n",
        "\n",
        "from cifar10_normal_train import *\n",
        "from cifar10_util import *\n",
        "from adam import Adam\n",
        "from sgd import SGD\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGABIvW6nrc6"
      },
      "source": [
        "## Load Data\n",
        "Divide cifar10 data among 50 clients in Non-IID fashion using Dirichlet distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1Nyn5Xlnrc6",
        "outputId": "2148c44a-9897-41f6-bf92-67d798026810"
      },
      "outputs": [],
      "source": [
        "n_users = 50\n",
        "user_tr_len = pickle.load(open('./data/user_tr_len.pkl','rb'))\n",
        "\n",
        "user_train_data_tensors = pickle.load(open('./data/user_train_data_tensors.pkl','rb'))\n",
        "user_train_label_tensors = pickle.load(open('./data/user_train_label_tensors.pkl','rb'))\n",
        "\n",
        "val_data_tensor = pickle.load(open('./data/val_data_tensor.pkl','rb'))\n",
        "val_label_tensor = pickle.load(open('./data/val_label_tensor.pkl','rb'))\n",
        "te_data_tensor = pickle.load(open('./data/te_data_tensor.pkl','rb'))\n",
        "te_label_tensor = pickle.load(open('./data/te_label_tensor.pkl','rb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOVMqc_9nrc8"
      },
      "source": [
        "## Our Aggregation Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "LMgKiRnynrc8"
      },
      "outputs": [],
      "source": [
        "def our_mean_defense(all_updates, n_attackers, history_updates):\n",
        "    discarded_history = get_discarded_index(n_attackers, history_updates)\n",
        "\n",
        "    mask = torch.ones(all_updates.size(0), dtype=torch.bool)\n",
        "    mask[discarded_history] = False\n",
        "    remaining_updates = all_updates[mask]\n",
        "\n",
        "    print('discarded index', discarded_history)\n",
        "\n",
        "    return torch.nanmean(remaining_updates, dim=0), np.array(discarded_history)\n",
        "\n",
        "####\n",
        "def euclidean_distance(row1, row2):\n",
        "    return torch.sqrt(torch.sum((row1 - row2) ** 2))\n",
        "####\n",
        "\n",
        "def get_discarded_index(n_attackers, history_updates):\n",
        "    n_users = history_updates.shape[0]\n",
        "\n",
        "    ####\n",
        "    distance_matrix = [[0 if i == j else euclidean_distance(history_updates[i, :], history_updates[j, :]) for j in range(n_users)] for i in range(n_users)]\n",
        "    ####\n",
        "\n",
        "    sum_of_distances = [sum(row) for row in distance_matrix]\n",
        "\n",
        "    discarded_history = []\n",
        "    for _ in range(n_attackers):\n",
        "        max_distance = max(sum_of_distances)\n",
        "        index_of_max_distance = sum_of_distances.index(max_distance)\n",
        "        discarded_history.append(index_of_max_distance)\n",
        "\n",
        "        for i in range(n_users):\n",
        "            sum_of_distances[i] -= distance_matrix[i][index_of_max_distance]\n",
        "        sum_of_distances[index_of_max_distance] = -1\n",
        "\n",
        "    return discarded_history\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set nepochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "nepochs= 300"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fang attack and our defense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_lambda_fang(all_updates, model_re, n_attacker):\n",
        "\n",
        "    distances = []\n",
        "    n_benign, d = all_updates.shape\n",
        "    for update in all_updates:\n",
        "        distance = torch.norm((all_updates - update), dim=1)\n",
        "        distances = distance[None, :] if not len(distances) else torch.cat((distances, distance[None, :]), 0)\n",
        "\n",
        "    distances[distances == 0] = 10000\n",
        "    distances = torch.sort(distances, dim=1)[0]\n",
        "    scores = torch.sum(distances[:, :n_benign - 2 - n_attacker], dim=1)\n",
        "    min_score = torch.min(scores)\n",
        "    term_1 = min_score / ((n_benign - n_attacker - 1) * torch.sqrt(torch.Tensor([d]))[0])\n",
        "    max_wre_dist = torch.max(torch.norm((all_updates - model_re), dim=1)) / (torch.sqrt(torch.Tensor([d]))[0])\n",
        "    # print(term_1 + max_wre_dist) # tensor(0.0001, device='cuda:0')\n",
        "    return (term_1 + max_wre_dist)\n",
        "\n",
        "\n",
        "def get_malicious_updates_fang(all_updates, model_re, deviation, n_attacker, history, epoch_num):\n",
        "\n",
        "    lamda = compute_lambda_fang(all_updates, model_re, n_attacker) # tensor(0.0001, device='cuda:0')\n",
        "    \n",
        "    threshold = 1e-5\n",
        "\n",
        "    mal_updates = []\n",
        "    \n",
        "    ####\n",
        "    history_updates = history.clone().detach()\n",
        "    ####\n",
        "\n",
        "    while lamda > threshold:\n",
        "        # print(\"lamda: \", lamda)\n",
        "        mal_update = (- lamda * deviation) # torch.Size([2472266])\n",
        "        mal_updates = torch.stack([mal_update] * n_attacker)   # torch.Size([2, 2472266])\n",
        "        mal_updates = torch.cat((mal_updates, all_updates[n_attacker:]), 0)  # torch.Size([12, 2472266])\n",
        "\n",
        "        history_updates[:, epoch_num] = all_updates.mean(dim=1, keepdim=True).squeeze()\n",
        "\n",
        "        agg_grads, discard_history = our_mean_defense(mal_updates, n_attacker, history_updates) # agg_grads.shape torch.Size([2472266]) # krum_candidate.shape torch.Size(1,)\n",
        "\n",
        "        count = np.sum(discard_history < n_attacker)\n",
        "        print(count, discard_history)\n",
        "        if count < n_attacker:\n",
        "            return mal_update\n",
        "        \n",
        "        lamda *= 0.5\n",
        "    print(\"lamda < threshold\")\n",
        "    if not len(mal_updates):\n",
        "        # print(lamda, threshold)\n",
        "        mal_update = (model_re - lamda * deviation)\n",
        "    return mal_update  # len(mal_update) 2472266"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "discarded index [42, 48, 13, 36, 6, 21, 31, 41, 46, 15]\n",
            "1 [42 48 13 36  6 21 31 41 46 15]\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 0, bulyan: at fang n_at 10 e 0 | val loss 2.3022 val acc 12.1956 best val_acc 12.195617\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Hizan\\AppData\\Local\\Temp\\ipykernel_13604\\262852829.py:126: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df = pd.concat([df, new_row], ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "discarded index [5, 6, 2, 4, 8, 7, 1, 0, 9, 3]\n",
            "10 [5 6 2 4 8 7 1 0 9 3]\n",
            "discarded index [5, 6, 2, 4, 8, 7, 1, 0, 9, 3]\n",
            "10 [5 6 2 4 8 7 1 0 9 3]\n",
            "discarded index [5, 6, 2, 4, 8, 7, 1, 0, 9, 3]\n",
            "10 [5 6 2 4 8 7 1 0 9 3]\n",
            "discarded index [5, 6, 2, 4, 8, 7, 1, 0, 9, 3]\n",
            "10 [5 6 2 4 8 7 1 0 9 3]\n",
            "discarded index [5, 6, 2, 4, 8, 7, 1, 0, 9, 3]\n",
            "10 [5 6 2 4 8 7 1 0 9 3]\n",
            "discarded index [5, 6, 2, 4, 8, 7, 1, 0, 9, 3]\n",
            "10 [5 6 2 4 8 7 1 0 9 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 1, bulyan: at fang n_at 10 e 1 | val loss 2.3017 val acc 13.4537 best val_acc 13.453734\n",
            "discarded index [6, 5, 4, 8, 0, 9, 2, 7, 3, 1]\n",
            "10 [6 5 4 8 0 9 2 7 3 1]\n",
            "discarded index [6, 5, 4, 8, 0, 9, 2, 7, 3, 1]\n",
            "10 [6 5 4 8 0 9 2 7 3 1]\n",
            "discarded index [6, 5, 4, 8, 0, 9, 2, 7, 3, 1]\n",
            "10 [6 5 4 8 0 9 2 7 3 1]\n",
            "discarded index [6, 5, 4, 8, 0, 9, 2, 7, 3, 1]\n",
            "10 [6 5 4 8 0 9 2 7 3 1]\n",
            "discarded index [6, 5, 4, 8, 0, 9, 2, 7, 3, 1]\n",
            "10 [6 5 4 8 0 9 2 7 3 1]\n",
            "discarded index [6, 5, 4, 8, 0, 9, 2, 7, 3, 1]\n",
            "10 [6 5 4 8 0 9 2 7 3 1]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 2, bulyan: at fang n_at 10 e 2 | val loss 2.3012 val acc 11.7492 best val_acc 13.453734\n",
            "discarded index [5, 6, 8, 4, 2, 3, 9, 1, 0, 7]\n",
            "10 [5 6 8 4 2 3 9 1 0 7]\n",
            "discarded index [5, 6, 8, 4, 2, 3, 9, 1, 0, 7]\n",
            "10 [5 6 8 4 2 3 9 1 0 7]\n",
            "discarded index [5, 6, 8, 4, 2, 3, 9, 1, 0, 7]\n",
            "10 [5 6 8 4 2 3 9 1 0 7]\n",
            "discarded index [5, 6, 8, 4, 2, 3, 9, 1, 0, 7]\n",
            "10 [5 6 8 4 2 3 9 1 0 7]\n",
            "discarded index [5, 6, 8, 4, 2, 3, 9, 1, 0, 7]\n",
            "10 [5 6 8 4 2 3 9 1 0 7]\n",
            "discarded index [5, 6, 8, 4, 2, 3, 9, 1, 0, 7]\n",
            "10 [5 6 8 4 2 3 9 1 0 7]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 3, bulyan: at fang n_at 10 e 3 | val loss 2.3006 val acc 10.3287 best val_acc 13.453734\n",
            "discarded index [5, 6, 4, 9, 8, 1, 2, 3, 7, 0]\n",
            "10 [5 6 4 9 8 1 2 3 7 0]\n",
            "discarded index [5, 6, 4, 9, 8, 1, 2, 3, 7, 0]\n",
            "10 [5 6 4 9 8 1 2 3 7 0]\n",
            "discarded index [5, 6, 4, 9, 8, 1, 2, 3, 7, 0]\n",
            "10 [5 6 4 9 8 1 2 3 7 0]\n",
            "discarded index [5, 6, 4, 9, 8, 1, 2, 3, 7, 0]\n",
            "10 [5 6 4 9 8 1 2 3 7 0]\n",
            "discarded index [5, 6, 4, 9, 8, 1, 2, 3, 7, 0]\n",
            "10 [5 6 4 9 8 1 2 3 7 0]\n",
            "discarded index [5, 6, 4, 9, 8, 1, 2, 3, 7, 0]\n",
            "10 [5 6 4 9 8 1 2 3 7 0]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 4, bulyan: at fang n_at 10 e 4 | val loss 2.3001 val acc 10.3693 best val_acc 13.453734\n",
            "discarded index [6, 5, 4, 8, 9, 3, 2, 7, 0, 1]\n",
            "10 [6 5 4 8 9 3 2 7 0 1]\n",
            "discarded index [6, 5, 4, 8, 9, 3, 2, 7, 0, 1]\n",
            "10 [6 5 4 8 9 3 2 7 0 1]\n",
            "discarded index [6, 5, 4, 8, 9, 3, 2, 7, 0, 1]\n",
            "10 [6 5 4 8 9 3 2 7 0 1]\n",
            "discarded index [6, 5, 4, 8, 9, 3, 2, 7, 0, 1]\n",
            "10 [6 5 4 8 9 3 2 7 0 1]\n",
            "discarded index [6, 5, 4, 8, 9, 3, 2, 7, 0, 1]\n",
            "10 [6 5 4 8 9 3 2 7 0 1]\n",
            "discarded index [6, 5, 4, 8, 9, 3, 2, 7, 0, 1]\n",
            "10 [6 5 4 8 9 3 2 7 0 1]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 5, bulyan: at fang n_at 10 e 5 | val loss 2.2995 val acc 11.4245 best val_acc 13.453734\n",
            "discarded index [5, 6, 4, 8, 9, 2, 3, 1, 0, 7]\n",
            "10 [5 6 4 8 9 2 3 1 0 7]\n",
            "discarded index [5, 6, 4, 8, 9, 2, 3, 1, 0, 7]\n",
            "10 [5 6 4 8 9 2 3 1 0 7]\n",
            "discarded index [5, 6, 4, 8, 9, 2, 3, 1, 0, 7]\n",
            "10 [5 6 4 8 9 2 3 1 0 7]\n",
            "discarded index [5, 6, 4, 8, 9, 2, 3, 1, 0, 7]\n",
            "10 [5 6 4 8 9 2 3 1 0 7]\n",
            "discarded index [5, 6, 4, 8, 9, 2, 3, 1, 0, 7]\n",
            "10 [5 6 4 8 9 2 3 1 0 7]\n",
            "discarded index [5, 6, 4, 8, 9, 2, 3, 1, 0, 7]\n",
            "10 [5 6 4 8 9 2 3 1 0 7]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 6, bulyan: at fang n_at 10 e 6 | val loss 2.2987 val acc 10.2273 best val_acc 13.453734\n",
            "discarded index [5, 6, 8, 4, 1, 2, 0, 3, 9, 7]\n",
            "10 [5 6 8 4 1 2 0 3 9 7]\n",
            "discarded index [5, 6, 8, 4, 1, 2, 0, 3, 9, 7]\n",
            "10 [5 6 8 4 1 2 0 3 9 7]\n",
            "discarded index [5, 6, 8, 4, 1, 2, 0, 3, 9, 7]\n",
            "10 [5 6 8 4 1 2 0 3 9 7]\n",
            "discarded index [5, 6, 8, 4, 1, 2, 0, 3, 9, 7]\n",
            "10 [5 6 8 4 1 2 0 3 9 7]\n",
            "discarded index [5, 6, 8, 4, 1, 2, 0, 3, 9, 7]\n",
            "10 [5 6 8 4 1 2 0 3 9 7]\n",
            "discarded index [5, 6, 8, 4, 1, 2, 0, 3, 9, 7]\n",
            "10 [5 6 8 4 1 2 0 3 9 7]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 7, bulyan: at fang n_at 10 e 7 | val loss 2.2979 val acc 10.7346 best val_acc 13.453734\n",
            "discarded index [6, 5, 4, 1, 0, 7, 2, 3, 8, 9]\n",
            "10 [6 5 4 1 0 7 2 3 8 9]\n",
            "discarded index [6, 5, 4, 1, 0, 7, 2, 3, 8, 9]\n",
            "10 [6 5 4 1 0 7 2 3 8 9]\n",
            "discarded index [6, 5, 4, 1, 0, 7, 2, 3, 8, 9]\n",
            "10 [6 5 4 1 0 7 2 3 8 9]\n",
            "discarded index [6, 5, 4, 1, 0, 7, 2, 3, 8, 9]\n",
            "10 [6 5 4 1 0 7 2 3 8 9]\n",
            "discarded index [6, 5, 4, 1, 0, 7, 2, 3, 8, 9]\n",
            "10 [6 5 4 1 0 7 2 3 8 9]\n",
            "discarded index [6, 5, 4, 1, 0, 7, 2, 3, 8, 9]\n",
            "10 [6 5 4 1 0 7 2 3 8 9]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 8, bulyan: at fang n_at 10 e 8 | val loss 2.2970 val acc 11.3231 best val_acc 13.453734\n",
            "discarded index [5, 6, 4, 8, 1, 2, 0, 7, 9, 3]\n",
            "10 [5 6 4 8 1 2 0 7 9 3]\n",
            "discarded index [5, 6, 4, 8, 1, 2, 0, 7, 9, 3]\n",
            "10 [5 6 4 8 1 2 0 7 9 3]\n",
            "discarded index [5, 6, 4, 8, 1, 2, 0, 7, 9, 3]\n",
            "10 [5 6 4 8 1 2 0 7 9 3]\n",
            "discarded index [5, 6, 4, 8, 1, 2, 0, 7, 9, 3]\n",
            "10 [5 6 4 8 1 2 0 7 9 3]\n",
            "discarded index [5, 6, 4, 8, 1, 2, 0, 7, 9, 3]\n",
            "10 [5 6 4 8 1 2 0 7 9 3]\n",
            "discarded index [5, 6, 4, 8, 1, 2, 0, 7, 9, 3]\n",
            "10 [5 6 4 8 1 2 0 7 9 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 9, bulyan: at fang n_at 10 e 9 | val loss 2.2958 val acc 13.1088 best val_acc 13.453734\n",
            "discarded index [5, 6, 4, 1, 8, 9, 7, 2, 3, 0]\n",
            "10 [5 6 4 1 8 9 7 2 3 0]\n",
            "discarded index [5, 6, 4, 1, 8, 9, 7, 2, 3, 0]\n",
            "10 [5 6 4 1 8 9 7 2 3 0]\n",
            "discarded index [5, 6, 4, 1, 8, 9, 7, 2, 3, 0]\n",
            "10 [5 6 4 1 8 9 7 2 3 0]\n",
            "discarded index [5, 6, 4, 1, 8, 9, 7, 2, 3, 0]\n",
            "10 [5 6 4 1 8 9 7 2 3 0]\n",
            "discarded index [5, 6, 4, 1, 8, 9, 7, 2, 3, 0]\n",
            "10 [5 6 4 1 8 9 7 2 3 0]\n",
            "discarded index [5, 6, 4, 1, 8, 9, 7, 2, 3, 0]\n",
            "10 [5 6 4 1 8 9 7 2 3 0]\n",
            "discarded index [5, 6, 4, 1, 8, 9, 7, 2, 3, 0]\n",
            "10 [5 6 4 1 8 9 7 2 3 0]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 10, bulyan: at fang n_at 10 e 10 | val loss 2.2943 val acc 14.5089 best val_acc 14.508929\n",
            "discarded index [6, 5, 8, 4, 1, 0, 3, 2, 7, 9]\n",
            "10 [6 5 8 4 1 0 3 2 7 9]\n",
            "discarded index [6, 5, 8, 4, 1, 0, 3, 2, 7, 9]\n",
            "10 [6 5 8 4 1 0 3 2 7 9]\n",
            "discarded index [6, 5, 8, 4, 1, 0, 3, 2, 7, 9]\n",
            "10 [6 5 8 4 1 0 3 2 7 9]\n",
            "discarded index [6, 5, 8, 4, 1, 0, 3, 2, 7, 9]\n",
            "10 [6 5 8 4 1 0 3 2 7 9]\n",
            "discarded index [6, 5, 8, 4, 1, 0, 3, 2, 7, 9]\n",
            "10 [6 5 8 4 1 0 3 2 7 9]\n",
            "discarded index [6, 5, 8, 4, 1, 0, 3, 2, 7, 9]\n",
            "10 [6 5 8 4 1 0 3 2 7 9]\n",
            "discarded index [6, 5, 8, 4, 1, 0, 3, 2, 7, 9]\n",
            "10 [6 5 8 4 1 0 3 2 7 9]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 11, bulyan: at fang n_at 10 e 11 | val loss 2.2924 val acc 15.1583 best val_acc 15.158279\n",
            "discarded index [5, 6, 4, 1, 2, 7, 0, 8, 3, 9]\n",
            "10 [5 6 4 1 2 7 0 8 3 9]\n",
            "discarded index [5, 6, 4, 1, 2, 7, 0, 8, 3, 9]\n",
            "10 [5 6 4 1 2 7 0 8 3 9]\n",
            "discarded index [5, 6, 4, 1, 2, 7, 0, 8, 3, 9]\n",
            "10 [5 6 4 1 2 7 0 8 3 9]\n",
            "discarded index [5, 6, 4, 1, 2, 7, 0, 8, 3, 9]\n",
            "10 [5 6 4 1 2 7 0 8 3 9]\n",
            "discarded index [5, 6, 4, 1, 2, 7, 0, 8, 3, 9]\n",
            "10 [5 6 4 1 2 7 0 8 3 9]\n",
            "discarded index [5, 6, 4, 1, 2, 7, 0, 8, 3, 9]\n",
            "10 [5 6 4 1 2 7 0 8 3 9]\n",
            "discarded index [5, 6, 4, 1, 2, 7, 0, 8, 3, 9]\n",
            "10 [5 6 4 1 2 7 0 8 3 9]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 12, bulyan: at fang n_at 10 e 12 | val loss 2.2898 val acc 15.3815 best val_acc 15.381494\n",
            "discarded index [5, 6, 4, 1, 8, 2, 7, 3, 9, 0]\n",
            "10 [5 6 4 1 8 2 7 3 9 0]\n",
            "discarded index [5, 6, 4, 1, 8, 2, 7, 3, 9, 0]\n",
            "10 [5 6 4 1 8 2 7 3 9 0]\n",
            "discarded index [5, 6, 4, 1, 8, 2, 7, 3, 9, 0]\n",
            "10 [5 6 4 1 8 2 7 3 9 0]\n",
            "discarded index [5, 6, 4, 1, 8, 2, 7, 3, 9, 0]\n",
            "10 [5 6 4 1 8 2 7 3 9 0]\n",
            "discarded index [5, 6, 4, 1, 8, 2, 7, 3, 9, 0]\n",
            "10 [5 6 4 1 8 2 7 3 9 0]\n",
            "discarded index [5, 6, 4, 1, 8, 2, 7, 3, 9, 0]\n",
            "10 [5 6 4 1 8 2 7 3 9 0]\n",
            "discarded index [5, 6, 4, 1, 8, 2, 7, 3, 9, 0]\n",
            "10 [5 6 4 1 8 2 7 3 9 0]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 13, bulyan: at fang n_at 10 e 13 | val loss 2.2865 val acc 16.2541 best val_acc 16.254058\n",
            "discarded index [6, 5, 4, 1, 8, 0, 3, 2, 9, 7]\n",
            "10 [6 5 4 1 8 0 3 2 9 7]\n",
            "discarded index [6, 5, 4, 1, 8, 0, 3, 2, 9, 7]\n",
            "10 [6 5 4 1 8 0 3 2 9 7]\n",
            "discarded index [6, 5, 4, 1, 8, 0, 3, 2, 9, 7]\n",
            "10 [6 5 4 1 8 0 3 2 9 7]\n",
            "discarded index [6, 5, 4, 1, 8, 0, 3, 2, 9, 7]\n",
            "10 [6 5 4 1 8 0 3 2 9 7]\n",
            "discarded index [6, 5, 4, 1, 8, 0, 3, 2, 9, 7]\n",
            "10 [6 5 4 1 8 0 3 2 9 7]\n",
            "discarded index [6, 5, 4, 1, 8, 0, 3, 2, 9, 7]\n",
            "10 [6 5 4 1 8 0 3 2 9 7]\n",
            "discarded index [6, 5, 4, 1, 8, 0, 3, 2, 9, 7]\n",
            "10 [6 5 4 1 8 0 3 2 9 7]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 14, bulyan: at fang n_at 10 e 14 | val loss 2.2819 val acc 15.5032 best val_acc 16.254058\n",
            "discarded index [5, 6, 8, 4, 1, 9, 2, 0, 3, 7]\n",
            "10 [5 6 8 4 1 9 2 0 3 7]\n",
            "discarded index [5, 6, 8, 4, 1, 9, 2, 0, 3, 7]\n",
            "10 [5 6 8 4 1 9 2 0 3 7]\n",
            "discarded index [5, 6, 8, 4, 1, 9, 2, 0, 3, 7]\n",
            "10 [5 6 8 4 1 9 2 0 3 7]\n",
            "discarded index [5, 6, 8, 4, 1, 9, 2, 0, 3, 7]\n",
            "10 [5 6 8 4 1 9 2 0 3 7]\n",
            "discarded index [5, 6, 8, 4, 1, 9, 2, 0, 3, 7]\n",
            "10 [5 6 8 4 1 9 2 0 3 7]\n",
            "discarded index [5, 6, 8, 4, 1, 9, 2, 0, 3, 7]\n",
            "10 [5 6 8 4 1 9 2 0 3 7]\n",
            "discarded index [5, 6, 8, 4, 1, 9, 2, 0, 3, 7]\n",
            "10 [5 6 8 4 1 9 2 0 3 7]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 15, bulyan: at fang n_at 10 e 15 | val loss 2.2758 val acc 14.5495 best val_acc 16.254058\n",
            "discarded index [5, 6, 4, 1, 2, 7, 8, 9, 3, 0]\n",
            "10 [5 6 4 1 2 7 8 9 3 0]\n",
            "discarded index [5, 6, 4, 1, 2, 7, 8, 9, 3, 0]\n",
            "10 [5 6 4 1 2 7 8 9 3 0]\n",
            "discarded index [5, 6, 4, 1, 2, 7, 8, 9, 3, 0]\n",
            "10 [5 6 4 1 2 7 8 9 3 0]\n",
            "discarded index [5, 6, 4, 1, 2, 7, 8, 9, 3, 0]\n",
            "10 [5 6 4 1 2 7 8 9 3 0]\n",
            "discarded index [5, 6, 4, 1, 2, 7, 8, 9, 3, 0]\n",
            "10 [5 6 4 1 2 7 8 9 3 0]\n",
            "discarded index [5, 6, 4, 1, 2, 7, 8, 9, 3, 0]\n",
            "10 [5 6 4 1 2 7 8 9 3 0]\n",
            "discarded index [5, 6, 4, 1, 2, 7, 8, 9, 3, 0]\n",
            "10 [5 6 4 1 2 7 8 9 3 0]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 16, bulyan: at fang n_at 10 e 16 | val loss 2.2674 val acc 13.5958 best val_acc 16.254058\n",
            "discarded index [6, 5, 1, 4, 9, 8, 7, 2, 0, 3]\n",
            "10 [6 5 1 4 9 8 7 2 0 3]\n",
            "discarded index [6, 5, 1, 4, 9, 8, 7, 2, 0, 3]\n",
            "10 [6 5 1 4 9 8 7 2 0 3]\n",
            "discarded index [6, 5, 1, 4, 9, 8, 7, 2, 0, 3]\n",
            "10 [6 5 1 4 9 8 7 2 0 3]\n",
            "discarded index [6, 5, 1, 4, 9, 8, 7, 2, 0, 3]\n",
            "10 [6 5 1 4 9 8 7 2 0 3]\n",
            "discarded index [6, 5, 1, 4, 9, 8, 7, 2, 0, 3]\n",
            "10 [6 5 1 4 9 8 7 2 0 3]\n",
            "discarded index [6, 5, 1, 4, 9, 8, 7, 2, 0, 3]\n",
            "10 [6 5 1 4 9 8 7 2 0 3]\n",
            "discarded index [6, 5, 1, 4, 9, 8, 7, 2, 0, 3]\n",
            "10 [6 5 1 4 9 8 7 2 0 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 17, bulyan: at fang n_at 10 e 17 | val loss 2.2567 val acc 13.0073 best val_acc 16.254058\n",
            "discarded index [5, 6, 4, 1, 9, 2, 3, 8, 0, 7]\n",
            "10 [5 6 4 1 9 2 3 8 0 7]\n",
            "discarded index [5, 6, 4, 1, 9, 2, 3, 8, 0, 7]\n",
            "10 [5 6 4 1 9 2 3 8 0 7]\n",
            "discarded index [5, 6, 4, 1, 9, 2, 3, 8, 0, 7]\n",
            "10 [5 6 4 1 9 2 3 8 0 7]\n",
            "discarded index [5, 6, 4, 1, 9, 2, 3, 8, 0, 7]\n",
            "10 [5 6 4 1 9 2 3 8 0 7]\n",
            "discarded index [5, 6, 4, 1, 9, 2, 3, 8, 0, 7]\n",
            "10 [5 6 4 1 9 2 3 8 0 7]\n",
            "discarded index [5, 6, 4, 1, 9, 2, 3, 8, 0, 7]\n",
            "10 [5 6 4 1 9 2 3 8 0 7]\n",
            "discarded index [5, 6, 4, 1, 9, 2, 3, 8, 0, 7]\n",
            "10 [5 6 4 1 9 2 3 8 0 7]\n",
            "discarded index [5, 6, 4, 1, 9, 2, 3, 8, 0, 7]\n",
            "10 [5 6 4 1 9 2 3 8 0 7]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 18, bulyan: at fang n_at 10 e 18 | val loss 2.2437 val acc 14.9756 best val_acc 16.254058\n",
            "discarded index [5, 9, 6, 1, 3, 2, 8, 4, 7, 0]\n",
            "10 [5 9 6 1 3 2 8 4 7 0]\n",
            "discarded index [5, 9, 6, 1, 3, 2, 8, 4, 7, 0]\n",
            "10 [5 9 6 1 3 2 8 4 7 0]\n",
            "discarded index [5, 9, 6, 1, 3, 2, 8, 4, 7, 0]\n",
            "10 [5 9 6 1 3 2 8 4 7 0]\n",
            "discarded index [5, 9, 6, 1, 3, 2, 8, 4, 7, 0]\n",
            "10 [5 9 6 1 3 2 8 4 7 0]\n",
            "discarded index [5, 9, 6, 1, 3, 2, 8, 4, 7, 0]\n",
            "10 [5 9 6 1 3 2 8 4 7 0]\n",
            "discarded index [5, 9, 6, 1, 3, 2, 8, 4, 7, 0]\n",
            "10 [5 9 6 1 3 2 8 4 7 0]\n",
            "discarded index [5, 9, 6, 1, 3, 2, 8, 4, 7, 0]\n",
            "10 [5 9 6 1 3 2 8 4 7 0]\n",
            "discarded index [5, 9, 6, 1, 3, 2, 8, 4, 7, 0]\n",
            "10 [5 9 6 1 3 2 8 4 7 0]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 19, bulyan: at fang n_at 10 e 19 | val loss 2.2299 val acc 16.3149 best val_acc 16.314935\n",
            "discarded index [5, 6, 4, 1, 9, 7, 8, 0, 2, 3]\n",
            "10 [5 6 4 1 9 7 8 0 2 3]\n",
            "discarded index [5, 6, 4, 1, 9, 7, 8, 0, 2, 3]\n",
            "10 [5 6 4 1 9 7 8 0 2 3]\n",
            "discarded index [5, 6, 4, 1, 9, 7, 8, 0, 2, 3]\n",
            "10 [5 6 4 1 9 7 8 0 2 3]\n",
            "discarded index [5, 6, 4, 1, 9, 7, 8, 0, 2, 3]\n",
            "10 [5 6 4 1 9 7 8 0 2 3]\n",
            "discarded index [5, 6, 4, 1, 9, 7, 8, 0, 2, 3]\n",
            "10 [5 6 4 1 9 7 8 0 2 3]\n",
            "discarded index [5, 6, 4, 1, 9, 7, 8, 0, 2, 3]\n",
            "10 [5 6 4 1 9 7 8 0 2 3]\n",
            "discarded index [5, 6, 4, 1, 9, 7, 8, 0, 2, 3]\n",
            "10 [5 6 4 1 9 7 8 0 2 3]\n",
            "discarded index [5, 6, 4, 1, 9, 7, 8, 0, 2, 3]\n",
            "10 [5 6 4 1 9 7 8 0 2 3]\n",
            "lamda < threshold\n",
            "discarded index [20, 0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
            "epoch: 20, bulyan: at fang n_at 10 e 20 | val loss 2.2184 val acc 16.2541 best val_acc 16.314935\n",
            "discarded index [5, 6, 4, 9, 1, 2, 3, 7, 8, 0]\n",
            "10 [5 6 4 9 1 2 3 7 8 0]\n",
            "discarded index [5, 6, 4, 9, 1, 2, 3, 7, 8, 0]\n",
            "10 [5 6 4 9 1 2 3 7 8 0]\n",
            "discarded index [5, 6, 4, 9, 1, 2, 3, 7, 8, 0]\n",
            "10 [5 6 4 9 1 2 3 7 8 0]\n",
            "discarded index [5, 6, 4, 9, 1, 2, 3, 7, 8, 0]\n",
            "10 [5 6 4 9 1 2 3 7 8 0]\n",
            "discarded index [5, 6, 4, 9, 1, 2, 3, 7, 8, 0]\n",
            "10 [5 6 4 9 1 2 3 7 8 0]\n",
            "discarded index [5, 6, 4, 9, 1, 2, 3, 7, 8, 0]\n",
            "10 [5 6 4 9 1 2 3 7 8 0]\n",
            "discarded index [5, 6, 4, 9, 1, 2, 3, 7, 8, 0]\n",
            "10 [5 6 4 9 1 2 3 7 8 0]\n",
            "discarded index [5, 6, 4, 9, 1, 2, 3, 7, 8, 0]\n",
            "10 [5 6 4 9 1 2 3 7 8 0]\n",
            "lamda < threshold\n",
            "discarded index [20, 0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
            "epoch: 21, bulyan: at fang n_at 10 e 21 | val loss 2.2056 val acc 21.9968 best val_acc 21.996753\n",
            "discarded index [20, 5, 6, 4, 7, 0, 8, 9, 1, 3]\n",
            "9 [20  5  6  4  7  0  8  9  1  3]\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 22, bulyan: at fang n_at 10 e 22 | val loss 2.2598 val acc 15.1177 best val_acc 21.996753\n",
            "discarded index [5, 9, 1, 3, 6, 0, 4, 7, 8, 2]\n",
            "10 [5 9 1 3 6 0 4 7 8 2]\n",
            "discarded index [5, 9, 1, 3, 6, 0, 4, 7, 8, 2]\n",
            "10 [5 9 1 3 6 0 4 7 8 2]\n",
            "discarded index [5, 9, 1, 3, 6, 0, 4, 7, 8, 2]\n",
            "10 [5 9 1 3 6 0 4 7 8 2]\n",
            "discarded index [5, 9, 1, 3, 6, 0, 4, 7, 8, 2]\n",
            "10 [5 9 1 3 6 0 4 7 8 2]\n",
            "discarded index [5, 9, 1, 3, 6, 0, 4, 7, 8, 2]\n",
            "10 [5 9 1 3 6 0 4 7 8 2]\n",
            "discarded index [5, 9, 1, 3, 6, 0, 4, 7, 8, 2]\n",
            "10 [5 9 1 3 6 0 4 7 8 2]\n",
            "discarded index [5, 9, 1, 3, 6, 0, 4, 7, 8, 2]\n",
            "10 [5 9 1 3 6 0 4 7 8 2]\n",
            "discarded index [5, 9, 1, 3, 6, 0, 4, 7, 8, 2]\n",
            "10 [5 9 1 3 6 0 4 7 8 2]\n",
            "discarded index [5, 9, 1, 3, 6, 0, 4, 7, 8, 2]\n",
            "10 [5 9 1 3 6 0 4 7 8 2]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 23, bulyan: at fang n_at 10 e 23 | val loss 2.3168 val acc 10.9781 best val_acc 21.996753\n",
            "discarded index [0, 7, 4, 6, 9, 5, 1, 3, 2, 8]\n",
            "10 [0 7 4 6 9 5 1 3 2 8]\n",
            "discarded index [0, 7, 4, 6, 9, 5, 1, 3, 2, 8]\n",
            "10 [0 7 4 6 9 5 1 3 2 8]\n",
            "discarded index [0, 7, 4, 6, 9, 5, 1, 3, 2, 8]\n",
            "10 [0 7 4 6 9 5 1 3 2 8]\n",
            "discarded index [0, 7, 4, 6, 9, 5, 1, 3, 2, 8]\n",
            "10 [0 7 4 6 9 5 1 3 2 8]\n",
            "discarded index [0, 7, 4, 6, 9, 5, 1, 3, 2, 8]\n",
            "10 [0 7 4 6 9 5 1 3 2 8]\n",
            "discarded index [0, 7, 4, 6, 9, 5, 1, 3, 2, 8]\n",
            "10 [0 7 4 6 9 5 1 3 2 8]\n",
            "discarded index [0, 7, 4, 6, 9, 5, 1, 3, 2, 8]\n",
            "10 [0 7 4 6 9 5 1 3 2 8]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 24, bulyan: at fang n_at 10 e 24 | val loss 2.3038 val acc 10.3287 best val_acc 21.996753\n",
            "discarded index [7, 0, 9, 3, 5, 6, 4, 8, 2, 1]\n",
            "10 [7 0 9 3 5 6 4 8 2 1]\n",
            "discarded index [7, 0, 9, 3, 5, 6, 4, 8, 2, 1]\n",
            "10 [7 0 9 3 5 6 4 8 2 1]\n",
            "discarded index [7, 0, 9, 3, 5, 6, 4, 8, 2, 1]\n",
            "10 [7 0 9 3 5 6 4 8 2 1]\n",
            "discarded index [7, 0, 9, 3, 5, 6, 4, 8, 2, 1]\n",
            "10 [7 0 9 3 5 6 4 8 2 1]\n",
            "discarded index [7, 0, 9, 3, 5, 6, 4, 8, 2, 1]\n",
            "10 [7 0 9 3 5 6 4 8 2 1]\n",
            "discarded index [7, 0, 9, 3, 5, 6, 4, 8, 2, 1]\n",
            "10 [7 0 9 3 5 6 4 8 2 1]\n",
            "discarded index [7, 0, 9, 3, 5, 6, 4, 8, 2, 1]\n",
            "10 [7 0 9 3 5 6 4 8 2 1]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 25, bulyan: at fang n_at 10 e 25 | val loss 2.2970 val acc 10.4911 best val_acc 21.996753\n",
            "discarded index [7, 9, 3, 0, 6, 2, 4, 1, 8, 5]\n",
            "10 [7 9 3 0 6 2 4 1 8 5]\n",
            "discarded index [7, 9, 3, 0, 6, 2, 4, 1, 8, 5]\n",
            "10 [7 9 3 0 6 2 4 1 8 5]\n",
            "discarded index [7, 9, 3, 0, 6, 2, 4, 1, 8, 5]\n",
            "10 [7 9 3 0 6 2 4 1 8 5]\n",
            "discarded index [7, 9, 3, 0, 6, 2, 4, 1, 8, 5]\n",
            "10 [7 9 3 0 6 2 4 1 8 5]\n",
            "discarded index [7, 9, 3, 0, 6, 2, 4, 1, 8, 5]\n",
            "10 [7 9 3 0 6 2 4 1 8 5]\n",
            "discarded index [7, 9, 3, 0, 6, 2, 4, 1, 8, 5]\n",
            "10 [7 9 3 0 6 2 4 1 8 5]\n",
            "discarded index [7, 9, 3, 0, 6, 2, 4, 1, 8, 5]\n",
            "10 [7 9 3 0 6 2 4 1 8 5]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 26, bulyan: at fang n_at 10 e 26 | val loss 2.2896 val acc 11.9927 best val_acc 21.996753\n",
            "discarded index [7, 9, 3, 1, 0, 6, 4, 5, 2, 8]\n",
            "10 [7 9 3 1 0 6 4 5 2 8]\n",
            "discarded index [7, 9, 3, 1, 0, 6, 4, 5, 2, 8]\n",
            "10 [7 9 3 1 0 6 4 5 2 8]\n",
            "discarded index [7, 9, 3, 1, 0, 6, 4, 5, 2, 8]\n",
            "10 [7 9 3 1 0 6 4 5 2 8]\n",
            "discarded index [7, 9, 3, 1, 0, 6, 4, 5, 2, 8]\n",
            "10 [7 9 3 1 0 6 4 5 2 8]\n",
            "discarded index [7, 9, 3, 1, 0, 6, 4, 5, 2, 8]\n",
            "10 [7 9 3 1 0 6 4 5 2 8]\n",
            "discarded index [7, 9, 3, 1, 0, 6, 4, 5, 2, 8]\n",
            "10 [7 9 3 1 0 6 4 5 2 8]\n",
            "discarded index [7, 9, 3, 1, 0, 6, 4, 5, 2, 8]\n",
            "10 [7 9 3 1 0 6 4 5 2 8]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 27, bulyan: at fang n_at 10 e 27 | val loss 2.2781 val acc 14.1031 best val_acc 21.996753\n",
            "discarded index [7, 9, 3, 1, 2, 8, 5, 6, 0, 4]\n",
            "10 [7 9 3 1 2 8 5 6 0 4]\n",
            "discarded index [7, 9, 3, 1, 2, 8, 5, 6, 0, 4]\n",
            "10 [7 9 3 1 2 8 5 6 0 4]\n",
            "discarded index [7, 9, 3, 1, 2, 8, 5, 6, 0, 4]\n",
            "10 [7 9 3 1 2 8 5 6 0 4]\n",
            "discarded index [7, 9, 3, 1, 2, 8, 5, 6, 0, 4]\n",
            "10 [7 9 3 1 2 8 5 6 0 4]\n",
            "discarded index [7, 9, 3, 1, 2, 8, 5, 6, 0, 4]\n",
            "10 [7 9 3 1 2 8 5 6 0 4]\n",
            "discarded index [7, 9, 3, 1, 2, 8, 5, 6, 0, 4]\n",
            "10 [7 9 3 1 2 8 5 6 0 4]\n",
            "discarded index [7, 9, 3, 1, 2, 8, 5, 6, 0, 4]\n",
            "10 [7 9 3 1 2 8 5 6 0 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 28, bulyan: at fang n_at 10 e 28 | val loss 2.2573 val acc 15.9294 best val_acc 21.996753\n",
            "discarded index [7, 5, 9, 3, 8, 2, 0, 4, 6, 1]\n",
            "10 [7 5 9 3 8 2 0 4 6 1]\n",
            "discarded index [7, 5, 9, 3, 8, 2, 0, 4, 6, 1]\n",
            "10 [7 5 9 3 8 2 0 4 6 1]\n",
            "discarded index [7, 5, 9, 3, 8, 2, 0, 4, 6, 1]\n",
            "10 [7 5 9 3 8 2 0 4 6 1]\n",
            "discarded index [7, 5, 9, 3, 8, 2, 0, 4, 6, 1]\n",
            "10 [7 5 9 3 8 2 0 4 6 1]\n",
            "discarded index [7, 5, 9, 3, 8, 2, 0, 4, 6, 1]\n",
            "10 [7 5 9 3 8 2 0 4 6 1]\n",
            "discarded index [7, 5, 9, 3, 8, 2, 0, 4, 6, 1]\n",
            "10 [7 5 9 3 8 2 0 4 6 1]\n",
            "discarded index [7, 5, 9, 3, 8, 2, 0, 4, 6, 1]\n",
            "10 [7 5 9 3 8 2 0 4 6 1]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 29, bulyan: at fang n_at 10 e 29 | val loss 2.2223 val acc 20.3531 best val_acc 21.996753\n",
            "discarded index [5, 7, 6, 0, 9, 3, 8, 4, 2, 1]\n",
            "10 [5 7 6 0 9 3 8 4 2 1]\n",
            "discarded index [5, 7, 6, 0, 9, 3, 8, 4, 2, 1]\n",
            "10 [5 7 6 0 9 3 8 4 2 1]\n",
            "discarded index [5, 7, 6, 0, 9, 3, 8, 4, 2, 1]\n",
            "10 [5 7 6 0 9 3 8 4 2 1]\n",
            "discarded index [5, 7, 6, 0, 9, 3, 8, 4, 2, 1]\n",
            "10 [5 7 6 0 9 3 8 4 2 1]\n",
            "discarded index [5, 7, 6, 0, 9, 3, 8, 4, 2, 1]\n",
            "10 [5 7 6 0 9 3 8 4 2 1]\n",
            "discarded index [5, 7, 6, 0, 9, 3, 8, 4, 2, 1]\n",
            "10 [5 7 6 0 9 3 8 4 2 1]\n",
            "discarded index [5, 7, 6, 0, 9, 3, 8, 4, 2, 1]\n",
            "10 [5 7 6 0 9 3 8 4 2 1]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 30, bulyan: at fang n_at 10 e 30 | val loss 2.1739 val acc 23.4781 best val_acc 23.478084\n",
            "discarded index [5, 0, 7, 9, 8, 4, 6, 2, 1, 3]\n",
            "10 [5 0 7 9 8 4 6 2 1 3]\n",
            "discarded index [5, 0, 7, 9, 8, 4, 6, 2, 1, 3]\n",
            "10 [5 0 7 9 8 4 6 2 1 3]\n",
            "discarded index [5, 0, 7, 9, 8, 4, 6, 2, 1, 3]\n",
            "10 [5 0 7 9 8 4 6 2 1 3]\n",
            "discarded index [5, 0, 7, 9, 8, 4, 6, 2, 1, 3]\n",
            "10 [5 0 7 9 8 4 6 2 1 3]\n",
            "discarded index [5, 0, 7, 9, 8, 4, 6, 2, 1, 3]\n",
            "10 [5 0 7 9 8 4 6 2 1 3]\n",
            "discarded index [5, 0, 7, 9, 8, 4, 6, 2, 1, 3]\n",
            "10 [5 0 7 9 8 4 6 2 1 3]\n",
            "discarded index [5, 0, 7, 9, 8, 4, 6, 2, 1, 3]\n",
            "10 [5 0 7 9 8 4 6 2 1 3]\n",
            "discarded index [5, 0, 7, 9, 8, 4, 6, 2, 1, 3]\n",
            "10 [5 0 7 9 8 4 6 2 1 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 31, bulyan: at fang n_at 10 e 31 | val loss 2.1286 val acc 24.3912 best val_acc 24.391234\n",
            "discarded index [5, 1, 7, 0, 6, 9, 8, 2, 4, 3]\n",
            "10 [5 1 7 0 6 9 8 2 4 3]\n",
            "discarded index [5, 1, 7, 0, 6, 9, 8, 2, 4, 3]\n",
            "10 [5 1 7 0 6 9 8 2 4 3]\n",
            "discarded index [5, 1, 7, 0, 6, 9, 8, 2, 4, 3]\n",
            "10 [5 1 7 0 6 9 8 2 4 3]\n",
            "discarded index [5, 1, 7, 0, 6, 9, 8, 2, 4, 3]\n",
            "10 [5 1 7 0 6 9 8 2 4 3]\n",
            "discarded index [5, 1, 7, 0, 6, 9, 8, 2, 4, 3]\n",
            "10 [5 1 7 0 6 9 8 2 4 3]\n",
            "discarded index [5, 1, 7, 0, 6, 9, 8, 2, 4, 3]\n",
            "10 [5 1 7 0 6 9 8 2 4 3]\n",
            "discarded index [5, 1, 7, 0, 6, 9, 8, 2, 4, 3]\n",
            "10 [5 1 7 0 6 9 8 2 4 3]\n",
            "discarded index [5, 1, 7, 0, 6, 9, 8, 2, 4, 3]\n",
            "10 [5 1 7 0 6 9 8 2 4 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 32, bulyan: at fang n_at 10 e 32 | val loss 2.1013 val acc 22.7070 best val_acc 24.391234\n",
            "discarded index [5, 6, 9, 8, 3, 4, 7, 0, 2, 1]\n",
            "10 [5 6 9 8 3 4 7 0 2 1]\n",
            "discarded index [5, 6, 9, 8, 3, 4, 7, 0, 2, 1]\n",
            "10 [5 6 9 8 3 4 7 0 2 1]\n",
            "discarded index [5, 6, 9, 8, 3, 4, 7, 0, 2, 1]\n",
            "10 [5 6 9 8 3 4 7 0 2 1]\n",
            "discarded index [5, 6, 9, 8, 3, 4, 7, 0, 2, 1]\n",
            "10 [5 6 9 8 3 4 7 0 2 1]\n",
            "discarded index [5, 6, 9, 8, 3, 4, 7, 0, 2, 1]\n",
            "10 [5 6 9 8 3 4 7 0 2 1]\n",
            "discarded index [5, 6, 9, 8, 3, 4, 7, 0, 2, 1]\n",
            "10 [5 6 9 8 3 4 7 0 2 1]\n",
            "discarded index [5, 6, 9, 8, 3, 4, 7, 0, 2, 1]\n",
            "10 [5 6 9 8 3 4 7 0 2 1]\n",
            "discarded index [5, 6, 9, 8, 3, 4, 7, 0, 2, 1]\n",
            "10 [5 6 9 8 3 4 7 0 2 1]\n",
            "discarded index [5, 6, 9, 8, 3, 4, 7, 0, 2, 1]\n",
            "10 [5 6 9 8 3 4 7 0 2 1]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 33, bulyan: at fang n_at 10 e 33 | val loss 2.2069 val acc 18.6688 best val_acc 24.391234\n",
            "discarded index [1, 6, 8, 3, 2, 5, 7, 4, 9, 0]\n",
            "10 [1 6 8 3 2 5 7 4 9 0]\n",
            "discarded index [1, 6, 8, 3, 2, 5, 7, 4, 9, 0]\n",
            "10 [1 6 8 3 2 5 7 4 9 0]\n",
            "discarded index [1, 6, 8, 3, 2, 5, 7, 4, 9, 0]\n",
            "10 [1 6 8 3 2 5 7 4 9 0]\n",
            "discarded index [1, 6, 8, 3, 2, 5, 7, 4, 9, 0]\n",
            "10 [1 6 8 3 2 5 7 4 9 0]\n",
            "discarded index [1, 6, 8, 3, 2, 5, 7, 4, 9, 0]\n",
            "10 [1 6 8 3 2 5 7 4 9 0]\n",
            "discarded index [1, 6, 8, 3, 2, 5, 7, 4, 9, 0]\n",
            "10 [1 6 8 3 2 5 7 4 9 0]\n",
            "discarded index [1, 6, 8, 3, 2, 5, 7, 4, 9, 0]\n",
            "10 [1 6 8 3 2 5 7 4 9 0]\n",
            "discarded index [1, 6, 8, 3, 2, 5, 7, 4, 9, 0]\n",
            "10 [1 6 8 3 2 5 7 4 9 0]\n",
            "discarded index [1, 6, 8, 3, 2, 5, 7, 4, 9, 0]\n",
            "10 [1 6 8 3 2 5 7 4 9 0]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 34, bulyan: at fang n_at 10 e 34 | val loss 2.7721 val acc 11.3636 best val_acc 24.391234\n",
            "discarded index [0, 5, 9, 7, 3, 2, 8, 4, 1, 6]\n",
            "10 [0 5 9 7 3 2 8 4 1 6]\n",
            "discarded index [0, 5, 9, 7, 3, 2, 8, 4, 1, 6]\n",
            "10 [0 5 9 7 3 2 8 4 1 6]\n",
            "discarded index [0, 5, 9, 7, 3, 2, 8, 4, 1, 6]\n",
            "10 [0 5 9 7 3 2 8 4 1 6]\n",
            "discarded index [0, 5, 9, 7, 3, 2, 8, 4, 1, 6]\n",
            "10 [0 5 9 7 3 2 8 4 1 6]\n",
            "discarded index [0, 5, 9, 7, 3, 2, 8, 4, 1, 6]\n",
            "10 [0 5 9 7 3 2 8 4 1 6]\n",
            "discarded index [0, 5, 9, 7, 3, 2, 8, 4, 1, 6]\n",
            "10 [0 5 9 7 3 2 8 4 1 6]\n",
            "discarded index [0, 5, 9, 7, 3, 2, 8, 4, 1, 6]\n",
            "10 [0 5 9 7 3 2 8 4 1 6]\n",
            "discarded index [0, 5, 9, 7, 3, 2, 8, 4, 1, 6]\n",
            "10 [0 5 9 7 3 2 8 4 1 6]\n",
            "discarded index [0, 5, 9, 7, 3, 2, 8, 4, 1, 6]\n",
            "10 [0 5 9 7 3 2 8 4 1 6]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 35, bulyan: at fang n_at 10 e 35 | val loss 2.3075 val acc 10.1867 best val_acc 24.391234\n",
            "discarded index [0, 9, 5, 7, 4, 2, 1, 3, 6, 8]\n",
            "10 [0 9 5 7 4 2 1 3 6 8]\n",
            "discarded index [0, 9, 5, 7, 4, 2, 1, 3, 6, 8]\n",
            "10 [0 9 5 7 4 2 1 3 6 8]\n",
            "discarded index [0, 9, 5, 7, 4, 2, 1, 3, 6, 8]\n",
            "10 [0 9 5 7 4 2 1 3 6 8]\n",
            "discarded index [0, 9, 5, 7, 4, 2, 1, 3, 6, 8]\n",
            "10 [0 9 5 7 4 2 1 3 6 8]\n",
            "discarded index [0, 9, 5, 7, 4, 2, 1, 3, 6, 8]\n",
            "10 [0 9 5 7 4 2 1 3 6 8]\n",
            "discarded index [0, 9, 5, 7, 4, 2, 1, 3, 6, 8]\n",
            "10 [0 9 5 7 4 2 1 3 6 8]\n",
            "discarded index [0, 9, 5, 7, 4, 2, 1, 3, 6, 8]\n",
            "10 [0 9 5 7 4 2 1 3 6 8]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 36, bulyan: at fang n_at 10 e 36 | val loss 2.3019 val acc 10.1867 best val_acc 24.391234\n",
            "discarded index [0, 7, 9, 5, 8, 3, 4, 2, 6, 1]\n",
            "10 [0 7 9 5 8 3 4 2 6 1]\n",
            "discarded index [0, 7, 9, 5, 8, 3, 4, 2, 6, 1]\n",
            "10 [0 7 9 5 8 3 4 2 6 1]\n",
            "discarded index [0, 7, 9, 5, 8, 3, 4, 2, 6, 1]\n",
            "10 [0 7 9 5 8 3 4 2 6 1]\n",
            "discarded index [0, 7, 9, 5, 8, 3, 4, 2, 6, 1]\n",
            "10 [0 7 9 5 8 3 4 2 6 1]\n",
            "discarded index [0, 7, 9, 5, 8, 3, 4, 2, 6, 1]\n",
            "10 [0 7 9 5 8 3 4 2 6 1]\n",
            "discarded index [0, 7, 9, 5, 8, 3, 4, 2, 6, 1]\n",
            "10 [0 7 9 5 8 3 4 2 6 1]\n",
            "discarded index [0, 7, 9, 5, 8, 3, 4, 2, 6, 1]\n",
            "10 [0 7 9 5 8 3 4 2 6 1]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 37, bulyan: at fang n_at 10 e 37 | val loss 2.2958 val acc 10.2476 best val_acc 24.391234\n",
            "discarded index [0, 7, 9, 5, 2, 4, 3, 8, 1, 6]\n",
            "10 [0 7 9 5 2 4 3 8 1 6]\n",
            "discarded index [0, 7, 9, 5, 2, 4, 3, 8, 1, 6]\n",
            "10 [0 7 9 5 2 4 3 8 1 6]\n",
            "discarded index [0, 7, 9, 5, 2, 4, 3, 8, 1, 6]\n",
            "10 [0 7 9 5 2 4 3 8 1 6]\n",
            "discarded index [0, 7, 9, 5, 2, 4, 3, 8, 1, 6]\n",
            "10 [0 7 9 5 2 4 3 8 1 6]\n",
            "discarded index [0, 7, 9, 5, 2, 4, 3, 8, 1, 6]\n",
            "10 [0 7 9 5 2 4 3 8 1 6]\n",
            "discarded index [0, 7, 9, 5, 2, 4, 3, 8, 1, 6]\n",
            "10 [0 7 9 5 2 4 3 8 1 6]\n",
            "discarded index [0, 7, 9, 5, 2, 4, 3, 8, 1, 6]\n",
            "10 [0 7 9 5 2 4 3 8 1 6]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 38, bulyan: at fang n_at 10 e 38 | val loss 2.2889 val acc 11.6883 best val_acc 24.391234\n",
            "discarded index [0, 9, 7, 4, 2, 5, 1, 6, 3, 8]\n",
            "10 [0 9 7 4 2 5 1 6 3 8]\n",
            "discarded index [0, 9, 7, 4, 2, 5, 1, 6, 3, 8]\n",
            "10 [0 9 7 4 2 5 1 6 3 8]\n",
            "discarded index [0, 9, 7, 4, 2, 5, 1, 6, 3, 8]\n",
            "10 [0 9 7 4 2 5 1 6 3 8]\n",
            "discarded index [0, 9, 7, 4, 2, 5, 1, 6, 3, 8]\n",
            "10 [0 9 7 4 2 5 1 6 3 8]\n",
            "discarded index [0, 9, 7, 4, 2, 5, 1, 6, 3, 8]\n",
            "10 [0 9 7 4 2 5 1 6 3 8]\n",
            "discarded index [0, 9, 7, 4, 2, 5, 1, 6, 3, 8]\n",
            "10 [0 9 7 4 2 5 1 6 3 8]\n",
            "discarded index [0, 9, 7, 4, 2, 5, 1, 6, 3, 8]\n",
            "10 [0 9 7 4 2 5 1 6 3 8]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 39, bulyan: at fang n_at 10 e 39 | val loss 2.2808 val acc 12.1144 best val_acc 24.391234\n",
            "discarded index [9, 0, 7, 4, 5, 1, 2, 3, 8, 6]\n",
            "10 [9 0 7 4 5 1 2 3 8 6]\n",
            "discarded index [9, 0, 7, 4, 5, 1, 2, 3, 8, 6]\n",
            "10 [9 0 7 4 5 1 2 3 8 6]\n",
            "discarded index [9, 0, 7, 4, 5, 1, 2, 3, 8, 6]\n",
            "10 [9 0 7 4 5 1 2 3 8 6]\n",
            "discarded index [9, 0, 7, 4, 5, 1, 2, 3, 8, 6]\n",
            "10 [9 0 7 4 5 1 2 3 8 6]\n",
            "discarded index [9, 0, 7, 4, 5, 1, 2, 3, 8, 6]\n",
            "10 [9 0 7 4 5 1 2 3 8 6]\n",
            "discarded index [9, 0, 7, 4, 5, 1, 2, 3, 8, 6]\n",
            "10 [9 0 7 4 5 1 2 3 8 6]\n",
            "discarded index [9, 0, 7, 4, 5, 1, 2, 3, 8, 6]\n",
            "10 [9 0 7 4 5 1 2 3 8 6]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 40, bulyan: at fang n_at 10 e 40 | val loss 2.2728 val acc 11.8709 best val_acc 24.391234\n",
            "discarded index [9, 0, 7, 8, 3, 5, 1, 6, 4, 2]\n",
            "10 [9 0 7 8 3 5 1 6 4 2]\n",
            "discarded index [9, 0, 7, 8, 3, 5, 1, 6, 4, 2]\n",
            "10 [9 0 7 8 3 5 1 6 4 2]\n",
            "discarded index [9, 0, 7, 8, 3, 5, 1, 6, 4, 2]\n",
            "10 [9 0 7 8 3 5 1 6 4 2]\n",
            "discarded index [9, 0, 7, 8, 3, 5, 1, 6, 4, 2]\n",
            "10 [9 0 7 8 3 5 1 6 4 2]\n",
            "discarded index [9, 0, 7, 8, 3, 5, 1, 6, 4, 2]\n",
            "10 [9 0 7 8 3 5 1 6 4 2]\n",
            "discarded index [9, 0, 7, 8, 3, 5, 1, 6, 4, 2]\n",
            "10 [9 0 7 8 3 5 1 6 4 2]\n",
            "discarded index [9, 0, 7, 8, 3, 5, 1, 6, 4, 2]\n",
            "10 [9 0 7 8 3 5 1 6 4 2]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 41, bulyan: at fang n_at 10 e 41 | val loss 2.2644 val acc 11.2013 best val_acc 24.391234\n",
            "discarded index [0, 7, 9, 1, 4, 5, 3, 8, 2, 6]\n",
            "10 [0 7 9 1 4 5 3 8 2 6]\n",
            "discarded index [0, 7, 9, 1, 4, 5, 3, 8, 2, 6]\n",
            "10 [0 7 9 1 4 5 3 8 2 6]\n",
            "discarded index [0, 7, 9, 1, 4, 5, 3, 8, 2, 6]\n",
            "10 [0 7 9 1 4 5 3 8 2 6]\n",
            "discarded index [0, 7, 9, 1, 4, 5, 3, 8, 2, 6]\n",
            "10 [0 7 9 1 4 5 3 8 2 6]\n",
            "discarded index [0, 7, 9, 1, 4, 5, 3, 8, 2, 6]\n",
            "10 [0 7 9 1 4 5 3 8 2 6]\n",
            "discarded index [0, 7, 9, 1, 4, 5, 3, 8, 2, 6]\n",
            "10 [0 7 9 1 4 5 3 8 2 6]\n",
            "discarded index [0, 7, 9, 1, 4, 5, 3, 8, 2, 6]\n",
            "10 [0 7 9 1 4 5 3 8 2 6]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 42, bulyan: at fang n_at 10 e 42 | val loss 2.2553 val acc 11.2825 best val_acc 24.391234\n",
            "discarded index [9, 0, 7, 4, 5, 1, 3, 8, 2, 6]\n",
            "10 [9 0 7 4 5 1 3 8 2 6]\n",
            "discarded index [9, 0, 7, 4, 5, 1, 3, 8, 2, 6]\n",
            "10 [9 0 7 4 5 1 3 8 2 6]\n",
            "discarded index [9, 0, 7, 4, 5, 1, 3, 8, 2, 6]\n",
            "10 [9 0 7 4 5 1 3 8 2 6]\n",
            "discarded index [9, 0, 7, 4, 5, 1, 3, 8, 2, 6]\n",
            "10 [9 0 7 4 5 1 3 8 2 6]\n",
            "discarded index [9, 0, 7, 4, 5, 1, 3, 8, 2, 6]\n",
            "10 [9 0 7 4 5 1 3 8 2 6]\n",
            "discarded index [9, 0, 7, 4, 5, 1, 3, 8, 2, 6]\n",
            "10 [9 0 7 4 5 1 3 8 2 6]\n",
            "discarded index [9, 0, 7, 4, 5, 1, 3, 8, 2, 6]\n",
            "10 [9 0 7 4 5 1 3 8 2 6]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 43, bulyan: at fang n_at 10 e 43 | val loss 2.2480 val acc 11.3636 best val_acc 24.391234\n",
            "discarded index [9, 0, 7, 5, 4, 1, 3, 8, 6, 2]\n",
            "10 [9 0 7 5 4 1 3 8 6 2]\n",
            "discarded index [9, 0, 7, 5, 4, 1, 3, 8, 6, 2]\n",
            "10 [9 0 7 5 4 1 3 8 6 2]\n",
            "discarded index [9, 0, 7, 5, 4, 1, 3, 8, 6, 2]\n",
            "10 [9 0 7 5 4 1 3 8 6 2]\n",
            "discarded index [9, 0, 7, 5, 4, 1, 3, 8, 6, 2]\n",
            "10 [9 0 7 5 4 1 3 8 6 2]\n",
            "discarded index [9, 0, 7, 5, 4, 1, 3, 8, 6, 2]\n",
            "10 [9 0 7 5 4 1 3 8 6 2]\n",
            "discarded index [9, 0, 7, 5, 4, 1, 3, 8, 6, 2]\n",
            "10 [9 0 7 5 4 1 3 8 6 2]\n",
            "discarded index [9, 0, 7, 5, 4, 1, 3, 8, 6, 2]\n",
            "10 [9 0 7 5 4 1 3 8 6 2]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 44, bulyan: at fang n_at 10 e 44 | val loss 2.2392 val acc 11.2216 best val_acc 24.391234\n",
            "discarded index [0, 9, 7, 1, 4, 6, 2, 5, 8, 3]\n",
            "10 [0 9 7 1 4 6 2 5 8 3]\n",
            "discarded index [0, 9, 7, 1, 4, 6, 2, 5, 8, 3]\n",
            "10 [0 9 7 1 4 6 2 5 8 3]\n",
            "discarded index [0, 9, 7, 1, 4, 6, 2, 5, 8, 3]\n",
            "10 [0 9 7 1 4 6 2 5 8 3]\n",
            "discarded index [0, 9, 7, 1, 4, 6, 2, 5, 8, 3]\n",
            "10 [0 9 7 1 4 6 2 5 8 3]\n",
            "discarded index [0, 9, 7, 1, 4, 6, 2, 5, 8, 3]\n",
            "10 [0 9 7 1 4 6 2 5 8 3]\n",
            "discarded index [0, 9, 7, 1, 4, 6, 2, 5, 8, 3]\n",
            "10 [0 9 7 1 4 6 2 5 8 3]\n",
            "discarded index [0, 9, 7, 1, 4, 6, 2, 5, 8, 3]\n",
            "10 [0 9 7 1 4 6 2 5 8 3]\n",
            "discarded index [0, 9, 7, 1, 4, 6, 2, 5, 8, 3]\n",
            "10 [0 9 7 1 4 6 2 5 8 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 45, bulyan: at fang n_at 10 e 45 | val loss 2.2310 val acc 11.3636 best val_acc 24.391234\n",
            "discarded index [0, 7, 9, 1, 5, 4, 6, 8, 2, 3]\n",
            "10 [0 7 9 1 5 4 6 8 2 3]\n",
            "discarded index [0, 7, 9, 1, 5, 4, 6, 8, 2, 3]\n",
            "10 [0 7 9 1 5 4 6 8 2 3]\n",
            "discarded index [0, 7, 9, 1, 5, 4, 6, 8, 2, 3]\n",
            "10 [0 7 9 1 5 4 6 8 2 3]\n",
            "discarded index [0, 7, 9, 1, 5, 4, 6, 8, 2, 3]\n",
            "10 [0 7 9 1 5 4 6 8 2 3]\n",
            "discarded index [0, 7, 9, 1, 5, 4, 6, 8, 2, 3]\n",
            "10 [0 7 9 1 5 4 6 8 2 3]\n",
            "discarded index [0, 7, 9, 1, 5, 4, 6, 8, 2, 3]\n",
            "10 [0 7 9 1 5 4 6 8 2 3]\n",
            "discarded index [0, 7, 9, 1, 5, 4, 6, 8, 2, 3]\n",
            "10 [0 7 9 1 5 4 6 8 2 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 46, bulyan: at fang n_at 10 e 46 | val loss 2.2235 val acc 11.3839 best val_acc 24.391234\n",
            "discarded index [0, 7, 9, 5, 1, 3, 8, 2, 6, 4]\n",
            "10 [0 7 9 5 1 3 8 2 6 4]\n",
            "discarded index [0, 7, 9, 5, 1, 3, 8, 2, 6, 4]\n",
            "10 [0 7 9 5 1 3 8 2 6 4]\n",
            "discarded index [0, 7, 9, 5, 1, 3, 8, 2, 6, 4]\n",
            "10 [0 7 9 5 1 3 8 2 6 4]\n",
            "discarded index [0, 7, 9, 5, 1, 3, 8, 2, 6, 4]\n",
            "10 [0 7 9 5 1 3 8 2 6 4]\n",
            "discarded index [0, 7, 9, 5, 1, 3, 8, 2, 6, 4]\n",
            "10 [0 7 9 5 1 3 8 2 6 4]\n",
            "discarded index [0, 7, 9, 5, 1, 3, 8, 2, 6, 4]\n",
            "10 [0 7 9 5 1 3 8 2 6 4]\n",
            "discarded index [0, 7, 9, 5, 1, 3, 8, 2, 6, 4]\n",
            "10 [0 7 9 5 1 3 8 2 6 4]\n",
            "discarded index [0, 7, 9, 5, 1, 3, 8, 2, 6, 4]\n",
            "10 [0 7 9 5 1 3 8 2 6 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 47, bulyan: at fang n_at 10 e 47 | val loss 2.2199 val acc 17.3295 best val_acc 24.391234\n",
            "discarded index [0, 9, 1, 5, 2, 3, 8, 7, 6, 4]\n",
            "10 [0 9 1 5 2 3 8 7 6 4]\n",
            "discarded index [0, 9, 1, 5, 2, 3, 8, 7, 6, 4]\n",
            "10 [0 9 1 5 2 3 8 7 6 4]\n",
            "discarded index [0, 9, 1, 5, 2, 3, 8, 7, 6, 4]\n",
            "10 [0 9 1 5 2 3 8 7 6 4]\n",
            "discarded index [0, 9, 1, 5, 2, 3, 8, 7, 6, 4]\n",
            "10 [0 9 1 5 2 3 8 7 6 4]\n",
            "discarded index [0, 9, 1, 5, 2, 3, 8, 7, 6, 4]\n",
            "10 [0 9 1 5 2 3 8 7 6 4]\n",
            "discarded index [0, 9, 1, 5, 2, 3, 8, 7, 6, 4]\n",
            "10 [0 9 1 5 2 3 8 7 6 4]\n",
            "discarded index [0, 9, 1, 5, 2, 3, 8, 7, 6, 4]\n",
            "10 [0 9 1 5 2 3 8 7 6 4]\n",
            "discarded index [0, 9, 1, 5, 2, 3, 8, 7, 6, 4]\n",
            "10 [0 9 1 5 2 3 8 7 6 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 48, bulyan: at fang n_at 10 e 48 | val loss 2.2172 val acc 16.2135 best val_acc 24.391234\n",
            "discarded index [0, 7, 9, 1, 5, 4, 6, 3, 8, 2]\n",
            "10 [0 7 9 1 5 4 6 3 8 2]\n",
            "discarded index [0, 7, 9, 1, 5, 4, 6, 3, 8, 2]\n",
            "10 [0 7 9 1 5 4 6 3 8 2]\n",
            "discarded index [0, 7, 9, 1, 5, 4, 6, 3, 8, 2]\n",
            "10 [0 7 9 1 5 4 6 3 8 2]\n",
            "discarded index [0, 7, 9, 1, 5, 4, 6, 3, 8, 2]\n",
            "10 [0 7 9 1 5 4 6 3 8 2]\n",
            "discarded index [0, 7, 9, 1, 5, 4, 6, 3, 8, 2]\n",
            "10 [0 7 9 1 5 4 6 3 8 2]\n",
            "discarded index [0, 7, 9, 1, 5, 4, 6, 3, 8, 2]\n",
            "10 [0 7 9 1 5 4 6 3 8 2]\n",
            "discarded index [0, 7, 9, 1, 5, 4, 6, 3, 8, 2]\n",
            "10 [0 7 9 1 5 4 6 3 8 2]\n",
            "discarded index [0, 7, 9, 1, 5, 4, 6, 3, 8, 2]\n",
            "10 [0 7 9 1 5 4 6 3 8 2]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 49, bulyan: at fang n_at 10 e 49 | val loss 2.2469 val acc 15.5235 best val_acc 24.391234\n",
            "discarded index [0, 7, 5, 4, 6, 9, 1, 3, 8, 2]\n",
            "10 [0 7 5 4 6 9 1 3 8 2]\n",
            "discarded index [0, 7, 5, 4, 6, 9, 1, 3, 8, 2]\n",
            "10 [0 7 5 4 6 9 1 3 8 2]\n",
            "discarded index [0, 7, 5, 4, 6, 9, 1, 3, 8, 2]\n",
            "10 [0 7 5 4 6 9 1 3 8 2]\n",
            "discarded index [0, 7, 5, 4, 6, 9, 1, 3, 8, 2]\n",
            "10 [0 7 5 4 6 9 1 3 8 2]\n",
            "discarded index [0, 7, 5, 4, 6, 9, 1, 3, 8, 2]\n",
            "10 [0 7 5 4 6 9 1 3 8 2]\n",
            "discarded index [0, 7, 5, 4, 6, 9, 1, 3, 8, 2]\n",
            "10 [0 7 5 4 6 9 1 3 8 2]\n",
            "discarded index [0, 7, 5, 4, 6, 9, 1, 3, 8, 2]\n",
            "10 [0 7 5 4 6 9 1 3 8 2]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 50, bulyan: at fang n_at 10 e 50 | val loss 2.2082 val acc 16.7005 best val_acc 24.391234\n",
            "discarded index [0, 6, 7, 4, 8, 9, 5, 1, 3, 2]\n",
            "10 [0 6 7 4 8 9 5 1 3 2]\n",
            "discarded index [0, 6, 7, 4, 8, 9, 5, 1, 3, 2]\n",
            "10 [0 6 7 4 8 9 5 1 3 2]\n",
            "discarded index [0, 6, 7, 4, 8, 9, 5, 1, 3, 2]\n",
            "10 [0 6 7 4 8 9 5 1 3 2]\n",
            "discarded index [0, 6, 7, 4, 8, 9, 5, 1, 3, 2]\n",
            "10 [0 6 7 4 8 9 5 1 3 2]\n",
            "discarded index [0, 6, 7, 4, 8, 9, 5, 1, 3, 2]\n",
            "10 [0 6 7 4 8 9 5 1 3 2]\n",
            "discarded index [0, 6, 7, 4, 8, 9, 5, 1, 3, 2]\n",
            "10 [0 6 7 4 8 9 5 1 3 2]\n",
            "discarded index [0, 6, 7, 4, 8, 9, 5, 1, 3, 2]\n",
            "10 [0 6 7 4 8 9 5 1 3 2]\n",
            "discarded index [0, 6, 7, 4, 8, 9, 5, 1, 3, 2]\n",
            "10 [0 6 7 4 8 9 5 1 3 2]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 51, bulyan: at fang n_at 10 e 51 | val loss 2.2367 val acc 15.7265 best val_acc 24.391234\n",
            "discarded index [9, 5, 1, 2, 0, 7, 4, 6, 3, 8]\n",
            "10 [9 5 1 2 0 7 4 6 3 8]\n",
            "discarded index [9, 5, 1, 2, 0, 7, 4, 6, 3, 8]\n",
            "10 [9 5 1 2 0 7 4 6 3 8]\n",
            "discarded index [9, 5, 1, 2, 0, 7, 4, 6, 3, 8]\n",
            "10 [9 5 1 2 0 7 4 6 3 8]\n",
            "discarded index [9, 5, 1, 2, 0, 7, 4, 6, 3, 8]\n",
            "10 [9 5 1 2 0 7 4 6 3 8]\n",
            "discarded index [9, 5, 1, 2, 0, 7, 4, 6, 3, 8]\n",
            "10 [9 5 1 2 0 7 4 6 3 8]\n",
            "discarded index [9, 5, 1, 2, 0, 7, 4, 6, 3, 8]\n",
            "10 [9 5 1 2 0 7 4 6 3 8]\n",
            "discarded index [9, 5, 1, 2, 0, 7, 4, 6, 3, 8]\n",
            "10 [9 5 1 2 0 7 4 6 3 8]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 52, bulyan: at fang n_at 10 e 52 | val loss 2.2004 val acc 16.6193 best val_acc 24.391234\n",
            "discarded index [0, 7, 5, 9, 6, 4, 1, 8, 3, 2]\n",
            "10 [0 7 5 9 6 4 1 8 3 2]\n",
            "discarded index [0, 7, 5, 9, 6, 4, 1, 8, 3, 2]\n",
            "10 [0 7 5 9 6 4 1 8 3 2]\n",
            "discarded index [0, 7, 5, 9, 6, 4, 1, 8, 3, 2]\n",
            "10 [0 7 5 9 6 4 1 8 3 2]\n",
            "discarded index [0, 7, 5, 9, 6, 4, 1, 8, 3, 2]\n",
            "10 [0 7 5 9 6 4 1 8 3 2]\n",
            "discarded index [0, 7, 5, 9, 6, 4, 1, 8, 3, 2]\n",
            "10 [0 7 5 9 6 4 1 8 3 2]\n",
            "discarded index [0, 7, 5, 9, 6, 4, 1, 8, 3, 2]\n",
            "10 [0 7 5 9 6 4 1 8 3 2]\n",
            "discarded index [0, 7, 5, 9, 6, 4, 1, 8, 3, 2]\n",
            "10 [0 7 5 9 6 4 1 8 3 2]\n",
            "discarded index [0, 7, 5, 9, 6, 4, 1, 8, 3, 2]\n",
            "10 [0 7 5 9 6 4 1 8 3 2]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 53, bulyan: at fang n_at 10 e 53 | val loss 2.2343 val acc 15.1380 best val_acc 24.391234\n",
            "discarded index [0, 7, 6, 4, 5, 8, 1, 9, 2, 3]\n",
            "10 [0 7 6 4 5 8 1 9 2 3]\n",
            "discarded index [0, 7, 6, 4, 5, 8, 1, 9, 2, 3]\n",
            "10 [0 7 6 4 5 8 1 9 2 3]\n",
            "discarded index [0, 7, 6, 4, 5, 8, 1, 9, 2, 3]\n",
            "10 [0 7 6 4 5 8 1 9 2 3]\n",
            "discarded index [0, 7, 6, 4, 5, 8, 1, 9, 2, 3]\n",
            "10 [0 7 6 4 5 8 1 9 2 3]\n",
            "discarded index [0, 7, 6, 4, 5, 8, 1, 9, 2, 3]\n",
            "10 [0 7 6 4 5 8 1 9 2 3]\n",
            "discarded index [0, 7, 6, 4, 5, 8, 1, 9, 2, 3]\n",
            "10 [0 7 6 4 5 8 1 9 2 3]\n",
            "discarded index [0, 7, 6, 4, 5, 8, 1, 9, 2, 3]\n",
            "10 [0 7 6 4 5 8 1 9 2 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 54, bulyan: at fang n_at 10 e 54 | val loss 2.1940 val acc 17.2687 best val_acc 24.391234\n",
            "discarded index [0, 7, 6, 4, 8, 9, 1, 5, 2, 3]\n",
            "10 [0 7 6 4 8 9 1 5 2 3]\n",
            "discarded index [0, 7, 6, 4, 8, 9, 1, 5, 2, 3]\n",
            "10 [0 7 6 4 8 9 1 5 2 3]\n",
            "discarded index [0, 7, 6, 4, 8, 9, 1, 5, 2, 3]\n",
            "10 [0 7 6 4 8 9 1 5 2 3]\n",
            "discarded index [0, 7, 6, 4, 8, 9, 1, 5, 2, 3]\n",
            "10 [0 7 6 4 8 9 1 5 2 3]\n",
            "discarded index [0, 7, 6, 4, 8, 9, 1, 5, 2, 3]\n",
            "10 [0 7 6 4 8 9 1 5 2 3]\n",
            "discarded index [0, 7, 6, 4, 8, 9, 1, 5, 2, 3]\n",
            "10 [0 7 6 4 8 9 1 5 2 3]\n",
            "discarded index [0, 7, 6, 4, 8, 9, 1, 5, 2, 3]\n",
            "10 [0 7 6 4 8 9 1 5 2 3]\n",
            "discarded index [0, 7, 6, 4, 8, 9, 1, 5, 2, 3]\n",
            "10 [0 7 6 4 8 9 1 5 2 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 55, bulyan: at fang n_at 10 e 55 | val loss 2.2309 val acc 15.2800 best val_acc 24.391234\n",
            "discarded index [0, 7, 5, 9, 4, 6, 3, 2, 1, 8]\n",
            "10 [0 7 5 9 4 6 3 2 1 8]\n",
            "discarded index [0, 7, 5, 9, 4, 6, 3, 2, 1, 8]\n",
            "10 [0 7 5 9 4 6 3 2 1 8]\n",
            "discarded index [0, 7, 5, 9, 4, 6, 3, 2, 1, 8]\n",
            "10 [0 7 5 9 4 6 3 2 1 8]\n",
            "discarded index [0, 7, 5, 9, 4, 6, 3, 2, 1, 8]\n",
            "10 [0 7 5 9 4 6 3 2 1 8]\n",
            "discarded index [0, 7, 5, 9, 4, 6, 3, 2, 1, 8]\n",
            "10 [0 7 5 9 4 6 3 2 1 8]\n",
            "discarded index [0, 7, 5, 9, 4, 6, 3, 2, 1, 8]\n",
            "10 [0 7 5 9 4 6 3 2 1 8]\n",
            "discarded index [0, 7, 5, 9, 4, 6, 3, 2, 1, 8]\n",
            "10 [0 7 5 9 4 6 3 2 1 8]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 56, bulyan: at fang n_at 10 e 56 | val loss 2.1806 val acc 17.5731 best val_acc 24.391234\n",
            "discarded index [0, 6, 5, 7, 9, 4, 1, 8, 2, 3]\n",
            "10 [0 6 5 7 9 4 1 8 2 3]\n",
            "discarded index [0, 6, 5, 7, 9, 4, 1, 8, 2, 3]\n",
            "10 [0 6 5 7 9 4 1 8 2 3]\n",
            "discarded index [0, 6, 5, 7, 9, 4, 1, 8, 2, 3]\n",
            "10 [0 6 5 7 9 4 1 8 2 3]\n",
            "discarded index [0, 6, 5, 7, 9, 4, 1, 8, 2, 3]\n",
            "10 [0 6 5 7 9 4 1 8 2 3]\n",
            "discarded index [0, 6, 5, 7, 9, 4, 1, 8, 2, 3]\n",
            "10 [0 6 5 7 9 4 1 8 2 3]\n",
            "discarded index [0, 6, 5, 7, 9, 4, 1, 8, 2, 3]\n",
            "10 [0 6 5 7 9 4 1 8 2 3]\n",
            "discarded index [0, 6, 5, 7, 9, 4, 1, 8, 2, 3]\n",
            "10 [0 6 5 7 9 4 1 8 2 3]\n",
            "discarded index [0, 6, 5, 7, 9, 4, 1, 8, 2, 3]\n",
            "10 [0 6 5 7 9 4 1 8 2 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 57, bulyan: at fang n_at 10 e 57 | val loss 2.1863 val acc 17.9180 best val_acc 24.391234\n",
            "discarded index [1, 9, 5, 2, 0, 7, 3, 8, 4, 6]\n",
            "10 [1 9 5 2 0 7 3 8 4 6]\n",
            "discarded index [1, 9, 5, 2, 0, 7, 3, 8, 4, 6]\n",
            "10 [1 9 5 2 0 7 3 8 4 6]\n",
            "discarded index [1, 9, 5, 2, 0, 7, 3, 8, 4, 6]\n",
            "10 [1 9 5 2 0 7 3 8 4 6]\n",
            "discarded index [1, 9, 5, 2, 0, 7, 3, 8, 4, 6]\n",
            "10 [1 9 5 2 0 7 3 8 4 6]\n",
            "discarded index [1, 9, 5, 2, 0, 7, 3, 8, 4, 6]\n",
            "10 [1 9 5 2 0 7 3 8 4 6]\n",
            "discarded index [1, 9, 5, 2, 0, 7, 3, 8, 4, 6]\n",
            "10 [1 9 5 2 0 7 3 8 4 6]\n",
            "discarded index [1, 9, 5, 2, 0, 7, 3, 8, 4, 6]\n",
            "10 [1 9 5 2 0 7 3 8 4 6]\n",
            "discarded index [1, 9, 5, 2, 0, 7, 3, 8, 4, 6]\n",
            "10 [1 9 5 2 0 7 3 8 4 6]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 58, bulyan: at fang n_at 10 e 58 | val loss 2.2017 val acc 17.8774 best val_acc 24.391234\n",
            "discarded index [0, 7, 6, 9, 5, 1, 3, 2, 8, 4]\n",
            "10 [0 7 6 9 5 1 3 2 8 4]\n",
            "discarded index [0, 7, 6, 9, 5, 1, 3, 2, 8, 4]\n",
            "10 [0 7 6 9 5 1 3 2 8 4]\n",
            "discarded index [0, 7, 6, 9, 5, 1, 3, 2, 8, 4]\n",
            "10 [0 7 6 9 5 1 3 2 8 4]\n",
            "discarded index [0, 7, 6, 9, 5, 1, 3, 2, 8, 4]\n",
            "10 [0 7 6 9 5 1 3 2 8 4]\n",
            "discarded index [0, 7, 6, 9, 5, 1, 3, 2, 8, 4]\n",
            "10 [0 7 6 9 5 1 3 2 8 4]\n",
            "discarded index [0, 7, 6, 9, 5, 1, 3, 2, 8, 4]\n",
            "10 [0 7 6 9 5 1 3 2 8 4]\n",
            "discarded index [0, 7, 6, 9, 5, 1, 3, 2, 8, 4]\n",
            "10 [0 7 6 9 5 1 3 2 8 4]\n",
            "discarded index [0, 7, 6, 9, 5, 1, 3, 2, 8, 4]\n",
            "10 [0 7 6 9 5 1 3 2 8 4]\n",
            "discarded index [0, 7, 6, 9, 5, 1, 3, 2, 8, 4]\n",
            "10 [0 7 6 9 5 1 3 2 8 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 59, bulyan: at fang n_at 10 e 59 | val loss 2.2819 val acc 11.6883 best val_acc 24.391234\n",
            "discarded index [5, 3, 0, 7, 4, 1, 2, 6, 9, 8]\n",
            "10 [5 3 0 7 4 1 2 6 9 8]\n",
            "discarded index [5, 3, 0, 7, 4, 1, 2, 6, 9, 8]\n",
            "10 [5 3 0 7 4 1 2 6 9 8]\n",
            "discarded index [5, 3, 0, 7, 4, 1, 2, 6, 9, 8]\n",
            "10 [5 3 0 7 4 1 2 6 9 8]\n",
            "discarded index [5, 3, 0, 7, 4, 1, 2, 6, 9, 8]\n",
            "10 [5 3 0 7 4 1 2 6 9 8]\n",
            "discarded index [5, 3, 0, 7, 4, 1, 2, 6, 9, 8]\n",
            "10 [5 3 0 7 4 1 2 6 9 8]\n",
            "discarded index [5, 3, 0, 7, 4, 1, 2, 6, 9, 8]\n",
            "10 [5 3 0 7 4 1 2 6 9 8]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 60, bulyan: at fang n_at 10 e 60 | val loss 2.2353 val acc 14.5292 best val_acc 24.391234\n",
            "discarded index [5, 0, 4, 7, 3, 9, 8, 1, 2, 6]\n",
            "10 [5 0 4 7 3 9 8 1 2 6]\n",
            "discarded index [5, 0, 4, 7, 3, 9, 8, 1, 2, 6]\n",
            "10 [5 0 4 7 3 9 8 1 2 6]\n",
            "discarded index [5, 0, 4, 7, 3, 9, 8, 1, 2, 6]\n",
            "10 [5 0 4 7 3 9 8 1 2 6]\n",
            "discarded index [5, 0, 4, 7, 3, 9, 8, 1, 2, 6]\n",
            "10 [5 0 4 7 3 9 8 1 2 6]\n",
            "discarded index [5, 0, 4, 7, 3, 9, 8, 1, 2, 6]\n",
            "10 [5 0 4 7 3 9 8 1 2 6]\n",
            "discarded index [5, 0, 4, 7, 3, 9, 8, 1, 2, 6]\n",
            "10 [5 0 4 7 3 9 8 1 2 6]\n",
            "discarded index [5, 0, 4, 7, 3, 9, 8, 1, 2, 6]\n",
            "10 [5 0 4 7 3 9 8 1 2 6]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 61, bulyan: at fang n_at 10 e 61 | val loss 2.1737 val acc 15.6453 best val_acc 24.391234\n",
            "discarded index [0, 5, 3, 9, 1, 8, 2, 6, 4, 7]\n",
            "10 [0 5 3 9 1 8 2 6 4 7]\n",
            "discarded index [0, 5, 3, 9, 1, 8, 2, 6, 4, 7]\n",
            "10 [0 5 3 9 1 8 2 6 4 7]\n",
            "discarded index [0, 5, 3, 9, 1, 8, 2, 6, 4, 7]\n",
            "10 [0 5 3 9 1 8 2 6 4 7]\n",
            "discarded index [0, 5, 3, 9, 1, 8, 2, 6, 4, 7]\n",
            "10 [0 5 3 9 1 8 2 6 4 7]\n",
            "discarded index [0, 5, 3, 9, 1, 8, 2, 6, 4, 7]\n",
            "10 [0 5 3 9 1 8 2 6 4 7]\n",
            "discarded index [0, 5, 3, 9, 1, 8, 2, 6, 4, 7]\n",
            "10 [0 5 3 9 1 8 2 6 4 7]\n",
            "discarded index [0, 5, 3, 9, 1, 8, 2, 6, 4, 7]\n",
            "10 [0 5 3 9 1 8 2 6 4 7]\n",
            "discarded index [0, 5, 3, 9, 1, 8, 2, 6, 4, 7]\n",
            "10 [0 5 3 9 1 8 2 6 4 7]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 62, bulyan: at fang n_at 10 e 62 | val loss 2.1615 val acc 16.9034 best val_acc 24.391234\n",
            "discarded index [0, 6, 7, 8, 4, 5, 9, 3, 1, 2]\n",
            "10 [0 6 7 8 4 5 9 3 1 2]\n",
            "discarded index [0, 6, 7, 8, 4, 5, 9, 3, 1, 2]\n",
            "10 [0 6 7 8 4 5 9 3 1 2]\n",
            "discarded index [0, 6, 7, 8, 4, 5, 9, 3, 1, 2]\n",
            "10 [0 6 7 8 4 5 9 3 1 2]\n",
            "discarded index [0, 6, 7, 8, 4, 5, 9, 3, 1, 2]\n",
            "10 [0 6 7 8 4 5 9 3 1 2]\n",
            "discarded index [0, 6, 7, 8, 4, 5, 9, 3, 1, 2]\n",
            "10 [0 6 7 8 4 5 9 3 1 2]\n",
            "discarded index [0, 6, 7, 8, 4, 5, 9, 3, 1, 2]\n",
            "10 [0 6 7 8 4 5 9 3 1 2]\n",
            "discarded index [0, 6, 7, 8, 4, 5, 9, 3, 1, 2]\n",
            "10 [0 6 7 8 4 5 9 3 1 2]\n",
            "discarded index [0, 6, 7, 8, 4, 5, 9, 3, 1, 2]\n",
            "10 [0 6 7 8 4 5 9 3 1 2]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 63, bulyan: at fang n_at 10 e 63 | val loss 2.1587 val acc 17.9383 best val_acc 24.391234\n",
            "discarded index [9, 5, 1, 0, 2, 8, 3, 6, 7, 4]\n",
            "10 [9 5 1 0 2 8 3 6 7 4]\n",
            "discarded index [9, 5, 1, 0, 2, 8, 3, 6, 7, 4]\n",
            "10 [9 5 1 0 2 8 3 6 7 4]\n",
            "discarded index [9, 5, 1, 0, 2, 8, 3, 6, 7, 4]\n",
            "10 [9 5 1 0 2 8 3 6 7 4]\n",
            "discarded index [9, 5, 1, 0, 2, 8, 3, 6, 7, 4]\n",
            "10 [9 5 1 0 2 8 3 6 7 4]\n",
            "discarded index [9, 5, 1, 0, 2, 8, 3, 6, 7, 4]\n",
            "10 [9 5 1 0 2 8 3 6 7 4]\n",
            "discarded index [9, 5, 1, 0, 2, 8, 3, 6, 7, 4]\n",
            "10 [9 5 1 0 2 8 3 6 7 4]\n",
            "discarded index [9, 5, 1, 0, 2, 8, 3, 6, 7, 4]\n",
            "10 [9 5 1 0 2 8 3 6 7 4]\n",
            "discarded index [9, 5, 1, 0, 2, 8, 3, 6, 7, 4]\n",
            "10 [9 5 1 0 2 8 3 6 7 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 64, bulyan: at fang n_at 10 e 64 | val loss 2.1588 val acc 18.7500 best val_acc 24.391234\n",
            "discarded index [0, 7, 5, 6, 9, 1, 4, 8, 2, 3]\n",
            "10 [0 7 5 6 9 1 4 8 2 3]\n",
            "discarded index [0, 7, 5, 6, 9, 1, 4, 8, 2, 3]\n",
            "10 [0 7 5 6 9 1 4 8 2 3]\n",
            "discarded index [0, 7, 5, 6, 9, 1, 4, 8, 2, 3]\n",
            "10 [0 7 5 6 9 1 4 8 2 3]\n",
            "discarded index [0, 7, 5, 6, 9, 1, 4, 8, 2, 3]\n",
            "10 [0 7 5 6 9 1 4 8 2 3]\n",
            "discarded index [0, 7, 5, 6, 9, 1, 4, 8, 2, 3]\n",
            "10 [0 7 5 6 9 1 4 8 2 3]\n",
            "discarded index [0, 7, 5, 6, 9, 1, 4, 8, 2, 3]\n",
            "10 [0 7 5 6 9 1 4 8 2 3]\n",
            "discarded index [0, 7, 5, 6, 9, 1, 4, 8, 2, 3]\n",
            "10 [0 7 5 6 9 1 4 8 2 3]\n",
            "discarded index [0, 7, 5, 6, 9, 1, 4, 8, 2, 3]\n",
            "10 [0 7 5 6 9 1 4 8 2 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 65, bulyan: at fang n_at 10 e 65 | val loss 2.2117 val acc 14.9148 best val_acc 24.391234\n",
            "discarded index [0, 5, 7, 4, 6, 9, 1, 3, 8, 2]\n",
            "10 [0 5 7 4 6 9 1 3 8 2]\n",
            "discarded index [0, 5, 7, 4, 6, 9, 1, 3, 8, 2]\n",
            "10 [0 5 7 4 6 9 1 3 8 2]\n",
            "discarded index [0, 5, 7, 4, 6, 9, 1, 3, 8, 2]\n",
            "10 [0 5 7 4 6 9 1 3 8 2]\n",
            "discarded index [0, 5, 7, 4, 6, 9, 1, 3, 8, 2]\n",
            "10 [0 5 7 4 6 9 1 3 8 2]\n",
            "discarded index [0, 5, 7, 4, 6, 9, 1, 3, 8, 2]\n",
            "10 [0 5 7 4 6 9 1 3 8 2]\n",
            "discarded index [0, 5, 7, 4, 6, 9, 1, 3, 8, 2]\n",
            "10 [0 5 7 4 6 9 1 3 8 2]\n",
            "discarded index [0, 5, 7, 4, 6, 9, 1, 3, 8, 2]\n",
            "10 [0 5 7 4 6 9 1 3 8 2]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 66, bulyan: at fang n_at 10 e 66 | val loss 2.1631 val acc 17.5731 best val_acc 24.391234\n",
            "discarded index [5, 0, 9, 1, 2, 3, 7, 6, 8, 4]\n",
            "10 [5 0 9 1 2 3 7 6 8 4]\n",
            "discarded index [5, 0, 9, 1, 2, 3, 7, 6, 8, 4]\n",
            "10 [5 0 9 1 2 3 7 6 8 4]\n",
            "discarded index [5, 0, 9, 1, 2, 3, 7, 6, 8, 4]\n",
            "10 [5 0 9 1 2 3 7 6 8 4]\n",
            "discarded index [5, 0, 9, 1, 2, 3, 7, 6, 8, 4]\n",
            "10 [5 0 9 1 2 3 7 6 8 4]\n",
            "discarded index [5, 0, 9, 1, 2, 3, 7, 6, 8, 4]\n",
            "10 [5 0 9 1 2 3 7 6 8 4]\n",
            "discarded index [5, 0, 9, 1, 2, 3, 7, 6, 8, 4]\n",
            "10 [5 0 9 1 2 3 7 6 8 4]\n",
            "discarded index [5, 0, 9, 1, 2, 3, 7, 6, 8, 4]\n",
            "10 [5 0 9 1 2 3 7 6 8 4]\n",
            "discarded index [5, 0, 9, 1, 2, 3, 7, 6, 8, 4]\n",
            "10 [5 0 9 1 2 3 7 6 8 4]\n",
            "discarded index [5, 0, 9, 1, 2, 3, 7, 6, 8, 4]\n",
            "10 [5 0 9 1 2 3 7 6 8 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 67, bulyan: at fang n_at 10 e 67 | val loss 2.2403 val acc 12.6015 best val_acc 24.391234\n",
            "discarded index [0, 7, 5, 3, 9, 8, 2, 1, 4, 6]\n",
            "10 [0 7 5 3 9 8 2 1 4 6]\n",
            "discarded index [0, 7, 5, 3, 9, 8, 2, 1, 4, 6]\n",
            "10 [0 7 5 3 9 8 2 1 4 6]\n",
            "discarded index [0, 7, 5, 3, 9, 8, 2, 1, 4, 6]\n",
            "10 [0 7 5 3 9 8 2 1 4 6]\n",
            "discarded index [0, 7, 5, 3, 9, 8, 2, 1, 4, 6]\n",
            "10 [0 7 5 3 9 8 2 1 4 6]\n",
            "discarded index [0, 7, 5, 3, 9, 8, 2, 1, 4, 6]\n",
            "10 [0 7 5 3 9 8 2 1 4 6]\n",
            "discarded index [0, 7, 5, 3, 9, 8, 2, 1, 4, 6]\n",
            "10 [0 7 5 3 9 8 2 1 4 6]\n",
            "discarded index [0, 7, 5, 3, 9, 8, 2, 1, 4, 6]\n",
            "10 [0 7 5 3 9 8 2 1 4 6]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 68, bulyan: at fang n_at 10 e 68 | val loss 2.1437 val acc 17.3093 best val_acc 24.391234\n",
            "discarded index [0, 6, 7, 5, 4, 3, 9, 8, 2, 1]\n",
            "10 [0 6 7 5 4 3 9 8 2 1]\n",
            "discarded index [0, 6, 7, 5, 4, 3, 9, 8, 2, 1]\n",
            "10 [0 6 7 5 4 3 9 8 2 1]\n",
            "discarded index [0, 6, 7, 5, 4, 3, 9, 8, 2, 1]\n",
            "10 [0 6 7 5 4 3 9 8 2 1]\n",
            "discarded index [0, 6, 7, 5, 4, 3, 9, 8, 2, 1]\n",
            "10 [0 6 7 5 4 3 9 8 2 1]\n",
            "discarded index [0, 6, 7, 5, 4, 3, 9, 8, 2, 1]\n",
            "10 [0 6 7 5 4 3 9 8 2 1]\n",
            "discarded index [0, 6, 7, 5, 4, 3, 9, 8, 2, 1]\n",
            "10 [0 6 7 5 4 3 9 8 2 1]\n",
            "discarded index [0, 6, 7, 5, 4, 3, 9, 8, 2, 1]\n",
            "10 [0 6 7 5 4 3 9 8 2 1]\n",
            "discarded index [0, 6, 7, 5, 4, 3, 9, 8, 2, 1]\n",
            "10 [0 6 7 5 4 3 9 8 2 1]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 69, bulyan: at fang n_at 10 e 69 | val loss 2.1446 val acc 17.9789 best val_acc 24.391234\n",
            "discarded index [1, 9, 5, 0, 4, 7, 3, 6, 2, 8]\n",
            "10 [1 9 5 0 4 7 3 6 2 8]\n",
            "discarded index [1, 9, 5, 0, 4, 7, 3, 6, 2, 8]\n",
            "10 [1 9 5 0 4 7 3 6 2 8]\n",
            "discarded index [1, 9, 5, 0, 4, 7, 3, 6, 2, 8]\n",
            "10 [1 9 5 0 4 7 3 6 2 8]\n",
            "discarded index [1, 9, 5, 0, 4, 7, 3, 6, 2, 8]\n",
            "10 [1 9 5 0 4 7 3 6 2 8]\n",
            "discarded index [1, 9, 5, 0, 4, 7, 3, 6, 2, 8]\n",
            "10 [1 9 5 0 4 7 3 6 2 8]\n",
            "discarded index [1, 9, 5, 0, 4, 7, 3, 6, 2, 8]\n",
            "10 [1 9 5 0 4 7 3 6 2 8]\n",
            "discarded index [1, 9, 5, 0, 4, 7, 3, 6, 2, 8]\n",
            "10 [1 9 5 0 4 7 3 6 2 8]\n",
            "discarded index [1, 9, 5, 0, 4, 7, 3, 6, 2, 8]\n",
            "10 [1 9 5 0 4 7 3 6 2 8]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 70, bulyan: at fang n_at 10 e 70 | val loss 2.1668 val acc 16.6193 best val_acc 24.391234\n",
            "discarded index [0, 3, 5, 2, 4, 7, 9, 8, 6, 1]\n",
            "10 [0 3 5 2 4 7 9 8 6 1]\n",
            "discarded index [0, 3, 5, 2, 4, 7, 9, 8, 6, 1]\n",
            "10 [0 3 5 2 4 7 9 8 6 1]\n",
            "discarded index [0, 3, 5, 2, 4, 7, 9, 8, 6, 1]\n",
            "10 [0 3 5 2 4 7 9 8 6 1]\n",
            "discarded index [0, 3, 5, 2, 4, 7, 9, 8, 6, 1]\n",
            "10 [0 3 5 2 4 7 9 8 6 1]\n",
            "discarded index [0, 3, 5, 2, 4, 7, 9, 8, 6, 1]\n",
            "10 [0 3 5 2 4 7 9 8 6 1]\n",
            "discarded index [0, 3, 5, 2, 4, 7, 9, 8, 6, 1]\n",
            "10 [0 3 5 2 4 7 9 8 6 1]\n",
            "discarded index [0, 3, 5, 2, 4, 7, 9, 8, 6, 1]\n",
            "10 [0 3 5 2 4 7 9 8 6 1]\n",
            "discarded index [0, 3, 5, 2, 4, 7, 9, 8, 6, 1]\n",
            "10 [0 3 5 2 4 7 9 8 6 1]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 71, bulyan: at fang n_at 10 e 71 | val loss 2.1327 val acc 19.5820 best val_acc 24.391234\n",
            "discarded index [5, 0, 6, 9, 7, 1, 2, 4, 3, 8]\n",
            "10 [5 0 6 9 7 1 2 4 3 8]\n",
            "discarded index [5, 0, 6, 9, 7, 1, 2, 4, 3, 8]\n",
            "10 [5 0 6 9 7 1 2 4 3 8]\n",
            "discarded index [5, 0, 6, 9, 7, 1, 2, 4, 3, 8]\n",
            "10 [5 0 6 9 7 1 2 4 3 8]\n",
            "discarded index [5, 0, 6, 9, 7, 1, 2, 4, 3, 8]\n",
            "10 [5 0 6 9 7 1 2 4 3 8]\n",
            "discarded index [5, 0, 6, 9, 7, 1, 2, 4, 3, 8]\n",
            "10 [5 0 6 9 7 1 2 4 3 8]\n",
            "discarded index [5, 0, 6, 9, 7, 1, 2, 4, 3, 8]\n",
            "10 [5 0 6 9 7 1 2 4 3 8]\n",
            "discarded index [5, 0, 6, 9, 7, 1, 2, 4, 3, 8]\n",
            "10 [5 0 6 9 7 1 2 4 3 8]\n",
            "discarded index [5, 0, 6, 9, 7, 1, 2, 4, 3, 8]\n",
            "10 [5 0 6 9 7 1 2 4 3 8]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 72, bulyan: at fang n_at 10 e 72 | val loss 2.1818 val acc 15.4424 best val_acc 24.391234\n",
            "discarded index [0, 9, 5, 7, 4, 6, 3, 2, 1, 8]\n",
            "10 [0 9 5 7 4 6 3 2 1 8]\n",
            "discarded index [0, 9, 5, 7, 4, 6, 3, 2, 1, 8]\n",
            "10 [0 9 5 7 4 6 3 2 1 8]\n",
            "discarded index [0, 9, 5, 7, 4, 6, 3, 2, 1, 8]\n",
            "10 [0 9 5 7 4 6 3 2 1 8]\n",
            "discarded index [0, 9, 5, 7, 4, 6, 3, 2, 1, 8]\n",
            "10 [0 9 5 7 4 6 3 2 1 8]\n",
            "discarded index [0, 9, 5, 7, 4, 6, 3, 2, 1, 8]\n",
            "10 [0 9 5 7 4 6 3 2 1 8]\n",
            "discarded index [0, 9, 5, 7, 4, 6, 3, 2, 1, 8]\n",
            "10 [0 9 5 7 4 6 3 2 1 8]\n",
            "discarded index [0, 9, 5, 7, 4, 6, 3, 2, 1, 8]\n",
            "10 [0 9 5 7 4 6 3 2 1 8]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 73, bulyan: at fang n_at 10 e 73 | val loss 2.2001 val acc 18.8718 best val_acc 24.391234\n",
            "discarded index [5, 0, 6, 7, 1, 9, 2, 3, 4, 8]\n",
            "10 [5 0 6 7 1 9 2 3 4 8]\n",
            "discarded index [5, 0, 6, 7, 1, 9, 2, 3, 4, 8]\n",
            "10 [5 0 6 7 1 9 2 3 4 8]\n",
            "discarded index [5, 0, 6, 7, 1, 9, 2, 3, 4, 8]\n",
            "10 [5 0 6 7 1 9 2 3 4 8]\n",
            "discarded index [5, 0, 6, 7, 1, 9, 2, 3, 4, 8]\n",
            "10 [5 0 6 7 1 9 2 3 4 8]\n",
            "discarded index [5, 0, 6, 7, 1, 9, 2, 3, 4, 8]\n",
            "10 [5 0 6 7 1 9 2 3 4 8]\n",
            "discarded index [5, 0, 6, 7, 1, 9, 2, 3, 4, 8]\n",
            "10 [5 0 6 7 1 9 2 3 4 8]\n",
            "discarded index [5, 0, 6, 7, 1, 9, 2, 3, 4, 8]\n",
            "10 [5 0 6 7 1 9 2 3 4 8]\n",
            "discarded index [5, 0, 6, 7, 1, 9, 2, 3, 4, 8]\n",
            "10 [5 0 6 7 1 9 2 3 4 8]\n",
            "discarded index [5, 0, 6, 7, 1, 9, 2, 3, 4, 8]\n",
            "10 [5 0 6 7 1 9 2 3 4 8]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 74, bulyan: at fang n_at 10 e 74 | val loss 2.3280 val acc 9.7403 best val_acc 24.391234\n",
            "discarded index [0, 7, 1, 3, 2, 4, 6, 9, 5, 8]\n",
            "10 [0 7 1 3 2 4 6 9 5 8]\n",
            "discarded index [0, 7, 1, 3, 2, 4, 6, 9, 5, 8]\n",
            "10 [0 7 1 3 2 4 6 9 5 8]\n",
            "discarded index [0, 7, 1, 3, 2, 4, 6, 9, 5, 8]\n",
            "10 [0 7 1 3 2 4 6 9 5 8]\n",
            "discarded index [0, 7, 1, 3, 2, 4, 6, 9, 5, 8]\n",
            "10 [0 7 1 3 2 4 6 9 5 8]\n",
            "discarded index [0, 7, 1, 3, 2, 4, 6, 9, 5, 8]\n",
            "10 [0 7 1 3 2 4 6 9 5 8]\n",
            "discarded index [0, 7, 1, 3, 2, 4, 6, 9, 5, 8]\n",
            "10 [0 7 1 3 2 4 6 9 5 8]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 75, bulyan: at fang n_at 10 e 75 | val loss 2.3071 val acc 10.1258 best val_acc 24.391234\n",
            "discarded index [0, 1, 4, 7, 2, 6, 5, 3, 9, 8]\n",
            "10 [0 1 4 7 2 6 5 3 9 8]\n",
            "discarded index [0, 1, 4, 7, 2, 6, 5, 3, 9, 8]\n",
            "10 [0 1 4 7 2 6 5 3 9 8]\n",
            "discarded index [0, 1, 4, 7, 2, 6, 5, 3, 9, 8]\n",
            "10 [0 1 4 7 2 6 5 3 9 8]\n",
            "discarded index [0, 1, 4, 7, 2, 6, 5, 3, 9, 8]\n",
            "10 [0 1 4 7 2 6 5 3 9 8]\n",
            "discarded index [0, 1, 4, 7, 2, 6, 5, 3, 9, 8]\n",
            "10 [0 1 4 7 2 6 5 3 9 8]\n",
            "discarded index [0, 1, 4, 7, 2, 6, 5, 3, 9, 8]\n",
            "10 [0 1 4 7 2 6 5 3 9 8]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 76, bulyan: at fang n_at 10 e 76 | val loss 2.2664 val acc 11.8912 best val_acc 24.391234\n",
            "discarded index [0, 1, 7, 4, 2, 6, 9, 5, 3, 8]\n",
            "10 [0 1 7 4 2 6 9 5 3 8]\n",
            "discarded index [0, 1, 7, 4, 2, 6, 9, 5, 3, 8]\n",
            "10 [0 1 7 4 2 6 9 5 3 8]\n",
            "discarded index [0, 1, 7, 4, 2, 6, 9, 5, 3, 8]\n",
            "10 [0 1 7 4 2 6 9 5 3 8]\n",
            "discarded index [0, 1, 7, 4, 2, 6, 9, 5, 3, 8]\n",
            "10 [0 1 7 4 2 6 9 5 3 8]\n",
            "discarded index [0, 1, 7, 4, 2, 6, 9, 5, 3, 8]\n",
            "10 [0 1 7 4 2 6 9 5 3 8]\n",
            "discarded index [0, 1, 7, 4, 2, 6, 9, 5, 3, 8]\n",
            "10 [0 1 7 4 2 6 9 5 3 8]\n",
            "discarded index [0, 1, 7, 4, 2, 6, 9, 5, 3, 8]\n",
            "10 [0 1 7 4 2 6 9 5 3 8]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 77, bulyan: at fang n_at 10 e 77 | val loss 2.2019 val acc 14.4683 best val_acc 24.391234\n",
            "discarded index [5, 0, 7, 4, 1, 6, 3, 2, 8, 9]\n",
            "10 [5 0 7 4 1 6 3 2 8 9]\n",
            "discarded index [5, 0, 7, 4, 1, 6, 3, 2, 8, 9]\n",
            "10 [5 0 7 4 1 6 3 2 8 9]\n",
            "discarded index [5, 0, 7, 4, 1, 6, 3, 2, 8, 9]\n",
            "10 [5 0 7 4 1 6 3 2 8 9]\n",
            "discarded index [5, 0, 7, 4, 1, 6, 3, 2, 8, 9]\n",
            "10 [5 0 7 4 1 6 3 2 8 9]\n",
            "discarded index [5, 0, 7, 4, 1, 6, 3, 2, 8, 9]\n",
            "10 [5 0 7 4 1 6 3 2 8 9]\n",
            "discarded index [5, 0, 7, 4, 1, 6, 3, 2, 8, 9]\n",
            "10 [5 0 7 4 1 6 3 2 8 9]\n",
            "discarded index [5, 0, 7, 4, 1, 6, 3, 2, 8, 9]\n",
            "10 [5 0 7 4 1 6 3 2 8 9]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 78, bulyan: at fang n_at 10 e 78 | val loss 2.1315 val acc 18.3847 best val_acc 24.391234\n",
            "discarded index [0, 5, 7, 3, 9, 2, 1, 6, 4, 8]\n",
            "10 [0 5 7 3 9 2 1 6 4 8]\n",
            "discarded index [0, 5, 7, 3, 9, 2, 1, 6, 4, 8]\n",
            "10 [0 5 7 3 9 2 1 6 4 8]\n",
            "discarded index [0, 5, 7, 3, 9, 2, 1, 6, 4, 8]\n",
            "10 [0 5 7 3 9 2 1 6 4 8]\n",
            "discarded index [0, 5, 7, 3, 9, 2, 1, 6, 4, 8]\n",
            "10 [0 5 7 3 9 2 1 6 4 8]\n",
            "discarded index [0, 5, 7, 3, 9, 2, 1, 6, 4, 8]\n",
            "10 [0 5 7 3 9 2 1 6 4 8]\n",
            "discarded index [0, 5, 7, 3, 9, 2, 1, 6, 4, 8]\n",
            "10 [0 5 7 3 9 2 1 6 4 8]\n",
            "discarded index [0, 5, 7, 3, 9, 2, 1, 6, 4, 8]\n",
            "10 [0 5 7 3 9 2 1 6 4 8]\n",
            "discarded index [0, 5, 7, 3, 9, 2, 1, 6, 4, 8]\n",
            "10 [0 5 7 3 9 2 1 6 4 8]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 79, bulyan: at fang n_at 10 e 79 | val loss 2.1197 val acc 18.2224 best val_acc 24.391234\n",
            "discarded index [0, 9, 5, 7, 1, 8, 2, 4, 6, 3]\n",
            "10 [0 9 5 7 1 8 2 4 6 3]\n",
            "discarded index [0, 9, 5, 7, 1, 8, 2, 4, 6, 3]\n",
            "10 [0 9 5 7 1 8 2 4 6 3]\n",
            "discarded index [0, 9, 5, 7, 1, 8, 2, 4, 6, 3]\n",
            "10 [0 9 5 7 1 8 2 4 6 3]\n",
            "discarded index [0, 9, 5, 7, 1, 8, 2, 4, 6, 3]\n",
            "10 [0 9 5 7 1 8 2 4 6 3]\n",
            "discarded index [0, 9, 5, 7, 1, 8, 2, 4, 6, 3]\n",
            "10 [0 9 5 7 1 8 2 4 6 3]\n",
            "discarded index [0, 9, 5, 7, 1, 8, 2, 4, 6, 3]\n",
            "10 [0 9 5 7 1 8 2 4 6 3]\n",
            "discarded index [0, 9, 5, 7, 1, 8, 2, 4, 6, 3]\n",
            "10 [0 9 5 7 1 8 2 4 6 3]\n",
            "discarded index [0, 9, 5, 7, 1, 8, 2, 4, 6, 3]\n",
            "10 [0 9 5 7 1 8 2 4 6 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 80, bulyan: at fang n_at 10 e 80 | val loss 2.1376 val acc 17.2281 best val_acc 24.391234\n",
            "discarded index [5, 0, 7, 6, 1, 9, 3, 8, 2, 4]\n",
            "10 [5 0 7 6 1 9 3 8 2 4]\n",
            "discarded index [5, 0, 7, 6, 1, 9, 3, 8, 2, 4]\n",
            "10 [5 0 7 6 1 9 3 8 2 4]\n",
            "discarded index [5, 0, 7, 6, 1, 9, 3, 8, 2, 4]\n",
            "10 [5 0 7 6 1 9 3 8 2 4]\n",
            "discarded index [5, 0, 7, 6, 1, 9, 3, 8, 2, 4]\n",
            "10 [5 0 7 6 1 9 3 8 2 4]\n",
            "discarded index [5, 0, 7, 6, 1, 9, 3, 8, 2, 4]\n",
            "10 [5 0 7 6 1 9 3 8 2 4]\n",
            "discarded index [5, 0, 7, 6, 1, 9, 3, 8, 2, 4]\n",
            "10 [5 0 7 6 1 9 3 8 2 4]\n",
            "discarded index [5, 0, 7, 6, 1, 9, 3, 8, 2, 4]\n",
            "10 [5 0 7 6 1 9 3 8 2 4]\n",
            "discarded index [5, 0, 7, 6, 1, 9, 3, 8, 2, 4]\n",
            "10 [5 0 7 6 1 9 3 8 2 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 81, bulyan: at fang n_at 10 e 81 | val loss 2.1409 val acc 18.5674 best val_acc 24.391234\n",
            "discarded index [5, 1, 0, 9, 2, 7, 3, 8, 6, 4]\n",
            "10 [5 1 0 9 2 7 3 8 6 4]\n",
            "discarded index [5, 1, 0, 9, 2, 7, 3, 8, 6, 4]\n",
            "10 [5 1 0 9 2 7 3 8 6 4]\n",
            "discarded index [5, 1, 0, 9, 2, 7, 3, 8, 6, 4]\n",
            "10 [5 1 0 9 2 7 3 8 6 4]\n",
            "discarded index [5, 1, 0, 9, 2, 7, 3, 8, 6, 4]\n",
            "10 [5 1 0 9 2 7 3 8 6 4]\n",
            "discarded index [5, 1, 0, 9, 2, 7, 3, 8, 6, 4]\n",
            "10 [5 1 0 9 2 7 3 8 6 4]\n",
            "discarded index [5, 1, 0, 9, 2, 7, 3, 8, 6, 4]\n",
            "10 [5 1 0 9 2 7 3 8 6 4]\n",
            "discarded index [5, 1, 0, 9, 2, 7, 3, 8, 6, 4]\n",
            "10 [5 1 0 9 2 7 3 8 6 4]\n",
            "discarded index [5, 1, 0, 9, 2, 7, 3, 8, 6, 4]\n",
            "10 [5 1 0 9 2 7 3 8 6 4]\n",
            "discarded index [5, 1, 0, 9, 2, 7, 3, 8, 6, 4]\n",
            "10 [5 1 0 9 2 7 3 8 6 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 82, bulyan: at fang n_at 10 e 82 | val loss 2.2545 val acc 12.8856 best val_acc 24.391234\n",
            "discarded index [0, 1, 7, 5, 3, 2, 6, 8, 4, 9]\n",
            "10 [0 1 7 5 3 2 6 8 4 9]\n",
            "discarded index [0, 1, 7, 5, 3, 2, 6, 8, 4, 9]\n",
            "10 [0 1 7 5 3 2 6 8 4 9]\n",
            "discarded index [0, 1, 7, 5, 3, 2, 6, 8, 4, 9]\n",
            "10 [0 1 7 5 3 2 6 8 4 9]\n",
            "discarded index [0, 1, 7, 5, 3, 2, 6, 8, 4, 9]\n",
            "10 [0 1 7 5 3 2 6 8 4 9]\n",
            "discarded index [0, 1, 7, 5, 3, 2, 6, 8, 4, 9]\n",
            "10 [0 1 7 5 3 2 6 8 4 9]\n",
            "discarded index [0, 1, 7, 5, 3, 2, 6, 8, 4, 9]\n",
            "10 [0 1 7 5 3 2 6 8 4 9]\n",
            "discarded index [0, 1, 7, 5, 3, 2, 6, 8, 4, 9]\n",
            "10 [0 1 7 5 3 2 6 8 4 9]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 83, bulyan: at fang n_at 10 e 83 | val loss 2.1389 val acc 18.6282 best val_acc 24.391234\n",
            "discarded index [0, 5, 3, 8, 4, 2, 9, 7, 6, 1]\n",
            "10 [0 5 3 8 4 2 9 7 6 1]\n",
            "discarded index [0, 5, 3, 8, 4, 2, 9, 7, 6, 1]\n",
            "10 [0 5 3 8 4 2 9 7 6 1]\n",
            "discarded index [0, 5, 3, 8, 4, 2, 9, 7, 6, 1]\n",
            "10 [0 5 3 8 4 2 9 7 6 1]\n",
            "discarded index [0, 5, 3, 8, 4, 2, 9, 7, 6, 1]\n",
            "10 [0 5 3 8 4 2 9 7 6 1]\n",
            "discarded index [0, 5, 3, 8, 4, 2, 9, 7, 6, 1]\n",
            "10 [0 5 3 8 4 2 9 7 6 1]\n",
            "discarded index [0, 5, 3, 8, 4, 2, 9, 7, 6, 1]\n",
            "10 [0 5 3 8 4 2 9 7 6 1]\n",
            "discarded index [0, 5, 3, 8, 4, 2, 9, 7, 6, 1]\n",
            "10 [0 5 3 8 4 2 9 7 6 1]\n",
            "discarded index [0, 5, 3, 8, 4, 2, 9, 7, 6, 1]\n",
            "10 [0 5 3 8 4 2 9 7 6 1]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 84, bulyan: at fang n_at 10 e 84 | val loss 2.1026 val acc 19.0341 best val_acc 24.391234\n",
            "discarded index [0, 9, 5, 1, 8, 7, 4, 6, 3, 2]\n",
            "10 [0 9 5 1 8 7 4 6 3 2]\n",
            "discarded index [0, 9, 5, 1, 8, 7, 4, 6, 3, 2]\n",
            "10 [0 9 5 1 8 7 4 6 3 2]\n",
            "discarded index [0, 9, 5, 1, 8, 7, 4, 6, 3, 2]\n",
            "10 [0 9 5 1 8 7 4 6 3 2]\n",
            "discarded index [0, 9, 5, 1, 8, 7, 4, 6, 3, 2]\n",
            "10 [0 9 5 1 8 7 4 6 3 2]\n",
            "discarded index [0, 9, 5, 1, 8, 7, 4, 6, 3, 2]\n",
            "10 [0 9 5 1 8 7 4 6 3 2]\n",
            "discarded index [0, 9, 5, 1, 8, 7, 4, 6, 3, 2]\n",
            "10 [0 9 5 1 8 7 4 6 3 2]\n",
            "discarded index [0, 9, 5, 1, 8, 7, 4, 6, 3, 2]\n",
            "10 [0 9 5 1 8 7 4 6 3 2]\n",
            "discarded index [0, 9, 5, 1, 8, 7, 4, 6, 3, 2]\n",
            "10 [0 9 5 1 8 7 4 6 3 2]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 85, bulyan: at fang n_at 10 e 85 | val loss 2.1047 val acc 17.9180 best val_acc 24.391234\n",
            "discarded index [0, 7, 5, 6, 1, 8, 3, 2, 9, 4]\n",
            "10 [0 7 5 6 1 8 3 2 9 4]\n",
            "discarded index [0, 7, 5, 6, 1, 8, 3, 2, 9, 4]\n",
            "10 [0 7 5 6 1 8 3 2 9 4]\n",
            "discarded index [0, 7, 5, 6, 1, 8, 3, 2, 9, 4]\n",
            "10 [0 7 5 6 1 8 3 2 9 4]\n",
            "discarded index [0, 7, 5, 6, 1, 8, 3, 2, 9, 4]\n",
            "10 [0 7 5 6 1 8 3 2 9 4]\n",
            "discarded index [0, 7, 5, 6, 1, 8, 3, 2, 9, 4]\n",
            "10 [0 7 5 6 1 8 3 2 9 4]\n",
            "discarded index [0, 7, 5, 6, 1, 8, 3, 2, 9, 4]\n",
            "10 [0 7 5 6 1 8 3 2 9 4]\n",
            "discarded index [0, 7, 5, 6, 1, 8, 3, 2, 9, 4]\n",
            "10 [0 7 5 6 1 8 3 2 9 4]\n",
            "discarded index [0, 7, 5, 6, 1, 8, 3, 2, 9, 4]\n",
            "10 [0 7 5 6 1 8 3 2 9 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 86, bulyan: at fang n_at 10 e 86 | val loss 2.0910 val acc 19.1558 best val_acc 24.391234\n",
            "discarded index [9, 5, 0, 3, 4, 7, 6, 2, 1, 8]\n",
            "10 [9 5 0 3 4 7 6 2 1 8]\n",
            "discarded index [9, 5, 0, 3, 4, 7, 6, 2, 1, 8]\n",
            "10 [9 5 0 3 4 7 6 2 1 8]\n",
            "discarded index [9, 5, 0, 3, 4, 7, 6, 2, 1, 8]\n",
            "10 [9 5 0 3 4 7 6 2 1 8]\n",
            "discarded index [9, 5, 0, 3, 4, 7, 6, 2, 1, 8]\n",
            "10 [9 5 0 3 4 7 6 2 1 8]\n",
            "discarded index [9, 5, 0, 3, 4, 7, 6, 2, 1, 8]\n",
            "10 [9 5 0 3 4 7 6 2 1 8]\n",
            "discarded index [9, 5, 0, 3, 4, 7, 6, 2, 1, 8]\n",
            "10 [9 5 0 3 4 7 6 2 1 8]\n",
            "discarded index [9, 5, 0, 3, 4, 7, 6, 2, 1, 8]\n",
            "10 [9 5 0 3 4 7 6 2 1 8]\n",
            "discarded index [9, 5, 0, 3, 4, 7, 6, 2, 1, 8]\n",
            "10 [9 5 0 3 4 7 6 2 1 8]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 87, bulyan: at fang n_at 10 e 87 | val loss 2.1096 val acc 17.5731 best val_acc 24.391234\n",
            "discarded index [0, 7, 5, 9, 2, 4, 8, 1, 6, 3]\n",
            "10 [0 7 5 9 2 4 8 1 6 3]\n",
            "discarded index [0, 7, 5, 9, 2, 4, 8, 1, 6, 3]\n",
            "10 [0 7 5 9 2 4 8 1 6 3]\n",
            "discarded index [0, 7, 5, 9, 2, 4, 8, 1, 6, 3]\n",
            "10 [0 7 5 9 2 4 8 1 6 3]\n",
            "discarded index [0, 7, 5, 9, 2, 4, 8, 1, 6, 3]\n",
            "10 [0 7 5 9 2 4 8 1 6 3]\n",
            "discarded index [0, 7, 5, 9, 2, 4, 8, 1, 6, 3]\n",
            "10 [0 7 5 9 2 4 8 1 6 3]\n",
            "discarded index [0, 7, 5, 9, 2, 4, 8, 1, 6, 3]\n",
            "10 [0 7 5 9 2 4 8 1 6 3]\n",
            "discarded index [0, 7, 5, 9, 2, 4, 8, 1, 6, 3]\n",
            "10 [0 7 5 9 2 4 8 1 6 3]\n",
            "discarded index [0, 7, 5, 9, 2, 4, 8, 1, 6, 3]\n",
            "10 [0 7 5 9 2 4 8 1 6 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 88, bulyan: at fang n_at 10 e 88 | val loss 2.1096 val acc 20.3328 best val_acc 24.391234\n",
            "discarded index [0, 5, 9, 8, 7, 1, 3, 2, 6, 4]\n",
            "10 [0 5 9 8 7 1 3 2 6 4]\n",
            "discarded index [0, 5, 9, 8, 7, 1, 3, 2, 6, 4]\n",
            "10 [0 5 9 8 7 1 3 2 6 4]\n",
            "discarded index [0, 5, 9, 8, 7, 1, 3, 2, 6, 4]\n",
            "10 [0 5 9 8 7 1 3 2 6 4]\n",
            "discarded index [0, 5, 9, 8, 7, 1, 3, 2, 6, 4]\n",
            "10 [0 5 9 8 7 1 3 2 6 4]\n",
            "discarded index [0, 5, 9, 8, 7, 1, 3, 2, 6, 4]\n",
            "10 [0 5 9 8 7 1 3 2 6 4]\n",
            "discarded index [0, 5, 9, 8, 7, 1, 3, 2, 6, 4]\n",
            "10 [0 5 9 8 7 1 3 2 6 4]\n",
            "discarded index [0, 5, 9, 8, 7, 1, 3, 2, 6, 4]\n",
            "10 [0 5 9 8 7 1 3 2 6 4]\n",
            "discarded index [0, 5, 9, 8, 7, 1, 3, 2, 6, 4]\n",
            "10 [0 5 9 8 7 1 3 2 6 4]\n",
            "discarded index [0, 5, 9, 8, 7, 1, 3, 2, 6, 4]\n",
            "10 [0 5 9 8 7 1 3 2 6 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 89, bulyan: at fang n_at 10 e 89 | val loss 2.2771 val acc 11.9318 best val_acc 24.391234\n",
            "discarded index [0, 7, 1, 3, 2, 9, 5, 6, 4, 8]\n",
            "10 [0 7 1 3 2 9 5 6 4 8]\n",
            "discarded index [0, 7, 1, 3, 2, 9, 5, 6, 4, 8]\n",
            "10 [0 7 1 3 2 9 5 6 4 8]\n",
            "discarded index [0, 7, 1, 3, 2, 9, 5, 6, 4, 8]\n",
            "10 [0 7 1 3 2 9 5 6 4 8]\n",
            "discarded index [0, 7, 1, 3, 2, 9, 5, 6, 4, 8]\n",
            "10 [0 7 1 3 2 9 5 6 4 8]\n",
            "discarded index [0, 7, 1, 3, 2, 9, 5, 6, 4, 8]\n",
            "10 [0 7 1 3 2 9 5 6 4 8]\n",
            "discarded index [0, 7, 1, 3, 2, 9, 5, 6, 4, 8]\n",
            "10 [0 7 1 3 2 9 5 6 4 8]\n",
            "discarded index [0, 7, 1, 3, 2, 9, 5, 6, 4, 8]\n",
            "10 [0 7 1 3 2 9 5 6 4 8]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 90, bulyan: at fang n_at 10 e 90 | val loss 2.1121 val acc 17.9992 best val_acc 24.391234\n",
            "discarded index [7, 0, 1, 8, 5, 9, 2, 6, 3, 4]\n",
            "10 [7 0 1 8 5 9 2 6 3 4]\n",
            "discarded index [7, 0, 1, 8, 5, 9, 2, 6, 3, 4]\n",
            "10 [7 0 1 8 5 9 2 6 3 4]\n",
            "discarded index [7, 0, 1, 8, 5, 9, 2, 6, 3, 4]\n",
            "10 [7 0 1 8 5 9 2 6 3 4]\n",
            "discarded index [7, 0, 1, 8, 5, 9, 2, 6, 3, 4]\n",
            "10 [7 0 1 8 5 9 2 6 3 4]\n",
            "discarded index [7, 0, 1, 8, 5, 9, 2, 6, 3, 4]\n",
            "10 [7 0 1 8 5 9 2 6 3 4]\n",
            "discarded index [7, 0, 1, 8, 5, 9, 2, 6, 3, 4]\n",
            "10 [7 0 1 8 5 9 2 6 3 4]\n",
            "discarded index [7, 0, 1, 8, 5, 9, 2, 6, 3, 4]\n",
            "10 [7 0 1 8 5 9 2 6 3 4]\n",
            "discarded index [7, 0, 1, 8, 5, 9, 2, 6, 3, 4]\n",
            "10 [7 0 1 8 5 9 2 6 3 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 91, bulyan: at fang n_at 10 e 91 | val loss 2.0828 val acc 21.9968 best val_acc 24.391234\n",
            "discarded index [0, 9, 5, 8, 6, 3, 7, 4, 2, 1]\n",
            "10 [0 9 5 8 6 3 7 4 2 1]\n",
            "discarded index [0, 9, 5, 8, 6, 3, 7, 4, 2, 1]\n",
            "10 [0 9 5 8 6 3 7 4 2 1]\n",
            "discarded index [0, 9, 5, 8, 6, 3, 7, 4, 2, 1]\n",
            "10 [0 9 5 8 6 3 7 4 2 1]\n",
            "discarded index [0, 9, 5, 8, 6, 3, 7, 4, 2, 1]\n",
            "10 [0 9 5 8 6 3 7 4 2 1]\n",
            "discarded index [0, 9, 5, 8, 6, 3, 7, 4, 2, 1]\n",
            "10 [0 9 5 8 6 3 7 4 2 1]\n",
            "discarded index [0, 9, 5, 8, 6, 3, 7, 4, 2, 1]\n",
            "10 [0 9 5 8 6 3 7 4 2 1]\n",
            "discarded index [0, 9, 5, 8, 6, 3, 7, 4, 2, 1]\n",
            "10 [0 9 5 8 6 3 7 4 2 1]\n",
            "discarded index [0, 9, 5, 8, 6, 3, 7, 4, 2, 1]\n",
            "10 [0 9 5 8 6 3 7 4 2 1]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 92, bulyan: at fang n_at 10 e 92 | val loss 2.0663 val acc 19.2167 best val_acc 24.391234\n",
            "discarded index [0, 7, 6, 9, 5, 1, 4, 8, 2, 3]\n",
            "10 [0 7 6 9 5 1 4 8 2 3]\n",
            "discarded index [0, 7, 6, 9, 5, 1, 4, 8, 2, 3]\n",
            "10 [0 7 6 9 5 1 4 8 2 3]\n",
            "discarded index [0, 7, 6, 9, 5, 1, 4, 8, 2, 3]\n",
            "10 [0 7 6 9 5 1 4 8 2 3]\n",
            "discarded index [0, 7, 6, 9, 5, 1, 4, 8, 2, 3]\n",
            "10 [0 7 6 9 5 1 4 8 2 3]\n",
            "discarded index [0, 7, 6, 9, 5, 1, 4, 8, 2, 3]\n",
            "10 [0 7 6 9 5 1 4 8 2 3]\n",
            "discarded index [0, 7, 6, 9, 5, 1, 4, 8, 2, 3]\n",
            "10 [0 7 6 9 5 1 4 8 2 3]\n",
            "discarded index [0, 7, 6, 9, 5, 1, 4, 8, 2, 3]\n",
            "10 [0 7 6 9 5 1 4 8 2 3]\n",
            "discarded index [0, 7, 6, 9, 5, 1, 4, 8, 2, 3]\n",
            "10 [0 7 6 9 5 1 4 8 2 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 93, bulyan: at fang n_at 10 e 93 | val loss 2.0613 val acc 21.3271 best val_acc 24.391234\n",
            "discarded index [0, 7, 4, 2, 5, 9, 3, 8, 6, 1]\n",
            "10 [0 7 4 2 5 9 3 8 6 1]\n",
            "discarded index [0, 7, 4, 2, 5, 9, 3, 8, 6, 1]\n",
            "10 [0 7 4 2 5 9 3 8 6 1]\n",
            "discarded index [0, 7, 4, 2, 5, 9, 3, 8, 6, 1]\n",
            "10 [0 7 4 2 5 9 3 8 6 1]\n",
            "discarded index [0, 7, 4, 2, 5, 9, 3, 8, 6, 1]\n",
            "10 [0 7 4 2 5 9 3 8 6 1]\n",
            "discarded index [0, 7, 4, 2, 5, 9, 3, 8, 6, 1]\n",
            "10 [0 7 4 2 5 9 3 8 6 1]\n",
            "discarded index [0, 7, 4, 2, 5, 9, 3, 8, 6, 1]\n",
            "10 [0 7 4 2 5 9 3 8 6 1]\n",
            "discarded index [0, 7, 4, 2, 5, 9, 3, 8, 6, 1]\n",
            "10 [0 7 4 2 5 9 3 8 6 1]\n",
            "discarded index [0, 7, 4, 2, 5, 9, 3, 8, 6, 1]\n",
            "10 [0 7 4 2 5 9 3 8 6 1]\n",
            "discarded index [0, 7, 4, 2, 5, 9, 3, 8, 6, 1]\n",
            "10 [0 7 4 2 5 9 3 8 6 1]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 94, bulyan: at fang n_at 10 e 94 | val loss 2.1508 val acc 16.3555 best val_acc 24.391234\n",
            "discarded index [0, 1, 7, 2, 8, 5, 4, 6, 9, 3]\n",
            "10 [0 1 7 2 8 5 4 6 9 3]\n",
            "discarded index [0, 1, 7, 2, 8, 5, 4, 6, 9, 3]\n",
            "10 [0 1 7 2 8 5 4 6 9 3]\n",
            "discarded index [0, 1, 7, 2, 8, 5, 4, 6, 9, 3]\n",
            "10 [0 1 7 2 8 5 4 6 9 3]\n",
            "discarded index [0, 1, 7, 2, 8, 5, 4, 6, 9, 3]\n",
            "10 [0 1 7 2 8 5 4 6 9 3]\n",
            "discarded index [0, 1, 7, 2, 8, 5, 4, 6, 9, 3]\n",
            "10 [0 1 7 2 8 5 4 6 9 3]\n",
            "discarded index [0, 1, 7, 2, 8, 5, 4, 6, 9, 3]\n",
            "10 [0 1 7 2 8 5 4 6 9 3]\n",
            "discarded index [0, 1, 7, 2, 8, 5, 4, 6, 9, 3]\n",
            "10 [0 1 7 2 8 5 4 6 9 3]\n",
            "discarded index [0, 1, 7, 2, 8, 5, 4, 6, 9, 3]\n",
            "10 [0 1 7 2 8 5 4 6 9 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 95, bulyan: at fang n_at 10 e 95 | val loss 2.3135 val acc 18.0398 best val_acc 24.391234\n",
            "discarded index [0, 6, 5, 7, 8, 1, 9, 2, 4, 3]\n",
            "10 [0 6 5 7 8 1 9 2 4 3]\n",
            "discarded index [0, 6, 5, 7, 8, 1, 9, 2, 4, 3]\n",
            "10 [0 6 5 7 8 1 9 2 4 3]\n",
            "discarded index [0, 6, 5, 7, 8, 1, 9, 2, 4, 3]\n",
            "10 [0 6 5 7 8 1 9 2 4 3]\n",
            "discarded index [0, 6, 5, 7, 8, 1, 9, 2, 4, 3]\n",
            "10 [0 6 5 7 8 1 9 2 4 3]\n",
            "discarded index [0, 6, 5, 7, 8, 1, 9, 2, 4, 3]\n",
            "10 [0 6 5 7 8 1 9 2 4 3]\n",
            "discarded index [0, 6, 5, 7, 8, 1, 9, 2, 4, 3]\n",
            "10 [0 6 5 7 8 1 9 2 4 3]\n",
            "discarded index [0, 6, 5, 7, 8, 1, 9, 2, 4, 3]\n",
            "10 [0 6 5 7 8 1 9 2 4 3]\n",
            "discarded index [0, 6, 5, 7, 8, 1, 9, 2, 4, 3]\n",
            "10 [0 6 5 7 8 1 9 2 4 3]\n",
            "discarded index [0, 6, 5, 7, 8, 1, 9, 2, 4, 3]\n",
            "10 [0 6 5 7 8 1 9 2 4 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 96, bulyan: at fang n_at 10 e 96 | val loss 2.3917 val acc 9.7808 best val_acc 24.391234\n",
            "discarded index [6, 1, 4, 7, 8, 9, 3, 5, 2, 0]\n",
            "10 [6 1 4 7 8 9 3 5 2 0]\n",
            "discarded index [6, 1, 4, 7, 8, 9, 3, 5, 2, 0]\n",
            "10 [6 1 4 7 8 9 3 5 2 0]\n",
            "discarded index [6, 1, 4, 7, 8, 9, 3, 5, 2, 0]\n",
            "10 [6 1 4 7 8 9 3 5 2 0]\n",
            "discarded index [6, 1, 4, 7, 8, 9, 3, 5, 2, 0]\n",
            "10 [6 1 4 7 8 9 3 5 2 0]\n",
            "discarded index [6, 1, 4, 7, 8, 9, 3, 5, 2, 0]\n",
            "10 [6 1 4 7 8 9 3 5 2 0]\n",
            "discarded index [6, 1, 4, 7, 8, 9, 3, 5, 2, 0]\n",
            "10 [6 1 4 7 8 9 3 5 2 0]\n",
            "discarded index [6, 1, 4, 7, 8, 9, 3, 5, 2, 0]\n",
            "10 [6 1 4 7 8 9 3 5 2 0]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 97, bulyan: at fang n_at 10 e 97 | val loss 2.3641 val acc 9.7606 best val_acc 24.391234\n",
            "discarded index [6, 1, 0, 2, 9, 8, 4, 7, 3, 5]\n",
            "10 [6 1 0 2 9 8 4 7 3 5]\n",
            "discarded index [6, 1, 0, 2, 9, 8, 4, 7, 3, 5]\n",
            "10 [6 1 0 2 9 8 4 7 3 5]\n",
            "discarded index [6, 1, 0, 2, 9, 8, 4, 7, 3, 5]\n",
            "10 [6 1 0 2 9 8 4 7 3 5]\n",
            "discarded index [6, 1, 0, 2, 9, 8, 4, 7, 3, 5]\n",
            "10 [6 1 0 2 9 8 4 7 3 5]\n",
            "discarded index [6, 1, 0, 2, 9, 8, 4, 7, 3, 5]\n",
            "10 [6 1 0 2 9 8 4 7 3 5]\n",
            "discarded index [6, 1, 0, 2, 9, 8, 4, 7, 3, 5]\n",
            "10 [6 1 0 2 9 8 4 7 3 5]\n",
            "discarded index [6, 1, 0, 2, 9, 8, 4, 7, 3, 5]\n",
            "10 [6 1 0 2 9 8 4 7 3 5]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 98, bulyan: at fang n_at 10 e 98 | val loss 2.3439 val acc 14.1437 best val_acc 24.391234\n",
            "discarded index [6, 9, 8, 4, 0, 1, 2, 5, 7, 3]\n",
            "10 [6 9 8 4 0 1 2 5 7 3]\n",
            "discarded index [6, 9, 8, 4, 0, 1, 2, 5, 7, 3]\n",
            "10 [6 9 8 4 0 1 2 5 7 3]\n",
            "discarded index [6, 9, 8, 4, 0, 1, 2, 5, 7, 3]\n",
            "10 [6 9 8 4 0 1 2 5 7 3]\n",
            "discarded index [6, 9, 8, 4, 0, 1, 2, 5, 7, 3]\n",
            "10 [6 9 8 4 0 1 2 5 7 3]\n",
            "discarded index [6, 9, 8, 4, 0, 1, 2, 5, 7, 3]\n",
            "10 [6 9 8 4 0 1 2 5 7 3]\n",
            "discarded index [6, 9, 8, 4, 0, 1, 2, 5, 7, 3]\n",
            "10 [6 9 8 4 0 1 2 5 7 3]\n",
            "discarded index [6, 9, 8, 4, 0, 1, 2, 5, 7, 3]\n",
            "10 [6 9 8 4 0 1 2 5 7 3]\n",
            "discarded index [6, 9, 8, 4, 0, 1, 2, 5, 7, 3]\n",
            "10 [6 9 8 4 0 1 2 5 7 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 99, bulyan: at fang n_at 10 e 99 | val loss 2.3237 val acc 14.2654 best val_acc 24.391234\n",
            "discarded index [6, 9, 1, 0, 2, 8, 4, 5, 7, 3]\n",
            "10 [6 9 1 0 2 8 4 5 7 3]\n",
            "discarded index [6, 9, 1, 0, 2, 8, 4, 5, 7, 3]\n",
            "10 [6 9 1 0 2 8 4 5 7 3]\n",
            "discarded index [6, 9, 1, 0, 2, 8, 4, 5, 7, 3]\n",
            "10 [6 9 1 0 2 8 4 5 7 3]\n",
            "discarded index [6, 9, 1, 0, 2, 8, 4, 5, 7, 3]\n",
            "10 [6 9 1 0 2 8 4 5 7 3]\n",
            "discarded index [6, 9, 1, 0, 2, 8, 4, 5, 7, 3]\n",
            "10 [6 9 1 0 2 8 4 5 7 3]\n",
            "discarded index [6, 9, 1, 0, 2, 8, 4, 5, 7, 3]\n",
            "10 [6 9 1 0 2 8 4 5 7 3]\n",
            "discarded index [6, 9, 1, 0, 2, 8, 4, 5, 7, 3]\n",
            "10 [6 9 1 0 2 8 4 5 7 3]\n",
            "discarded index [6, 9, 1, 0, 2, 8, 4, 5, 7, 3]\n",
            "10 [6 9 1 0 2 8 4 5 7 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 100, bulyan: at fang n_at 10 e 100 | val loss 2.3050 val acc 14.7321 best val_acc 24.391234\n",
            "discarded index [6, 0, 1, 2, 7, 9, 8, 4, 3, 5]\n",
            "10 [6 0 1 2 7 9 8 4 3 5]\n",
            "discarded index [6, 0, 1, 2, 7, 9, 8, 4, 3, 5]\n",
            "10 [6 0 1 2 7 9 8 4 3 5]\n",
            "discarded index [6, 0, 1, 2, 7, 9, 8, 4, 3, 5]\n",
            "10 [6 0 1 2 7 9 8 4 3 5]\n",
            "discarded index [6, 0, 1, 2, 7, 9, 8, 4, 3, 5]\n",
            "10 [6 0 1 2 7 9 8 4 3 5]\n",
            "discarded index [6, 0, 1, 2, 7, 9, 8, 4, 3, 5]\n",
            "10 [6 0 1 2 7 9 8 4 3 5]\n",
            "discarded index [6, 0, 1, 2, 7, 9, 8, 4, 3, 5]\n",
            "10 [6 0 1 2 7 9 8 4 3 5]\n",
            "discarded index [6, 0, 1, 2, 7, 9, 8, 4, 3, 5]\n",
            "10 [6 0 1 2 7 9 8 4 3 5]\n",
            "discarded index [6, 0, 1, 2, 7, 9, 8, 4, 3, 5]\n",
            "10 [6 0 1 2 7 9 8 4 3 5]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 101, bulyan: at fang n_at 10 e 101 | val loss 2.3126 val acc 11.1404 best val_acc 24.391234\n",
            "discarded index [6, 8, 9, 7, 4, 3, 5, 2, 1, 0]\n",
            "10 [6 8 9 7 4 3 5 2 1 0]\n",
            "discarded index [6, 8, 9, 7, 4, 3, 5, 2, 1, 0]\n",
            "10 [6 8 9 7 4 3 5 2 1 0]\n",
            "discarded index [6, 8, 9, 7, 4, 3, 5, 2, 1, 0]\n",
            "10 [6 8 9 7 4 3 5 2 1 0]\n",
            "discarded index [6, 8, 9, 7, 4, 3, 5, 2, 1, 0]\n",
            "10 [6 8 9 7 4 3 5 2 1 0]\n",
            "discarded index [6, 8, 9, 7, 4, 3, 5, 2, 1, 0]\n",
            "10 [6 8 9 7 4 3 5 2 1 0]\n",
            "discarded index [6, 8, 9, 7, 4, 3, 5, 2, 1, 0]\n",
            "10 [6 8 9 7 4 3 5 2 1 0]\n",
            "discarded index [6, 8, 9, 7, 4, 3, 5, 2, 1, 0]\n",
            "10 [6 8 9 7 4 3 5 2 1 0]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 102, bulyan: at fang n_at 10 e 102 | val loss 2.2962 val acc 13.2711 best val_acc 24.391234\n",
            "discarded index [6, 9, 8, 1, 0, 2, 7, 3, 5, 4]\n",
            "10 [6 9 8 1 0 2 7 3 5 4]\n",
            "discarded index [6, 9, 8, 1, 0, 2, 7, 3, 5, 4]\n",
            "10 [6 9 8 1 0 2 7 3 5 4]\n",
            "discarded index [6, 9, 8, 1, 0, 2, 7, 3, 5, 4]\n",
            "10 [6 9 8 1 0 2 7 3 5 4]\n",
            "discarded index [6, 9, 8, 1, 0, 2, 7, 3, 5, 4]\n",
            "10 [6 9 8 1 0 2 7 3 5 4]\n",
            "discarded index [6, 9, 8, 1, 0, 2, 7, 3, 5, 4]\n",
            "10 [6 9 8 1 0 2 7 3 5 4]\n",
            "discarded index [6, 9, 8, 1, 0, 2, 7, 3, 5, 4]\n",
            "10 [6 9 8 1 0 2 7 3 5 4]\n",
            "discarded index [6, 9, 8, 1, 0, 2, 7, 3, 5, 4]\n",
            "10 [6 9 8 1 0 2 7 3 5 4]\n",
            "discarded index [6, 9, 8, 1, 0, 2, 7, 3, 5, 4]\n",
            "10 [6 9 8 1 0 2 7 3 5 4]\n",
            "discarded index [6, 9, 8, 1, 0, 2, 7, 3, 5, 4]\n",
            "10 [6 9 8 1 0 2 7 3 5 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 103, bulyan: at fang n_at 10 e 103 | val loss 2.3289 val acc 9.4156 best val_acc 24.391234\n",
            "discarded index [6, 0, 4, 7, 1, 8, 2, 5, 3, 9]\n",
            "10 [6 0 4 7 1 8 2 5 3 9]\n",
            "discarded index [6, 0, 4, 7, 1, 8, 2, 5, 3, 9]\n",
            "10 [6 0 4 7 1 8 2 5 3 9]\n",
            "discarded index [6, 0, 4, 7, 1, 8, 2, 5, 3, 9]\n",
            "10 [6 0 4 7 1 8 2 5 3 9]\n",
            "discarded index [6, 0, 4, 7, 1, 8, 2, 5, 3, 9]\n",
            "10 [6 0 4 7 1 8 2 5 3 9]\n",
            "discarded index [6, 0, 4, 7, 1, 8, 2, 5, 3, 9]\n",
            "10 [6 0 4 7 1 8 2 5 3 9]\n",
            "discarded index [6, 0, 4, 7, 1, 8, 2, 5, 3, 9]\n",
            "10 [6 0 4 7 1 8 2 5 3 9]\n",
            "discarded index [6, 0, 4, 7, 1, 8, 2, 5, 3, 9]\n",
            "10 [6 0 4 7 1 8 2 5 3 9]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 104, bulyan: at fang n_at 10 e 104 | val loss 2.3068 val acc 9.5373 best val_acc 24.391234\n",
            "discarded index [6, 7, 4, 0, 8, 2, 1, 5, 9, 3]\n",
            "10 [6 7 4 0 8 2 1 5 9 3]\n",
            "discarded index [6, 7, 4, 0, 8, 2, 1, 5, 9, 3]\n",
            "10 [6 7 4 0 8 2 1 5 9 3]\n",
            "discarded index [6, 7, 4, 0, 8, 2, 1, 5, 9, 3]\n",
            "10 [6 7 4 0 8 2 1 5 9 3]\n",
            "discarded index [6, 7, 4, 0, 8, 2, 1, 5, 9, 3]\n",
            "10 [6 7 4 0 8 2 1 5 9 3]\n",
            "discarded index [6, 7, 4, 0, 8, 2, 1, 5, 9, 3]\n",
            "10 [6 7 4 0 8 2 1 5 9 3]\n",
            "discarded index [6, 7, 4, 0, 8, 2, 1, 5, 9, 3]\n",
            "10 [6 7 4 0 8 2 1 5 9 3]\n",
            "discarded index [6, 7, 4, 0, 8, 2, 1, 5, 9, 3]\n",
            "10 [6 7 4 0 8 2 1 5 9 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 105, bulyan: at fang n_at 10 e 105 | val loss 2.2815 val acc 10.3084 best val_acc 24.391234\n",
            "discarded index [6, 7, 4, 8, 9, 3, 5, 1, 2, 0]\n",
            "10 [6 7 4 8 9 3 5 1 2 0]\n",
            "discarded index [6, 7, 4, 8, 9, 3, 5, 1, 2, 0]\n",
            "10 [6 7 4 8 9 3 5 1 2 0]\n",
            "discarded index [6, 7, 4, 8, 9, 3, 5, 1, 2, 0]\n",
            "10 [6 7 4 8 9 3 5 1 2 0]\n",
            "discarded index [6, 7, 4, 8, 9, 3, 5, 1, 2, 0]\n",
            "10 [6 7 4 8 9 3 5 1 2 0]\n",
            "discarded index [6, 7, 4, 8, 9, 3, 5, 1, 2, 0]\n",
            "10 [6 7 4 8 9 3 5 1 2 0]\n",
            "discarded index [6, 7, 4, 8, 9, 3, 5, 1, 2, 0]\n",
            "10 [6 7 4 8 9 3 5 1 2 0]\n",
            "discarded index [6, 7, 4, 8, 9, 3, 5, 1, 2, 0]\n",
            "10 [6 7 4 8 9 3 5 1 2 0]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 106, bulyan: at fang n_at 10 e 106 | val loss 2.2484 val acc 11.2419 best val_acc 24.391234\n",
            "discarded index [6, 0, 8, 7, 4, 9, 5, 1, 2, 3]\n",
            "10 [6 0 8 7 4 9 5 1 2 3]\n",
            "discarded index [6, 0, 8, 7, 4, 9, 5, 1, 2, 3]\n",
            "10 [6 0 8 7 4 9 5 1 2 3]\n",
            "discarded index [6, 0, 8, 7, 4, 9, 5, 1, 2, 3]\n",
            "10 [6 0 8 7 4 9 5 1 2 3]\n",
            "discarded index [6, 0, 8, 7, 4, 9, 5, 1, 2, 3]\n",
            "10 [6 0 8 7 4 9 5 1 2 3]\n",
            "discarded index [6, 0, 8, 7, 4, 9, 5, 1, 2, 3]\n",
            "10 [6 0 8 7 4 9 5 1 2 3]\n",
            "discarded index [6, 0, 8, 7, 4, 9, 5, 1, 2, 3]\n",
            "10 [6 0 8 7 4 9 5 1 2 3]\n",
            "discarded index [6, 0, 8, 7, 4, 9, 5, 1, 2, 3]\n",
            "10 [6 0 8 7 4 9 5 1 2 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 107, bulyan: at fang n_at 10 e 107 | val loss 2.2079 val acc 12.3377 best val_acc 24.391234\n",
            "discarded index [6, 0, 2, 1, 7, 9, 8, 4, 5, 3]\n",
            "10 [6 0 2 1 7 9 8 4 5 3]\n",
            "discarded index [6, 0, 2, 1, 7, 9, 8, 4, 5, 3]\n",
            "10 [6 0 2 1 7 9 8 4 5 3]\n",
            "discarded index [6, 0, 2, 1, 7, 9, 8, 4, 5, 3]\n",
            "10 [6 0 2 1 7 9 8 4 5 3]\n",
            "discarded index [6, 0, 2, 1, 7, 9, 8, 4, 5, 3]\n",
            "10 [6 0 2 1 7 9 8 4 5 3]\n",
            "discarded index [6, 0, 2, 1, 7, 9, 8, 4, 5, 3]\n",
            "10 [6 0 2 1 7 9 8 4 5 3]\n",
            "discarded index [6, 0, 2, 1, 7, 9, 8, 4, 5, 3]\n",
            "10 [6 0 2 1 7 9 8 4 5 3]\n",
            "discarded index [6, 0, 2, 1, 7, 9, 8, 4, 5, 3]\n",
            "10 [6 0 2 1 7 9 8 4 5 3]\n",
            "discarded index [6, 0, 2, 1, 7, 9, 8, 4, 5, 3]\n",
            "10 [6 0 2 1 7 9 8 4 5 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 108, bulyan: at fang n_at 10 e 108 | val loss 2.1738 val acc 14.2857 best val_acc 24.391234\n",
            "discarded index [6, 7, 8, 9, 2, 0, 1, 5, 4, 3]\n",
            "10 [6 7 8 9 2 0 1 5 4 3]\n",
            "discarded index [6, 7, 8, 9, 2, 0, 1, 5, 4, 3]\n",
            "10 [6 7 8 9 2 0 1 5 4 3]\n",
            "discarded index [6, 7, 8, 9, 2, 0, 1, 5, 4, 3]\n",
            "10 [6 7 8 9 2 0 1 5 4 3]\n",
            "discarded index [6, 7, 8, 9, 2, 0, 1, 5, 4, 3]\n",
            "10 [6 7 8 9 2 0 1 5 4 3]\n",
            "discarded index [6, 7, 8, 9, 2, 0, 1, 5, 4, 3]\n",
            "10 [6 7 8 9 2 0 1 5 4 3]\n",
            "discarded index [6, 7, 8, 9, 2, 0, 1, 5, 4, 3]\n",
            "10 [6 7 8 9 2 0 1 5 4 3]\n",
            "discarded index [6, 7, 8, 9, 2, 0, 1, 5, 4, 3]\n",
            "10 [6 7 8 9 2 0 1 5 4 3]\n",
            "discarded index [6, 7, 8, 9, 2, 0, 1, 5, 4, 3]\n",
            "10 [6 7 8 9 2 0 1 5 4 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 109, bulyan: at fang n_at 10 e 109 | val loss 2.1510 val acc 18.8109 best val_acc 24.391234\n",
            "discarded index [6, 0, 8, 7, 9, 1, 2, 3, 5, 4]\n",
            "10 [6 0 8 7 9 1 2 3 5 4]\n",
            "discarded index [6, 0, 8, 7, 9, 1, 2, 3, 5, 4]\n",
            "10 [6 0 8 7 9 1 2 3 5 4]\n",
            "discarded index [6, 0, 8, 7, 9, 1, 2, 3, 5, 4]\n",
            "10 [6 0 8 7 9 1 2 3 5 4]\n",
            "discarded index [6, 0, 8, 7, 9, 1, 2, 3, 5, 4]\n",
            "10 [6 0 8 7 9 1 2 3 5 4]\n",
            "discarded index [6, 0, 8, 7, 9, 1, 2, 3, 5, 4]\n",
            "10 [6 0 8 7 9 1 2 3 5 4]\n",
            "discarded index [6, 0, 8, 7, 9, 1, 2, 3, 5, 4]\n",
            "10 [6 0 8 7 9 1 2 3 5 4]\n",
            "discarded index [6, 0, 8, 7, 9, 1, 2, 3, 5, 4]\n",
            "10 [6 0 8 7 9 1 2 3 5 4]\n",
            "discarded index [6, 0, 8, 7, 9, 1, 2, 3, 5, 4]\n",
            "10 [6 0 8 7 9 1 2 3 5 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 110, bulyan: at fang n_at 10 e 110 | val loss 2.1258 val acc 21.4894 best val_acc 24.391234\n",
            "discarded index [6, 9, 8, 2, 0, 7, 3, 5, 4, 1]\n",
            "10 [6 9 8 2 0 7 3 5 4 1]\n",
            "discarded index [6, 9, 8, 2, 0, 7, 3, 5, 4, 1]\n",
            "10 [6 9 8 2 0 7 3 5 4 1]\n",
            "discarded index [6, 9, 8, 2, 0, 7, 3, 5, 4, 1]\n",
            "10 [6 9 8 2 0 7 3 5 4 1]\n",
            "discarded index [6, 9, 8, 2, 0, 7, 3, 5, 4, 1]\n",
            "10 [6 9 8 2 0 7 3 5 4 1]\n",
            "discarded index [6, 9, 8, 2, 0, 7, 3, 5, 4, 1]\n",
            "10 [6 9 8 2 0 7 3 5 4 1]\n",
            "discarded index [6, 9, 8, 2, 0, 7, 3, 5, 4, 1]\n",
            "10 [6 9 8 2 0 7 3 5 4 1]\n",
            "discarded index [6, 9, 8, 2, 0, 7, 3, 5, 4, 1]\n",
            "10 [6 9 8 2 0 7 3 5 4 1]\n",
            "discarded index [6, 9, 8, 2, 0, 7, 3, 5, 4, 1]\n",
            "10 [6 9 8 2 0 7 3 5 4 1]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 111, bulyan: at fang n_at 10 e 111 | val loss 2.2778 val acc 15.1177 best val_acc 24.391234\n",
            "discarded index [7, 6, 2, 3, 4, 8, 9, 5, 0, 1]\n",
            "10 [7 6 2 3 4 8 9 5 0 1]\n",
            "discarded index [7, 6, 2, 3, 4, 8, 9, 5, 0, 1]\n",
            "10 [7 6 2 3 4 8 9 5 0 1]\n",
            "discarded index [7, 6, 2, 3, 4, 8, 9, 5, 0, 1]\n",
            "10 [7 6 2 3 4 8 9 5 0 1]\n",
            "discarded index [7, 6, 2, 3, 4, 8, 9, 5, 0, 1]\n",
            "10 [7 6 2 3 4 8 9 5 0 1]\n",
            "discarded index [7, 6, 2, 3, 4, 8, 9, 5, 0, 1]\n",
            "10 [7 6 2 3 4 8 9 5 0 1]\n",
            "discarded index [7, 6, 2, 3, 4, 8, 9, 5, 0, 1]\n",
            "10 [7 6 2 3 4 8 9 5 0 1]\n",
            "discarded index [7, 6, 2, 3, 4, 8, 9, 5, 0, 1]\n",
            "10 [7 6 2 3 4 8 9 5 0 1]\n",
            "discarded index [7, 6, 2, 3, 4, 8, 9, 5, 0, 1]\n",
            "10 [7 6 2 3 4 8 9 5 0 1]\n",
            "discarded index [7, 6, 2, 3, 4, 8, 9, 5, 0, 1]\n",
            "10 [7 6 2 3 4 8 9 5 0 1]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 112, bulyan: at fang n_at 10 e 112 | val loss 2.4995 val acc 10.3693 best val_acc 24.391234\n",
            "discarded index [9, 5, 8, 0, 6, 3, 2, 4, 7, 1]\n",
            "10 [9 5 8 0 6 3 2 4 7 1]\n",
            "discarded index [9, 5, 8, 0, 6, 3, 2, 4, 7, 1]\n",
            "10 [9 5 8 0 6 3 2 4 7 1]\n",
            "discarded index [9, 5, 8, 0, 6, 3, 2, 4, 7, 1]\n",
            "10 [9 5 8 0 6 3 2 4 7 1]\n",
            "discarded index [9, 5, 8, 0, 6, 3, 2, 4, 7, 1]\n",
            "10 [9 5 8 0 6 3 2 4 7 1]\n",
            "discarded index [9, 5, 8, 0, 6, 3, 2, 4, 7, 1]\n",
            "10 [9 5 8 0 6 3 2 4 7 1]\n",
            "discarded index [9, 5, 8, 0, 6, 3, 2, 4, 7, 1]\n",
            "10 [9 5 8 0 6 3 2 4 7 1]\n",
            "discarded index [9, 5, 8, 0, 6, 3, 2, 4, 7, 1]\n",
            "10 [9 5 8 0 6 3 2 4 7 1]\n",
            "discarded index [9, 5, 8, 0, 6, 3, 2, 4, 7, 1]\n",
            "10 [9 5 8 0 6 3 2 4 7 1]\n",
            "discarded index [9, 5, 8, 0, 6, 3, 2, 4, 7, 1]\n",
            "10 [9 5 8 0 6 3 2 4 7 1]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 113, bulyan: at fang n_at 10 e 113 | val loss 2.3184 val acc 10.1461 best val_acc 24.391234\n",
            "discarded index [7, 6, 4, 5, 0, 9, 2, 3, 1, 8]\n",
            "10 [7 6 4 5 0 9 2 3 1 8]\n",
            "discarded index [7, 6, 4, 5, 0, 9, 2, 3, 1, 8]\n",
            "10 [7 6 4 5 0 9 2 3 1 8]\n",
            "discarded index [7, 6, 4, 5, 0, 9, 2, 3, 1, 8]\n",
            "10 [7 6 4 5 0 9 2 3 1 8]\n",
            "discarded index [7, 6, 4, 5, 0, 9, 2, 3, 1, 8]\n",
            "10 [7 6 4 5 0 9 2 3 1 8]\n",
            "discarded index [7, 6, 4, 5, 0, 9, 2, 3, 1, 8]\n",
            "10 [7 6 4 5 0 9 2 3 1 8]\n",
            "discarded index [7, 6, 4, 5, 0, 9, 2, 3, 1, 8]\n",
            "10 [7 6 4 5 0 9 2 3 1 8]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 114, bulyan: at fang n_at 10 e 114 | val loss 2.3144 val acc 10.1461 best val_acc 24.391234\n",
            "discarded index [7, 6, 4, 5, 8, 2, 0, 1, 9, 3]\n",
            "10 [7 6 4 5 8 2 0 1 9 3]\n",
            "discarded index [7, 6, 4, 5, 8, 2, 0, 1, 9, 3]\n",
            "10 [7 6 4 5 8 2 0 1 9 3]\n",
            "discarded index [7, 6, 4, 5, 8, 2, 0, 1, 9, 3]\n",
            "10 [7 6 4 5 8 2 0 1 9 3]\n",
            "discarded index [7, 6, 4, 5, 8, 2, 0, 1, 9, 3]\n",
            "10 [7 6 4 5 8 2 0 1 9 3]\n",
            "discarded index [7, 6, 4, 5, 8, 2, 0, 1, 9, 3]\n",
            "10 [7 6 4 5 8 2 0 1 9 3]\n",
            "discarded index [7, 6, 4, 5, 8, 2, 0, 1, 9, 3]\n",
            "10 [7 6 4 5 8 2 0 1 9 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 115, bulyan: at fang n_at 10 e 115 | val loss 2.3109 val acc 10.1461 best val_acc 24.391234\n",
            "discarded index [6, 0, 9, 7, 4, 5, 1, 3, 8, 2]\n",
            "10 [6 0 9 7 4 5 1 3 8 2]\n",
            "discarded index [6, 0, 9, 7, 4, 5, 1, 3, 8, 2]\n",
            "10 [6 0 9 7 4 5 1 3 8 2]\n",
            "discarded index [6, 0, 9, 7, 4, 5, 1, 3, 8, 2]\n",
            "10 [6 0 9 7 4 5 1 3 8 2]\n",
            "discarded index [6, 0, 9, 7, 4, 5, 1, 3, 8, 2]\n",
            "10 [6 0 9 7 4 5 1 3 8 2]\n",
            "discarded index [6, 0, 9, 7, 4, 5, 1, 3, 8, 2]\n",
            "10 [6 0 9 7 4 5 1 3 8 2]\n",
            "discarded index [6, 0, 9, 7, 4, 5, 1, 3, 8, 2]\n",
            "10 [6 0 9 7 4 5 1 3 8 2]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 116, bulyan: at fang n_at 10 e 116 | val loss 2.3072 val acc 10.1461 best val_acc 24.391234\n",
            "discarded index [0, 7, 9, 6, 4, 5, 3, 1, 2, 8]\n",
            "10 [0 7 9 6 4 5 3 1 2 8]\n",
            "discarded index [0, 7, 9, 6, 4, 5, 3, 1, 2, 8]\n",
            "10 [0 7 9 6 4 5 3 1 2 8]\n",
            "discarded index [0, 7, 9, 6, 4, 5, 3, 1, 2, 8]\n",
            "10 [0 7 9 6 4 5 3 1 2 8]\n",
            "discarded index [0, 7, 9, 6, 4, 5, 3, 1, 2, 8]\n",
            "10 [0 7 9 6 4 5 3 1 2 8]\n",
            "discarded index [0, 7, 9, 6, 4, 5, 3, 1, 2, 8]\n",
            "10 [0 7 9 6 4 5 3 1 2 8]\n",
            "discarded index [0, 7, 9, 6, 4, 5, 3, 1, 2, 8]\n",
            "10 [0 7 9 6 4 5 3 1 2 8]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 117, bulyan: at fang n_at 10 e 117 | val loss 2.3032 val acc 10.1461 best val_acc 24.391234\n",
            "discarded index [0, 7, 1, 9, 8, 3, 2, 6, 4, 5]\n",
            "10 [0 7 1 9 8 3 2 6 4 5]\n",
            "discarded index [0, 7, 1, 9, 8, 3, 2, 6, 4, 5]\n",
            "10 [0 7 1 9 8 3 2 6 4 5]\n",
            "discarded index [0, 7, 1, 9, 8, 3, 2, 6, 4, 5]\n",
            "10 [0 7 1 9 8 3 2 6 4 5]\n",
            "discarded index [0, 7, 1, 9, 8, 3, 2, 6, 4, 5]\n",
            "10 [0 7 1 9 8 3 2 6 4 5]\n",
            "discarded index [0, 7, 1, 9, 8, 3, 2, 6, 4, 5]\n",
            "10 [0 7 1 9 8 3 2 6 4 5]\n",
            "discarded index [0, 7, 1, 9, 8, 3, 2, 6, 4, 5]\n",
            "10 [0 7 1 9 8 3 2 6 4 5]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 118, bulyan: at fang n_at 10 e 118 | val loss 2.2985 val acc 10.1461 best val_acc 24.391234\n",
            "discarded index [0, 6, 7, 3, 9, 2, 8, 1, 4, 5]\n",
            "10 [0 6 7 3 9 2 8 1 4 5]\n",
            "discarded index [0, 6, 7, 3, 9, 2, 8, 1, 4, 5]\n",
            "10 [0 6 7 3 9 2 8 1 4 5]\n",
            "discarded index [0, 6, 7, 3, 9, 2, 8, 1, 4, 5]\n",
            "10 [0 6 7 3 9 2 8 1 4 5]\n",
            "discarded index [0, 6, 7, 3, 9, 2, 8, 1, 4, 5]\n",
            "10 [0 6 7 3 9 2 8 1 4 5]\n",
            "discarded index [0, 6, 7, 3, 9, 2, 8, 1, 4, 5]\n",
            "10 [0 6 7 3 9 2 8 1 4 5]\n",
            "discarded index [0, 6, 7, 3, 9, 2, 8, 1, 4, 5]\n",
            "10 [0 6 7 3 9 2 8 1 4 5]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 119, bulyan: at fang n_at 10 e 119 | val loss 2.2926 val acc 10.1461 best val_acc 24.391234\n",
            "discarded index [0, 9, 7, 5, 6, 8, 4, 2, 3, 1]\n",
            "10 [0 9 7 5 6 8 4 2 3 1]\n",
            "discarded index [0, 9, 7, 5, 6, 8, 4, 2, 3, 1]\n",
            "10 [0 9 7 5 6 8 4 2 3 1]\n",
            "discarded index [0, 9, 7, 5, 6, 8, 4, 2, 3, 1]\n",
            "10 [0 9 7 5 6 8 4 2 3 1]\n",
            "discarded index [0, 9, 7, 5, 6, 8, 4, 2, 3, 1]\n",
            "10 [0 9 7 5 6 8 4 2 3 1]\n",
            "discarded index [0, 9, 7, 5, 6, 8, 4, 2, 3, 1]\n",
            "10 [0 9 7 5 6 8 4 2 3 1]\n",
            "discarded index [0, 9, 7, 5, 6, 8, 4, 2, 3, 1]\n",
            "10 [0 9 7 5 6 8 4 2 3 1]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 120, bulyan: at fang n_at 10 e 120 | val loss 2.2849 val acc 10.1664 best val_acc 24.391234\n",
            "discarded index [5, 0, 7, 4, 1, 9, 6, 8, 2, 3]\n",
            "10 [5 0 7 4 1 9 6 8 2 3]\n",
            "discarded index [5, 0, 7, 4, 1, 9, 6, 8, 2, 3]\n",
            "10 [5 0 7 4 1 9 6 8 2 3]\n",
            "discarded index [5, 0, 7, 4, 1, 9, 6, 8, 2, 3]\n",
            "10 [5 0 7 4 1 9 6 8 2 3]\n",
            "discarded index [5, 0, 7, 4, 1, 9, 6, 8, 2, 3]\n",
            "10 [5 0 7 4 1 9 6 8 2 3]\n",
            "discarded index [5, 0, 7, 4, 1, 9, 6, 8, 2, 3]\n",
            "10 [5 0 7 4 1 9 6 8 2 3]\n",
            "discarded index [5, 0, 7, 4, 1, 9, 6, 8, 2, 3]\n",
            "10 [5 0 7 4 1 9 6 8 2 3]\n",
            "discarded index [5, 0, 7, 4, 1, 9, 6, 8, 2, 3]\n",
            "10 [5 0 7 4 1 9 6 8 2 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 121, bulyan: at fang n_at 10 e 121 | val loss 2.2740 val acc 10.3084 best val_acc 24.391234\n",
            "discarded index [0, 5, 9, 8, 2, 3, 6, 7, 1, 4]\n",
            "10 [0 5 9 8 2 3 6 7 1 4]\n",
            "discarded index [0, 5, 9, 8, 2, 3, 6, 7, 1, 4]\n",
            "10 [0 5 9 8 2 3 6 7 1 4]\n",
            "discarded index [0, 5, 9, 8, 2, 3, 6, 7, 1, 4]\n",
            "10 [0 5 9 8 2 3 6 7 1 4]\n",
            "discarded index [0, 5, 9, 8, 2, 3, 6, 7, 1, 4]\n",
            "10 [0 5 9 8 2 3 6 7 1 4]\n",
            "discarded index [0, 5, 9, 8, 2, 3, 6, 7, 1, 4]\n",
            "10 [0 5 9 8 2 3 6 7 1 4]\n",
            "discarded index [0, 5, 9, 8, 2, 3, 6, 7, 1, 4]\n",
            "10 [0 5 9 8 2 3 6 7 1 4]\n",
            "discarded index [0, 5, 9, 8, 2, 3, 6, 7, 1, 4]\n",
            "10 [0 5 9 8 2 3 6 7 1 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 122, bulyan: at fang n_at 10 e 122 | val loss 2.2587 val acc 10.7955 best val_acc 24.391234\n",
            "discarded index [0, 5, 7, 2, 8, 4, 6, 1, 9, 3]\n",
            "10 [0 5 7 2 8 4 6 1 9 3]\n",
            "discarded index [0, 5, 7, 2, 8, 4, 6, 1, 9, 3]\n",
            "10 [0 5 7 2 8 4 6 1 9 3]\n",
            "discarded index [0, 5, 7, 2, 8, 4, 6, 1, 9, 3]\n",
            "10 [0 5 7 2 8 4 6 1 9 3]\n",
            "discarded index [0, 5, 7, 2, 8, 4, 6, 1, 9, 3]\n",
            "10 [0 5 7 2 8 4 6 1 9 3]\n",
            "discarded index [0, 5, 7, 2, 8, 4, 6, 1, 9, 3]\n",
            "10 [0 5 7 2 8 4 6 1 9 3]\n",
            "discarded index [0, 5, 7, 2, 8, 4, 6, 1, 9, 3]\n",
            "10 [0 5 7 2 8 4 6 1 9 3]\n",
            "discarded index [0, 5, 7, 2, 8, 4, 6, 1, 9, 3]\n",
            "10 [0 5 7 2 8 4 6 1 9 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 123, bulyan: at fang n_at 10 e 123 | val loss 2.2378 val acc 15.0162 best val_acc 24.391234\n",
            "discarded index [5, 0, 2, 3, 7, 4, 9, 6, 1, 8]\n",
            "10 [5 0 2 3 7 4 9 6 1 8]\n",
            "discarded index [5, 0, 2, 3, 7, 4, 9, 6, 1, 8]\n",
            "10 [5 0 2 3 7 4 9 6 1 8]\n",
            "discarded index [5, 0, 2, 3, 7, 4, 9, 6, 1, 8]\n",
            "10 [5 0 2 3 7 4 9 6 1 8]\n",
            "discarded index [5, 0, 2, 3, 7, 4, 9, 6, 1, 8]\n",
            "10 [5 0 2 3 7 4 9 6 1 8]\n",
            "discarded index [5, 0, 2, 3, 7, 4, 9, 6, 1, 8]\n",
            "10 [5 0 2 3 7 4 9 6 1 8]\n",
            "discarded index [5, 0, 2, 3, 7, 4, 9, 6, 1, 8]\n",
            "10 [5 0 2 3 7 4 9 6 1 8]\n",
            "discarded index [5, 0, 2, 3, 7, 4, 9, 6, 1, 8]\n",
            "10 [5 0 2 3 7 4 9 6 1 8]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 124, bulyan: at fang n_at 10 e 124 | val loss 2.2120 val acc 16.3961 best val_acc 24.391234\n",
            "discarded index [5, 1, 6, 0, 3, 9, 4, 2, 8, 7]\n",
            "10 [5 1 6 0 3 9 4 2 8 7]\n",
            "discarded index [5, 1, 6, 0, 3, 9, 4, 2, 8, 7]\n",
            "10 [5 1 6 0 3 9 4 2 8 7]\n",
            "discarded index [5, 1, 6, 0, 3, 9, 4, 2, 8, 7]\n",
            "10 [5 1 6 0 3 9 4 2 8 7]\n",
            "discarded index [5, 1, 6, 0, 3, 9, 4, 2, 8, 7]\n",
            "10 [5 1 6 0 3 9 4 2 8 7]\n",
            "discarded index [5, 1, 6, 0, 3, 9, 4, 2, 8, 7]\n",
            "10 [5 1 6 0 3 9 4 2 8 7]\n",
            "discarded index [5, 1, 6, 0, 3, 9, 4, 2, 8, 7]\n",
            "10 [5 1 6 0 3 9 4 2 8 7]\n",
            "discarded index [5, 1, 6, 0, 3, 9, 4, 2, 8, 7]\n",
            "10 [5 1 6 0 3 9 4 2 8 7]\n",
            "discarded index [5, 1, 6, 0, 3, 9, 4, 2, 8, 7]\n",
            "10 [5 1 6 0 3 9 4 2 8 7]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 125, bulyan: at fang n_at 10 e 125 | val loss 2.1886 val acc 16.8628 best val_acc 24.391234\n",
            "discarded index [6, 2, 5, 3, 1, 7, 9, 4, 0, 8]\n",
            "10 [6 2 5 3 1 7 9 4 0 8]\n",
            "discarded index [6, 2, 5, 3, 1, 7, 9, 4, 0, 8]\n",
            "10 [6 2 5 3 1 7 9 4 0 8]\n",
            "discarded index [6, 2, 5, 3, 1, 7, 9, 4, 0, 8]\n",
            "10 [6 2 5 3 1 7 9 4 0 8]\n",
            "discarded index [6, 2, 5, 3, 1, 7, 9, 4, 0, 8]\n",
            "10 [6 2 5 3 1 7 9 4 0 8]\n",
            "discarded index [6, 2, 5, 3, 1, 7, 9, 4, 0, 8]\n",
            "10 [6 2 5 3 1 7 9 4 0 8]\n",
            "discarded index [6, 2, 5, 3, 1, 7, 9, 4, 0, 8]\n",
            "10 [6 2 5 3 1 7 9 4 0 8]\n",
            "discarded index [6, 2, 5, 3, 1, 7, 9, 4, 0, 8]\n",
            "10 [6 2 5 3 1 7 9 4 0 8]\n",
            "discarded index [6, 2, 5, 3, 1, 7, 9, 4, 0, 8]\n",
            "10 [6 2 5 3 1 7 9 4 0 8]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 126, bulyan: at fang n_at 10 e 126 | val loss 2.1706 val acc 16.1729 best val_acc 24.391234\n",
            "discarded index [5, 4, 6, 7, 8, 0, 2, 1, 9, 3]\n",
            "10 [5 4 6 7 8 0 2 1 9 3]\n",
            "discarded index [5, 4, 6, 7, 8, 0, 2, 1, 9, 3]\n",
            "10 [5 4 6 7 8 0 2 1 9 3]\n",
            "discarded index [5, 4, 6, 7, 8, 0, 2, 1, 9, 3]\n",
            "10 [5 4 6 7 8 0 2 1 9 3]\n",
            "discarded index [5, 4, 6, 7, 8, 0, 2, 1, 9, 3]\n",
            "10 [5 4 6 7 8 0 2 1 9 3]\n",
            "discarded index [5, 4, 6, 7, 8, 0, 2, 1, 9, 3]\n",
            "10 [5 4 6 7 8 0 2 1 9 3]\n",
            "discarded index [5, 4, 6, 7, 8, 0, 2, 1, 9, 3]\n",
            "10 [5 4 6 7 8 0 2 1 9 3]\n",
            "discarded index [5, 4, 6, 7, 8, 0, 2, 1, 9, 3]\n",
            "10 [5 4 6 7 8 0 2 1 9 3]\n",
            "discarded index [5, 4, 6, 7, 8, 0, 2, 1, 9, 3]\n",
            "10 [5 4 6 7 8 0 2 1 9 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 127, bulyan: at fang n_at 10 e 127 | val loss 2.1549 val acc 16.4367 best val_acc 24.391234\n",
            "discarded index [5, 6, 1, 3, 4, 7, 8, 2, 9, 0]\n",
            "10 [5 6 1 3 4 7 8 2 9 0]\n",
            "discarded index [5, 6, 1, 3, 4, 7, 8, 2, 9, 0]\n",
            "10 [5 6 1 3 4 7 8 2 9 0]\n",
            "discarded index [5, 6, 1, 3, 4, 7, 8, 2, 9, 0]\n",
            "10 [5 6 1 3 4 7 8 2 9 0]\n",
            "discarded index [5, 6, 1, 3, 4, 7, 8, 2, 9, 0]\n",
            "10 [5 6 1 3 4 7 8 2 9 0]\n",
            "discarded index [5, 6, 1, 3, 4, 7, 8, 2, 9, 0]\n",
            "10 [5 6 1 3 4 7 8 2 9 0]\n",
            "discarded index [5, 6, 1, 3, 4, 7, 8, 2, 9, 0]\n",
            "10 [5 6 1 3 4 7 8 2 9 0]\n",
            "discarded index [5, 6, 1, 3, 4, 7, 8, 2, 9, 0]\n",
            "10 [5 6 1 3 4 7 8 2 9 0]\n",
            "discarded index [5, 6, 1, 3, 4, 7, 8, 2, 9, 0]\n",
            "10 [5 6 1 3 4 7 8 2 9 0]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 128, bulyan: at fang n_at 10 e 128 | val loss 2.1391 val acc 16.9440 best val_acc 24.391234\n",
            "discarded index [6, 5, 2, 4, 3, 1, 9, 7, 0, 8]\n",
            "10 [6 5 2 4 3 1 9 7 0 8]\n",
            "discarded index [6, 5, 2, 4, 3, 1, 9, 7, 0, 8]\n",
            "10 [6 5 2 4 3 1 9 7 0 8]\n",
            "discarded index [6, 5, 2, 4, 3, 1, 9, 7, 0, 8]\n",
            "10 [6 5 2 4 3 1 9 7 0 8]\n",
            "discarded index [6, 5, 2, 4, 3, 1, 9, 7, 0, 8]\n",
            "10 [6 5 2 4 3 1 9 7 0 8]\n",
            "discarded index [6, 5, 2, 4, 3, 1, 9, 7, 0, 8]\n",
            "10 [6 5 2 4 3 1 9 7 0 8]\n",
            "discarded index [6, 5, 2, 4, 3, 1, 9, 7, 0, 8]\n",
            "10 [6 5 2 4 3 1 9 7 0 8]\n",
            "discarded index [6, 5, 2, 4, 3, 1, 9, 7, 0, 8]\n",
            "10 [6 5 2 4 3 1 9 7 0 8]\n",
            "discarded index [6, 5, 2, 4, 3, 1, 9, 7, 0, 8]\n",
            "10 [6 5 2 4 3 1 9 7 0 8]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 129, bulyan: at fang n_at 10 e 129 | val loss 2.1224 val acc 16.9440 best val_acc 24.391234\n",
            "discarded index [7, 6, 4, 8, 9, 0, 1, 5, 2, 3]\n",
            "10 [7 6 4 8 9 0 1 5 2 3]\n",
            "discarded index [7, 6, 4, 8, 9, 0, 1, 5, 2, 3]\n",
            "10 [7 6 4 8 9 0 1 5 2 3]\n",
            "discarded index [7, 6, 4, 8, 9, 0, 1, 5, 2, 3]\n",
            "10 [7 6 4 8 9 0 1 5 2 3]\n",
            "discarded index [7, 6, 4, 8, 9, 0, 1, 5, 2, 3]\n",
            "10 [7 6 4 8 9 0 1 5 2 3]\n",
            "discarded index [7, 6, 4, 8, 9, 0, 1, 5, 2, 3]\n",
            "10 [7 6 4 8 9 0 1 5 2 3]\n",
            "discarded index [7, 6, 4, 8, 9, 0, 1, 5, 2, 3]\n",
            "10 [7 6 4 8 9 0 1 5 2 3]\n",
            "discarded index [7, 6, 4, 8, 9, 0, 1, 5, 2, 3]\n",
            "10 [7 6 4 8 9 0 1 5 2 3]\n",
            "discarded index [7, 6, 4, 8, 9, 0, 1, 5, 2, 3]\n",
            "10 [7 6 4 8 9 0 1 5 2 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 130, bulyan: at fang n_at 10 e 130 | val loss 2.1016 val acc 18.5471 best val_acc 24.391234\n",
            "discarded index [6, 1, 4, 8, 5, 0, 7, 9, 3, 2]\n",
            "10 [6 1 4 8 5 0 7 9 3 2]\n",
            "discarded index [6, 1, 4, 8, 5, 0, 7, 9, 3, 2]\n",
            "10 [6 1 4 8 5 0 7 9 3 2]\n",
            "discarded index [6, 1, 4, 8, 5, 0, 7, 9, 3, 2]\n",
            "10 [6 1 4 8 5 0 7 9 3 2]\n",
            "discarded index [6, 1, 4, 8, 5, 0, 7, 9, 3, 2]\n",
            "10 [6 1 4 8 5 0 7 9 3 2]\n",
            "discarded index [6, 1, 4, 8, 5, 0, 7, 9, 3, 2]\n",
            "10 [6 1 4 8 5 0 7 9 3 2]\n",
            "discarded index [6, 1, 4, 8, 5, 0, 7, 9, 3, 2]\n",
            "10 [6 1 4 8 5 0 7 9 3 2]\n",
            "discarded index [6, 1, 4, 8, 5, 0, 7, 9, 3, 2]\n",
            "10 [6 1 4 8 5 0 7 9 3 2]\n",
            "discarded index [6, 1, 4, 8, 5, 0, 7, 9, 3, 2]\n",
            "10 [6 1 4 8 5 0 7 9 3 2]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 131, bulyan: at fang n_at 10 e 131 | val loss 2.0846 val acc 17.1063 best val_acc 24.391234\n",
            "discarded index [6, 2, 8, 4, 9, 7, 1, 5, 3, 0]\n",
            "10 [6 2 8 4 9 7 1 5 3 0]\n",
            "discarded index [6, 2, 8, 4, 9, 7, 1, 5, 3, 0]\n",
            "10 [6 2 8 4 9 7 1 5 3 0]\n",
            "discarded index [6, 2, 8, 4, 9, 7, 1, 5, 3, 0]\n",
            "10 [6 2 8 4 9 7 1 5 3 0]\n",
            "discarded index [6, 2, 8, 4, 9, 7, 1, 5, 3, 0]\n",
            "10 [6 2 8 4 9 7 1 5 3 0]\n",
            "discarded index [6, 2, 8, 4, 9, 7, 1, 5, 3, 0]\n",
            "10 [6 2 8 4 9 7 1 5 3 0]\n",
            "discarded index [6, 2, 8, 4, 9, 7, 1, 5, 3, 0]\n",
            "10 [6 2 8 4 9 7 1 5 3 0]\n",
            "discarded index [6, 2, 8, 4, 9, 7, 1, 5, 3, 0]\n",
            "10 [6 2 8 4 9 7 1 5 3 0]\n",
            "discarded index [6, 2, 8, 4, 9, 7, 1, 5, 3, 0]\n",
            "10 [6 2 8 4 9 7 1 5 3 0]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 132, bulyan: at fang n_at 10 e 132 | val loss 2.0639 val acc 19.5211 best val_acc 24.391234\n",
            "discarded index [6, 2, 9, 7, 8, 3, 5, 0, 4, 1]\n",
            "10 [6 2 9 7 8 3 5 0 4 1]\n",
            "discarded index [6, 2, 9, 7, 8, 3, 5, 0, 4, 1]\n",
            "10 [6 2 9 7 8 3 5 0 4 1]\n",
            "discarded index [6, 2, 9, 7, 8, 3, 5, 0, 4, 1]\n",
            "10 [6 2 9 7 8 3 5 0 4 1]\n",
            "discarded index [6, 2, 9, 7, 8, 3, 5, 0, 4, 1]\n",
            "10 [6 2 9 7 8 3 5 0 4 1]\n",
            "discarded index [6, 2, 9, 7, 8, 3, 5, 0, 4, 1]\n",
            "10 [6 2 9 7 8 3 5 0 4 1]\n",
            "discarded index [6, 2, 9, 7, 8, 3, 5, 0, 4, 1]\n",
            "10 [6 2 9 7 8 3 5 0 4 1]\n",
            "discarded index [6, 2, 9, 7, 8, 3, 5, 0, 4, 1]\n",
            "10 [6 2 9 7 8 3 5 0 4 1]\n",
            "discarded index [6, 2, 9, 7, 8, 3, 5, 0, 4, 1]\n",
            "10 [6 2 9 7 8 3 5 0 4 1]\n",
            "discarded index [6, 2, 9, 7, 8, 3, 5, 0, 4, 1]\n",
            "10 [6 2 9 7 8 3 5 0 4 1]\n",
            "lamda < threshold\n",
            "discarded index [20, 0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
            "epoch: 133, bulyan: at fang n_at 10 e 133 | val loss 2.0861 val acc 16.9034 best val_acc 24.391234\n",
            "discarded index [6, 0, 1, 3, 5, 2, 7, 8, 9, 4]\n",
            "10 [6 0 1 3 5 2 7 8 9 4]\n",
            "discarded index [6, 0, 1, 3, 5, 2, 7, 8, 9, 4]\n",
            "10 [6 0 1 3 5 2 7 8 9 4]\n",
            "discarded index [6, 0, 1, 3, 5, 2, 7, 8, 9, 4]\n",
            "10 [6 0 1 3 5 2 7 8 9 4]\n",
            "discarded index [6, 0, 1, 3, 5, 2, 7, 8, 9, 4]\n",
            "10 [6 0 1 3 5 2 7 8 9 4]\n",
            "discarded index [6, 0, 1, 3, 5, 2, 7, 8, 9, 4]\n",
            "10 [6 0 1 3 5 2 7 8 9 4]\n",
            "discarded index [6, 0, 1, 3, 5, 2, 7, 8, 9, 4]\n",
            "10 [6 0 1 3 5 2 7 8 9 4]\n",
            "discarded index [6, 0, 1, 3, 5, 2, 7, 8, 9, 4]\n",
            "10 [6 0 1 3 5 2 7 8 9 4]\n",
            "discarded index [6, 0, 1, 3, 5, 2, 7, 8, 9, 4]\n",
            "10 [6 0 1 3 5 2 7 8 9 4]\n",
            "discarded index [6, 0, 1, 3, 5, 2, 7, 8, 9, 4]\n",
            "10 [6 0 1 3 5 2 7 8 9 4]\n",
            "lamda < threshold\n",
            "discarded index [20, 0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
            "epoch: 134, bulyan: at fang n_at 10 e 134 | val loss 2.1743 val acc 17.4513 best val_acc 24.391234\n",
            "discarded index [20, 9, 4, 7, 6, 2, 8, 1, 3, 5]\n",
            "9 [20  9  4  7  6  2  8  1  3  5]\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 135, bulyan: at fang n_at 10 e 135 | val loss 2.1902 val acc 17.1266 best val_acc 24.391234\n",
            "discarded index [0, 1, 4, 6, 9, 2, 8, 3, 7, 5]\n",
            "10 [0 1 4 6 9 2 8 3 7 5]\n",
            "discarded index [0, 1, 4, 6, 9, 2, 8, 3, 7, 5]\n",
            "10 [0 1 4 6 9 2 8 3 7 5]\n",
            "discarded index [0, 1, 4, 6, 9, 2, 8, 3, 7, 5]\n",
            "10 [0 1 4 6 9 2 8 3 7 5]\n",
            "discarded index [0, 1, 4, 6, 9, 2, 8, 3, 7, 5]\n",
            "10 [0 1 4 6 9 2 8 3 7 5]\n",
            "discarded index [0, 1, 4, 6, 9, 2, 8, 3, 7, 5]\n",
            "10 [0 1 4 6 9 2 8 3 7 5]\n",
            "discarded index [0, 1, 4, 6, 9, 2, 8, 3, 7, 5]\n",
            "10 [0 1 4 6 9 2 8 3 7 5]\n",
            "discarded index [0, 1, 4, 6, 9, 2, 8, 3, 7, 5]\n",
            "10 [0 1 4 6 9 2 8 3 7 5]\n",
            "discarded index [0, 1, 4, 6, 9, 2, 8, 3, 7, 5]\n",
            "10 [0 1 4 6 9 2 8 3 7 5]\n",
            "discarded index [0, 1, 4, 6, 9, 2, 8, 3, 7, 5]\n",
            "10 [0 1 4 6 9 2 8 3 7 5]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 136, bulyan: at fang n_at 10 e 136 | val loss 2.2424 val acc 11.0795 best val_acc 24.391234\n",
            "discarded index [0, 5, 9, 6, 1, 8, 4, 7, 3, 2]\n",
            "10 [0 5 9 6 1 8 4 7 3 2]\n",
            "discarded index [0, 5, 9, 6, 1, 8, 4, 7, 3, 2]\n",
            "10 [0 5 9 6 1 8 4 7 3 2]\n",
            "discarded index [0, 5, 9, 6, 1, 8, 4, 7, 3, 2]\n",
            "10 [0 5 9 6 1 8 4 7 3 2]\n",
            "discarded index [0, 5, 9, 6, 1, 8, 4, 7, 3, 2]\n",
            "10 [0 5 9 6 1 8 4 7 3 2]\n",
            "discarded index [0, 5, 9, 6, 1, 8, 4, 7, 3, 2]\n",
            "10 [0 5 9 6 1 8 4 7 3 2]\n",
            "discarded index [0, 5, 9, 6, 1, 8, 4, 7, 3, 2]\n",
            "10 [0 5 9 6 1 8 4 7 3 2]\n",
            "discarded index [0, 5, 9, 6, 1, 8, 4, 7, 3, 2]\n",
            "10 [0 5 9 6 1 8 4 7 3 2]\n",
            "discarded index [0, 5, 9, 6, 1, 8, 4, 7, 3, 2]\n",
            "10 [0 5 9 6 1 8 4 7 3 2]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 137, bulyan: at fang n_at 10 e 137 | val loss 2.2011 val acc 15.5032 best val_acc 24.391234\n",
            "discarded index [0, 7, 2, 3, 1, 4, 8, 5, 9, 6]\n",
            "10 [0 7 2 3 1 4 8 5 9 6]\n",
            "discarded index [0, 7, 2, 3, 1, 4, 8, 5, 9, 6]\n",
            "10 [0 7 2 3 1 4 8 5 9 6]\n",
            "discarded index [0, 7, 2, 3, 1, 4, 8, 5, 9, 6]\n",
            "10 [0 7 2 3 1 4 8 5 9 6]\n",
            "discarded index [0, 7, 2, 3, 1, 4, 8, 5, 9, 6]\n",
            "10 [0 7 2 3 1 4 8 5 9 6]\n",
            "discarded index [0, 7, 2, 3, 1, 4, 8, 5, 9, 6]\n",
            "10 [0 7 2 3 1 4 8 5 9 6]\n",
            "discarded index [0, 7, 2, 3, 1, 4, 8, 5, 9, 6]\n",
            "10 [0 7 2 3 1 4 8 5 9 6]\n",
            "discarded index [0, 7, 2, 3, 1, 4, 8, 5, 9, 6]\n",
            "10 [0 7 2 3 1 4 8 5 9 6]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 138, bulyan: at fang n_at 10 e 138 | val loss 2.1530 val acc 18.2833 best val_acc 24.391234\n",
            "discarded index [0, 6, 9, 1, 2, 3, 5, 4, 8, 7]\n",
            "10 [0 6 9 1 2 3 5 4 8 7]\n",
            "discarded index [0, 6, 9, 1, 2, 3, 5, 4, 8, 7]\n",
            "10 [0 6 9 1 2 3 5 4 8 7]\n",
            "discarded index [0, 6, 9, 1, 2, 3, 5, 4, 8, 7]\n",
            "10 [0 6 9 1 2 3 5 4 8 7]\n",
            "discarded index [0, 6, 9, 1, 2, 3, 5, 4, 8, 7]\n",
            "10 [0 6 9 1 2 3 5 4 8 7]\n",
            "discarded index [0, 6, 9, 1, 2, 3, 5, 4, 8, 7]\n",
            "10 [0 6 9 1 2 3 5 4 8 7]\n",
            "discarded index [0, 6, 9, 1, 2, 3, 5, 4, 8, 7]\n",
            "10 [0 6 9 1 2 3 5 4 8 7]\n",
            "discarded index [0, 6, 9, 1, 2, 3, 5, 4, 8, 7]\n",
            "10 [0 6 9 1 2 3 5 4 8 7]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 139, bulyan: at fang n_at 10 e 139 | val loss 2.1139 val acc 18.6080 best val_acc 24.391234\n",
            "discarded index [0, 6, 9, 1, 4, 8, 5, 7, 2, 3]\n",
            "10 [0 6 9 1 4 8 5 7 2 3]\n",
            "discarded index [0, 6, 9, 1, 4, 8, 5, 7, 2, 3]\n",
            "10 [0 6 9 1 4 8 5 7 2 3]\n",
            "discarded index [0, 6, 9, 1, 4, 8, 5, 7, 2, 3]\n",
            "10 [0 6 9 1 4 8 5 7 2 3]\n",
            "discarded index [0, 6, 9, 1, 4, 8, 5, 7, 2, 3]\n",
            "10 [0 6 9 1 4 8 5 7 2 3]\n",
            "discarded index [0, 6, 9, 1, 4, 8, 5, 7, 2, 3]\n",
            "10 [0 6 9 1 4 8 5 7 2 3]\n",
            "discarded index [0, 6, 9, 1, 4, 8, 5, 7, 2, 3]\n",
            "10 [0 6 9 1 4 8 5 7 2 3]\n",
            "discarded index [0, 6, 9, 1, 4, 8, 5, 7, 2, 3]\n",
            "10 [0 6 9 1 4 8 5 7 2 3]\n",
            "discarded index [0, 6, 9, 1, 4, 8, 5, 7, 2, 3]\n",
            "10 [0 6 9 1 4 8 5 7 2 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 140, bulyan: at fang n_at 10 e 140 | val loss 2.0872 val acc 18.3239 best val_acc 24.391234\n",
            "discarded index [0, 6, 2, 4, 9, 8, 1, 3, 7, 5]\n",
            "10 [0 6 2 4 9 8 1 3 7 5]\n",
            "discarded index [0, 6, 2, 4, 9, 8, 1, 3, 7, 5]\n",
            "10 [0 6 2 4 9 8 1 3 7 5]\n",
            "discarded index [0, 6, 2, 4, 9, 8, 1, 3, 7, 5]\n",
            "10 [0 6 2 4 9 8 1 3 7 5]\n",
            "discarded index [0, 6, 2, 4, 9, 8, 1, 3, 7, 5]\n",
            "10 [0 6 2 4 9 8 1 3 7 5]\n",
            "discarded index [0, 6, 2, 4, 9, 8, 1, 3, 7, 5]\n",
            "10 [0 6 2 4 9 8 1 3 7 5]\n",
            "discarded index [0, 6, 2, 4, 9, 8, 1, 3, 7, 5]\n",
            "10 [0 6 2 4 9 8 1 3 7 5]\n",
            "discarded index [0, 6, 2, 4, 9, 8, 1, 3, 7, 5]\n",
            "10 [0 6 2 4 9 8 1 3 7 5]\n",
            "discarded index [0, 6, 2, 4, 9, 8, 1, 3, 7, 5]\n",
            "10 [0 6 2 4 9 8 1 3 7 5]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 141, bulyan: at fang n_at 10 e 141 | val loss 2.0594 val acc 18.3442 best val_acc 24.391234\n",
            "discarded index [6, 7, 9, 8, 4, 5, 0, 3, 2, 1]\n",
            "10 [6 7 9 8 4 5 0 3 2 1]\n",
            "discarded index [6, 7, 9, 8, 4, 5, 0, 3, 2, 1]\n",
            "10 [6 7 9 8 4 5 0 3 2 1]\n",
            "discarded index [6, 7, 9, 8, 4, 5, 0, 3, 2, 1]\n",
            "10 [6 7 9 8 4 5 0 3 2 1]\n",
            "discarded index [6, 7, 9, 8, 4, 5, 0, 3, 2, 1]\n",
            "10 [6 7 9 8 4 5 0 3 2 1]\n",
            "discarded index [6, 7, 9, 8, 4, 5, 0, 3, 2, 1]\n",
            "10 [6 7 9 8 4 5 0 3 2 1]\n",
            "discarded index [6, 7, 9, 8, 4, 5, 0, 3, 2, 1]\n",
            "10 [6 7 9 8 4 5 0 3 2 1]\n",
            "discarded index [6, 7, 9, 8, 4, 5, 0, 3, 2, 1]\n",
            "10 [6 7 9 8 4 5 0 3 2 1]\n",
            "discarded index [6, 7, 9, 8, 4, 5, 0, 3, 2, 1]\n",
            "10 [6 7 9 8 4 5 0 3 2 1]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 142, bulyan: at fang n_at 10 e 142 | val loss 2.0480 val acc 17.4513 best val_acc 24.391234\n",
            "discarded index [0, 1, 6, 4, 8, 9, 2, 5, 7, 3]\n",
            "10 [0 1 6 4 8 9 2 5 7 3]\n",
            "discarded index [0, 1, 6, 4, 8, 9, 2, 5, 7, 3]\n",
            "10 [0 1 6 4 8 9 2 5 7 3]\n",
            "discarded index [0, 1, 6, 4, 8, 9, 2, 5, 7, 3]\n",
            "10 [0 1 6 4 8 9 2 5 7 3]\n",
            "discarded index [0, 1, 6, 4, 8, 9, 2, 5, 7, 3]\n",
            "10 [0 1 6 4 8 9 2 5 7 3]\n",
            "discarded index [0, 1, 6, 4, 8, 9, 2, 5, 7, 3]\n",
            "10 [0 1 6 4 8 9 2 5 7 3]\n",
            "discarded index [0, 1, 6, 4, 8, 9, 2, 5, 7, 3]\n",
            "10 [0 1 6 4 8 9 2 5 7 3]\n",
            "discarded index [0, 1, 6, 4, 8, 9, 2, 5, 7, 3]\n",
            "10 [0 1 6 4 8 9 2 5 7 3]\n",
            "discarded index [0, 1, 6, 4, 8, 9, 2, 5, 7, 3]\n",
            "10 [0 1 6 4 8 9 2 5 7 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 143, bulyan: at fang n_at 10 e 143 | val loss 2.0341 val acc 18.8312 best val_acc 24.391234\n",
            "discarded index [9, 8, 4, 2, 3, 0, 7, 5, 6, 1]\n",
            "10 [9 8 4 2 3 0 7 5 6 1]\n",
            "discarded index [9, 8, 4, 2, 3, 0, 7, 5, 6, 1]\n",
            "10 [9 8 4 2 3 0 7 5 6 1]\n",
            "discarded index [9, 8, 4, 2, 3, 0, 7, 5, 6, 1]\n",
            "10 [9 8 4 2 3 0 7 5 6 1]\n",
            "discarded index [9, 8, 4, 2, 3, 0, 7, 5, 6, 1]\n",
            "10 [9 8 4 2 3 0 7 5 6 1]\n",
            "discarded index [9, 8, 4, 2, 3, 0, 7, 5, 6, 1]\n",
            "10 [9 8 4 2 3 0 7 5 6 1]\n",
            "discarded index [9, 8, 4, 2, 3, 0, 7, 5, 6, 1]\n",
            "10 [9 8 4 2 3 0 7 5 6 1]\n",
            "discarded index [9, 8, 4, 2, 3, 0, 7, 5, 6, 1]\n",
            "10 [9 8 4 2 3 0 7 5 6 1]\n",
            "discarded index [9, 8, 4, 2, 3, 0, 7, 5, 6, 1]\n",
            "10 [9 8 4 2 3 0 7 5 6 1]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 144, bulyan: at fang n_at 10 e 144 | val loss 2.1411 val acc 15.0162 best val_acc 24.391234\n",
            "discarded index [6, 5, 7, 9, 4, 8, 0, 3, 2, 1]\n",
            "10 [6 5 7 9 4 8 0 3 2 1]\n",
            "discarded index [6, 5, 7, 9, 4, 8, 0, 3, 2, 1]\n",
            "10 [6 5 7 9 4 8 0 3 2 1]\n",
            "discarded index [6, 5, 7, 9, 4, 8, 0, 3, 2, 1]\n",
            "10 [6 5 7 9 4 8 0 3 2 1]\n",
            "discarded index [6, 5, 7, 9, 4, 8, 0, 3, 2, 1]\n",
            "10 [6 5 7 9 4 8 0 3 2 1]\n",
            "discarded index [6, 5, 7, 9, 4, 8, 0, 3, 2, 1]\n",
            "10 [6 5 7 9 4 8 0 3 2 1]\n",
            "discarded index [6, 5, 7, 9, 4, 8, 0, 3, 2, 1]\n",
            "10 [6 5 7 9 4 8 0 3 2 1]\n",
            "discarded index [6, 5, 7, 9, 4, 8, 0, 3, 2, 1]\n",
            "10 [6 5 7 9 4 8 0 3 2 1]\n",
            "discarded index [6, 5, 7, 9, 4, 8, 0, 3, 2, 1]\n",
            "10 [6 5 7 9 4 8 0 3 2 1]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 145, bulyan: at fang n_at 10 e 145 | val loss 2.2273 val acc 16.3149 best val_acc 24.391234\n",
            "discarded index [5, 4, 0, 1, 7, 8, 2, 3, 9, 6]\n",
            "10 [5 4 0 1 7 8 2 3 9 6]\n",
            "discarded index [5, 4, 0, 1, 7, 8, 2, 3, 9, 6]\n",
            "10 [5 4 0 1 7 8 2 3 9 6]\n",
            "discarded index [5, 4, 0, 1, 7, 8, 2, 3, 9, 6]\n",
            "10 [5 4 0 1 7 8 2 3 9 6]\n",
            "discarded index [5, 4, 0, 1, 7, 8, 2, 3, 9, 6]\n",
            "10 [5 4 0 1 7 8 2 3 9 6]\n",
            "discarded index [5, 4, 0, 1, 7, 8, 2, 3, 9, 6]\n",
            "10 [5 4 0 1 7 8 2 3 9 6]\n",
            "discarded index [5, 4, 0, 1, 7, 8, 2, 3, 9, 6]\n",
            "10 [5 4 0 1 7 8 2 3 9 6]\n",
            "discarded index [5, 4, 0, 1, 7, 8, 2, 3, 9, 6]\n",
            "10 [5 4 0 1 7 8 2 3 9 6]\n",
            "discarded index [5, 4, 0, 1, 7, 8, 2, 3, 9, 6]\n",
            "10 [5 4 0 1 7 8 2 3 9 6]\n",
            "discarded index [5, 4, 0, 1, 7, 8, 2, 3, 9, 6]\n",
            "10 [5 4 0 1 7 8 2 3 9 6]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 146, bulyan: at fang n_at 10 e 146 | val loss 2.1418 val acc 17.8977 best val_acc 24.391234\n",
            "discarded index [4, 8, 0, 6, 3, 5, 9, 7, 1, 2]\n",
            "10 [4 8 0 6 3 5 9 7 1 2]\n",
            "discarded index [4, 8, 0, 6, 3, 5, 9, 7, 1, 2]\n",
            "10 [4 8 0 6 3 5 9 7 1 2]\n",
            "discarded index [4, 8, 0, 6, 3, 5, 9, 7, 1, 2]\n",
            "10 [4 8 0 6 3 5 9 7 1 2]\n",
            "discarded index [4, 8, 0, 6, 3, 5, 9, 7, 1, 2]\n",
            "10 [4 8 0 6 3 5 9 7 1 2]\n",
            "discarded index [4, 8, 0, 6, 3, 5, 9, 7, 1, 2]\n",
            "10 [4 8 0 6 3 5 9 7 1 2]\n",
            "discarded index [4, 8, 0, 6, 3, 5, 9, 7, 1, 2]\n",
            "10 [4 8 0 6 3 5 9 7 1 2]\n",
            "discarded index [4, 8, 0, 6, 3, 5, 9, 7, 1, 2]\n",
            "10 [4 8 0 6 3 5 9 7 1 2]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 147, bulyan: at fang n_at 10 e 147 | val loss 2.1078 val acc 17.4513 best val_acc 24.391234\n",
            "discarded index [5, 6, 7, 4, 8, 9, 0, 3, 1, 2]\n",
            "10 [5 6 7 4 8 9 0 3 1 2]\n",
            "discarded index [5, 6, 7, 4, 8, 9, 0, 3, 1, 2]\n",
            "10 [5 6 7 4 8 9 0 3 1 2]\n",
            "discarded index [5, 6, 7, 4, 8, 9, 0, 3, 1, 2]\n",
            "10 [5 6 7 4 8 9 0 3 1 2]\n",
            "discarded index [5, 6, 7, 4, 8, 9, 0, 3, 1, 2]\n",
            "10 [5 6 7 4 8 9 0 3 1 2]\n",
            "discarded index [5, 6, 7, 4, 8, 9, 0, 3, 1, 2]\n",
            "10 [5 6 7 4 8 9 0 3 1 2]\n",
            "discarded index [5, 6, 7, 4, 8, 9, 0, 3, 1, 2]\n",
            "10 [5 6 7 4 8 9 0 3 1 2]\n",
            "discarded index [5, 6, 7, 4, 8, 9, 0, 3, 1, 2]\n",
            "10 [5 6 7 4 8 9 0 3 1 2]\n",
            "discarded index [5, 6, 7, 4, 8, 9, 0, 3, 1, 2]\n",
            "10 [5 6 7 4 8 9 0 3 1 2]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 148, bulyan: at fang n_at 10 e 148 | val loss 2.0722 val acc 18.6688 best val_acc 24.391234\n",
            "discarded index [6, 1, 5, 0, 7, 4, 9, 3, 8, 2]\n",
            "10 [6 1 5 0 7 4 9 3 8 2]\n",
            "discarded index [6, 1, 5, 0, 7, 4, 9, 3, 8, 2]\n",
            "10 [6 1 5 0 7 4 9 3 8 2]\n",
            "discarded index [6, 1, 5, 0, 7, 4, 9, 3, 8, 2]\n",
            "10 [6 1 5 0 7 4 9 3 8 2]\n",
            "discarded index [6, 1, 5, 0, 7, 4, 9, 3, 8, 2]\n",
            "10 [6 1 5 0 7 4 9 3 8 2]\n",
            "discarded index [6, 1, 5, 0, 7, 4, 9, 3, 8, 2]\n",
            "10 [6 1 5 0 7 4 9 3 8 2]\n",
            "discarded index [6, 1, 5, 0, 7, 4, 9, 3, 8, 2]\n",
            "10 [6 1 5 0 7 4 9 3 8 2]\n",
            "discarded index [6, 1, 5, 0, 7, 4, 9, 3, 8, 2]\n",
            "10 [6 1 5 0 7 4 9 3 8 2]\n",
            "discarded index [6, 1, 5, 0, 7, 4, 9, 3, 8, 2]\n",
            "10 [6 1 5 0 7 4 9 3 8 2]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 149, bulyan: at fang n_at 10 e 149 | val loss 2.0426 val acc 18.1615 best val_acc 24.391234\n",
            "discarded index [6, 4, 8, 5, 3, 2, 7, 1, 9, 0]\n",
            "10 [6 4 8 5 3 2 7 1 9 0]\n",
            "discarded index [6, 4, 8, 5, 3, 2, 7, 1, 9, 0]\n",
            "10 [6 4 8 5 3 2 7 1 9 0]\n",
            "discarded index [6, 4, 8, 5, 3, 2, 7, 1, 9, 0]\n",
            "10 [6 4 8 5 3 2 7 1 9 0]\n",
            "discarded index [6, 4, 8, 5, 3, 2, 7, 1, 9, 0]\n",
            "10 [6 4 8 5 3 2 7 1 9 0]\n",
            "discarded index [6, 4, 8, 5, 3, 2, 7, 1, 9, 0]\n",
            "10 [6 4 8 5 3 2 7 1 9 0]\n",
            "discarded index [6, 4, 8, 5, 3, 2, 7, 1, 9, 0]\n",
            "10 [6 4 8 5 3 2 7 1 9 0]\n",
            "discarded index [6, 4, 8, 5, 3, 2, 7, 1, 9, 0]\n",
            "10 [6 4 8 5 3 2 7 1 9 0]\n",
            "discarded index [6, 4, 8, 5, 3, 2, 7, 1, 9, 0]\n",
            "10 [6 4 8 5 3 2 7 1 9 0]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 150, bulyan: at fang n_at 10 e 150 | val loss 2.0280 val acc 20.3734 best val_acc 24.391234\n",
            "discarded index [6, 0, 9, 4, 8, 5, 1, 2, 7, 3]\n",
            "10 [6 0 9 4 8 5 1 2 7 3]\n",
            "discarded index [6, 0, 9, 4, 8, 5, 1, 2, 7, 3]\n",
            "10 [6 0 9 4 8 5 1 2 7 3]\n",
            "discarded index [6, 0, 9, 4, 8, 5, 1, 2, 7, 3]\n",
            "10 [6 0 9 4 8 5 1 2 7 3]\n",
            "discarded index [6, 0, 9, 4, 8, 5, 1, 2, 7, 3]\n",
            "10 [6 0 9 4 8 5 1 2 7 3]\n",
            "discarded index [6, 0, 9, 4, 8, 5, 1, 2, 7, 3]\n",
            "10 [6 0 9 4 8 5 1 2 7 3]\n",
            "discarded index [6, 0, 9, 4, 8, 5, 1, 2, 7, 3]\n",
            "10 [6 0 9 4 8 5 1 2 7 3]\n",
            "discarded index [6, 0, 9, 4, 8, 5, 1, 2, 7, 3]\n",
            "10 [6 0 9 4 8 5 1 2 7 3]\n",
            "discarded index [6, 0, 9, 4, 8, 5, 1, 2, 7, 3]\n",
            "10 [6 0 9 4 8 5 1 2 7 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 151, bulyan: at fang n_at 10 e 151 | val loss 2.0922 val acc 18.2833 best val_acc 24.391234\n",
            "discarded index [5, 1, 3, 6, 0, 8, 7, 9, 2, 4]\n",
            "10 [5 1 3 6 0 8 7 9 2 4]\n",
            "discarded index [5, 1, 3, 6, 0, 8, 7, 9, 2, 4]\n",
            "10 [5 1 3 6 0 8 7 9 2 4]\n",
            "discarded index [5, 1, 3, 6, 0, 8, 7, 9, 2, 4]\n",
            "10 [5 1 3 6 0 8 7 9 2 4]\n",
            "discarded index [5, 1, 3, 6, 0, 8, 7, 9, 2, 4]\n",
            "10 [5 1 3 6 0 8 7 9 2 4]\n",
            "discarded index [5, 1, 3, 6, 0, 8, 7, 9, 2, 4]\n",
            "10 [5 1 3 6 0 8 7 9 2 4]\n",
            "discarded index [5, 1, 3, 6, 0, 8, 7, 9, 2, 4]\n",
            "10 [5 1 3 6 0 8 7 9 2 4]\n",
            "discarded index [5, 1, 3, 6, 0, 8, 7, 9, 2, 4]\n",
            "10 [5 1 3 6 0 8 7 9 2 4]\n",
            "discarded index [5, 1, 3, 6, 0, 8, 7, 9, 2, 4]\n",
            "10 [5 1 3 6 0 8 7 9 2 4]\n",
            "discarded index [5, 1, 3, 6, 0, 8, 7, 9, 2, 4]\n",
            "10 [5 1 3 6 0 8 7 9 2 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 152, bulyan: at fang n_at 10 e 152 | val loss 2.2376 val acc 12.1753 best val_acc 24.391234\n",
            "discarded index [9, 5, 0, 7, 8, 4, 3, 1, 6, 2]\n",
            "10 [9 5 0 7 8 4 3 1 6 2]\n",
            "discarded index [9, 5, 0, 7, 8, 4, 3, 1, 6, 2]\n",
            "10 [9 5 0 7 8 4 3 1 6 2]\n",
            "discarded index [9, 5, 0, 7, 8, 4, 3, 1, 6, 2]\n",
            "10 [9 5 0 7 8 4 3 1 6 2]\n",
            "discarded index [9, 5, 0, 7, 8, 4, 3, 1, 6, 2]\n",
            "10 [9 5 0 7 8 4 3 1 6 2]\n",
            "discarded index [9, 5, 0, 7, 8, 4, 3, 1, 6, 2]\n",
            "10 [9 5 0 7 8 4 3 1 6 2]\n",
            "discarded index [9, 5, 0, 7, 8, 4, 3, 1, 6, 2]\n",
            "10 [9 5 0 7 8 4 3 1 6 2]\n",
            "discarded index [9, 5, 0, 7, 8, 4, 3, 1, 6, 2]\n",
            "10 [9 5 0 7 8 4 3 1 6 2]\n",
            "discarded index [9, 5, 0, 7, 8, 4, 3, 1, 6, 2]\n",
            "10 [9 5 0 7 8 4 3 1 6 2]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 153, bulyan: at fang n_at 10 e 153 | val loss 2.0782 val acc 16.0106 best val_acc 24.391234\n",
            "discarded index [6, 9, 8, 4, 1, 5, 0, 7, 2, 3]\n",
            "10 [6 9 8 4 1 5 0 7 2 3]\n",
            "discarded index [6, 9, 8, 4, 1, 5, 0, 7, 2, 3]\n",
            "10 [6 9 8 4 1 5 0 7 2 3]\n",
            "discarded index [6, 9, 8, 4, 1, 5, 0, 7, 2, 3]\n",
            "10 [6 9 8 4 1 5 0 7 2 3]\n",
            "discarded index [6, 9, 8, 4, 1, 5, 0, 7, 2, 3]\n",
            "10 [6 9 8 4 1 5 0 7 2 3]\n",
            "discarded index [6, 9, 8, 4, 1, 5, 0, 7, 2, 3]\n",
            "10 [6 9 8 4 1 5 0 7 2 3]\n",
            "discarded index [6, 9, 8, 4, 1, 5, 0, 7, 2, 3]\n",
            "10 [6 9 8 4 1 5 0 7 2 3]\n",
            "discarded index [6, 9, 8, 4, 1, 5, 0, 7, 2, 3]\n",
            "10 [6 9 8 4 1 5 0 7 2 3]\n",
            "discarded index [6, 9, 8, 4, 1, 5, 0, 7, 2, 3]\n",
            "10 [6 9 8 4 1 5 0 7 2 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 154, bulyan: at fang n_at 10 e 154 | val loss 2.0067 val acc 22.5852 best val_acc 24.391234\n",
            "discarded index [1, 5, 0, 7, 6, 4, 8, 9, 2, 3]\n",
            "10 [1 5 0 7 6 4 8 9 2 3]\n",
            "discarded index [1, 5, 0, 7, 6, 4, 8, 9, 2, 3]\n",
            "10 [1 5 0 7 6 4 8 9 2 3]\n",
            "discarded index [1, 5, 0, 7, 6, 4, 8, 9, 2, 3]\n",
            "10 [1 5 0 7 6 4 8 9 2 3]\n",
            "discarded index [1, 5, 0, 7, 6, 4, 8, 9, 2, 3]\n",
            "10 [1 5 0 7 6 4 8 9 2 3]\n",
            "discarded index [1, 5, 0, 7, 6, 4, 8, 9, 2, 3]\n",
            "10 [1 5 0 7 6 4 8 9 2 3]\n",
            "discarded index [1, 5, 0, 7, 6, 4, 8, 9, 2, 3]\n",
            "10 [1 5 0 7 6 4 8 9 2 3]\n",
            "discarded index [1, 5, 0, 7, 6, 4, 8, 9, 2, 3]\n",
            "10 [1 5 0 7 6 4 8 9 2 3]\n",
            "discarded index [1, 5, 0, 7, 6, 4, 8, 9, 2, 3]\n",
            "10 [1 5 0 7 6 4 8 9 2 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 155, bulyan: at fang n_at 10 e 155 | val loss 1.9845 val acc 22.3011 best val_acc 24.391234\n",
            "discarded index [9, 8, 6, 4, 0, 1, 7, 5, 3, 2]\n",
            "10 [9 8 6 4 0 1 7 5 3 2]\n",
            "discarded index [9, 8, 6, 4, 0, 1, 7, 5, 3, 2]\n",
            "10 [9 8 6 4 0 1 7 5 3 2]\n",
            "discarded index [9, 8, 6, 4, 0, 1, 7, 5, 3, 2]\n",
            "10 [9 8 6 4 0 1 7 5 3 2]\n",
            "discarded index [9, 8, 6, 4, 0, 1, 7, 5, 3, 2]\n",
            "10 [9 8 6 4 0 1 7 5 3 2]\n",
            "discarded index [9, 8, 6, 4, 0, 1, 7, 5, 3, 2]\n",
            "10 [9 8 6 4 0 1 7 5 3 2]\n",
            "discarded index [9, 8, 6, 4, 0, 1, 7, 5, 3, 2]\n",
            "10 [9 8 6 4 0 1 7 5 3 2]\n",
            "discarded index [9, 8, 6, 4, 0, 1, 7, 5, 3, 2]\n",
            "10 [9 8 6 4 0 1 7 5 3 2]\n",
            "discarded index [9, 8, 6, 4, 0, 1, 7, 5, 3, 2]\n",
            "10 [9 8 6 4 0 1 7 5 3 2]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 156, bulyan: at fang n_at 10 e 156 | val loss 1.9847 val acc 21.8547 best val_acc 24.391234\n",
            "discarded index [6, 0, 9, 8, 7, 4, 1, 2, 3, 5]\n",
            "10 [6 0 9 8 7 4 1 2 3 5]\n",
            "discarded index [6, 0, 9, 8, 7, 4, 1, 2, 3, 5]\n",
            "10 [6 0 9 8 7 4 1 2 3 5]\n",
            "discarded index [6, 0, 9, 8, 7, 4, 1, 2, 3, 5]\n",
            "10 [6 0 9 8 7 4 1 2 3 5]\n",
            "discarded index [6, 0, 9, 8, 7, 4, 1, 2, 3, 5]\n",
            "10 [6 0 9 8 7 4 1 2 3 5]\n",
            "discarded index [6, 0, 9, 8, 7, 4, 1, 2, 3, 5]\n",
            "10 [6 0 9 8 7 4 1 2 3 5]\n",
            "discarded index [6, 0, 9, 8, 7, 4, 1, 2, 3, 5]\n",
            "10 [6 0 9 8 7 4 1 2 3 5]\n",
            "discarded index [6, 0, 9, 8, 7, 4, 1, 2, 3, 5]\n",
            "10 [6 0 9 8 7 4 1 2 3 5]\n",
            "discarded index [6, 0, 9, 8, 7, 4, 1, 2, 3, 5]\n",
            "10 [6 0 9 8 7 4 1 2 3 5]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 157, bulyan: at fang n_at 10 e 157 | val loss 2.1944 val acc 17.7963 best val_acc 24.391234\n",
            "discarded index [1, 6, 5, 0, 3, 8, 4, 9, 7, 2]\n",
            "10 [1 6 5 0 3 8 4 9 7 2]\n",
            "discarded index [1, 6, 5, 0, 3, 8, 4, 9, 7, 2]\n",
            "10 [1 6 5 0 3 8 4 9 7 2]\n",
            "discarded index [1, 6, 5, 0, 3, 8, 4, 9, 7, 2]\n",
            "10 [1 6 5 0 3 8 4 9 7 2]\n",
            "discarded index [1, 6, 5, 0, 3, 8, 4, 9, 7, 2]\n",
            "10 [1 6 5 0 3 8 4 9 7 2]\n",
            "discarded index [1, 6, 5, 0, 3, 8, 4, 9, 7, 2]\n",
            "10 [1 6 5 0 3 8 4 9 7 2]\n",
            "discarded index [1, 6, 5, 0, 3, 8, 4, 9, 7, 2]\n",
            "10 [1 6 5 0 3 8 4 9 7 2]\n",
            "discarded index [1, 6, 5, 0, 3, 8, 4, 9, 7, 2]\n",
            "10 [1 6 5 0 3 8 4 9 7 2]\n",
            "discarded index [1, 6, 5, 0, 3, 8, 4, 9, 7, 2]\n",
            "10 [1 6 5 0 3 8 4 9 7 2]\n",
            "discarded index [1, 6, 5, 0, 3, 8, 4, 9, 7, 2]\n",
            "10 [1 6 5 0 3 8 4 9 7 2]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 158, bulyan: at fang n_at 10 e 158 | val loss 2.5022 val acc 12.2362 best val_acc 24.391234\n",
            "discarded index [5, 0, 6, 4, 1, 2, 9, 3, 7, 8]\n",
            "10 [5 0 6 4 1 2 9 3 7 8]\n",
            "discarded index [5, 0, 6, 4, 1, 2, 9, 3, 7, 8]\n",
            "10 [5 0 6 4 1 2 9 3 7 8]\n",
            "discarded index [5, 0, 6, 4, 1, 2, 9, 3, 7, 8]\n",
            "10 [5 0 6 4 1 2 9 3 7 8]\n",
            "discarded index [5, 0, 6, 4, 1, 2, 9, 3, 7, 8]\n",
            "10 [5 0 6 4 1 2 9 3 7 8]\n",
            "discarded index [5, 0, 6, 4, 1, 2, 9, 3, 7, 8]\n",
            "10 [5 0 6 4 1 2 9 3 7 8]\n",
            "discarded index [5, 0, 6, 4, 1, 2, 9, 3, 7, 8]\n",
            "10 [5 0 6 4 1 2 9 3 7 8]\n",
            "discarded index [5, 0, 6, 4, 1, 2, 9, 3, 7, 8]\n",
            "10 [5 0 6 4 1 2 9 3 7 8]\n",
            "discarded index [5, 0, 6, 4, 1, 2, 9, 3, 7, 8]\n",
            "10 [5 0 6 4 1 2 9 3 7 8]\n",
            "discarded index [5, 0, 6, 4, 1, 2, 9, 3, 7, 8]\n",
            "10 [5 0 6 4 1 2 9 3 7 8]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 159, bulyan: at fang n_at 10 e 159 | val loss 2.2499 val acc 17.5933 best val_acc 24.391234\n",
            "discarded index [6, 5, 1, 0, 2, 3, 8, 9, 7, 4]\n",
            "10 [6 5 1 0 2 3 8 9 7 4]\n",
            "discarded index [6, 5, 1, 0, 2, 3, 8, 9, 7, 4]\n",
            "10 [6 5 1 0 2 3 8 9 7 4]\n",
            "discarded index [6, 5, 1, 0, 2, 3, 8, 9, 7, 4]\n",
            "10 [6 5 1 0 2 3 8 9 7 4]\n",
            "discarded index [6, 5, 1, 0, 2, 3, 8, 9, 7, 4]\n",
            "10 [6 5 1 0 2 3 8 9 7 4]\n",
            "discarded index [6, 5, 1, 0, 2, 3, 8, 9, 7, 4]\n",
            "10 [6 5 1 0 2 3 8 9 7 4]\n",
            "discarded index [6, 5, 1, 0, 2, 3, 8, 9, 7, 4]\n",
            "10 [6 5 1 0 2 3 8 9 7 4]\n",
            "discarded index [6, 5, 1, 0, 2, 3, 8, 9, 7, 4]\n",
            "10 [6 5 1 0 2 3 8 9 7 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 160, bulyan: at fang n_at 10 e 160 | val loss 2.1929 val acc 18.6688 best val_acc 24.391234\n",
            "discarded index [6, 1, 4, 5, 0, 2, 3, 9, 7, 8]\n",
            "10 [6 1 4 5 0 2 3 9 7 8]\n",
            "discarded index [6, 1, 4, 5, 0, 2, 3, 9, 7, 8]\n",
            "10 [6 1 4 5 0 2 3 9 7 8]\n",
            "discarded index [6, 1, 4, 5, 0, 2, 3, 9, 7, 8]\n",
            "10 [6 1 4 5 0 2 3 9 7 8]\n",
            "discarded index [6, 1, 4, 5, 0, 2, 3, 9, 7, 8]\n",
            "10 [6 1 4 5 0 2 3 9 7 8]\n",
            "discarded index [6, 1, 4, 5, 0, 2, 3, 9, 7, 8]\n",
            "10 [6 1 4 5 0 2 3 9 7 8]\n",
            "discarded index [6, 1, 4, 5, 0, 2, 3, 9, 7, 8]\n",
            "10 [6 1 4 5 0 2 3 9 7 8]\n",
            "discarded index [6, 1, 4, 5, 0, 2, 3, 9, 7, 8]\n",
            "10 [6 1 4 5 0 2 3 9 7 8]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 161, bulyan: at fang n_at 10 e 161 | val loss 2.1547 val acc 17.2687 best val_acc 24.391234\n",
            "discarded index [5, 6, 4, 8, 2, 3, 1, 9, 0, 7]\n",
            "10 [5 6 4 8 2 3 1 9 0 7]\n",
            "discarded index [5, 6, 4, 8, 2, 3, 1, 9, 0, 7]\n",
            "10 [5 6 4 8 2 3 1 9 0 7]\n",
            "discarded index [5, 6, 4, 8, 2, 3, 1, 9, 0, 7]\n",
            "10 [5 6 4 8 2 3 1 9 0 7]\n",
            "discarded index [5, 6, 4, 8, 2, 3, 1, 9, 0, 7]\n",
            "10 [5 6 4 8 2 3 1 9 0 7]\n",
            "discarded index [5, 6, 4, 8, 2, 3, 1, 9, 0, 7]\n",
            "10 [5 6 4 8 2 3 1 9 0 7]\n",
            "discarded index [5, 6, 4, 8, 2, 3, 1, 9, 0, 7]\n",
            "10 [5 6 4 8 2 3 1 9 0 7]\n",
            "discarded index [5, 6, 4, 8, 2, 3, 1, 9, 0, 7]\n",
            "10 [5 6 4 8 2 3 1 9 0 7]\n",
            "discarded index [5, 6, 4, 8, 2, 3, 1, 9, 0, 7]\n",
            "10 [5 6 4 8 2 3 1 9 0 7]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 162, bulyan: at fang n_at 10 e 162 | val loss 2.1283 val acc 19.8864 best val_acc 24.391234\n",
            "discarded index [6, 4, 8, 7, 9, 3, 5, 1, 2, 0]\n",
            "10 [6 4 8 7 9 3 5 1 2 0]\n",
            "discarded index [6, 4, 8, 7, 9, 3, 5, 1, 2, 0]\n",
            "10 [6 4 8 7 9 3 5 1 2 0]\n",
            "discarded index [6, 4, 8, 7, 9, 3, 5, 1, 2, 0]\n",
            "10 [6 4 8 7 9 3 5 1 2 0]\n",
            "discarded index [6, 4, 8, 7, 9, 3, 5, 1, 2, 0]\n",
            "10 [6 4 8 7 9 3 5 1 2 0]\n",
            "discarded index [6, 4, 8, 7, 9, 3, 5, 1, 2, 0]\n",
            "10 [6 4 8 7 9 3 5 1 2 0]\n",
            "discarded index [6, 4, 8, 7, 9, 3, 5, 1, 2, 0]\n",
            "10 [6 4 8 7 9 3 5 1 2 0]\n",
            "discarded index [6, 4, 8, 7, 9, 3, 5, 1, 2, 0]\n",
            "10 [6 4 8 7 9 3 5 1 2 0]\n",
            "discarded index [6, 4, 8, 7, 9, 3, 5, 1, 2, 0]\n",
            "10 [6 4 8 7 9 3 5 1 2 0]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 163, bulyan: at fang n_at 10 e 163 | val loss 2.1198 val acc 18.9123 best val_acc 24.391234\n",
            "discarded index [6, 1, 5, 0, 3, 2, 4, 8, 7, 9]\n",
            "10 [6 1 5 0 3 2 4 8 7 9]\n",
            "discarded index [6, 1, 5, 0, 3, 2, 4, 8, 7, 9]\n",
            "10 [6 1 5 0 3 2 4 8 7 9]\n",
            "discarded index [6, 1, 5, 0, 3, 2, 4, 8, 7, 9]\n",
            "10 [6 1 5 0 3 2 4 8 7 9]\n",
            "discarded index [6, 1, 5, 0, 3, 2, 4, 8, 7, 9]\n",
            "10 [6 1 5 0 3 2 4 8 7 9]\n",
            "discarded index [6, 1, 5, 0, 3, 2, 4, 8, 7, 9]\n",
            "10 [6 1 5 0 3 2 4 8 7 9]\n",
            "discarded index [6, 1, 5, 0, 3, 2, 4, 8, 7, 9]\n",
            "10 [6 1 5 0 3 2 4 8 7 9]\n",
            "discarded index [6, 1, 5, 0, 3, 2, 4, 8, 7, 9]\n",
            "10 [6 1 5 0 3 2 4 8 7 9]\n",
            "discarded index [6, 1, 5, 0, 3, 2, 4, 8, 7, 9]\n",
            "10 [6 1 5 0 3 2 4 8 7 9]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 164, bulyan: at fang n_at 10 e 164 | val loss 2.1454 val acc 16.4367 best val_acc 24.391234\n",
            "discarded index [7, 9, 6, 8, 4, 0, 1, 2, 3, 5]\n",
            "10 [7 9 6 8 4 0 1 2 3 5]\n",
            "discarded index [7, 9, 6, 8, 4, 0, 1, 2, 3, 5]\n",
            "10 [7 9 6 8 4 0 1 2 3 5]\n",
            "discarded index [7, 9, 6, 8, 4, 0, 1, 2, 3, 5]\n",
            "10 [7 9 6 8 4 0 1 2 3 5]\n",
            "discarded index [7, 9, 6, 8, 4, 0, 1, 2, 3, 5]\n",
            "10 [7 9 6 8 4 0 1 2 3 5]\n",
            "discarded index [7, 9, 6, 8, 4, 0, 1, 2, 3, 5]\n",
            "10 [7 9 6 8 4 0 1 2 3 5]\n",
            "discarded index [7, 9, 6, 8, 4, 0, 1, 2, 3, 5]\n",
            "10 [7 9 6 8 4 0 1 2 3 5]\n",
            "discarded index [7, 9, 6, 8, 4, 0, 1, 2, 3, 5]\n",
            "10 [7 9 6 8 4 0 1 2 3 5]\n",
            "discarded index [7, 9, 6, 8, 4, 0, 1, 2, 3, 5]\n",
            "10 [7 9 6 8 4 0 1 2 3 5]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 165, bulyan: at fang n_at 10 e 165 | val loss 2.2155 val acc 15.8685 best val_acc 24.391234\n",
            "discarded index [7, 4, 6, 1, 8, 0, 5, 9, 3, 2]\n",
            "10 [7 4 6 1 8 0 5 9 3 2]\n",
            "discarded index [7, 4, 6, 1, 8, 0, 5, 9, 3, 2]\n",
            "10 [7 4 6 1 8 0 5 9 3 2]\n",
            "discarded index [7, 4, 6, 1, 8, 0, 5, 9, 3, 2]\n",
            "10 [7 4 6 1 8 0 5 9 3 2]\n",
            "discarded index [7, 4, 6, 1, 8, 0, 5, 9, 3, 2]\n",
            "10 [7 4 6 1 8 0 5 9 3 2]\n",
            "discarded index [7, 4, 6, 1, 8, 0, 5, 9, 3, 2]\n",
            "10 [7 4 6 1 8 0 5 9 3 2]\n",
            "discarded index [7, 4, 6, 1, 8, 0, 5, 9, 3, 2]\n",
            "10 [7 4 6 1 8 0 5 9 3 2]\n",
            "discarded index [7, 4, 6, 1, 8, 0, 5, 9, 3, 2]\n",
            "10 [7 4 6 1 8 0 5 9 3 2]\n",
            "discarded index [7, 4, 6, 1, 8, 0, 5, 9, 3, 2]\n",
            "10 [7 4 6 1 8 0 5 9 3 2]\n",
            "discarded index [7, 4, 6, 1, 8, 0, 5, 9, 3, 2]\n",
            "10 [7 4 6 1 8 0 5 9 3 2]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 166, bulyan: at fang n_at 10 e 166 | val loss 2.2829 val acc 10.7955 best val_acc 24.391234\n",
            "discarded index [0, 7, 1, 2, 4, 9, 5, 6, 3, 8]\n",
            "10 [0 7 1 2 4 9 5 6 3 8]\n",
            "discarded index [0, 7, 1, 2, 4, 9, 5, 6, 3, 8]\n",
            "10 [0 7 1 2 4 9 5 6 3 8]\n",
            "discarded index [0, 7, 1, 2, 4, 9, 5, 6, 3, 8]\n",
            "10 [0 7 1 2 4 9 5 6 3 8]\n",
            "discarded index [0, 7, 1, 2, 4, 9, 5, 6, 3, 8]\n",
            "10 [0 7 1 2 4 9 5 6 3 8]\n",
            "discarded index [0, 7, 1, 2, 4, 9, 5, 6, 3, 8]\n",
            "10 [0 7 1 2 4 9 5 6 3 8]\n",
            "discarded index [0, 7, 1, 2, 4, 9, 5, 6, 3, 8]\n",
            "10 [0 7 1 2 4 9 5 6 3 8]\n",
            "discarded index [0, 7, 1, 2, 4, 9, 5, 6, 3, 8]\n",
            "10 [0 7 1 2 4 9 5 6 3 8]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 167, bulyan: at fang n_at 10 e 167 | val loss 2.2295 val acc 16.0308 best val_acc 24.391234\n",
            "discarded index [7, 9, 4, 1, 5, 2, 0, 8, 3, 6]\n",
            "10 [7 9 4 1 5 2 0 8 3 6]\n",
            "discarded index [7, 9, 4, 1, 5, 2, 0, 8, 3, 6]\n",
            "10 [7 9 4 1 5 2 0 8 3 6]\n",
            "discarded index [7, 9, 4, 1, 5, 2, 0, 8, 3, 6]\n",
            "10 [7 9 4 1 5 2 0 8 3 6]\n",
            "discarded index [7, 9, 4, 1, 5, 2, 0, 8, 3, 6]\n",
            "10 [7 9 4 1 5 2 0 8 3 6]\n",
            "discarded index [7, 9, 4, 1, 5, 2, 0, 8, 3, 6]\n",
            "10 [7 9 4 1 5 2 0 8 3 6]\n",
            "discarded index [7, 9, 4, 1, 5, 2, 0, 8, 3, 6]\n",
            "10 [7 9 4 1 5 2 0 8 3 6]\n",
            "discarded index [7, 9, 4, 1, 5, 2, 0, 8, 3, 6]\n",
            "10 [7 9 4 1 5 2 0 8 3 6]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 168, bulyan: at fang n_at 10 e 168 | val loss 2.1488 val acc 21.0024 best val_acc 24.391234\n",
            "discarded index [5, 7, 9, 4, 8, 6, 0, 3, 1, 2]\n",
            "10 [5 7 9 4 8 6 0 3 1 2]\n",
            "discarded index [5, 7, 9, 4, 8, 6, 0, 3, 1, 2]\n",
            "10 [5 7 9 4 8 6 0 3 1 2]\n",
            "discarded index [5, 7, 9, 4, 8, 6, 0, 3, 1, 2]\n",
            "10 [5 7 9 4 8 6 0 3 1 2]\n",
            "discarded index [5, 7, 9, 4, 8, 6, 0, 3, 1, 2]\n",
            "10 [5 7 9 4 8 6 0 3 1 2]\n",
            "discarded index [5, 7, 9, 4, 8, 6, 0, 3, 1, 2]\n",
            "10 [5 7 9 4 8 6 0 3 1 2]\n",
            "discarded index [5, 7, 9, 4, 8, 6, 0, 3, 1, 2]\n",
            "10 [5 7 9 4 8 6 0 3 1 2]\n",
            "discarded index [5, 7, 9, 4, 8, 6, 0, 3, 1, 2]\n",
            "10 [5 7 9 4 8 6 0 3 1 2]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 169, bulyan: at fang n_at 10 e 169 | val loss 2.0915 val acc 20.9416 best val_acc 24.391234\n",
            "discarded index [5, 7, 1, 9, 8, 4, 0, 6, 2, 3]\n",
            "10 [5 7 1 9 8 4 0 6 2 3]\n",
            "discarded index [5, 7, 1, 9, 8, 4, 0, 6, 2, 3]\n",
            "10 [5 7 1 9 8 4 0 6 2 3]\n",
            "discarded index [5, 7, 1, 9, 8, 4, 0, 6, 2, 3]\n",
            "10 [5 7 1 9 8 4 0 6 2 3]\n",
            "discarded index [5, 7, 1, 9, 8, 4, 0, 6, 2, 3]\n",
            "10 [5 7 1 9 8 4 0 6 2 3]\n",
            "discarded index [5, 7, 1, 9, 8, 4, 0, 6, 2, 3]\n",
            "10 [5 7 1 9 8 4 0 6 2 3]\n",
            "discarded index [5, 7, 1, 9, 8, 4, 0, 6, 2, 3]\n",
            "10 [5 7 1 9 8 4 0 6 2 3]\n",
            "discarded index [5, 7, 1, 9, 8, 4, 0, 6, 2, 3]\n",
            "10 [5 7 1 9 8 4 0 6 2 3]\n",
            "discarded index [5, 7, 1, 9, 8, 4, 0, 6, 2, 3]\n",
            "10 [5 7 1 9 8 4 0 6 2 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 170, bulyan: at fang n_at 10 e 170 | val loss 2.0490 val acc 21.8953 best val_acc 24.391234\n",
            "discarded index [7, 5, 1, 2, 8, 9, 6, 3, 0, 4]\n",
            "10 [7 5 1 2 8 9 6 3 0 4]\n",
            "discarded index [7, 5, 1, 2, 8, 9, 6, 3, 0, 4]\n",
            "10 [7 5 1 2 8 9 6 3 0 4]\n",
            "discarded index [7, 5, 1, 2, 8, 9, 6, 3, 0, 4]\n",
            "10 [7 5 1 2 8 9 6 3 0 4]\n",
            "discarded index [7, 5, 1, 2, 8, 9, 6, 3, 0, 4]\n",
            "10 [7 5 1 2 8 9 6 3 0 4]\n",
            "discarded index [7, 5, 1, 2, 8, 9, 6, 3, 0, 4]\n",
            "10 [7 5 1 2 8 9 6 3 0 4]\n",
            "discarded index [7, 5, 1, 2, 8, 9, 6, 3, 0, 4]\n",
            "10 [7 5 1 2 8 9 6 3 0 4]\n",
            "discarded index [7, 5, 1, 2, 8, 9, 6, 3, 0, 4]\n",
            "10 [7 5 1 2 8 9 6 3 0 4]\n",
            "discarded index [7, 5, 1, 2, 8, 9, 6, 3, 0, 4]\n",
            "10 [7 5 1 2 8 9 6 3 0 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 171, bulyan: at fang n_at 10 e 171 | val loss 2.0166 val acc 21.2662 best val_acc 24.391234\n",
            "discarded index [6, 9, 8, 5, 4, 7, 2, 3, 0, 1]\n",
            "10 [6 9 8 5 4 7 2 3 0 1]\n",
            "discarded index [6, 9, 8, 5, 4, 7, 2, 3, 0, 1]\n",
            "10 [6 9 8 5 4 7 2 3 0 1]\n",
            "discarded index [6, 9, 8, 5, 4, 7, 2, 3, 0, 1]\n",
            "10 [6 9 8 5 4 7 2 3 0 1]\n",
            "discarded index [6, 9, 8, 5, 4, 7, 2, 3, 0, 1]\n",
            "10 [6 9 8 5 4 7 2 3 0 1]\n",
            "discarded index [6, 9, 8, 5, 4, 7, 2, 3, 0, 1]\n",
            "10 [6 9 8 5 4 7 2 3 0 1]\n",
            "discarded index [6, 9, 8, 5, 4, 7, 2, 3, 0, 1]\n",
            "10 [6 9 8 5 4 7 2 3 0 1]\n",
            "discarded index [6, 9, 8, 5, 4, 7, 2, 3, 0, 1]\n",
            "10 [6 9 8 5 4 7 2 3 0 1]\n",
            "discarded index [6, 9, 8, 5, 4, 7, 2, 3, 0, 1]\n",
            "10 [6 9 8 5 4 7 2 3 0 1]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 172, bulyan: at fang n_at 10 e 172 | val loss 1.9925 val acc 21.1851 best val_acc 24.391234\n",
            "discarded index [6, 1, 0, 7, 9, 8, 2, 5, 4, 3]\n",
            "10 [6 1 0 7 9 8 2 5 4 3]\n",
            "discarded index [6, 1, 0, 7, 9, 8, 2, 5, 4, 3]\n",
            "10 [6 1 0 7 9 8 2 5 4 3]\n",
            "discarded index [6, 1, 0, 7, 9, 8, 2, 5, 4, 3]\n",
            "10 [6 1 0 7 9 8 2 5 4 3]\n",
            "discarded index [6, 1, 0, 7, 9, 8, 2, 5, 4, 3]\n",
            "10 [6 1 0 7 9 8 2 5 4 3]\n",
            "discarded index [6, 1, 0, 7, 9, 8, 2, 5, 4, 3]\n",
            "10 [6 1 0 7 9 8 2 5 4 3]\n",
            "discarded index [6, 1, 0, 7, 9, 8, 2, 5, 4, 3]\n",
            "10 [6 1 0 7 9 8 2 5 4 3]\n",
            "discarded index [6, 1, 0, 7, 9, 8, 2, 5, 4, 3]\n",
            "10 [6 1 0 7 9 8 2 5 4 3]\n",
            "discarded index [6, 1, 0, 7, 9, 8, 2, 5, 4, 3]\n",
            "10 [6 1 0 7 9 8 2 5 4 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 173, bulyan: at fang n_at 10 e 173 | val loss 2.0043 val acc 21.5503 best val_acc 24.391234\n",
            "discarded index [5, 8, 7, 2, 6, 9, 1, 3, 0, 4]\n",
            "10 [5 8 7 2 6 9 1 3 0 4]\n",
            "discarded index [5, 8, 7, 2, 6, 9, 1, 3, 0, 4]\n",
            "10 [5 8 7 2 6 9 1 3 0 4]\n",
            "discarded index [5, 8, 7, 2, 6, 9, 1, 3, 0, 4]\n",
            "10 [5 8 7 2 6 9 1 3 0 4]\n",
            "discarded index [5, 8, 7, 2, 6, 9, 1, 3, 0, 4]\n",
            "10 [5 8 7 2 6 9 1 3 0 4]\n",
            "discarded index [5, 8, 7, 2, 6, 9, 1, 3, 0, 4]\n",
            "10 [5 8 7 2 6 9 1 3 0 4]\n",
            "discarded index [5, 8, 7, 2, 6, 9, 1, 3, 0, 4]\n",
            "10 [5 8 7 2 6 9 1 3 0 4]\n",
            "discarded index [5, 8, 7, 2, 6, 9, 1, 3, 0, 4]\n",
            "10 [5 8 7 2 6 9 1 3 0 4]\n",
            "discarded index [5, 8, 7, 2, 6, 9, 1, 3, 0, 4]\n",
            "10 [5 8 7 2 6 9 1 3 0 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 174, bulyan: at fang n_at 10 e 174 | val loss 2.2507 val acc 16.7208 best val_acc 24.391234\n",
            "discarded index [0, 7, 1, 9, 6, 2, 5, 8, 4, 3]\n",
            "10 [0 7 1 9 6 2 5 8 4 3]\n",
            "discarded index [0, 7, 1, 9, 6, 2, 5, 8, 4, 3]\n",
            "10 [0 7 1 9 6 2 5 8 4 3]\n",
            "discarded index [0, 7, 1, 9, 6, 2, 5, 8, 4, 3]\n",
            "10 [0 7 1 9 6 2 5 8 4 3]\n",
            "discarded index [0, 7, 1, 9, 6, 2, 5, 8, 4, 3]\n",
            "10 [0 7 1 9 6 2 5 8 4 3]\n",
            "discarded index [0, 7, 1, 9, 6, 2, 5, 8, 4, 3]\n",
            "10 [0 7 1 9 6 2 5 8 4 3]\n",
            "discarded index [0, 7, 1, 9, 6, 2, 5, 8, 4, 3]\n",
            "10 [0 7 1 9 6 2 5 8 4 3]\n",
            "discarded index [0, 7, 1, 9, 6, 2, 5, 8, 4, 3]\n",
            "10 [0 7 1 9 6 2 5 8 4 3]\n",
            "discarded index [0, 7, 1, 9, 6, 2, 5, 8, 4, 3]\n",
            "10 [0 7 1 9 6 2 5 8 4 3]\n",
            "discarded index [0, 7, 1, 9, 6, 2, 5, 8, 4, 3]\n",
            "10 [0 7 1 9 6 2 5 8 4 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 175, bulyan: at fang n_at 10 e 175 | val loss 2.1116 val acc 16.1526 best val_acc 24.391234\n",
            "discarded index [6, 7, 5, 4, 2, 8, 9, 3, 1, 0]\n",
            "10 [6 7 5 4 2 8 9 3 1 0]\n",
            "discarded index [6, 7, 5, 4, 2, 8, 9, 3, 1, 0]\n",
            "10 [6 7 5 4 2 8 9 3 1 0]\n",
            "discarded index [6, 7, 5, 4, 2, 8, 9, 3, 1, 0]\n",
            "10 [6 7 5 4 2 8 9 3 1 0]\n",
            "discarded index [6, 7, 5, 4, 2, 8, 9, 3, 1, 0]\n",
            "10 [6 7 5 4 2 8 9 3 1 0]\n",
            "discarded index [6, 7, 5, 4, 2, 8, 9, 3, 1, 0]\n",
            "10 [6 7 5 4 2 8 9 3 1 0]\n",
            "discarded index [6, 7, 5, 4, 2, 8, 9, 3, 1, 0]\n",
            "10 [6 7 5 4 2 8 9 3 1 0]\n",
            "discarded index [6, 7, 5, 4, 2, 8, 9, 3, 1, 0]\n",
            "10 [6 7 5 4 2 8 9 3 1 0]\n",
            "discarded index [6, 7, 5, 4, 2, 8, 9, 3, 1, 0]\n",
            "10 [6 7 5 4 2 8 9 3 1 0]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 176, bulyan: at fang n_at 10 e 176 | val loss 2.0575 val acc 18.9529 best val_acc 24.391234\n",
            "discarded index [5, 0, 2, 1, 3, 8, 4, 9, 6, 7]\n",
            "10 [5 0 2 1 3 8 4 9 6 7]\n",
            "discarded index [5, 0, 2, 1, 3, 8, 4, 9, 6, 7]\n",
            "10 [5 0 2 1 3 8 4 9 6 7]\n",
            "discarded index [5, 0, 2, 1, 3, 8, 4, 9, 6, 7]\n",
            "10 [5 0 2 1 3 8 4 9 6 7]\n",
            "discarded index [5, 0, 2, 1, 3, 8, 4, 9, 6, 7]\n",
            "10 [5 0 2 1 3 8 4 9 6 7]\n",
            "discarded index [5, 0, 2, 1, 3, 8, 4, 9, 6, 7]\n",
            "10 [5 0 2 1 3 8 4 9 6 7]\n",
            "discarded index [5, 0, 2, 1, 3, 8, 4, 9, 6, 7]\n",
            "10 [5 0 2 1 3 8 4 9 6 7]\n",
            "discarded index [5, 0, 2, 1, 3, 8, 4, 9, 6, 7]\n",
            "10 [5 0 2 1 3 8 4 9 6 7]\n",
            "discarded index [5, 0, 2, 1, 3, 8, 4, 9, 6, 7]\n",
            "10 [5 0 2 1 3 8 4 9 6 7]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 177, bulyan: at fang n_at 10 e 177 | val loss 2.0430 val acc 20.0690 best val_acc 24.391234\n",
            "discarded index [5, 3, 2, 0, 9, 4, 7, 8, 6, 1]\n",
            "10 [5 3 2 0 9 4 7 8 6 1]\n",
            "discarded index [5, 3, 2, 0, 9, 4, 7, 8, 6, 1]\n",
            "10 [5 3 2 0 9 4 7 8 6 1]\n",
            "discarded index [5, 3, 2, 0, 9, 4, 7, 8, 6, 1]\n",
            "10 [5 3 2 0 9 4 7 8 6 1]\n",
            "discarded index [5, 3, 2, 0, 9, 4, 7, 8, 6, 1]\n",
            "10 [5 3 2 0 9 4 7 8 6 1]\n",
            "discarded index [5, 3, 2, 0, 9, 4, 7, 8, 6, 1]\n",
            "10 [5 3 2 0 9 4 7 8 6 1]\n",
            "discarded index [5, 3, 2, 0, 9, 4, 7, 8, 6, 1]\n",
            "10 [5 3 2 0 9 4 7 8 6 1]\n",
            "discarded index [5, 3, 2, 0, 9, 4, 7, 8, 6, 1]\n",
            "10 [5 3 2 0 9 4 7 8 6 1]\n",
            "discarded index [5, 3, 2, 0, 9, 4, 7, 8, 6, 1]\n",
            "10 [5 3 2 0 9 4 7 8 6 1]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 178, bulyan: at fang n_at 10 e 178 | val loss 2.0650 val acc 18.9326 best val_acc 24.391234\n",
            "discarded index [6, 0, 1, 9, 4, 8, 3, 2, 5, 7]\n",
            "10 [6 0 1 9 4 8 3 2 5 7]\n",
            "discarded index [6, 0, 1, 9, 4, 8, 3, 2, 5, 7]\n",
            "10 [6 0 1 9 4 8 3 2 5 7]\n",
            "discarded index [6, 0, 1, 9, 4, 8, 3, 2, 5, 7]\n",
            "10 [6 0 1 9 4 8 3 2 5 7]\n",
            "discarded index [6, 0, 1, 9, 4, 8, 3, 2, 5, 7]\n",
            "10 [6 0 1 9 4 8 3 2 5 7]\n",
            "discarded index [6, 0, 1, 9, 4, 8, 3, 2, 5, 7]\n",
            "10 [6 0 1 9 4 8 3 2 5 7]\n",
            "discarded index [6, 0, 1, 9, 4, 8, 3, 2, 5, 7]\n",
            "10 [6 0 1 9 4 8 3 2 5 7]\n",
            "discarded index [6, 0, 1, 9, 4, 8, 3, 2, 5, 7]\n",
            "10 [6 0 1 9 4 8 3 2 5 7]\n",
            "discarded index [6, 0, 1, 9, 4, 8, 3, 2, 5, 7]\n",
            "10 [6 0 1 9 4 8 3 2 5 7]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 179, bulyan: at fang n_at 10 e 179 | val loss 2.0474 val acc 22.0576 best val_acc 24.391234\n",
            "discarded index [9, 6, 8, 4, 2, 0, 1, 3, 5, 7]\n",
            "10 [9 6 8 4 2 0 1 3 5 7]\n",
            "discarded index [9, 6, 8, 4, 2, 0, 1, 3, 5, 7]\n",
            "10 [9 6 8 4 2 0 1 3 5 7]\n",
            "discarded index [9, 6, 8, 4, 2, 0, 1, 3, 5, 7]\n",
            "10 [9 6 8 4 2 0 1 3 5 7]\n",
            "discarded index [9, 6, 8, 4, 2, 0, 1, 3, 5, 7]\n",
            "10 [9 6 8 4 2 0 1 3 5 7]\n",
            "discarded index [9, 6, 8, 4, 2, 0, 1, 3, 5, 7]\n",
            "10 [9 6 8 4 2 0 1 3 5 7]\n",
            "discarded index [9, 6, 8, 4, 2, 0, 1, 3, 5, 7]\n",
            "10 [9 6 8 4 2 0 1 3 5 7]\n",
            "discarded index [9, 6, 8, 4, 2, 0, 1, 3, 5, 7]\n",
            "10 [9 6 8 4 2 0 1 3 5 7]\n",
            "discarded index [9, 6, 8, 4, 2, 0, 1, 3, 5, 7]\n",
            "10 [9 6 8 4 2 0 1 3 5 7]\n",
            "discarded index [9, 6, 8, 4, 2, 0, 1, 3, 5, 7]\n",
            "10 [9 6 8 4 2 0 1 3 5 7]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 180, bulyan: at fang n_at 10 e 180 | val loss 2.1566 val acc 18.1818 best val_acc 24.391234\n",
            "discarded index [1, 7, 0, 2, 4, 8, 6, 3, 5, 9]\n",
            "10 [1 7 0 2 4 8 6 3 5 9]\n",
            "discarded index [1, 7, 0, 2, 4, 8, 6, 3, 5, 9]\n",
            "10 [1 7 0 2 4 8 6 3 5 9]\n",
            "discarded index [1, 7, 0, 2, 4, 8, 6, 3, 5, 9]\n",
            "10 [1 7 0 2 4 8 6 3 5 9]\n",
            "discarded index [1, 7, 0, 2, 4, 8, 6, 3, 5, 9]\n",
            "10 [1 7 0 2 4 8 6 3 5 9]\n",
            "discarded index [1, 7, 0, 2, 4, 8, 6, 3, 5, 9]\n",
            "10 [1 7 0 2 4 8 6 3 5 9]\n",
            "discarded index [1, 7, 0, 2, 4, 8, 6, 3, 5, 9]\n",
            "10 [1 7 0 2 4 8 6 3 5 9]\n",
            "discarded index [1, 7, 0, 2, 4, 8, 6, 3, 5, 9]\n",
            "10 [1 7 0 2 4 8 6 3 5 9]\n",
            "discarded index [1, 7, 0, 2, 4, 8, 6, 3, 5, 9]\n",
            "10 [1 7 0 2 4 8 6 3 5 9]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 181, bulyan: at fang n_at 10 e 181 | val loss 2.0395 val acc 20.5966 best val_acc 24.391234\n",
            "discarded index [9, 2, 7, 6, 3, 5, 1, 0, 8, 4]\n",
            "10 [9 2 7 6 3 5 1 0 8 4]\n",
            "discarded index [9, 2, 7, 6, 3, 5, 1, 0, 8, 4]\n",
            "10 [9 2 7 6 3 5 1 0 8 4]\n",
            "discarded index [9, 2, 7, 6, 3, 5, 1, 0, 8, 4]\n",
            "10 [9 2 7 6 3 5 1 0 8 4]\n",
            "discarded index [9, 2, 7, 6, 3, 5, 1, 0, 8, 4]\n",
            "10 [9 2 7 6 3 5 1 0 8 4]\n",
            "discarded index [9, 2, 7, 6, 3, 5, 1, 0, 8, 4]\n",
            "10 [9 2 7 6 3 5 1 0 8 4]\n",
            "discarded index [9, 2, 7, 6, 3, 5, 1, 0, 8, 4]\n",
            "10 [9 2 7 6 3 5 1 0 8 4]\n",
            "discarded index [9, 2, 7, 6, 3, 5, 1, 0, 8, 4]\n",
            "10 [9 2 7 6 3 5 1 0 8 4]\n",
            "discarded index [9, 2, 7, 6, 3, 5, 1, 0, 8, 4]\n",
            "10 [9 2 7 6 3 5 1 0 8 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 182, bulyan: at fang n_at 10 e 182 | val loss 2.0098 val acc 21.5300 best val_acc 24.391234\n",
            "discarded index [5, 1, 2, 7, 0, 3, 6, 8, 4, 9]\n",
            "10 [5 1 2 7 0 3 6 8 4 9]\n",
            "discarded index [5, 1, 2, 7, 0, 3, 6, 8, 4, 9]\n",
            "10 [5 1 2 7 0 3 6 8 4 9]\n",
            "discarded index [5, 1, 2, 7, 0, 3, 6, 8, 4, 9]\n",
            "10 [5 1 2 7 0 3 6 8 4 9]\n",
            "discarded index [5, 1, 2, 7, 0, 3, 6, 8, 4, 9]\n",
            "10 [5 1 2 7 0 3 6 8 4 9]\n",
            "discarded index [5, 1, 2, 7, 0, 3, 6, 8, 4, 9]\n",
            "10 [5 1 2 7 0 3 6 8 4 9]\n",
            "discarded index [5, 1, 2, 7, 0, 3, 6, 8, 4, 9]\n",
            "10 [5 1 2 7 0 3 6 8 4 9]\n",
            "discarded index [5, 1, 2, 7, 0, 3, 6, 8, 4, 9]\n",
            "10 [5 1 2 7 0 3 6 8 4 9]\n",
            "discarded index [5, 1, 2, 7, 0, 3, 6, 8, 4, 9]\n",
            "10 [5 1 2 7 0 3 6 8 4 9]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 183, bulyan: at fang n_at 10 e 183 | val loss 1.9619 val acc 23.5998 best val_acc 24.391234\n",
            "discarded index [5, 6, 9, 3, 2, 1, 8, 7, 0, 4]\n",
            "10 [5 6 9 3 2 1 8 7 0 4]\n",
            "discarded index [5, 6, 9, 3, 2, 1, 8, 7, 0, 4]\n",
            "10 [5 6 9 3 2 1 8 7 0 4]\n",
            "discarded index [5, 6, 9, 3, 2, 1, 8, 7, 0, 4]\n",
            "10 [5 6 9 3 2 1 8 7 0 4]\n",
            "discarded index [5, 6, 9, 3, 2, 1, 8, 7, 0, 4]\n",
            "10 [5 6 9 3 2 1 8 7 0 4]\n",
            "discarded index [5, 6, 9, 3, 2, 1, 8, 7, 0, 4]\n",
            "10 [5 6 9 3 2 1 8 7 0 4]\n",
            "discarded index [5, 6, 9, 3, 2, 1, 8, 7, 0, 4]\n",
            "10 [5 6 9 3 2 1 8 7 0 4]\n",
            "discarded index [5, 6, 9, 3, 2, 1, 8, 7, 0, 4]\n",
            "10 [5 6 9 3 2 1 8 7 0 4]\n",
            "discarded index [5, 6, 9, 3, 2, 1, 8, 7, 0, 4]\n",
            "10 [5 6 9 3 2 1 8 7 0 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 184, bulyan: at fang n_at 10 e 184 | val loss 1.9679 val acc 23.2752 best val_acc 24.391234\n",
            "discarded index [6, 0, 1, 7, 5, 3, 2, 9, 8, 4]\n",
            "10 [6 0 1 7 5 3 2 9 8 4]\n",
            "discarded index [6, 0, 1, 7, 5, 3, 2, 9, 8, 4]\n",
            "10 [6 0 1 7 5 3 2 9 8 4]\n",
            "discarded index [6, 0, 1, 7, 5, 3, 2, 9, 8, 4]\n",
            "10 [6 0 1 7 5 3 2 9 8 4]\n",
            "discarded index [6, 0, 1, 7, 5, 3, 2, 9, 8, 4]\n",
            "10 [6 0 1 7 5 3 2 9 8 4]\n",
            "discarded index [6, 0, 1, 7, 5, 3, 2, 9, 8, 4]\n",
            "10 [6 0 1 7 5 3 2 9 8 4]\n",
            "discarded index [6, 0, 1, 7, 5, 3, 2, 9, 8, 4]\n",
            "10 [6 0 1 7 5 3 2 9 8 4]\n",
            "discarded index [6, 0, 1, 7, 5, 3, 2, 9, 8, 4]\n",
            "10 [6 0 1 7 5 3 2 9 8 4]\n",
            "discarded index [6, 0, 1, 7, 5, 3, 2, 9, 8, 4]\n",
            "10 [6 0 1 7 5 3 2 9 8 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 185, bulyan: at fang n_at 10 e 185 | val loss 2.0634 val acc 23.6810 best val_acc 24.391234\n",
            "discarded index [8, 6, 0, 9, 4, 5, 2, 7, 3, 1]\n",
            "10 [8 6 0 9 4 5 2 7 3 1]\n",
            "discarded index [8, 6, 0, 9, 4, 5, 2, 7, 3, 1]\n",
            "10 [8 6 0 9 4 5 2 7 3 1]\n",
            "discarded index [8, 6, 0, 9, 4, 5, 2, 7, 3, 1]\n",
            "10 [8 6 0 9 4 5 2 7 3 1]\n",
            "discarded index [8, 6, 0, 9, 4, 5, 2, 7, 3, 1]\n",
            "10 [8 6 0 9 4 5 2 7 3 1]\n",
            "discarded index [8, 6, 0, 9, 4, 5, 2, 7, 3, 1]\n",
            "10 [8 6 0 9 4 5 2 7 3 1]\n",
            "discarded index [8, 6, 0, 9, 4, 5, 2, 7, 3, 1]\n",
            "10 [8 6 0 9 4 5 2 7 3 1]\n",
            "discarded index [8, 6, 0, 9, 4, 5, 2, 7, 3, 1]\n",
            "10 [8 6 0 9 4 5 2 7 3 1]\n",
            "discarded index [8, 6, 0, 9, 4, 5, 2, 7, 3, 1]\n",
            "10 [8 6 0 9 4 5 2 7 3 1]\n",
            "discarded index [8, 6, 0, 9, 4, 5, 2, 7, 3, 1]\n",
            "10 [8 6 0 9 4 5 2 7 3 1]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 186, bulyan: at fang n_at 10 e 186 | val loss 2.2560 val acc 16.3352 best val_acc 24.391234\n",
            "discarded index [0, 1, 5, 7, 2, 3, 4, 9, 6, 8]\n",
            "10 [0 1 5 7 2 3 4 9 6 8]\n",
            "discarded index [0, 1, 5, 7, 2, 3, 4, 9, 6, 8]\n",
            "10 [0 1 5 7 2 3 4 9 6 8]\n",
            "discarded index [0, 1, 5, 7, 2, 3, 4, 9, 6, 8]\n",
            "10 [0 1 5 7 2 3 4 9 6 8]\n",
            "discarded index [0, 1, 5, 7, 2, 3, 4, 9, 6, 8]\n",
            "10 [0 1 5 7 2 3 4 9 6 8]\n",
            "discarded index [0, 1, 5, 7, 2, 3, 4, 9, 6, 8]\n",
            "10 [0 1 5 7 2 3 4 9 6 8]\n",
            "discarded index [0, 1, 5, 7, 2, 3, 4, 9, 6, 8]\n",
            "10 [0 1 5 7 2 3 4 9 6 8]\n",
            "discarded index [0, 1, 5, 7, 2, 3, 4, 9, 6, 8]\n",
            "10 [0 1 5 7 2 3 4 9 6 8]\n",
            "discarded index [0, 1, 5, 7, 2, 3, 4, 9, 6, 8]\n",
            "10 [0 1 5 7 2 3 4 9 6 8]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 187, bulyan: at fang n_at 10 e 187 | val loss 2.0928 val acc 17.4919 best val_acc 24.391234\n",
            "discarded index [6, 0, 7, 9, 1, 3, 5, 4, 2, 8]\n",
            "10 [6 0 7 9 1 3 5 4 2 8]\n",
            "discarded index [6, 0, 7, 9, 1, 3, 5, 4, 2, 8]\n",
            "10 [6 0 7 9 1 3 5 4 2 8]\n",
            "discarded index [6, 0, 7, 9, 1, 3, 5, 4, 2, 8]\n",
            "10 [6 0 7 9 1 3 5 4 2 8]\n",
            "discarded index [6, 0, 7, 9, 1, 3, 5, 4, 2, 8]\n",
            "10 [6 0 7 9 1 3 5 4 2 8]\n",
            "discarded index [6, 0, 7, 9, 1, 3, 5, 4, 2, 8]\n",
            "10 [6 0 7 9 1 3 5 4 2 8]\n",
            "discarded index [6, 0, 7, 9, 1, 3, 5, 4, 2, 8]\n",
            "10 [6 0 7 9 1 3 5 4 2 8]\n",
            "discarded index [6, 0, 7, 9, 1, 3, 5, 4, 2, 8]\n",
            "10 [6 0 7 9 1 3 5 4 2 8]\n",
            "discarded index [6, 0, 7, 9, 1, 3, 5, 4, 2, 8]\n",
            "10 [6 0 7 9 1 3 5 4 2 8]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 188, bulyan: at fang n_at 10 e 188 | val loss 2.0474 val acc 23.3157 best val_acc 24.391234\n",
            "discarded index [0, 3, 8, 5, 4, 7, 6, 2, 9, 1]\n",
            "10 [0 3 8 5 4 7 6 2 9 1]\n",
            "discarded index [0, 3, 8, 5, 4, 7, 6, 2, 9, 1]\n",
            "10 [0 3 8 5 4 7 6 2 9 1]\n",
            "discarded index [0, 3, 8, 5, 4, 7, 6, 2, 9, 1]\n",
            "10 [0 3 8 5 4 7 6 2 9 1]\n",
            "discarded index [0, 3, 8, 5, 4, 7, 6, 2, 9, 1]\n",
            "10 [0 3 8 5 4 7 6 2 9 1]\n",
            "discarded index [0, 3, 8, 5, 4, 7, 6, 2, 9, 1]\n",
            "10 [0 3 8 5 4 7 6 2 9 1]\n",
            "discarded index [0, 3, 8, 5, 4, 7, 6, 2, 9, 1]\n",
            "10 [0 3 8 5 4 7 6 2 9 1]\n",
            "discarded index [0, 3, 8, 5, 4, 7, 6, 2, 9, 1]\n",
            "10 [0 3 8 5 4 7 6 2 9 1]\n",
            "discarded index [0, 3, 8, 5, 4, 7, 6, 2, 9, 1]\n",
            "10 [0 3 8 5 4 7 6 2 9 1]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 189, bulyan: at fang n_at 10 e 189 | val loss 1.9967 val acc 22.9505 best val_acc 24.391234\n",
            "discarded index [5, 3, 9, 4, 2, 7, 8, 6, 0, 1]\n",
            "10 [5 3 9 4 2 7 8 6 0 1]\n",
            "discarded index [5, 3, 9, 4, 2, 7, 8, 6, 0, 1]\n",
            "10 [5 3 9 4 2 7 8 6 0 1]\n",
            "discarded index [5, 3, 9, 4, 2, 7, 8, 6, 0, 1]\n",
            "10 [5 3 9 4 2 7 8 6 0 1]\n",
            "discarded index [5, 3, 9, 4, 2, 7, 8, 6, 0, 1]\n",
            "10 [5 3 9 4 2 7 8 6 0 1]\n",
            "discarded index [5, 3, 9, 4, 2, 7, 8, 6, 0, 1]\n",
            "10 [5 3 9 4 2 7 8 6 0 1]\n",
            "discarded index [5, 3, 9, 4, 2, 7, 8, 6, 0, 1]\n",
            "10 [5 3 9 4 2 7 8 6 0 1]\n",
            "discarded index [5, 3, 9, 4, 2, 7, 8, 6, 0, 1]\n",
            "10 [5 3 9 4 2 7 8 6 0 1]\n",
            "discarded index [5, 3, 9, 4, 2, 7, 8, 6, 0, 1]\n",
            "10 [5 3 9 4 2 7 8 6 0 1]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 190, bulyan: at fang n_at 10 e 190 | val loss 1.9745 val acc 23.0925 best val_acc 24.391234\n",
            "discarded index [6, 1, 0, 9, 8, 4, 7, 3, 5, 2]\n",
            "10 [6 1 0 9 8 4 7 3 5 2]\n",
            "discarded index [6, 1, 0, 9, 8, 4, 7, 3, 5, 2]\n",
            "10 [6 1 0 9 8 4 7 3 5 2]\n",
            "discarded index [6, 1, 0, 9, 8, 4, 7, 3, 5, 2]\n",
            "10 [6 1 0 9 8 4 7 3 5 2]\n",
            "discarded index [6, 1, 0, 9, 8, 4, 7, 3, 5, 2]\n",
            "10 [6 1 0 9 8 4 7 3 5 2]\n",
            "discarded index [6, 1, 0, 9, 8, 4, 7, 3, 5, 2]\n",
            "10 [6 1 0 9 8 4 7 3 5 2]\n",
            "discarded index [6, 1, 0, 9, 8, 4, 7, 3, 5, 2]\n",
            "10 [6 1 0 9 8 4 7 3 5 2]\n",
            "discarded index [6, 1, 0, 9, 8, 4, 7, 3, 5, 2]\n",
            "10 [6 1 0 9 8 4 7 3 5 2]\n",
            "discarded index [6, 1, 0, 9, 8, 4, 7, 3, 5, 2]\n",
            "10 [6 1 0 9 8 4 7 3 5 2]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 191, bulyan: at fang n_at 10 e 191 | val loss 1.9859 val acc 21.6112 best val_acc 24.391234\n",
            "discarded index [3, 6, 8, 1, 7, 0, 2, 5, 9, 4]\n",
            "10 [3 6 8 1 7 0 2 5 9 4]\n",
            "discarded index [3, 6, 8, 1, 7, 0, 2, 5, 9, 4]\n",
            "10 [3 6 8 1 7 0 2 5 9 4]\n",
            "discarded index [3, 6, 8, 1, 7, 0, 2, 5, 9, 4]\n",
            "10 [3 6 8 1 7 0 2 5 9 4]\n",
            "discarded index [3, 6, 8, 1, 7, 0, 2, 5, 9, 4]\n",
            "10 [3 6 8 1 7 0 2 5 9 4]\n",
            "discarded index [3, 6, 8, 1, 7, 0, 2, 5, 9, 4]\n",
            "10 [3 6 8 1 7 0 2 5 9 4]\n",
            "discarded index [3, 6, 8, 1, 7, 0, 2, 5, 9, 4]\n",
            "10 [3 6 8 1 7 0 2 5 9 4]\n",
            "discarded index [3, 6, 8, 1, 7, 0, 2, 5, 9, 4]\n",
            "10 [3 6 8 1 7 0 2 5 9 4]\n",
            "discarded index [3, 6, 8, 1, 7, 0, 2, 5, 9, 4]\n",
            "10 [3 6 8 1 7 0 2 5 9 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 192, bulyan: at fang n_at 10 e 192 | val loss 2.0348 val acc 18.8312 best val_acc 24.391234\n",
            "discarded index [7, 0, 1, 9, 2, 4, 3, 6, 8, 5]\n",
            "10 [7 0 1 9 2 4 3 6 8 5]\n",
            "discarded index [7, 0, 1, 9, 2, 4, 3, 6, 8, 5]\n",
            "10 [7 0 1 9 2 4 3 6 8 5]\n",
            "discarded index [7, 0, 1, 9, 2, 4, 3, 6, 8, 5]\n",
            "10 [7 0 1 9 2 4 3 6 8 5]\n",
            "discarded index [7, 0, 1, 9, 2, 4, 3, 6, 8, 5]\n",
            "10 [7 0 1 9 2 4 3 6 8 5]\n",
            "discarded index [7, 0, 1, 9, 2, 4, 3, 6, 8, 5]\n",
            "10 [7 0 1 9 2 4 3 6 8 5]\n",
            "discarded index [7, 0, 1, 9, 2, 4, 3, 6, 8, 5]\n",
            "10 [7 0 1 9 2 4 3 6 8 5]\n",
            "discarded index [7, 0, 1, 9, 2, 4, 3, 6, 8, 5]\n",
            "10 [7 0 1 9 2 4 3 6 8 5]\n",
            "discarded index [7, 0, 1, 9, 2, 4, 3, 6, 8, 5]\n",
            "10 [7 0 1 9 2 4 3 6 8 5]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 193, bulyan: at fang n_at 10 e 193 | val loss 1.9530 val acc 24.6144 best val_acc 24.614448\n",
            "discarded index [6, 8, 2, 1, 0, 5, 3, 7, 4, 9]\n",
            "10 [6 8 2 1 0 5 3 7 4 9]\n",
            "discarded index [6, 8, 2, 1, 0, 5, 3, 7, 4, 9]\n",
            "10 [6 8 2 1 0 5 3 7 4 9]\n",
            "discarded index [6, 8, 2, 1, 0, 5, 3, 7, 4, 9]\n",
            "10 [6 8 2 1 0 5 3 7 4 9]\n",
            "discarded index [6, 8, 2, 1, 0, 5, 3, 7, 4, 9]\n",
            "10 [6 8 2 1 0 5 3 7 4 9]\n",
            "discarded index [6, 8, 2, 1, 0, 5, 3, 7, 4, 9]\n",
            "10 [6 8 2 1 0 5 3 7 4 9]\n",
            "discarded index [6, 8, 2, 1, 0, 5, 3, 7, 4, 9]\n",
            "10 [6 8 2 1 0 5 3 7 4 9]\n",
            "discarded index [6, 8, 2, 1, 0, 5, 3, 7, 4, 9]\n",
            "10 [6 8 2 1 0 5 3 7 4 9]\n",
            "discarded index [6, 8, 2, 1, 0, 5, 3, 7, 4, 9]\n",
            "10 [6 8 2 1 0 5 3 7 4 9]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 194, bulyan: at fang n_at 10 e 194 | val loss 1.9129 val acc 24.7971 best val_acc 24.797078\n",
            "discarded index [5, 7, 2, 1, 6, 0, 9, 8, 4, 3]\n",
            "10 [5 7 2 1 6 0 9 8 4 3]\n",
            "discarded index [5, 7, 2, 1, 6, 0, 9, 8, 4, 3]\n",
            "10 [5 7 2 1 6 0 9 8 4 3]\n",
            "discarded index [5, 7, 2, 1, 6, 0, 9, 8, 4, 3]\n",
            "10 [5 7 2 1 6 0 9 8 4 3]\n",
            "discarded index [5, 7, 2, 1, 6, 0, 9, 8, 4, 3]\n",
            "10 [5 7 2 1 6 0 9 8 4 3]\n",
            "discarded index [5, 7, 2, 1, 6, 0, 9, 8, 4, 3]\n",
            "10 [5 7 2 1 6 0 9 8 4 3]\n",
            "discarded index [5, 7, 2, 1, 6, 0, 9, 8, 4, 3]\n",
            "10 [5 7 2 1 6 0 9 8 4 3]\n",
            "discarded index [5, 7, 2, 1, 6, 0, 9, 8, 4, 3]\n",
            "10 [5 7 2 1 6 0 9 8 4 3]\n",
            "discarded index [5, 7, 2, 1, 6, 0, 9, 8, 4, 3]\n",
            "10 [5 7 2 1 6 0 9 8 4 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 195, bulyan: at fang n_at 10 e 195 | val loss 1.9221 val acc 23.9651 best val_acc 24.797078\n",
            "discarded index [6, 9, 8, 7, 4, 5, 3, 0, 2, 1]\n",
            "10 [6 9 8 7 4 5 3 0 2 1]\n",
            "discarded index [6, 9, 8, 7, 4, 5, 3, 0, 2, 1]\n",
            "10 [6 9 8 7 4 5 3 0 2 1]\n",
            "discarded index [6, 9, 8, 7, 4, 5, 3, 0, 2, 1]\n",
            "10 [6 9 8 7 4 5 3 0 2 1]\n",
            "discarded index [6, 9, 8, 7, 4, 5, 3, 0, 2, 1]\n",
            "10 [6 9 8 7 4 5 3 0 2 1]\n",
            "discarded index [6, 9, 8, 7, 4, 5, 3, 0, 2, 1]\n",
            "10 [6 9 8 7 4 5 3 0 2 1]\n",
            "discarded index [6, 9, 8, 7, 4, 5, 3, 0, 2, 1]\n",
            "10 [6 9 8 7 4 5 3 0 2 1]\n",
            "discarded index [6, 9, 8, 7, 4, 5, 3, 0, 2, 1]\n",
            "10 [6 9 8 7 4 5 3 0 2 1]\n",
            "discarded index [6, 9, 8, 7, 4, 5, 3, 0, 2, 1]\n",
            "10 [6 9 8 7 4 5 3 0 2 1]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 196, bulyan: at fang n_at 10 e 196 | val loss 1.9625 val acc 25.9943 best val_acc 25.994318\n",
            "discarded index [1, 5, 6, 0, 4, 7, 8, 9, 3, 2]\n",
            "10 [1 5 6 0 4 7 8 9 3 2]\n",
            "discarded index [1, 5, 6, 0, 4, 7, 8, 9, 3, 2]\n",
            "10 [1 5 6 0 4 7 8 9 3 2]\n",
            "discarded index [1, 5, 6, 0, 4, 7, 8, 9, 3, 2]\n",
            "10 [1 5 6 0 4 7 8 9 3 2]\n",
            "discarded index [1, 5, 6, 0, 4, 7, 8, 9, 3, 2]\n",
            "10 [1 5 6 0 4 7 8 9 3 2]\n",
            "discarded index [1, 5, 6, 0, 4, 7, 8, 9, 3, 2]\n",
            "10 [1 5 6 0 4 7 8 9 3 2]\n",
            "discarded index [1, 5, 6, 0, 4, 7, 8, 9, 3, 2]\n",
            "10 [1 5 6 0 4 7 8 9 3 2]\n",
            "discarded index [1, 5, 6, 0, 4, 7, 8, 9, 3, 2]\n",
            "10 [1 5 6 0 4 7 8 9 3 2]\n",
            "discarded index [1, 5, 6, 0, 4, 7, 8, 9, 3, 2]\n",
            "10 [1 5 6 0 4 7 8 9 3 2]\n",
            "discarded index [1, 5, 6, 0, 4, 7, 8, 9, 3, 2]\n",
            "10 [1 5 6 0 4 7 8 9 3 2]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 197, bulyan: at fang n_at 10 e 197 | val loss 2.1111 val acc 17.6136 best val_acc 25.994318\n",
            "discarded index [5, 6, 0, 8, 4, 9, 1, 3, 2, 7]\n",
            "10 [5 6 0 8 4 9 1 3 2 7]\n",
            "discarded index [5, 6, 0, 8, 4, 9, 1, 3, 2, 7]\n",
            "10 [5 6 0 8 4 9 1 3 2 7]\n",
            "discarded index [5, 6, 0, 8, 4, 9, 1, 3, 2, 7]\n",
            "10 [5 6 0 8 4 9 1 3 2 7]\n",
            "discarded index [5, 6, 0, 8, 4, 9, 1, 3, 2, 7]\n",
            "10 [5 6 0 8 4 9 1 3 2 7]\n",
            "discarded index [5, 6, 0, 8, 4, 9, 1, 3, 2, 7]\n",
            "10 [5 6 0 8 4 9 1 3 2 7]\n",
            "discarded index [5, 6, 0, 8, 4, 9, 1, 3, 2, 7]\n",
            "10 [5 6 0 8 4 9 1 3 2 7]\n",
            "discarded index [5, 6, 0, 8, 4, 9, 1, 3, 2, 7]\n",
            "10 [5 6 0 8 4 9 1 3 2 7]\n",
            "discarded index [5, 6, 0, 8, 4, 9, 1, 3, 2, 7]\n",
            "10 [5 6 0 8 4 9 1 3 2 7]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 198, bulyan: at fang n_at 10 e 198 | val loss 2.0203 val acc 21.5300 best val_acc 25.994318\n",
            "discarded index [7, 6, 9, 3, 4, 1, 2, 5, 8, 0]\n",
            "10 [7 6 9 3 4 1 2 5 8 0]\n",
            "discarded index [7, 6, 9, 3, 4, 1, 2, 5, 8, 0]\n",
            "10 [7 6 9 3 4 1 2 5 8 0]\n",
            "discarded index [7, 6, 9, 3, 4, 1, 2, 5, 8, 0]\n",
            "10 [7 6 9 3 4 1 2 5 8 0]\n",
            "discarded index [7, 6, 9, 3, 4, 1, 2, 5, 8, 0]\n",
            "10 [7 6 9 3 4 1 2 5 8 0]\n",
            "discarded index [7, 6, 9, 3, 4, 1, 2, 5, 8, 0]\n",
            "10 [7 6 9 3 4 1 2 5 8 0]\n",
            "discarded index [7, 6, 9, 3, 4, 1, 2, 5, 8, 0]\n",
            "10 [7 6 9 3 4 1 2 5 8 0]\n",
            "discarded index [7, 6, 9, 3, 4, 1, 2, 5, 8, 0]\n",
            "10 [7 6 9 3 4 1 2 5 8 0]\n",
            "discarded index [7, 6, 9, 3, 4, 1, 2, 5, 8, 0]\n",
            "10 [7 6 9 3 4 1 2 5 8 0]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 199, bulyan: at fang n_at 10 e 199 | val loss 2.0076 val acc 23.3157 best val_acc 25.994318\n",
            "discarded index [0, 1, 7, 9, 8, 6, 4, 5, 2, 3]\n",
            "10 [0 1 7 9 8 6 4 5 2 3]\n",
            "discarded index [0, 1, 7, 9, 8, 6, 4, 5, 2, 3]\n",
            "10 [0 1 7 9 8 6 4 5 2 3]\n",
            "discarded index [0, 1, 7, 9, 8, 6, 4, 5, 2, 3]\n",
            "10 [0 1 7 9 8 6 4 5 2 3]\n",
            "discarded index [0, 1, 7, 9, 8, 6, 4, 5, 2, 3]\n",
            "10 [0 1 7 9 8 6 4 5 2 3]\n",
            "discarded index [0, 1, 7, 9, 8, 6, 4, 5, 2, 3]\n",
            "10 [0 1 7 9 8 6 4 5 2 3]\n",
            "discarded index [0, 1, 7, 9, 8, 6, 4, 5, 2, 3]\n",
            "10 [0 1 7 9 8 6 4 5 2 3]\n",
            "discarded index [0, 1, 7, 9, 8, 6, 4, 5, 2, 3]\n",
            "10 [0 1 7 9 8 6 4 5 2 3]\n",
            "discarded index [0, 1, 7, 9, 8, 6, 4, 5, 2, 3]\n",
            "10 [0 1 7 9 8 6 4 5 2 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 200, bulyan: at fang n_at 10 e 200 | val loss 2.0142 val acc 22.7679 best val_acc 25.994318\n",
            "discarded index [9, 8, 6, 0, 3, 1, 7, 2, 5, 4]\n",
            "10 [9 8 6 0 3 1 7 2 5 4]\n",
            "discarded index [9, 8, 6, 0, 3, 1, 7, 2, 5, 4]\n",
            "10 [9 8 6 0 3 1 7 2 5 4]\n",
            "discarded index [9, 8, 6, 0, 3, 1, 7, 2, 5, 4]\n",
            "10 [9 8 6 0 3 1 7 2 5 4]\n",
            "discarded index [9, 8, 6, 0, 3, 1, 7, 2, 5, 4]\n",
            "10 [9 8 6 0 3 1 7 2 5 4]\n",
            "discarded index [9, 8, 6, 0, 3, 1, 7, 2, 5, 4]\n",
            "10 [9 8 6 0 3 1 7 2 5 4]\n",
            "discarded index [9, 8, 6, 0, 3, 1, 7, 2, 5, 4]\n",
            "10 [9 8 6 0 3 1 7 2 5 4]\n",
            "discarded index [9, 8, 6, 0, 3, 1, 7, 2, 5, 4]\n",
            "10 [9 8 6 0 3 1 7 2 5 4]\n",
            "discarded index [9, 8, 6, 0, 3, 1, 7, 2, 5, 4]\n",
            "10 [9 8 6 0 3 1 7 2 5 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 201, bulyan: at fang n_at 10 e 201 | val loss 2.1450 val acc 19.3182 best val_acc 25.994318\n",
            "discarded index [7, 1, 9, 0, 3, 8, 6, 4, 5, 2]\n",
            "10 [7 1 9 0 3 8 6 4 5 2]\n",
            "discarded index [7, 1, 9, 0, 3, 8, 6, 4, 5, 2]\n",
            "10 [7 1 9 0 3 8 6 4 5 2]\n",
            "discarded index [7, 1, 9, 0, 3, 8, 6, 4, 5, 2]\n",
            "10 [7 1 9 0 3 8 6 4 5 2]\n",
            "discarded index [7, 1, 9, 0, 3, 8, 6, 4, 5, 2]\n",
            "10 [7 1 9 0 3 8 6 4 5 2]\n",
            "discarded index [7, 1, 9, 0, 3, 8, 6, 4, 5, 2]\n",
            "10 [7 1 9 0 3 8 6 4 5 2]\n",
            "discarded index [7, 1, 9, 0, 3, 8, 6, 4, 5, 2]\n",
            "10 [7 1 9 0 3 8 6 4 5 2]\n",
            "discarded index [7, 1, 9, 0, 3, 8, 6, 4, 5, 2]\n",
            "10 [7 1 9 0 3 8 6 4 5 2]\n",
            "discarded index [7, 1, 9, 0, 3, 8, 6, 4, 5, 2]\n",
            "10 [7 1 9 0 3 8 6 4 5 2]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 202, bulyan: at fang n_at 10 e 202 | val loss 2.0261 val acc 22.4229 best val_acc 25.994318\n",
            "discarded index [6, 0, 1, 9, 5, 8, 4, 2, 7, 3]\n",
            "10 [6 0 1 9 5 8 4 2 7 3]\n",
            "discarded index [6, 0, 1, 9, 5, 8, 4, 2, 7, 3]\n",
            "10 [6 0 1 9 5 8 4 2 7 3]\n",
            "discarded index [6, 0, 1, 9, 5, 8, 4, 2, 7, 3]\n",
            "10 [6 0 1 9 5 8 4 2 7 3]\n",
            "discarded index [6, 0, 1, 9, 5, 8, 4, 2, 7, 3]\n",
            "10 [6 0 1 9 5 8 4 2 7 3]\n",
            "discarded index [6, 0, 1, 9, 5, 8, 4, 2, 7, 3]\n",
            "10 [6 0 1 9 5 8 4 2 7 3]\n",
            "discarded index [6, 0, 1, 9, 5, 8, 4, 2, 7, 3]\n",
            "10 [6 0 1 9 5 8 4 2 7 3]\n",
            "discarded index [6, 0, 1, 9, 5, 8, 4, 2, 7, 3]\n",
            "10 [6 0 1 9 5 8 4 2 7 3]\n",
            "discarded index [6, 0, 1, 9, 5, 8, 4, 2, 7, 3]\n",
            "10 [6 0 1 9 5 8 4 2 7 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 203, bulyan: at fang n_at 10 e 203 | val loss 1.9738 val acc 24.9797 best val_acc 25.994318\n",
            "discarded index [5, 6, 8, 1, 7, 4, 2, 0, 3, 9]\n",
            "10 [5 6 8 1 7 4 2 0 3 9]\n",
            "discarded index [5, 6, 8, 1, 7, 4, 2, 0, 3, 9]\n",
            "10 [5 6 8 1 7 4 2 0 3 9]\n",
            "discarded index [5, 6, 8, 1, 7, 4, 2, 0, 3, 9]\n",
            "10 [5 6 8 1 7 4 2 0 3 9]\n",
            "discarded index [5, 6, 8, 1, 7, 4, 2, 0, 3, 9]\n",
            "10 [5 6 8 1 7 4 2 0 3 9]\n",
            "discarded index [5, 6, 8, 1, 7, 4, 2, 0, 3, 9]\n",
            "10 [5 6 8 1 7 4 2 0 3 9]\n",
            "discarded index [5, 6, 8, 1, 7, 4, 2, 0, 3, 9]\n",
            "10 [5 6 8 1 7 4 2 0 3 9]\n",
            "discarded index [5, 6, 8, 1, 7, 4, 2, 0, 3, 9]\n",
            "10 [5 6 8 1 7 4 2 0 3 9]\n",
            "discarded index [5, 6, 8, 1, 7, 4, 2, 0, 3, 9]\n",
            "10 [5 6 8 1 7 4 2 0 3 9]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 204, bulyan: at fang n_at 10 e 204 | val loss 1.9314 val acc 27.6583 best val_acc 27.658279\n",
            "discarded index [5, 6, 7, 4, 2, 0, 9, 1, 3, 8]\n",
            "10 [5 6 7 4 2 0 9 1 3 8]\n",
            "discarded index [5, 6, 7, 4, 2, 0, 9, 1, 3, 8]\n",
            "10 [5 6 7 4 2 0 9 1 3 8]\n",
            "discarded index [5, 6, 7, 4, 2, 0, 9, 1, 3, 8]\n",
            "10 [5 6 7 4 2 0 9 1 3 8]\n",
            "discarded index [5, 6, 7, 4, 2, 0, 9, 1, 3, 8]\n",
            "10 [5 6 7 4 2 0 9 1 3 8]\n",
            "discarded index [5, 6, 7, 4, 2, 0, 9, 1, 3, 8]\n",
            "10 [5 6 7 4 2 0 9 1 3 8]\n",
            "discarded index [5, 6, 7, 4, 2, 0, 9, 1, 3, 8]\n",
            "10 [5 6 7 4 2 0 9 1 3 8]\n",
            "discarded index [5, 6, 7, 4, 2, 0, 9, 1, 3, 8]\n",
            "10 [5 6 7 4 2 0 9 1 3 8]\n",
            "discarded index [5, 6, 7, 4, 2, 0, 9, 1, 3, 8]\n",
            "10 [5 6 7 4 2 0 9 1 3 8]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 205, bulyan: at fang n_at 10 e 205 | val loss 1.9125 val acc 26.6640 best val_acc 27.658279\n",
            "discarded index [0, 1, 7, 6, 9, 8, 2, 5, 3, 4]\n",
            "10 [0 1 7 6 9 8 2 5 3 4]\n",
            "discarded index [0, 1, 7, 6, 9, 8, 2, 5, 3, 4]\n",
            "10 [0 1 7 6 9 8 2 5 3 4]\n",
            "discarded index [0, 1, 7, 6, 9, 8, 2, 5, 3, 4]\n",
            "10 [0 1 7 6 9 8 2 5 3 4]\n",
            "discarded index [0, 1, 7, 6, 9, 8, 2, 5, 3, 4]\n",
            "10 [0 1 7 6 9 8 2 5 3 4]\n",
            "discarded index [0, 1, 7, 6, 9, 8, 2, 5, 3, 4]\n",
            "10 [0 1 7 6 9 8 2 5 3 4]\n",
            "discarded index [0, 1, 7, 6, 9, 8, 2, 5, 3, 4]\n",
            "10 [0 1 7 6 9 8 2 5 3 4]\n",
            "discarded index [0, 1, 7, 6, 9, 8, 2, 5, 3, 4]\n",
            "10 [0 1 7 6 9 8 2 5 3 4]\n",
            "discarded index [0, 1, 7, 6, 9, 8, 2, 5, 3, 4]\n",
            "10 [0 1 7 6 9 8 2 5 3 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 206, bulyan: at fang n_at 10 e 206 | val loss 1.9165 val acc 27.0292 best val_acc 27.658279\n",
            "discarded index [5, 2, 7, 1, 3, 0, 9, 6, 4, 8]\n",
            "10 [5 2 7 1 3 0 9 6 4 8]\n",
            "discarded index [5, 2, 7, 1, 3, 0, 9, 6, 4, 8]\n",
            "10 [5 2 7 1 3 0 9 6 4 8]\n",
            "discarded index [5, 2, 7, 1, 3, 0, 9, 6, 4, 8]\n",
            "10 [5 2 7 1 3 0 9 6 4 8]\n",
            "discarded index [5, 2, 7, 1, 3, 0, 9, 6, 4, 8]\n",
            "10 [5 2 7 1 3 0 9 6 4 8]\n",
            "discarded index [5, 2, 7, 1, 3, 0, 9, 6, 4, 8]\n",
            "10 [5 2 7 1 3 0 9 6 4 8]\n",
            "discarded index [5, 2, 7, 1, 3, 0, 9, 6, 4, 8]\n",
            "10 [5 2 7 1 3 0 9 6 4 8]\n",
            "discarded index [5, 2, 7, 1, 3, 0, 9, 6, 4, 8]\n",
            "10 [5 2 7 1 3 0 9 6 4 8]\n",
            "discarded index [5, 2, 7, 1, 3, 0, 9, 6, 4, 8]\n",
            "10 [5 2 7 1 3 0 9 6 4 8]\n",
            "discarded index [5, 2, 7, 1, 3, 0, 9, 6, 4, 8]\n",
            "10 [5 2 7 1 3 0 9 6 4 8]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 207, bulyan: at fang n_at 10 e 207 | val loss 1.9812 val acc 26.0552 best val_acc 27.658279\n",
            "discarded index [0, 9, 6, 5, 8, 4, 2, 3, 7, 1]\n",
            "10 [0 9 6 5 8 4 2 3 7 1]\n",
            "discarded index [0, 9, 6, 5, 8, 4, 2, 3, 7, 1]\n",
            "10 [0 9 6 5 8 4 2 3 7 1]\n",
            "discarded index [0, 9, 6, 5, 8, 4, 2, 3, 7, 1]\n",
            "10 [0 9 6 5 8 4 2 3 7 1]\n",
            "discarded index [0, 9, 6, 5, 8, 4, 2, 3, 7, 1]\n",
            "10 [0 9 6 5 8 4 2 3 7 1]\n",
            "discarded index [0, 9, 6, 5, 8, 4, 2, 3, 7, 1]\n",
            "10 [0 9 6 5 8 4 2 3 7 1]\n",
            "discarded index [0, 9, 6, 5, 8, 4, 2, 3, 7, 1]\n",
            "10 [0 9 6 5 8 4 2 3 7 1]\n",
            "discarded index [0, 9, 6, 5, 8, 4, 2, 3, 7, 1]\n",
            "10 [0 9 6 5 8 4 2 3 7 1]\n",
            "discarded index [0, 9, 6, 5, 8, 4, 2, 3, 7, 1]\n",
            "10 [0 9 6 5 8 4 2 3 7 1]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 208, bulyan: at fang n_at 10 e 208 | val loss 1.9140 val acc 28.5714 best val_acc 28.571429\n",
            "discarded index [1, 0, 5, 6, 8, 4, 7, 2, 9, 3]\n",
            "10 [1 0 5 6 8 4 7 2 9 3]\n",
            "discarded index [1, 0, 5, 6, 8, 4, 7, 2, 9, 3]\n",
            "10 [1 0 5 6 8 4 7 2 9 3]\n",
            "discarded index [1, 0, 5, 6, 8, 4, 7, 2, 9, 3]\n",
            "10 [1 0 5 6 8 4 7 2 9 3]\n",
            "discarded index [1, 0, 5, 6, 8, 4, 7, 2, 9, 3]\n",
            "10 [1 0 5 6 8 4 7 2 9 3]\n",
            "discarded index [1, 0, 5, 6, 8, 4, 7, 2, 9, 3]\n",
            "10 [1 0 5 6 8 4 7 2 9 3]\n",
            "discarded index [1, 0, 5, 6, 8, 4, 7, 2, 9, 3]\n",
            "10 [1 0 5 6 8 4 7 2 9 3]\n",
            "discarded index [1, 0, 5, 6, 8, 4, 7, 2, 9, 3]\n",
            "10 [1 0 5 6 8 4 7 2 9 3]\n",
            "discarded index [1, 0, 5, 6, 8, 4, 7, 2, 9, 3]\n",
            "10 [1 0 5 6 8 4 7 2 9 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 209, bulyan: at fang n_at 10 e 209 | val loss 1.9966 val acc 24.2898 best val_acc 28.571429\n",
            "discarded index [9, 0, 6, 8, 3, 7, 2, 1, 4, 5]\n",
            "10 [9 0 6 8 3 7 2 1 4 5]\n",
            "discarded index [9, 0, 6, 8, 3, 7, 2, 1, 4, 5]\n",
            "10 [9 0 6 8 3 7 2 1 4 5]\n",
            "discarded index [9, 0, 6, 8, 3, 7, 2, 1, 4, 5]\n",
            "10 [9 0 6 8 3 7 2 1 4 5]\n",
            "discarded index [9, 0, 6, 8, 3, 7, 2, 1, 4, 5]\n",
            "10 [9 0 6 8 3 7 2 1 4 5]\n",
            "discarded index [9, 0, 6, 8, 3, 7, 2, 1, 4, 5]\n",
            "10 [9 0 6 8 3 7 2 1 4 5]\n",
            "discarded index [9, 0, 6, 8, 3, 7, 2, 1, 4, 5]\n",
            "10 [9 0 6 8 3 7 2 1 4 5]\n",
            "discarded index [9, 0, 6, 8, 3, 7, 2, 1, 4, 5]\n",
            "10 [9 0 6 8 3 7 2 1 4 5]\n",
            "discarded index [9, 0, 6, 8, 3, 7, 2, 1, 4, 5]\n",
            "10 [9 0 6 8 3 7 2 1 4 5]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 210, bulyan: at fang n_at 10 e 210 | val loss 1.9108 val acc 26.2581 best val_acc 28.571429\n",
            "discarded index [6, 5, 7, 8, 9, 3, 1, 4, 2, 0]\n",
            "10 [6 5 7 8 9 3 1 4 2 0]\n",
            "discarded index [6, 5, 7, 8, 9, 3, 1, 4, 2, 0]\n",
            "10 [6 5 7 8 9 3 1 4 2 0]\n",
            "discarded index [6, 5, 7, 8, 9, 3, 1, 4, 2, 0]\n",
            "10 [6 5 7 8 9 3 1 4 2 0]\n",
            "discarded index [6, 5, 7, 8, 9, 3, 1, 4, 2, 0]\n",
            "10 [6 5 7 8 9 3 1 4 2 0]\n",
            "discarded index [6, 5, 7, 8, 9, 3, 1, 4, 2, 0]\n",
            "10 [6 5 7 8 9 3 1 4 2 0]\n",
            "discarded index [6, 5, 7, 8, 9, 3, 1, 4, 2, 0]\n",
            "10 [6 5 7 8 9 3 1 4 2 0]\n",
            "discarded index [6, 5, 7, 8, 9, 3, 1, 4, 2, 0]\n",
            "10 [6 5 7 8 9 3 1 4 2 0]\n",
            "discarded index [6, 5, 7, 8, 9, 3, 1, 4, 2, 0]\n",
            "10 [6 5 7 8 9 3 1 4 2 0]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 211, bulyan: at fang n_at 10 e 211 | val loss 1.9191 val acc 26.0349 best val_acc 28.571429\n",
            "discarded index [0, 1, 9, 7, 3, 2, 5, 6, 8, 4]\n",
            "10 [0 1 9 7 3 2 5 6 8 4]\n",
            "discarded index [0, 1, 9, 7, 3, 2, 5, 6, 8, 4]\n",
            "10 [0 1 9 7 3 2 5 6 8 4]\n",
            "discarded index [0, 1, 9, 7, 3, 2, 5, 6, 8, 4]\n",
            "10 [0 1 9 7 3 2 5 6 8 4]\n",
            "discarded index [0, 1, 9, 7, 3, 2, 5, 6, 8, 4]\n",
            "10 [0 1 9 7 3 2 5 6 8 4]\n",
            "discarded index [0, 1, 9, 7, 3, 2, 5, 6, 8, 4]\n",
            "10 [0 1 9 7 3 2 5 6 8 4]\n",
            "discarded index [0, 1, 9, 7, 3, 2, 5, 6, 8, 4]\n",
            "10 [0 1 9 7 3 2 5 6 8 4]\n",
            "discarded index [0, 1, 9, 7, 3, 2, 5, 6, 8, 4]\n",
            "10 [0 1 9 7 3 2 5 6 8 4]\n",
            "discarded index [0, 1, 9, 7, 3, 2, 5, 6, 8, 4]\n",
            "10 [0 1 9 7 3 2 5 6 8 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 212, bulyan: at fang n_at 10 e 212 | val loss 1.9130 val acc 25.1623 best val_acc 28.571429\n",
            "discarded index [6, 8, 3, 9, 4, 0, 1, 5, 2, 7]\n",
            "10 [6 8 3 9 4 0 1 5 2 7]\n",
            "discarded index [6, 8, 3, 9, 4, 0, 1, 5, 2, 7]\n",
            "10 [6 8 3 9 4 0 1 5 2 7]\n",
            "discarded index [6, 8, 3, 9, 4, 0, 1, 5, 2, 7]\n",
            "10 [6 8 3 9 4 0 1 5 2 7]\n",
            "discarded index [6, 8, 3, 9, 4, 0, 1, 5, 2, 7]\n",
            "10 [6 8 3 9 4 0 1 5 2 7]\n",
            "discarded index [6, 8, 3, 9, 4, 0, 1, 5, 2, 7]\n",
            "10 [6 8 3 9 4 0 1 5 2 7]\n",
            "discarded index [6, 8, 3, 9, 4, 0, 1, 5, 2, 7]\n",
            "10 [6 8 3 9 4 0 1 5 2 7]\n",
            "discarded index [6, 8, 3, 9, 4, 0, 1, 5, 2, 7]\n",
            "10 [6 8 3 9 4 0 1 5 2 7]\n",
            "discarded index [6, 8, 3, 9, 4, 0, 1, 5, 2, 7]\n",
            "10 [6 8 3 9 4 0 1 5 2 7]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 213, bulyan: at fang n_at 10 e 213 | val loss 1.9773 val acc 24.3709 best val_acc 28.571429\n",
            "discarded index [7, 0, 5, 9, 8, 3, 6, 2, 1, 4]\n",
            "10 [7 0 5 9 8 3 6 2 1 4]\n",
            "discarded index [7, 0, 5, 9, 8, 3, 6, 2, 1, 4]\n",
            "10 [7 0 5 9 8 3 6 2 1 4]\n",
            "discarded index [7, 0, 5, 9, 8, 3, 6, 2, 1, 4]\n",
            "10 [7 0 5 9 8 3 6 2 1 4]\n",
            "discarded index [7, 0, 5, 9, 8, 3, 6, 2, 1, 4]\n",
            "10 [7 0 5 9 8 3 6 2 1 4]\n",
            "discarded index [7, 0, 5, 9, 8, 3, 6, 2, 1, 4]\n",
            "10 [7 0 5 9 8 3 6 2 1 4]\n",
            "discarded index [7, 0, 5, 9, 8, 3, 6, 2, 1, 4]\n",
            "10 [7 0 5 9 8 3 6 2 1 4]\n",
            "discarded index [7, 0, 5, 9, 8, 3, 6, 2, 1, 4]\n",
            "10 [7 0 5 9 8 3 6 2 1 4]\n",
            "discarded index [7, 0, 5, 9, 8, 3, 6, 2, 1, 4]\n",
            "10 [7 0 5 9 8 3 6 2 1 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 214, bulyan: at fang n_at 10 e 214 | val loss 1.8916 val acc 26.4002 best val_acc 28.571429\n",
            "discarded index [0, 1, 7, 4, 5, 6, 3, 8, 9, 2]\n",
            "10 [0 1 7 4 5 6 3 8 9 2]\n",
            "discarded index [0, 1, 7, 4, 5, 6, 3, 8, 9, 2]\n",
            "10 [0 1 7 4 5 6 3 8 9 2]\n",
            "discarded index [0, 1, 7, 4, 5, 6, 3, 8, 9, 2]\n",
            "10 [0 1 7 4 5 6 3 8 9 2]\n",
            "discarded index [0, 1, 7, 4, 5, 6, 3, 8, 9, 2]\n",
            "10 [0 1 7 4 5 6 3 8 9 2]\n",
            "discarded index [0, 1, 7, 4, 5, 6, 3, 8, 9, 2]\n",
            "10 [0 1 7 4 5 6 3 8 9 2]\n",
            "discarded index [0, 1, 7, 4, 5, 6, 3, 8, 9, 2]\n",
            "10 [0 1 7 4 5 6 3 8 9 2]\n",
            "discarded index [0, 1, 7, 4, 5, 6, 3, 8, 9, 2]\n",
            "10 [0 1 7 4 5 6 3 8 9 2]\n",
            "discarded index [0, 1, 7, 4, 5, 6, 3, 8, 9, 2]\n",
            "10 [0 1 7 4 5 6 3 8 9 2]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 215, bulyan: at fang n_at 10 e 215 | val loss 1.8404 val acc 31.0674 best val_acc 31.067370\n",
            "discarded index [9, 8, 4, 3, 6, 0, 5, 2, 1, 7]\n",
            "10 [9 8 4 3 6 0 5 2 1 7]\n",
            "discarded index [9, 8, 4, 3, 6, 0, 5, 2, 1, 7]\n",
            "10 [9 8 4 3 6 0 5 2 1 7]\n",
            "discarded index [9, 8, 4, 3, 6, 0, 5, 2, 1, 7]\n",
            "10 [9 8 4 3 6 0 5 2 1 7]\n",
            "discarded index [9, 8, 4, 3, 6, 0, 5, 2, 1, 7]\n",
            "10 [9 8 4 3 6 0 5 2 1 7]\n",
            "discarded index [9, 8, 4, 3, 6, 0, 5, 2, 1, 7]\n",
            "10 [9 8 4 3 6 0 5 2 1 7]\n",
            "discarded index [9, 8, 4, 3, 6, 0, 5, 2, 1, 7]\n",
            "10 [9 8 4 3 6 0 5 2 1 7]\n",
            "discarded index [9, 8, 4, 3, 6, 0, 5, 2, 1, 7]\n",
            "10 [9 8 4 3 6 0 5 2 1 7]\n",
            "discarded index [9, 8, 4, 3, 6, 0, 5, 2, 1, 7]\n",
            "10 [9 8 4 3 6 0 5 2 1 7]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 216, bulyan: at fang n_at 10 e 216 | val loss 1.8656 val acc 30.0933 best val_acc 31.067370\n",
            "discarded index [6, 9, 8, 3, 0, 4, 5, 7, 1, 2]\n",
            "10 [6 9 8 3 0 4 5 7 1 2]\n",
            "discarded index [6, 9, 8, 3, 0, 4, 5, 7, 1, 2]\n",
            "10 [6 9 8 3 0 4 5 7 1 2]\n",
            "discarded index [6, 9, 8, 3, 0, 4, 5, 7, 1, 2]\n",
            "10 [6 9 8 3 0 4 5 7 1 2]\n",
            "discarded index [6, 9, 8, 3, 0, 4, 5, 7, 1, 2]\n",
            "10 [6 9 8 3 0 4 5 7 1 2]\n",
            "discarded index [6, 9, 8, 3, 0, 4, 5, 7, 1, 2]\n",
            "10 [6 9 8 3 0 4 5 7 1 2]\n",
            "discarded index [6, 9, 8, 3, 0, 4, 5, 7, 1, 2]\n",
            "10 [6 9 8 3 0 4 5 7 1 2]\n",
            "discarded index [6, 9, 8, 3, 0, 4, 5, 7, 1, 2]\n",
            "10 [6 9 8 3 0 4 5 7 1 2]\n",
            "discarded index [6, 9, 8, 3, 0, 4, 5, 7, 1, 2]\n",
            "10 [6 9 8 3 0 4 5 7 1 2]\n",
            "discarded index [6, 9, 8, 3, 0, 4, 5, 7, 1, 2]\n",
            "10 [6 9 8 3 0 4 5 7 1 2]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 217, bulyan: at fang n_at 10 e 217 | val loss 2.1159 val acc 21.4083 best val_acc 31.067370\n",
            "discarded index [0, 5, 9, 4, 8, 3, 2, 6, 1, 7]\n",
            "10 [0 5 9 4 8 3 2 6 1 7]\n",
            "discarded index [0, 5, 9, 4, 8, 3, 2, 6, 1, 7]\n",
            "10 [0 5 9 4 8 3 2 6 1 7]\n",
            "discarded index [0, 5, 9, 4, 8, 3, 2, 6, 1, 7]\n",
            "10 [0 5 9 4 8 3 2 6 1 7]\n",
            "discarded index [0, 5, 9, 4, 8, 3, 2, 6, 1, 7]\n",
            "10 [0 5 9 4 8 3 2 6 1 7]\n",
            "discarded index [0, 5, 9, 4, 8, 3, 2, 6, 1, 7]\n",
            "10 [0 5 9 4 8 3 2 6 1 7]\n",
            "discarded index [0, 5, 9, 4, 8, 3, 2, 6, 1, 7]\n",
            "10 [0 5 9 4 8 3 2 6 1 7]\n",
            "discarded index [0, 5, 9, 4, 8, 3, 2, 6, 1, 7]\n",
            "10 [0 5 9 4 8 3 2 6 1 7]\n",
            "discarded index [0, 5, 9, 4, 8, 3, 2, 6, 1, 7]\n",
            "10 [0 5 9 4 8 3 2 6 1 7]\n",
            "discarded index [0, 5, 9, 4, 8, 3, 2, 6, 1, 7]\n",
            "10 [0 5 9 4 8 3 2 6 1 7]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 218, bulyan: at fang n_at 10 e 218 | val loss 1.9709 val acc 24.6753 best val_acc 31.067370\n",
            "discarded index [3, 4, 7, 1, 5, 0, 9, 2, 8, 6]\n",
            "10 [3 4 7 1 5 0 9 2 8 6]\n",
            "discarded index [3, 4, 7, 1, 5, 0, 9, 2, 8, 6]\n",
            "10 [3 4 7 1 5 0 9 2 8 6]\n",
            "discarded index [3, 4, 7, 1, 5, 0, 9, 2, 8, 6]\n",
            "10 [3 4 7 1 5 0 9 2 8 6]\n",
            "discarded index [3, 4, 7, 1, 5, 0, 9, 2, 8, 6]\n",
            "10 [3 4 7 1 5 0 9 2 8 6]\n",
            "discarded index [3, 4, 7, 1, 5, 0, 9, 2, 8, 6]\n",
            "10 [3 4 7 1 5 0 9 2 8 6]\n",
            "discarded index [3, 4, 7, 1, 5, 0, 9, 2, 8, 6]\n",
            "10 [3 4 7 1 5 0 9 2 8 6]\n",
            "discarded index [3, 4, 7, 1, 5, 0, 9, 2, 8, 6]\n",
            "10 [3 4 7 1 5 0 9 2 8 6]\n",
            "discarded index [3, 4, 7, 1, 5, 0, 9, 2, 8, 6]\n",
            "10 [3 4 7 1 5 0 9 2 8 6]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 219, bulyan: at fang n_at 10 e 219 | val loss 1.8791 val acc 27.9221 best val_acc 31.067370\n",
            "discarded index [4, 1, 3, 5, 0, 2, 6, 7, 8, 9]\n",
            "10 [4 1 3 5 0 2 6 7 8 9]\n",
            "discarded index [4, 1, 3, 5, 0, 2, 6, 7, 8, 9]\n",
            "10 [4 1 3 5 0 2 6 7 8 9]\n",
            "discarded index [4, 1, 3, 5, 0, 2, 6, 7, 8, 9]\n",
            "10 [4 1 3 5 0 2 6 7 8 9]\n",
            "discarded index [4, 1, 3, 5, 0, 2, 6, 7, 8, 9]\n",
            "10 [4 1 3 5 0 2 6 7 8 9]\n",
            "discarded index [4, 1, 3, 5, 0, 2, 6, 7, 8, 9]\n",
            "10 [4 1 3 5 0 2 6 7 8 9]\n",
            "discarded index [4, 1, 3, 5, 0, 2, 6, 7, 8, 9]\n",
            "10 [4 1 3 5 0 2 6 7 8 9]\n",
            "discarded index [4, 1, 3, 5, 0, 2, 6, 7, 8, 9]\n",
            "10 [4 1 3 5 0 2 6 7 8 9]\n",
            "discarded index [4, 1, 3, 5, 0, 2, 6, 7, 8, 9]\n",
            "10 [4 1 3 5 0 2 6 7 8 9]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 220, bulyan: at fang n_at 10 e 220 | val loss 1.8283 val acc 29.6469 best val_acc 31.067370\n",
            "discarded index [0, 1, 7, 6, 9, 8, 3, 2, 4, 5]\n",
            "10 [0 1 7 6 9 8 3 2 4 5]\n",
            "discarded index [0, 1, 7, 6, 9, 8, 3, 2, 4, 5]\n",
            "10 [0 1 7 6 9 8 3 2 4 5]\n",
            "discarded index [0, 1, 7, 6, 9, 8, 3, 2, 4, 5]\n",
            "10 [0 1 7 6 9 8 3 2 4 5]\n",
            "discarded index [0, 1, 7, 6, 9, 8, 3, 2, 4, 5]\n",
            "10 [0 1 7 6 9 8 3 2 4 5]\n",
            "discarded index [0, 1, 7, 6, 9, 8, 3, 2, 4, 5]\n",
            "10 [0 1 7 6 9 8 3 2 4 5]\n",
            "discarded index [0, 1, 7, 6, 9, 8, 3, 2, 4, 5]\n",
            "10 [0 1 7 6 9 8 3 2 4 5]\n",
            "discarded index [0, 1, 7, 6, 9, 8, 3, 2, 4, 5]\n",
            "10 [0 1 7 6 9 8 3 2 4 5]\n",
            "discarded index [0, 1, 7, 6, 9, 8, 3, 2, 4, 5]\n",
            "10 [0 1 7 6 9 8 3 2 4 5]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 221, bulyan: at fang n_at 10 e 221 | val loss 1.8591 val acc 29.8295 best val_acc 31.067370\n",
            "discarded index [4, 1, 8, 7, 3, 2, 9, 5, 6, 0]\n",
            "10 [4 1 8 7 3 2 9 5 6 0]\n",
            "discarded index [4, 1, 8, 7, 3, 2, 9, 5, 6, 0]\n",
            "10 [4 1 8 7 3 2 9 5 6 0]\n",
            "discarded index [4, 1, 8, 7, 3, 2, 9, 5, 6, 0]\n",
            "10 [4 1 8 7 3 2 9 5 6 0]\n",
            "discarded index [4, 1, 8, 7, 3, 2, 9, 5, 6, 0]\n",
            "10 [4 1 8 7 3 2 9 5 6 0]\n",
            "discarded index [4, 1, 8, 7, 3, 2, 9, 5, 6, 0]\n",
            "10 [4 1 8 7 3 2 9 5 6 0]\n",
            "discarded index [4, 1, 8, 7, 3, 2, 9, 5, 6, 0]\n",
            "10 [4 1 8 7 3 2 9 5 6 0]\n",
            "discarded index [4, 1, 8, 7, 3, 2, 9, 5, 6, 0]\n",
            "10 [4 1 8 7 3 2 9 5 6 0]\n",
            "discarded index [4, 1, 8, 7, 3, 2, 9, 5, 6, 0]\n",
            "10 [4 1 8 7 3 2 9 5 6 0]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 222, bulyan: at fang n_at 10 e 222 | val loss 2.0200 val acc 24.3304 best val_acc 31.067370\n",
            "discarded index [0, 7, 1, 9, 6, 3, 4, 8, 5, 2]\n",
            "10 [0 7 1 9 6 3 4 8 5 2]\n",
            "discarded index [0, 7, 1, 9, 6, 3, 4, 8, 5, 2]\n",
            "10 [0 7 1 9 6 3 4 8 5 2]\n",
            "discarded index [0, 7, 1, 9, 6, 3, 4, 8, 5, 2]\n",
            "10 [0 7 1 9 6 3 4 8 5 2]\n",
            "discarded index [0, 7, 1, 9, 6, 3, 4, 8, 5, 2]\n",
            "10 [0 7 1 9 6 3 4 8 5 2]\n",
            "discarded index [0, 7, 1, 9, 6, 3, 4, 8, 5, 2]\n",
            "10 [0 7 1 9 6 3 4 8 5 2]\n",
            "discarded index [0, 7, 1, 9, 6, 3, 4, 8, 5, 2]\n",
            "10 [0 7 1 9 6 3 4 8 5 2]\n",
            "discarded index [0, 7, 1, 9, 6, 3, 4, 8, 5, 2]\n",
            "10 [0 7 1 9 6 3 4 8 5 2]\n",
            "discarded index [0, 7, 1, 9, 6, 3, 4, 8, 5, 2]\n",
            "10 [0 7 1 9 6 3 4 8 5 2]\n",
            "discarded index [0, 7, 1, 9, 6, 3, 4, 8, 5, 2]\n",
            "10 [0 7 1 9 6 3 4 8 5 2]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 223, bulyan: at fang n_at 10 e 223 | val loss 2.0273 val acc 22.1997 best val_acc 31.067370\n",
            "discarded index [3, 7, 6, 0, 5, 1, 9, 2, 4, 8]\n",
            "10 [3 7 6 0 5 1 9 2 4 8]\n",
            "discarded index [3, 7, 6, 0, 5, 1, 9, 2, 4, 8]\n",
            "10 [3 7 6 0 5 1 9 2 4 8]\n",
            "discarded index [3, 7, 6, 0, 5, 1, 9, 2, 4, 8]\n",
            "10 [3 7 6 0 5 1 9 2 4 8]\n",
            "discarded index [3, 7, 6, 0, 5, 1, 9, 2, 4, 8]\n",
            "10 [3 7 6 0 5 1 9 2 4 8]\n",
            "discarded index [3, 7, 6, 0, 5, 1, 9, 2, 4, 8]\n",
            "10 [3 7 6 0 5 1 9 2 4 8]\n",
            "discarded index [3, 7, 6, 0, 5, 1, 9, 2, 4, 8]\n",
            "10 [3 7 6 0 5 1 9 2 4 8]\n",
            "discarded index [3, 7, 6, 0, 5, 1, 9, 2, 4, 8]\n",
            "10 [3 7 6 0 5 1 9 2 4 8]\n",
            "discarded index [3, 7, 6, 0, 5, 1, 9, 2, 4, 8]\n",
            "10 [3 7 6 0 5 1 9 2 4 8]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 224, bulyan: at fang n_at 10 e 224 | val loss 1.9327 val acc 26.4205 best val_acc 31.067370\n",
            "discarded index [0, 6, 7, 8, 9, 2, 5, 1, 3, 4]\n",
            "10 [0 6 7 8 9 2 5 1 3 4]\n",
            "discarded index [0, 6, 7, 8, 9, 2, 5, 1, 3, 4]\n",
            "10 [0 6 7 8 9 2 5 1 3 4]\n",
            "discarded index [0, 6, 7, 8, 9, 2, 5, 1, 3, 4]\n",
            "10 [0 6 7 8 9 2 5 1 3 4]\n",
            "discarded index [0, 6, 7, 8, 9, 2, 5, 1, 3, 4]\n",
            "10 [0 6 7 8 9 2 5 1 3 4]\n",
            "discarded index [0, 6, 7, 8, 9, 2, 5, 1, 3, 4]\n",
            "10 [0 6 7 8 9 2 5 1 3 4]\n",
            "discarded index [0, 6, 7, 8, 9, 2, 5, 1, 3, 4]\n",
            "10 [0 6 7 8 9 2 5 1 3 4]\n",
            "discarded index [0, 6, 7, 8, 9, 2, 5, 1, 3, 4]\n",
            "10 [0 6 7 8 9 2 5 1 3 4]\n",
            "discarded index [0, 6, 7, 8, 9, 2, 5, 1, 3, 4]\n",
            "10 [0 6 7 8 9 2 5 1 3 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 225, bulyan: at fang n_at 10 e 225 | val loss 1.9265 val acc 26.2987 best val_acc 31.067370\n",
            "discarded index [6, 7, 8, 5, 2, 0, 9, 4, 3, 1]\n",
            "10 [6 7 8 5 2 0 9 4 3 1]\n",
            "discarded index [6, 7, 8, 5, 2, 0, 9, 4, 3, 1]\n",
            "10 [6 7 8 5 2 0 9 4 3 1]\n",
            "discarded index [6, 7, 8, 5, 2, 0, 9, 4, 3, 1]\n",
            "10 [6 7 8 5 2 0 9 4 3 1]\n",
            "discarded index [6, 7, 8, 5, 2, 0, 9, 4, 3, 1]\n",
            "10 [6 7 8 5 2 0 9 4 3 1]\n",
            "discarded index [6, 7, 8, 5, 2, 0, 9, 4, 3, 1]\n",
            "10 [6 7 8 5 2 0 9 4 3 1]\n",
            "discarded index [6, 7, 8, 5, 2, 0, 9, 4, 3, 1]\n",
            "10 [6 7 8 5 2 0 9 4 3 1]\n",
            "discarded index [6, 7, 8, 5, 2, 0, 9, 4, 3, 1]\n",
            "10 [6 7 8 5 2 0 9 4 3 1]\n",
            "discarded index [6, 7, 8, 5, 2, 0, 9, 4, 3, 1]\n",
            "10 [6 7 8 5 2 0 9 4 3 1]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 226, bulyan: at fang n_at 10 e 226 | val loss 2.0300 val acc 21.7532 best val_acc 31.067370\n",
            "discarded index [7, 6, 3, 4, 2, 1, 9, 8, 0, 5]\n",
            "10 [7 6 3 4 2 1 9 8 0 5]\n",
            "discarded index [7, 6, 3, 4, 2, 1, 9, 8, 0, 5]\n",
            "10 [7 6 3 4 2 1 9 8 0 5]\n",
            "discarded index [7, 6, 3, 4, 2, 1, 9, 8, 0, 5]\n",
            "10 [7 6 3 4 2 1 9 8 0 5]\n",
            "discarded index [7, 6, 3, 4, 2, 1, 9, 8, 0, 5]\n",
            "10 [7 6 3 4 2 1 9 8 0 5]\n",
            "discarded index [7, 6, 3, 4, 2, 1, 9, 8, 0, 5]\n",
            "10 [7 6 3 4 2 1 9 8 0 5]\n",
            "discarded index [7, 6, 3, 4, 2, 1, 9, 8, 0, 5]\n",
            "10 [7 6 3 4 2 1 9 8 0 5]\n",
            "discarded index [7, 6, 3, 4, 2, 1, 9, 8, 0, 5]\n",
            "10 [7 6 3 4 2 1 9 8 0 5]\n",
            "discarded index [7, 6, 3, 4, 2, 1, 9, 8, 0, 5]\n",
            "10 [7 6 3 4 2 1 9 8 0 5]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 227, bulyan: at fang n_at 10 e 227 | val loss 1.9357 val acc 29.7078 best val_acc 31.067370\n",
            "discarded index [0, 6, 9, 8, 5, 3, 2, 4, 7, 1]\n",
            "10 [0 6 9 8 5 3 2 4 7 1]\n",
            "discarded index [0, 6, 9, 8, 5, 3, 2, 4, 7, 1]\n",
            "10 [0 6 9 8 5 3 2 4 7 1]\n",
            "discarded index [0, 6, 9, 8, 5, 3, 2, 4, 7, 1]\n",
            "10 [0 6 9 8 5 3 2 4 7 1]\n",
            "discarded index [0, 6, 9, 8, 5, 3, 2, 4, 7, 1]\n",
            "10 [0 6 9 8 5 3 2 4 7 1]\n",
            "discarded index [0, 6, 9, 8, 5, 3, 2, 4, 7, 1]\n",
            "10 [0 6 9 8 5 3 2 4 7 1]\n",
            "discarded index [0, 6, 9, 8, 5, 3, 2, 4, 7, 1]\n",
            "10 [0 6 9 8 5 3 2 4 7 1]\n",
            "discarded index [0, 6, 9, 8, 5, 3, 2, 4, 7, 1]\n",
            "10 [0 6 9 8 5 3 2 4 7 1]\n",
            "discarded index [0, 6, 9, 8, 5, 3, 2, 4, 7, 1]\n",
            "10 [0 6 9 8 5 3 2 4 7 1]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 228, bulyan: at fang n_at 10 e 228 | val loss 1.9689 val acc 27.6989 best val_acc 31.067370\n",
            "discarded index [6, 1, 0, 2, 3, 8, 7, 9, 4, 5]\n",
            "10 [6 1 0 2 3 8 7 9 4 5]\n",
            "discarded index [6, 1, 0, 2, 3, 8, 7, 9, 4, 5]\n",
            "10 [6 1 0 2 3 8 7 9 4 5]\n",
            "discarded index [6, 1, 0, 2, 3, 8, 7, 9, 4, 5]\n",
            "10 [6 1 0 2 3 8 7 9 4 5]\n",
            "discarded index [6, 1, 0, 2, 3, 8, 7, 9, 4, 5]\n",
            "10 [6 1 0 2 3 8 7 9 4 5]\n",
            "discarded index [6, 1, 0, 2, 3, 8, 7, 9, 4, 5]\n",
            "10 [6 1 0 2 3 8 7 9 4 5]\n",
            "discarded index [6, 1, 0, 2, 3, 8, 7, 9, 4, 5]\n",
            "10 [6 1 0 2 3 8 7 9 4 5]\n",
            "discarded index [6, 1, 0, 2, 3, 8, 7, 9, 4, 5]\n",
            "10 [6 1 0 2 3 8 7 9 4 5]\n",
            "discarded index [6, 1, 0, 2, 3, 8, 7, 9, 4, 5]\n",
            "10 [6 1 0 2 3 8 7 9 4 5]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 229, bulyan: at fang n_at 10 e 229 | val loss 1.9011 val acc 27.7800 best val_acc 31.067370\n",
            "discarded index [6, 0, 1, 5, 8, 9, 4, 7, 2, 3]\n",
            "10 [6 0 1 5 8 9 4 7 2 3]\n",
            "discarded index [6, 0, 1, 5, 8, 9, 4, 7, 2, 3]\n",
            "10 [6 0 1 5 8 9 4 7 2 3]\n",
            "discarded index [6, 0, 1, 5, 8, 9, 4, 7, 2, 3]\n",
            "10 [6 0 1 5 8 9 4 7 2 3]\n",
            "discarded index [6, 0, 1, 5, 8, 9, 4, 7, 2, 3]\n",
            "10 [6 0 1 5 8 9 4 7 2 3]\n",
            "discarded index [6, 0, 1, 5, 8, 9, 4, 7, 2, 3]\n",
            "10 [6 0 1 5 8 9 4 7 2 3]\n",
            "discarded index [6, 0, 1, 5, 8, 9, 4, 7, 2, 3]\n",
            "10 [6 0 1 5 8 9 4 7 2 3]\n",
            "discarded index [6, 0, 1, 5, 8, 9, 4, 7, 2, 3]\n",
            "10 [6 0 1 5 8 9 4 7 2 3]\n",
            "discarded index [6, 0, 1, 5, 8, 9, 4, 7, 2, 3]\n",
            "10 [6 0 1 5 8 9 4 7 2 3]\n",
            "discarded index [6, 0, 1, 5, 8, 9, 4, 7, 2, 3]\n",
            "10 [6 0 1 5 8 9 4 7 2 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 230, bulyan: at fang n_at 10 e 230 | val loss 1.9545 val acc 26.4205 best val_acc 31.067370\n",
            "discarded index [0, 9, 7, 4, 8, 1, 6, 2, 5, 3]\n",
            "10 [0 9 7 4 8 1 6 2 5 3]\n",
            "discarded index [0, 9, 7, 4, 8, 1, 6, 2, 5, 3]\n",
            "10 [0 9 7 4 8 1 6 2 5 3]\n",
            "discarded index [0, 9, 7, 4, 8, 1, 6, 2, 5, 3]\n",
            "10 [0 9 7 4 8 1 6 2 5 3]\n",
            "discarded index [0, 9, 7, 4, 8, 1, 6, 2, 5, 3]\n",
            "10 [0 9 7 4 8 1 6 2 5 3]\n",
            "discarded index [0, 9, 7, 4, 8, 1, 6, 2, 5, 3]\n",
            "10 [0 9 7 4 8 1 6 2 5 3]\n",
            "discarded index [0, 9, 7, 4, 8, 1, 6, 2, 5, 3]\n",
            "10 [0 9 7 4 8 1 6 2 5 3]\n",
            "discarded index [0, 9, 7, 4, 8, 1, 6, 2, 5, 3]\n",
            "10 [0 9 7 4 8 1 6 2 5 3]\n",
            "discarded index [0, 9, 7, 4, 8, 1, 6, 2, 5, 3]\n",
            "10 [0 9 7 4 8 1 6 2 5 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 231, bulyan: at fang n_at 10 e 231 | val loss 1.8758 val acc 27.4351 best val_acc 31.067370\n",
            "discarded index [5, 3, 4, 2, 8, 6, 1, 9, 0, 7]\n",
            "10 [5 3 4 2 8 6 1 9 0 7]\n",
            "discarded index [5, 3, 4, 2, 8, 6, 1, 9, 0, 7]\n",
            "10 [5 3 4 2 8 6 1 9 0 7]\n",
            "discarded index [5, 3, 4, 2, 8, 6, 1, 9, 0, 7]\n",
            "10 [5 3 4 2 8 6 1 9 0 7]\n",
            "discarded index [5, 3, 4, 2, 8, 6, 1, 9, 0, 7]\n",
            "10 [5 3 4 2 8 6 1 9 0 7]\n",
            "discarded index [5, 3, 4, 2, 8, 6, 1, 9, 0, 7]\n",
            "10 [5 3 4 2 8 6 1 9 0 7]\n",
            "discarded index [5, 3, 4, 2, 8, 6, 1, 9, 0, 7]\n",
            "10 [5 3 4 2 8 6 1 9 0 7]\n",
            "discarded index [5, 3, 4, 2, 8, 6, 1, 9, 0, 7]\n",
            "10 [5 3 4 2 8 6 1 9 0 7]\n",
            "discarded index [5, 3, 4, 2, 8, 6, 1, 9, 0, 7]\n",
            "10 [5 3 4 2 8 6 1 9 0 7]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 232, bulyan: at fang n_at 10 e 232 | val loss 1.9382 val acc 27.1713 best val_acc 31.067370\n",
            "discarded index [0, 1, 6, 3, 2, 4, 7, 9, 5, 8]\n",
            "10 [0 1 6 3 2 4 7 9 5 8]\n",
            "discarded index [0, 1, 6, 3, 2, 4, 7, 9, 5, 8]\n",
            "10 [0 1 6 3 2 4 7 9 5 8]\n",
            "discarded index [0, 1, 6, 3, 2, 4, 7, 9, 5, 8]\n",
            "10 [0 1 6 3 2 4 7 9 5 8]\n",
            "discarded index [0, 1, 6, 3, 2, 4, 7, 9, 5, 8]\n",
            "10 [0 1 6 3 2 4 7 9 5 8]\n",
            "discarded index [0, 1, 6, 3, 2, 4, 7, 9, 5, 8]\n",
            "10 [0 1 6 3 2 4 7 9 5 8]\n",
            "discarded index [0, 1, 6, 3, 2, 4, 7, 9, 5, 8]\n",
            "10 [0 1 6 3 2 4 7 9 5 8]\n",
            "discarded index [0, 1, 6, 3, 2, 4, 7, 9, 5, 8]\n",
            "10 [0 1 6 3 2 4 7 9 5 8]\n",
            "discarded index [0, 1, 6, 3, 2, 4, 7, 9, 5, 8]\n",
            "10 [0 1 6 3 2 4 7 9 5 8]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 233, bulyan: at fang n_at 10 e 233 | val loss 1.9192 val acc 27.2727 best val_acc 31.067370\n",
            "discarded index [6, 1, 8, 9, 4, 2, 0, 7, 3, 5]\n",
            "10 [6 1 8 9 4 2 0 7 3 5]\n",
            "discarded index [6, 1, 8, 9, 4, 2, 0, 7, 3, 5]\n",
            "10 [6 1 8 9 4 2 0 7 3 5]\n",
            "discarded index [6, 1, 8, 9, 4, 2, 0, 7, 3, 5]\n",
            "10 [6 1 8 9 4 2 0 7 3 5]\n",
            "discarded index [6, 1, 8, 9, 4, 2, 0, 7, 3, 5]\n",
            "10 [6 1 8 9 4 2 0 7 3 5]\n",
            "discarded index [6, 1, 8, 9, 4, 2, 0, 7, 3, 5]\n",
            "10 [6 1 8 9 4 2 0 7 3 5]\n",
            "discarded index [6, 1, 8, 9, 4, 2, 0, 7, 3, 5]\n",
            "10 [6 1 8 9 4 2 0 7 3 5]\n",
            "discarded index [6, 1, 8, 9, 4, 2, 0, 7, 3, 5]\n",
            "10 [6 1 8 9 4 2 0 7 3 5]\n",
            "discarded index [6, 1, 8, 9, 4, 2, 0, 7, 3, 5]\n",
            "10 [6 1 8 9 4 2 0 7 3 5]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 234, bulyan: at fang n_at 10 e 234 | val loss 2.0205 val acc 23.2955 best val_acc 31.067370\n",
            "discarded index [7, 1, 5, 2, 6, 9, 4, 3, 8, 0]\n",
            "10 [7 1 5 2 6 9 4 3 8 0]\n",
            "discarded index [7, 1, 5, 2, 6, 9, 4, 3, 8, 0]\n",
            "10 [7 1 5 2 6 9 4 3 8 0]\n",
            "discarded index [7, 1, 5, 2, 6, 9, 4, 3, 8, 0]\n",
            "10 [7 1 5 2 6 9 4 3 8 0]\n",
            "discarded index [7, 1, 5, 2, 6, 9, 4, 3, 8, 0]\n",
            "10 [7 1 5 2 6 9 4 3 8 0]\n",
            "discarded index [7, 1, 5, 2, 6, 9, 4, 3, 8, 0]\n",
            "10 [7 1 5 2 6 9 4 3 8 0]\n",
            "discarded index [7, 1, 5, 2, 6, 9, 4, 3, 8, 0]\n",
            "10 [7 1 5 2 6 9 4 3 8 0]\n",
            "discarded index [7, 1, 5, 2, 6, 9, 4, 3, 8, 0]\n",
            "10 [7 1 5 2 6 9 4 3 8 0]\n",
            "discarded index [7, 1, 5, 2, 6, 9, 4, 3, 8, 0]\n",
            "10 [7 1 5 2 6 9 4 3 8 0]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 235, bulyan: at fang n_at 10 e 235 | val loss 1.8812 val acc 29.1193 best val_acc 31.067370\n",
            "discarded index [6, 1, 8, 7, 9, 5, 2, 4, 3, 0]\n",
            "10 [6 1 8 7 9 5 2 4 3 0]\n",
            "discarded index [6, 1, 8, 7, 9, 5, 2, 4, 3, 0]\n",
            "10 [6 1 8 7 9 5 2 4 3 0]\n",
            "discarded index [6, 1, 8, 7, 9, 5, 2, 4, 3, 0]\n",
            "10 [6 1 8 7 9 5 2 4 3 0]\n",
            "discarded index [6, 1, 8, 7, 9, 5, 2, 4, 3, 0]\n",
            "10 [6 1 8 7 9 5 2 4 3 0]\n",
            "discarded index [6, 1, 8, 7, 9, 5, 2, 4, 3, 0]\n",
            "10 [6 1 8 7 9 5 2 4 3 0]\n",
            "discarded index [6, 1, 8, 7, 9, 5, 2, 4, 3, 0]\n",
            "10 [6 1 8 7 9 5 2 4 3 0]\n",
            "discarded index [6, 1, 8, 7, 9, 5, 2, 4, 3, 0]\n",
            "10 [6 1 8 7 9 5 2 4 3 0]\n",
            "discarded index [6, 1, 8, 7, 9, 5, 2, 4, 3, 0]\n",
            "10 [6 1 8 7 9 5 2 4 3 0]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 236, bulyan: at fang n_at 10 e 236 | val loss 1.8338 val acc 30.3571 best val_acc 31.067370\n",
            "discarded index [5, 7, 1, 2, 4, 0, 3, 6, 8, 9]\n",
            "10 [5 7 1 2 4 0 3 6 8 9]\n",
            "discarded index [5, 7, 1, 2, 4, 0, 3, 6, 8, 9]\n",
            "10 [5 7 1 2 4 0 3 6 8 9]\n",
            "discarded index [5, 7, 1, 2, 4, 0, 3, 6, 8, 9]\n",
            "10 [5 7 1 2 4 0 3 6 8 9]\n",
            "discarded index [5, 7, 1, 2, 4, 0, 3, 6, 8, 9]\n",
            "10 [5 7 1 2 4 0 3 6 8 9]\n",
            "discarded index [5, 7, 1, 2, 4, 0, 3, 6, 8, 9]\n",
            "10 [5 7 1 2 4 0 3 6 8 9]\n",
            "discarded index [5, 7, 1, 2, 4, 0, 3, 6, 8, 9]\n",
            "10 [5 7 1 2 4 0 3 6 8 9]\n",
            "discarded index [5, 7, 1, 2, 4, 0, 3, 6, 8, 9]\n",
            "10 [5 7 1 2 4 0 3 6 8 9]\n",
            "discarded index [5, 7, 1, 2, 4, 0, 3, 6, 8, 9]\n",
            "10 [5 7 1 2 4 0 3 6 8 9]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 237, bulyan: at fang n_at 10 e 237 | val loss 1.9404 val acc 25.8726 best val_acc 31.067370\n",
            "discarded index [7, 0, 6, 4, 5, 8, 1, 9, 2, 3]\n",
            "10 [7 0 6 4 5 8 1 9 2 3]\n",
            "discarded index [7, 0, 6, 4, 5, 8, 1, 9, 2, 3]\n",
            "10 [7 0 6 4 5 8 1 9 2 3]\n",
            "discarded index [7, 0, 6, 4, 5, 8, 1, 9, 2, 3]\n",
            "10 [7 0 6 4 5 8 1 9 2 3]\n",
            "discarded index [7, 0, 6, 4, 5, 8, 1, 9, 2, 3]\n",
            "10 [7 0 6 4 5 8 1 9 2 3]\n",
            "discarded index [7, 0, 6, 4, 5, 8, 1, 9, 2, 3]\n",
            "10 [7 0 6 4 5 8 1 9 2 3]\n",
            "discarded index [7, 0, 6, 4, 5, 8, 1, 9, 2, 3]\n",
            "10 [7 0 6 4 5 8 1 9 2 3]\n",
            "discarded index [7, 0, 6, 4, 5, 8, 1, 9, 2, 3]\n",
            "10 [7 0 6 4 5 8 1 9 2 3]\n",
            "discarded index [7, 0, 6, 4, 5, 8, 1, 9, 2, 3]\n",
            "10 [7 0 6 4 5 8 1 9 2 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 238, bulyan: at fang n_at 10 e 238 | val loss 1.9477 val acc 25.8117 best val_acc 31.067370\n",
            "discarded index [9, 7, 0, 1, 2, 3, 4, 5, 8, 6]\n",
            "10 [9 7 0 1 2 3 4 5 8 6]\n",
            "discarded index [9, 7, 0, 1, 2, 3, 4, 5, 8, 6]\n",
            "10 [9 7 0 1 2 3 4 5 8 6]\n",
            "discarded index [9, 7, 0, 1, 2, 3, 4, 5, 8, 6]\n",
            "10 [9 7 0 1 2 3 4 5 8 6]\n",
            "discarded index [9, 7, 0, 1, 2, 3, 4, 5, 8, 6]\n",
            "10 [9 7 0 1 2 3 4 5 8 6]\n",
            "discarded index [9, 7, 0, 1, 2, 3, 4, 5, 8, 6]\n",
            "10 [9 7 0 1 2 3 4 5 8 6]\n",
            "discarded index [9, 7, 0, 1, 2, 3, 4, 5, 8, 6]\n",
            "10 [9 7 0 1 2 3 4 5 8 6]\n",
            "discarded index [9, 7, 0, 1, 2, 3, 4, 5, 8, 6]\n",
            "10 [9 7 0 1 2 3 4 5 8 6]\n",
            "discarded index [9, 7, 0, 1, 2, 3, 4, 5, 8, 6]\n",
            "10 [9 7 0 1 2 3 4 5 8 6]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 239, bulyan: at fang n_at 10 e 239 | val loss 1.8579 val acc 28.9570 best val_acc 31.067370\n",
            "discarded index [9, 0, 8, 1, 6, 3, 4, 2, 7, 5]\n",
            "10 [9 0 8 1 6 3 4 2 7 5]\n",
            "discarded index [9, 0, 8, 1, 6, 3, 4, 2, 7, 5]\n",
            "10 [9 0 8 1 6 3 4 2 7 5]\n",
            "discarded index [9, 0, 8, 1, 6, 3, 4, 2, 7, 5]\n",
            "10 [9 0 8 1 6 3 4 2 7 5]\n",
            "discarded index [9, 0, 8, 1, 6, 3, 4, 2, 7, 5]\n",
            "10 [9 0 8 1 6 3 4 2 7 5]\n",
            "discarded index [9, 0, 8, 1, 6, 3, 4, 2, 7, 5]\n",
            "10 [9 0 8 1 6 3 4 2 7 5]\n",
            "discarded index [9, 0, 8, 1, 6, 3, 4, 2, 7, 5]\n",
            "10 [9 0 8 1 6 3 4 2 7 5]\n",
            "discarded index [9, 0, 8, 1, 6, 3, 4, 2, 7, 5]\n",
            "10 [9 0 8 1 6 3 4 2 7 5]\n",
            "discarded index [9, 0, 8, 1, 6, 3, 4, 2, 7, 5]\n",
            "10 [9 0 8 1 6 3 4 2 7 5]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 240, bulyan: at fang n_at 10 e 240 | val loss 1.8228 val acc 30.0122 best val_acc 31.067370\n",
            "discarded index [4, 5, 7, 2, 6, 8, 3, 1, 9, 0]\n",
            "10 [4 5 7 2 6 8 3 1 9 0]\n",
            "discarded index [4, 5, 7, 2, 6, 8, 3, 1, 9, 0]\n",
            "10 [4 5 7 2 6 8 3 1 9 0]\n",
            "discarded index [4, 5, 7, 2, 6, 8, 3, 1, 9, 0]\n",
            "10 [4 5 7 2 6 8 3 1 9 0]\n",
            "discarded index [4, 5, 7, 2, 6, 8, 3, 1, 9, 0]\n",
            "10 [4 5 7 2 6 8 3 1 9 0]\n",
            "discarded index [4, 5, 7, 2, 6, 8, 3, 1, 9, 0]\n",
            "10 [4 5 7 2 6 8 3 1 9 0]\n",
            "discarded index [4, 5, 7, 2, 6, 8, 3, 1, 9, 0]\n",
            "10 [4 5 7 2 6 8 3 1 9 0]\n",
            "discarded index [4, 5, 7, 2, 6, 8, 3, 1, 9, 0]\n",
            "10 [4 5 7 2 6 8 3 1 9 0]\n",
            "discarded index [4, 5, 7, 2, 6, 8, 3, 1, 9, 0]\n",
            "10 [4 5 7 2 6 8 3 1 9 0]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 241, bulyan: at fang n_at 10 e 241 | val loss 1.8556 val acc 30.9659 best val_acc 31.067370\n",
            "discarded index [0, 8, 1, 6, 5, 7, 2, 3, 4, 9]\n",
            "10 [0 8 1 6 5 7 2 3 4 9]\n",
            "discarded index [0, 8, 1, 6, 5, 7, 2, 3, 4, 9]\n",
            "10 [0 8 1 6 5 7 2 3 4 9]\n",
            "discarded index [0, 8, 1, 6, 5, 7, 2, 3, 4, 9]\n",
            "10 [0 8 1 6 5 7 2 3 4 9]\n",
            "discarded index [0, 8, 1, 6, 5, 7, 2, 3, 4, 9]\n",
            "10 [0 8 1 6 5 7 2 3 4 9]\n",
            "discarded index [0, 8, 1, 6, 5, 7, 2, 3, 4, 9]\n",
            "10 [0 8 1 6 5 7 2 3 4 9]\n",
            "discarded index [0, 8, 1, 6, 5, 7, 2, 3, 4, 9]\n",
            "10 [0 8 1 6 5 7 2 3 4 9]\n",
            "discarded index [0, 8, 1, 6, 5, 7, 2, 3, 4, 9]\n",
            "10 [0 8 1 6 5 7 2 3 4 9]\n",
            "discarded index [0, 8, 1, 6, 5, 7, 2, 3, 4, 9]\n",
            "10 [0 8 1 6 5 7 2 3 4 9]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 242, bulyan: at fang n_at 10 e 242 | val loss 1.9973 val acc 28.1047 best val_acc 31.067370\n",
            "discarded index [6, 0, 8, 9, 4, 7, 3, 5, 1, 2]\n",
            "10 [6 0 8 9 4 7 3 5 1 2]\n",
            "discarded index [6, 0, 8, 9, 4, 7, 3, 5, 1, 2]\n",
            "10 [6 0 8 9 4 7 3 5 1 2]\n",
            "discarded index [6, 0, 8, 9, 4, 7, 3, 5, 1, 2]\n",
            "10 [6 0 8 9 4 7 3 5 1 2]\n",
            "discarded index [6, 0, 8, 9, 4, 7, 3, 5, 1, 2]\n",
            "10 [6 0 8 9 4 7 3 5 1 2]\n",
            "discarded index [6, 0, 8, 9, 4, 7, 3, 5, 1, 2]\n",
            "10 [6 0 8 9 4 7 3 5 1 2]\n",
            "discarded index [6, 0, 8, 9, 4, 7, 3, 5, 1, 2]\n",
            "10 [6 0 8 9 4 7 3 5 1 2]\n",
            "discarded index [6, 0, 8, 9, 4, 7, 3, 5, 1, 2]\n",
            "10 [6 0 8 9 4 7 3 5 1 2]\n",
            "discarded index [6, 0, 8, 9, 4, 7, 3, 5, 1, 2]\n",
            "10 [6 0 8 9 4 7 3 5 1 2]\n",
            "discarded index [6, 0, 8, 9, 4, 7, 3, 5, 1, 2]\n",
            "10 [6 0 8 9 4 7 3 5 1 2]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 243, bulyan: at fang n_at 10 e 243 | val loss 2.2595 val acc 20.7386 best val_acc 31.067370\n",
            "discarded index [1, 6, 0, 9, 8, 5, 2, 7, 4, 3]\n",
            "10 [1 6 0 9 8 5 2 7 4 3]\n",
            "discarded index [1, 6, 0, 9, 8, 5, 2, 7, 4, 3]\n",
            "10 [1 6 0 9 8 5 2 7 4 3]\n",
            "discarded index [1, 6, 0, 9, 8, 5, 2, 7, 4, 3]\n",
            "10 [1 6 0 9 8 5 2 7 4 3]\n",
            "discarded index [1, 6, 0, 9, 8, 5, 2, 7, 4, 3]\n",
            "10 [1 6 0 9 8 5 2 7 4 3]\n",
            "discarded index [1, 6, 0, 9, 8, 5, 2, 7, 4, 3]\n",
            "10 [1 6 0 9 8 5 2 7 4 3]\n",
            "discarded index [1, 6, 0, 9, 8, 5, 2, 7, 4, 3]\n",
            "10 [1 6 0 9 8 5 2 7 4 3]\n",
            "discarded index [1, 6, 0, 9, 8, 5, 2, 7, 4, 3]\n",
            "10 [1 6 0 9 8 5 2 7 4 3]\n",
            "discarded index [1, 6, 0, 9, 8, 5, 2, 7, 4, 3]\n",
            "10 [1 6 0 9 8 5 2 7 4 3]\n",
            "discarded index [1, 6, 0, 9, 8, 5, 2, 7, 4, 3]\n",
            "10 [1 6 0 9 8 5 2 7 4 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 244, bulyan: at fang n_at 10 e 244 | val loss 2.0526 val acc 21.7127 best val_acc 31.067370\n",
            "discarded index [6, 7, 9, 1, 0, 5, 8, 3, 2, 4]\n",
            "10 [6 7 9 1 0 5 8 3 2 4]\n",
            "discarded index [6, 7, 9, 1, 0, 5, 8, 3, 2, 4]\n",
            "10 [6 7 9 1 0 5 8 3 2 4]\n",
            "discarded index [6, 7, 9, 1, 0, 5, 8, 3, 2, 4]\n",
            "10 [6 7 9 1 0 5 8 3 2 4]\n",
            "discarded index [6, 7, 9, 1, 0, 5, 8, 3, 2, 4]\n",
            "10 [6 7 9 1 0 5 8 3 2 4]\n",
            "discarded index [6, 7, 9, 1, 0, 5, 8, 3, 2, 4]\n",
            "10 [6 7 9 1 0 5 8 3 2 4]\n",
            "discarded index [6, 7, 9, 1, 0, 5, 8, 3, 2, 4]\n",
            "10 [6 7 9 1 0 5 8 3 2 4]\n",
            "discarded index [6, 7, 9, 1, 0, 5, 8, 3, 2, 4]\n",
            "10 [6 7 9 1 0 5 8 3 2 4]\n",
            "discarded index [6, 7, 9, 1, 0, 5, 8, 3, 2, 4]\n",
            "10 [6 7 9 1 0 5 8 3 2 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 245, bulyan: at fang n_at 10 e 245 | val loss 1.9924 val acc 27.8815 best val_acc 31.067370\n",
            "discarded index [6, 8, 1, 5, 3, 0, 7, 2, 4, 9]\n",
            "10 [6 8 1 5 3 0 7 2 4 9]\n",
            "discarded index [6, 8, 1, 5, 3, 0, 7, 2, 4, 9]\n",
            "10 [6 8 1 5 3 0 7 2 4 9]\n",
            "discarded index [6, 8, 1, 5, 3, 0, 7, 2, 4, 9]\n",
            "10 [6 8 1 5 3 0 7 2 4 9]\n",
            "discarded index [6, 8, 1, 5, 3, 0, 7, 2, 4, 9]\n",
            "10 [6 8 1 5 3 0 7 2 4 9]\n",
            "discarded index [6, 8, 1, 5, 3, 0, 7, 2, 4, 9]\n",
            "10 [6 8 1 5 3 0 7 2 4 9]\n",
            "discarded index [6, 8, 1, 5, 3, 0, 7, 2, 4, 9]\n",
            "10 [6 8 1 5 3 0 7 2 4 9]\n",
            "discarded index [6, 8, 1, 5, 3, 0, 7, 2, 4, 9]\n",
            "10 [6 8 1 5 3 0 7 2 4 9]\n",
            "discarded index [6, 8, 1, 5, 3, 0, 7, 2, 4, 9]\n",
            "10 [6 8 1 5 3 0 7 2 4 9]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 246, bulyan: at fang n_at 10 e 246 | val loss 1.9555 val acc 27.5162 best val_acc 31.067370\n",
            "discarded index [5, 7, 6, 9, 0, 2, 4, 8, 1, 3]\n",
            "10 [5 7 6 9 0 2 4 8 1 3]\n",
            "discarded index [5, 7, 6, 9, 0, 2, 4, 8, 1, 3]\n",
            "10 [5 7 6 9 0 2 4 8 1 3]\n",
            "discarded index [5, 7, 6, 9, 0, 2, 4, 8, 1, 3]\n",
            "10 [5 7 6 9 0 2 4 8 1 3]\n",
            "discarded index [5, 7, 6, 9, 0, 2, 4, 8, 1, 3]\n",
            "10 [5 7 6 9 0 2 4 8 1 3]\n",
            "discarded index [5, 7, 6, 9, 0, 2, 4, 8, 1, 3]\n",
            "10 [5 7 6 9 0 2 4 8 1 3]\n",
            "discarded index [5, 7, 6, 9, 0, 2, 4, 8, 1, 3]\n",
            "10 [5 7 6 9 0 2 4 8 1 3]\n",
            "discarded index [5, 7, 6, 9, 0, 2, 4, 8, 1, 3]\n",
            "10 [5 7 6 9 0 2 4 8 1 3]\n",
            "discarded index [5, 7, 6, 9, 0, 2, 4, 8, 1, 3]\n",
            "10 [5 7 6 9 0 2 4 8 1 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 247, bulyan: at fang n_at 10 e 247 | val loss 1.9951 val acc 25.9131 best val_acc 31.067370\n",
            "discarded index [0, 1, 2, 7, 4, 3, 5, 9, 6, 8]\n",
            "10 [0 1 2 7 4 3 5 9 6 8]\n",
            "discarded index [0, 1, 2, 7, 4, 3, 5, 9, 6, 8]\n",
            "10 [0 1 2 7 4 3 5 9 6 8]\n",
            "discarded index [0, 1, 2, 7, 4, 3, 5, 9, 6, 8]\n",
            "10 [0 1 2 7 4 3 5 9 6 8]\n",
            "discarded index [0, 1, 2, 7, 4, 3, 5, 9, 6, 8]\n",
            "10 [0 1 2 7 4 3 5 9 6 8]\n",
            "discarded index [0, 1, 2, 7, 4, 3, 5, 9, 6, 8]\n",
            "10 [0 1 2 7 4 3 5 9 6 8]\n",
            "discarded index [0, 1, 2, 7, 4, 3, 5, 9, 6, 8]\n",
            "10 [0 1 2 7 4 3 5 9 6 8]\n",
            "discarded index [0, 1, 2, 7, 4, 3, 5, 9, 6, 8]\n",
            "10 [0 1 2 7 4 3 5 9 6 8]\n",
            "discarded index [0, 1, 2, 7, 4, 3, 5, 9, 6, 8]\n",
            "10 [0 1 2 7 4 3 5 9 6 8]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 248, bulyan: at fang n_at 10 e 248 | val loss 1.8554 val acc 29.7890 best val_acc 31.067370\n",
            "discarded index [6, 8, 9, 3, 4, 5, 1, 7, 2, 0]\n",
            "10 [6 8 9 3 4 5 1 7 2 0]\n",
            "discarded index [6, 8, 9, 3, 4, 5, 1, 7, 2, 0]\n",
            "10 [6 8 9 3 4 5 1 7 2 0]\n",
            "discarded index [6, 8, 9, 3, 4, 5, 1, 7, 2, 0]\n",
            "10 [6 8 9 3 4 5 1 7 2 0]\n",
            "discarded index [6, 8, 9, 3, 4, 5, 1, 7, 2, 0]\n",
            "10 [6 8 9 3 4 5 1 7 2 0]\n",
            "discarded index [6, 8, 9, 3, 4, 5, 1, 7, 2, 0]\n",
            "10 [6 8 9 3 4 5 1 7 2 0]\n",
            "discarded index [6, 8, 9, 3, 4, 5, 1, 7, 2, 0]\n",
            "10 [6 8 9 3 4 5 1 7 2 0]\n",
            "discarded index [6, 8, 9, 3, 4, 5, 1, 7, 2, 0]\n",
            "10 [6 8 9 3 4 5 1 7 2 0]\n",
            "discarded index [6, 8, 9, 3, 4, 5, 1, 7, 2, 0]\n",
            "10 [6 8 9 3 4 5 1 7 2 0]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 249, bulyan: at fang n_at 10 e 249 | val loss 1.8431 val acc 28.4294 best val_acc 31.067370\n",
            "discarded index [0, 1, 9, 2, 7, 6, 8, 5, 3, 4]\n",
            "10 [0 1 9 2 7 6 8 5 3 4]\n",
            "discarded index [0, 1, 9, 2, 7, 6, 8, 5, 3, 4]\n",
            "10 [0 1 9 2 7 6 8 5 3 4]\n",
            "discarded index [0, 1, 9, 2, 7, 6, 8, 5, 3, 4]\n",
            "10 [0 1 9 2 7 6 8 5 3 4]\n",
            "discarded index [0, 1, 9, 2, 7, 6, 8, 5, 3, 4]\n",
            "10 [0 1 9 2 7 6 8 5 3 4]\n",
            "discarded index [0, 1, 9, 2, 7, 6, 8, 5, 3, 4]\n",
            "10 [0 1 9 2 7 6 8 5 3 4]\n",
            "discarded index [0, 1, 9, 2, 7, 6, 8, 5, 3, 4]\n",
            "10 [0 1 9 2 7 6 8 5 3 4]\n",
            "discarded index [0, 1, 9, 2, 7, 6, 8, 5, 3, 4]\n",
            "10 [0 1 9 2 7 6 8 5 3 4]\n",
            "discarded index [0, 1, 9, 2, 7, 6, 8, 5, 3, 4]\n",
            "10 [0 1 9 2 7 6 8 5 3 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 250, bulyan: at fang n_at 10 e 250 | val loss 1.7743 val acc 31.0471 best val_acc 31.067370\n",
            "discarded index [0, 1, 7, 9, 5, 6, 8, 3, 2, 4]\n",
            "10 [0 1 7 9 5 6 8 3 2 4]\n",
            "discarded index [0, 1, 7, 9, 5, 6, 8, 3, 2, 4]\n",
            "10 [0 1 7 9 5 6 8 3 2 4]\n",
            "discarded index [0, 1, 7, 9, 5, 6, 8, 3, 2, 4]\n",
            "10 [0 1 7 9 5 6 8 3 2 4]\n",
            "discarded index [0, 1, 7, 9, 5, 6, 8, 3, 2, 4]\n",
            "10 [0 1 7 9 5 6 8 3 2 4]\n",
            "discarded index [0, 1, 7, 9, 5, 6, 8, 3, 2, 4]\n",
            "10 [0 1 7 9 5 6 8 3 2 4]\n",
            "discarded index [0, 1, 7, 9, 5, 6, 8, 3, 2, 4]\n",
            "10 [0 1 7 9 5 6 8 3 2 4]\n",
            "discarded index [0, 1, 7, 9, 5, 6, 8, 3, 2, 4]\n",
            "10 [0 1 7 9 5 6 8 3 2 4]\n",
            "discarded index [0, 1, 7, 9, 5, 6, 8, 3, 2, 4]\n",
            "10 [0 1 7 9 5 6 8 3 2 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 251, bulyan: at fang n_at 10 e 251 | val loss 1.7888 val acc 30.6006 best val_acc 31.067370\n",
            "discarded index [3, 1, 2, 5, 4, 0, 9, 6, 7, 8]\n",
            "10 [3 1 2 5 4 0 9 6 7 8]\n",
            "discarded index [3, 1, 2, 5, 4, 0, 9, 6, 7, 8]\n",
            "10 [3 1 2 5 4 0 9 6 7 8]\n",
            "discarded index [3, 1, 2, 5, 4, 0, 9, 6, 7, 8]\n",
            "10 [3 1 2 5 4 0 9 6 7 8]\n",
            "discarded index [3, 1, 2, 5, 4, 0, 9, 6, 7, 8]\n",
            "10 [3 1 2 5 4 0 9 6 7 8]\n",
            "discarded index [3, 1, 2, 5, 4, 0, 9, 6, 7, 8]\n",
            "10 [3 1 2 5 4 0 9 6 7 8]\n",
            "discarded index [3, 1, 2, 5, 4, 0, 9, 6, 7, 8]\n",
            "10 [3 1 2 5 4 0 9 6 7 8]\n",
            "discarded index [3, 1, 2, 5, 4, 0, 9, 6, 7, 8]\n",
            "10 [3 1 2 5 4 0 9 6 7 8]\n",
            "discarded index [3, 1, 2, 5, 4, 0, 9, 6, 7, 8]\n",
            "10 [3 1 2 5 4 0 9 6 7 8]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 252, bulyan: at fang n_at 10 e 252 | val loss 1.8220 val acc 30.1339 best val_acc 31.067370\n",
            "discarded index [7, 0, 5, 3, 4, 9, 8, 2, 1, 6]\n",
            "10 [7 0 5 3 4 9 8 2 1 6]\n",
            "discarded index [7, 0, 5, 3, 4, 9, 8, 2, 1, 6]\n",
            "10 [7 0 5 3 4 9 8 2 1 6]\n",
            "discarded index [7, 0, 5, 3, 4, 9, 8, 2, 1, 6]\n",
            "10 [7 0 5 3 4 9 8 2 1 6]\n",
            "discarded index [7, 0, 5, 3, 4, 9, 8, 2, 1, 6]\n",
            "10 [7 0 5 3 4 9 8 2 1 6]\n",
            "discarded index [7, 0, 5, 3, 4, 9, 8, 2, 1, 6]\n",
            "10 [7 0 5 3 4 9 8 2 1 6]\n",
            "discarded index [7, 0, 5, 3, 4, 9, 8, 2, 1, 6]\n",
            "10 [7 0 5 3 4 9 8 2 1 6]\n",
            "discarded index [7, 0, 5, 3, 4, 9, 8, 2, 1, 6]\n",
            "10 [7 0 5 3 4 9 8 2 1 6]\n",
            "discarded index [7, 0, 5, 3, 4, 9, 8, 2, 1, 6]\n",
            "10 [7 0 5 3 4 9 8 2 1 6]\n",
            "discarded index [7, 0, 5, 3, 4, 9, 8, 2, 1, 6]\n",
            "10 [7 0 5 3 4 9 8 2 1 6]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 253, bulyan: at fang n_at 10 e 253 | val loss 1.8967 val acc 26.5625 best val_acc 31.067370\n",
            "discarded index [6, 7, 0, 1, 3, 9, 2, 5, 8, 4]\n",
            "10 [6 7 0 1 3 9 2 5 8 4]\n",
            "discarded index [6, 7, 0, 1, 3, 9, 2, 5, 8, 4]\n",
            "10 [6 7 0 1 3 9 2 5 8 4]\n",
            "discarded index [6, 7, 0, 1, 3, 9, 2, 5, 8, 4]\n",
            "10 [6 7 0 1 3 9 2 5 8 4]\n",
            "discarded index [6, 7, 0, 1, 3, 9, 2, 5, 8, 4]\n",
            "10 [6 7 0 1 3 9 2 5 8 4]\n",
            "discarded index [6, 7, 0, 1, 3, 9, 2, 5, 8, 4]\n",
            "10 [6 7 0 1 3 9 2 5 8 4]\n",
            "discarded index [6, 7, 0, 1, 3, 9, 2, 5, 8, 4]\n",
            "10 [6 7 0 1 3 9 2 5 8 4]\n",
            "discarded index [6, 7, 0, 1, 3, 9, 2, 5, 8, 4]\n",
            "10 [6 7 0 1 3 9 2 5 8 4]\n",
            "discarded index [6, 7, 0, 1, 3, 9, 2, 5, 8, 4]\n",
            "10 [6 7 0 1 3 9 2 5 8 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 254, bulyan: at fang n_at 10 e 254 | val loss 1.8197 val acc 29.8701 best val_acc 31.067370\n",
            "discarded index [9, 1, 7, 0, 4, 2, 3, 5, 8, 6]\n",
            "10 [9 1 7 0 4 2 3 5 8 6]\n",
            "discarded index [9, 1, 7, 0, 4, 2, 3, 5, 8, 6]\n",
            "10 [9 1 7 0 4 2 3 5 8 6]\n",
            "discarded index [9, 1, 7, 0, 4, 2, 3, 5, 8, 6]\n",
            "10 [9 1 7 0 4 2 3 5 8 6]\n",
            "discarded index [9, 1, 7, 0, 4, 2, 3, 5, 8, 6]\n",
            "10 [9 1 7 0 4 2 3 5 8 6]\n",
            "discarded index [9, 1, 7, 0, 4, 2, 3, 5, 8, 6]\n",
            "10 [9 1 7 0 4 2 3 5 8 6]\n",
            "discarded index [9, 1, 7, 0, 4, 2, 3, 5, 8, 6]\n",
            "10 [9 1 7 0 4 2 3 5 8 6]\n",
            "discarded index [9, 1, 7, 0, 4, 2, 3, 5, 8, 6]\n",
            "10 [9 1 7 0 4 2 3 5 8 6]\n",
            "discarded index [9, 1, 7, 0, 4, 2, 3, 5, 8, 6]\n",
            "10 [9 1 7 0 4 2 3 5 8 6]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 255, bulyan: at fang n_at 10 e 255 | val loss 1.8209 val acc 28.7946 best val_acc 31.067370\n",
            "discarded index [1, 0, 9, 2, 8, 7, 6, 4, 3, 5]\n",
            "10 [1 0 9 2 8 7 6 4 3 5]\n",
            "discarded index [1, 0, 9, 2, 8, 7, 6, 4, 3, 5]\n",
            "10 [1 0 9 2 8 7 6 4 3 5]\n",
            "discarded index [1, 0, 9, 2, 8, 7, 6, 4, 3, 5]\n",
            "10 [1 0 9 2 8 7 6 4 3 5]\n",
            "discarded index [1, 0, 9, 2, 8, 7, 6, 4, 3, 5]\n",
            "10 [1 0 9 2 8 7 6 4 3 5]\n",
            "discarded index [1, 0, 9, 2, 8, 7, 6, 4, 3, 5]\n",
            "10 [1 0 9 2 8 7 6 4 3 5]\n",
            "discarded index [1, 0, 9, 2, 8, 7, 6, 4, 3, 5]\n",
            "10 [1 0 9 2 8 7 6 4 3 5]\n",
            "discarded index [1, 0, 9, 2, 8, 7, 6, 4, 3, 5]\n",
            "10 [1 0 9 2 8 7 6 4 3 5]\n",
            "discarded index [1, 0, 9, 2, 8, 7, 6, 4, 3, 5]\n",
            "10 [1 0 9 2 8 7 6 4 3 5]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 256, bulyan: at fang n_at 10 e 256 | val loss 1.7455 val acc 33.3604 best val_acc 33.360390\n",
            "discarded index [0, 1, 6, 7, 2, 8, 5, 9, 4, 3]\n",
            "10 [0 1 6 7 2 8 5 9 4 3]\n",
            "discarded index [0, 1, 6, 7, 2, 8, 5, 9, 4, 3]\n",
            "10 [0 1 6 7 2 8 5 9 4 3]\n",
            "discarded index [0, 1, 6, 7, 2, 8, 5, 9, 4, 3]\n",
            "10 [0 1 6 7 2 8 5 9 4 3]\n",
            "discarded index [0, 1, 6, 7, 2, 8, 5, 9, 4, 3]\n",
            "10 [0 1 6 7 2 8 5 9 4 3]\n",
            "discarded index [0, 1, 6, 7, 2, 8, 5, 9, 4, 3]\n",
            "10 [0 1 6 7 2 8 5 9 4 3]\n",
            "discarded index [0, 1, 6, 7, 2, 8, 5, 9, 4, 3]\n",
            "10 [0 1 6 7 2 8 5 9 4 3]\n",
            "discarded index [0, 1, 6, 7, 2, 8, 5, 9, 4, 3]\n",
            "10 [0 1 6 7 2 8 5 9 4 3]\n",
            "discarded index [0, 1, 6, 7, 2, 8, 5, 9, 4, 3]\n",
            "10 [0 1 6 7 2 8 5 9 4 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 257, bulyan: at fang n_at 10 e 257 | val loss 1.7482 val acc 33.4416 best val_acc 33.441558\n",
            "discarded index [8, 4, 2, 5, 7, 6, 0, 3, 1, 9]\n",
            "10 [8 4 2 5 7 6 0 3 1 9]\n",
            "discarded index [8, 4, 2, 5, 7, 6, 0, 3, 1, 9]\n",
            "10 [8 4 2 5 7 6 0 3 1 9]\n",
            "discarded index [8, 4, 2, 5, 7, 6, 0, 3, 1, 9]\n",
            "10 [8 4 2 5 7 6 0 3 1 9]\n",
            "discarded index [8, 4, 2, 5, 7, 6, 0, 3, 1, 9]\n",
            "10 [8 4 2 5 7 6 0 3 1 9]\n",
            "discarded index [8, 4, 2, 5, 7, 6, 0, 3, 1, 9]\n",
            "10 [8 4 2 5 7 6 0 3 1 9]\n",
            "discarded index [8, 4, 2, 5, 7, 6, 0, 3, 1, 9]\n",
            "10 [8 4 2 5 7 6 0 3 1 9]\n",
            "discarded index [8, 4, 2, 5, 7, 6, 0, 3, 1, 9]\n",
            "10 [8 4 2 5 7 6 0 3 1 9]\n",
            "discarded index [8, 4, 2, 5, 7, 6, 0, 3, 1, 9]\n",
            "10 [8 4 2 5 7 6 0 3 1 9]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 258, bulyan: at fang n_at 10 e 258 | val loss 1.7865 val acc 33.2183 best val_acc 33.441558\n",
            "discarded index [9, 6, 0, 1, 7, 3, 2, 5, 8, 4]\n",
            "10 [9 6 0 1 7 3 2 5 8 4]\n",
            "discarded index [9, 6, 0, 1, 7, 3, 2, 5, 8, 4]\n",
            "10 [9 6 0 1 7 3 2 5 8 4]\n",
            "discarded index [9, 6, 0, 1, 7, 3, 2, 5, 8, 4]\n",
            "10 [9 6 0 1 7 3 2 5 8 4]\n",
            "discarded index [9, 6, 0, 1, 7, 3, 2, 5, 8, 4]\n",
            "10 [9 6 0 1 7 3 2 5 8 4]\n",
            "discarded index [9, 6, 0, 1, 7, 3, 2, 5, 8, 4]\n",
            "10 [9 6 0 1 7 3 2 5 8 4]\n",
            "discarded index [9, 6, 0, 1, 7, 3, 2, 5, 8, 4]\n",
            "10 [9 6 0 1 7 3 2 5 8 4]\n",
            "discarded index [9, 6, 0, 1, 7, 3, 2, 5, 8, 4]\n",
            "10 [9 6 0 1 7 3 2 5 8 4]\n",
            "discarded index [9, 6, 0, 1, 7, 3, 2, 5, 8, 4]\n",
            "10 [9 6 0 1 7 3 2 5 8 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 259, bulyan: at fang n_at 10 e 259 | val loss 1.8843 val acc 31.8791 best val_acc 33.441558\n",
            "discarded index [1, 3, 0, 7, 5, 2, 6, 4, 9, 8]\n",
            "10 [1 3 0 7 5 2 6 4 9 8]\n",
            "discarded index [1, 3, 0, 7, 5, 2, 6, 4, 9, 8]\n",
            "10 [1 3 0 7 5 2 6 4 9 8]\n",
            "discarded index [1, 3, 0, 7, 5, 2, 6, 4, 9, 8]\n",
            "10 [1 3 0 7 5 2 6 4 9 8]\n",
            "discarded index [1, 3, 0, 7, 5, 2, 6, 4, 9, 8]\n",
            "10 [1 3 0 7 5 2 6 4 9 8]\n",
            "discarded index [1, 3, 0, 7, 5, 2, 6, 4, 9, 8]\n",
            "10 [1 3 0 7 5 2 6 4 9 8]\n",
            "discarded index [1, 3, 0, 7, 5, 2, 6, 4, 9, 8]\n",
            "10 [1 3 0 7 5 2 6 4 9 8]\n",
            "discarded index [1, 3, 0, 7, 5, 2, 6, 4, 9, 8]\n",
            "10 [1 3 0 7 5 2 6 4 9 8]\n",
            "discarded index [1, 3, 0, 7, 5, 2, 6, 4, 9, 8]\n",
            "10 [1 3 0 7 5 2 6 4 9 8]\n",
            "discarded index [1, 3, 0, 7, 5, 2, 6, 4, 9, 8]\n",
            "10 [1 3 0 7 5 2 6 4 9 8]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 260, bulyan: at fang n_at 10 e 260 | val loss 2.0459 val acc 23.0722 best val_acc 33.441558\n",
            "discarded index [7, 6, 1, 0, 5, 2, 4, 9, 3, 8]\n",
            "10 [7 6 1 0 5 2 4 9 3 8]\n",
            "discarded index [7, 6, 1, 0, 5, 2, 4, 9, 3, 8]\n",
            "10 [7 6 1 0 5 2 4 9 3 8]\n",
            "discarded index [7, 6, 1, 0, 5, 2, 4, 9, 3, 8]\n",
            "10 [7 6 1 0 5 2 4 9 3 8]\n",
            "discarded index [7, 6, 1, 0, 5, 2, 4, 9, 3, 8]\n",
            "10 [7 6 1 0 5 2 4 9 3 8]\n",
            "discarded index [7, 6, 1, 0, 5, 2, 4, 9, 3, 8]\n",
            "10 [7 6 1 0 5 2 4 9 3 8]\n",
            "discarded index [7, 6, 1, 0, 5, 2, 4, 9, 3, 8]\n",
            "10 [7 6 1 0 5 2 4 9 3 8]\n",
            "discarded index [7, 6, 1, 0, 5, 2, 4, 9, 3, 8]\n",
            "10 [7 6 1 0 5 2 4 9 3 8]\n",
            "discarded index [7, 6, 1, 0, 5, 2, 4, 9, 3, 8]\n",
            "10 [7 6 1 0 5 2 4 9 3 8]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 261, bulyan: at fang n_at 10 e 261 | val loss 2.0594 val acc 22.3011 best val_acc 33.441558\n",
            "discarded index [9, 8, 0, 3, 6, 5, 2, 4, 1, 7]\n",
            "10 [9 8 0 3 6 5 2 4 1 7]\n",
            "discarded index [9, 8, 0, 3, 6, 5, 2, 4, 1, 7]\n",
            "10 [9 8 0 3 6 5 2 4 1 7]\n",
            "discarded index [9, 8, 0, 3, 6, 5, 2, 4, 1, 7]\n",
            "10 [9 8 0 3 6 5 2 4 1 7]\n",
            "discarded index [9, 8, 0, 3, 6, 5, 2, 4, 1, 7]\n",
            "10 [9 8 0 3 6 5 2 4 1 7]\n",
            "discarded index [9, 8, 0, 3, 6, 5, 2, 4, 1, 7]\n",
            "10 [9 8 0 3 6 5 2 4 1 7]\n",
            "discarded index [9, 8, 0, 3, 6, 5, 2, 4, 1, 7]\n",
            "10 [9 8 0 3 6 5 2 4 1 7]\n",
            "discarded index [9, 8, 0, 3, 6, 5, 2, 4, 1, 7]\n",
            "10 [9 8 0 3 6 5 2 4 1 7]\n",
            "discarded index [9, 8, 0, 3, 6, 5, 2, 4, 1, 7]\n",
            "10 [9 8 0 3 6 5 2 4 1 7]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 262, bulyan: at fang n_at 10 e 262 | val loss 1.9216 val acc 29.2005 best val_acc 33.441558\n",
            "discarded index [3, 1, 9, 5, 8, 6, 7, 4, 2, 0]\n",
            "10 [3 1 9 5 8 6 7 4 2 0]\n",
            "discarded index [3, 1, 9, 5, 8, 6, 7, 4, 2, 0]\n",
            "10 [3 1 9 5 8 6 7 4 2 0]\n",
            "discarded index [3, 1, 9, 5, 8, 6, 7, 4, 2, 0]\n",
            "10 [3 1 9 5 8 6 7 4 2 0]\n",
            "discarded index [3, 1, 9, 5, 8, 6, 7, 4, 2, 0]\n",
            "10 [3 1 9 5 8 6 7 4 2 0]\n",
            "discarded index [3, 1, 9, 5, 8, 6, 7, 4, 2, 0]\n",
            "10 [3 1 9 5 8 6 7 4 2 0]\n",
            "discarded index [3, 1, 9, 5, 8, 6, 7, 4, 2, 0]\n",
            "10 [3 1 9 5 8 6 7 4 2 0]\n",
            "discarded index [3, 1, 9, 5, 8, 6, 7, 4, 2, 0]\n",
            "10 [3 1 9 5 8 6 7 4 2 0]\n",
            "discarded index [3, 1, 9, 5, 8, 6, 7, 4, 2, 0]\n",
            "10 [3 1 9 5 8 6 7 4 2 0]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 263, bulyan: at fang n_at 10 e 263 | val loss 1.8609 val acc 30.2354 best val_acc 33.441558\n",
            "discarded index [1, 8, 6, 9, 5, 4, 2, 3, 0, 7]\n",
            "10 [1 8 6 9 5 4 2 3 0 7]\n",
            "discarded index [1, 8, 6, 9, 5, 4, 2, 3, 0, 7]\n",
            "10 [1 8 6 9 5 4 2 3 0 7]\n",
            "discarded index [1, 8, 6, 9, 5, 4, 2, 3, 0, 7]\n",
            "10 [1 8 6 9 5 4 2 3 0 7]\n",
            "discarded index [1, 8, 6, 9, 5, 4, 2, 3, 0, 7]\n",
            "10 [1 8 6 9 5 4 2 3 0 7]\n",
            "discarded index [1, 8, 6, 9, 5, 4, 2, 3, 0, 7]\n",
            "10 [1 8 6 9 5 4 2 3 0 7]\n",
            "discarded index [1, 8, 6, 9, 5, 4, 2, 3, 0, 7]\n",
            "10 [1 8 6 9 5 4 2 3 0 7]\n",
            "discarded index [1, 8, 6, 9, 5, 4, 2, 3, 0, 7]\n",
            "10 [1 8 6 9 5 4 2 3 0 7]\n",
            "discarded index [1, 8, 6, 9, 5, 4, 2, 3, 0, 7]\n",
            "10 [1 8 6 9 5 4 2 3 0 7]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 264, bulyan: at fang n_at 10 e 264 | val loss 1.8195 val acc 31.8588 best val_acc 33.441558\n",
            "discarded index [6, 7, 0, 8, 4, 9, 3, 2, 5, 1]\n",
            "10 [6 7 0 8 4 9 3 2 5 1]\n",
            "discarded index [6, 7, 0, 8, 4, 9, 3, 2, 5, 1]\n",
            "10 [6 7 0 8 4 9 3 2 5 1]\n",
            "discarded index [6, 7, 0, 8, 4, 9, 3, 2, 5, 1]\n",
            "10 [6 7 0 8 4 9 3 2 5 1]\n",
            "discarded index [6, 7, 0, 8, 4, 9, 3, 2, 5, 1]\n",
            "10 [6 7 0 8 4 9 3 2 5 1]\n",
            "discarded index [6, 7, 0, 8, 4, 9, 3, 2, 5, 1]\n",
            "10 [6 7 0 8 4 9 3 2 5 1]\n",
            "discarded index [6, 7, 0, 8, 4, 9, 3, 2, 5, 1]\n",
            "10 [6 7 0 8 4 9 3 2 5 1]\n",
            "discarded index [6, 7, 0, 8, 4, 9, 3, 2, 5, 1]\n",
            "10 [6 7 0 8 4 9 3 2 5 1]\n",
            "discarded index [6, 7, 0, 8, 4, 9, 3, 2, 5, 1]\n",
            "10 [6 7 0 8 4 9 3 2 5 1]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 265, bulyan: at fang n_at 10 e 265 | val loss 1.8364 val acc 30.5601 best val_acc 33.441558\n",
            "discarded index [0, 1, 7, 6, 3, 8, 4, 9, 5, 2]\n",
            "10 [0 1 7 6 3 8 4 9 5 2]\n",
            "discarded index [0, 1, 7, 6, 3, 8, 4, 9, 5, 2]\n",
            "10 [0 1 7 6 3 8 4 9 5 2]\n",
            "discarded index [0, 1, 7, 6, 3, 8, 4, 9, 5, 2]\n",
            "10 [0 1 7 6 3 8 4 9 5 2]\n",
            "discarded index [0, 1, 7, 6, 3, 8, 4, 9, 5, 2]\n",
            "10 [0 1 7 6 3 8 4 9 5 2]\n",
            "discarded index [0, 1, 7, 6, 3, 8, 4, 9, 5, 2]\n",
            "10 [0 1 7 6 3 8 4 9 5 2]\n",
            "discarded index [0, 1, 7, 6, 3, 8, 4, 9, 5, 2]\n",
            "10 [0 1 7 6 3 8 4 9 5 2]\n",
            "discarded index [0, 1, 7, 6, 3, 8, 4, 9, 5, 2]\n",
            "10 [0 1 7 6 3 8 4 9 5 2]\n",
            "discarded index [0, 1, 7, 6, 3, 8, 4, 9, 5, 2]\n",
            "10 [0 1 7 6 3 8 4 9 5 2]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 266, bulyan: at fang n_at 10 e 266 | val loss 1.8433 val acc 32.1631 best val_acc 33.441558\n",
            "discarded index [5, 6, 0, 9, 8, 7, 4, 2, 1, 3]\n",
            "10 [5 6 0 9 8 7 4 2 1 3]\n",
            "discarded index [5, 6, 0, 9, 8, 7, 4, 2, 1, 3]\n",
            "10 [5 6 0 9 8 7 4 2 1 3]\n",
            "discarded index [5, 6, 0, 9, 8, 7, 4, 2, 1, 3]\n",
            "10 [5 6 0 9 8 7 4 2 1 3]\n",
            "discarded index [5, 6, 0, 9, 8, 7, 4, 2, 1, 3]\n",
            "10 [5 6 0 9 8 7 4 2 1 3]\n",
            "discarded index [5, 6, 0, 9, 8, 7, 4, 2, 1, 3]\n",
            "10 [5 6 0 9 8 7 4 2 1 3]\n",
            "discarded index [5, 6, 0, 9, 8, 7, 4, 2, 1, 3]\n",
            "10 [5 6 0 9 8 7 4 2 1 3]\n",
            "discarded index [5, 6, 0, 9, 8, 7, 4, 2, 1, 3]\n",
            "10 [5 6 0 9 8 7 4 2 1 3]\n",
            "discarded index [5, 6, 0, 9, 8, 7, 4, 2, 1, 3]\n",
            "10 [5 6 0 9 8 7 4 2 1 3]\n",
            "discarded index [5, 6, 0, 9, 8, 7, 4, 2, 1, 3]\n",
            "10 [5 6 0 9 8 7 4 2 1 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 267, bulyan: at fang n_at 10 e 267 | val loss 1.9062 val acc 30.0933 best val_acc 33.441558\n",
            "discarded index [0, 9, 1, 7, 3, 2, 6, 5, 8, 4]\n",
            "10 [0 9 1 7 3 2 6 5 8 4]\n",
            "discarded index [0, 9, 1, 7, 3, 2, 6, 5, 8, 4]\n",
            "10 [0 9 1 7 3 2 6 5 8 4]\n",
            "discarded index [0, 9, 1, 7, 3, 2, 6, 5, 8, 4]\n",
            "10 [0 9 1 7 3 2 6 5 8 4]\n",
            "discarded index [0, 9, 1, 7, 3, 2, 6, 5, 8, 4]\n",
            "10 [0 9 1 7 3 2 6 5 8 4]\n",
            "discarded index [0, 9, 1, 7, 3, 2, 6, 5, 8, 4]\n",
            "10 [0 9 1 7 3 2 6 5 8 4]\n",
            "discarded index [0, 9, 1, 7, 3, 2, 6, 5, 8, 4]\n",
            "10 [0 9 1 7 3 2 6 5 8 4]\n",
            "discarded index [0, 9, 1, 7, 3, 2, 6, 5, 8, 4]\n",
            "10 [0 9 1 7 3 2 6 5 8 4]\n",
            "discarded index [0, 9, 1, 7, 3, 2, 6, 5, 8, 4]\n",
            "10 [0 9 1 7 3 2 6 5 8 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 268, bulyan: at fang n_at 10 e 268 | val loss 1.7791 val acc 30.2557 best val_acc 33.441558\n",
            "discarded index [1, 0, 6, 2, 8, 4, 9, 7, 5, 3]\n",
            "10 [1 0 6 2 8 4 9 7 5 3]\n",
            "discarded index [1, 0, 6, 2, 8, 4, 9, 7, 5, 3]\n",
            "10 [1 0 6 2 8 4 9 7 5 3]\n",
            "discarded index [1, 0, 6, 2, 8, 4, 9, 7, 5, 3]\n",
            "10 [1 0 6 2 8 4 9 7 5 3]\n",
            "discarded index [1, 0, 6, 2, 8, 4, 9, 7, 5, 3]\n",
            "10 [1 0 6 2 8 4 9 7 5 3]\n",
            "discarded index [1, 0, 6, 2, 8, 4, 9, 7, 5, 3]\n",
            "10 [1 0 6 2 8 4 9 7 5 3]\n",
            "discarded index [1, 0, 6, 2, 8, 4, 9, 7, 5, 3]\n",
            "10 [1 0 6 2 8 4 9 7 5 3]\n",
            "discarded index [1, 0, 6, 2, 8, 4, 9, 7, 5, 3]\n",
            "10 [1 0 6 2 8 4 9 7 5 3]\n",
            "discarded index [1, 0, 6, 2, 8, 4, 9, 7, 5, 3]\n",
            "10 [1 0 6 2 8 4 9 7 5 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 269, bulyan: at fang n_at 10 e 269 | val loss 1.8459 val acc 30.2151 best val_acc 33.441558\n",
            "discarded index [6, 1, 0, 4, 2, 3, 5, 9, 8, 7]\n",
            "10 [6 1 0 4 2 3 5 9 8 7]\n",
            "discarded index [6, 1, 0, 4, 2, 3, 5, 9, 8, 7]\n",
            "10 [6 1 0 4 2 3 5 9 8 7]\n",
            "discarded index [6, 1, 0, 4, 2, 3, 5, 9, 8, 7]\n",
            "10 [6 1 0 4 2 3 5 9 8 7]\n",
            "discarded index [6, 1, 0, 4, 2, 3, 5, 9, 8, 7]\n",
            "10 [6 1 0 4 2 3 5 9 8 7]\n",
            "discarded index [6, 1, 0, 4, 2, 3, 5, 9, 8, 7]\n",
            "10 [6 1 0 4 2 3 5 9 8 7]\n",
            "discarded index [6, 1, 0, 4, 2, 3, 5, 9, 8, 7]\n",
            "10 [6 1 0 4 2 3 5 9 8 7]\n",
            "discarded index [6, 1, 0, 4, 2, 3, 5, 9, 8, 7]\n",
            "10 [6 1 0 4 2 3 5 9 8 7]\n",
            "discarded index [6, 1, 0, 4, 2, 3, 5, 9, 8, 7]\n",
            "10 [6 1 0 4 2 3 5 9 8 7]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 270, bulyan: at fang n_at 10 e 270 | val loss 1.7556 val acc 31.3312 best val_acc 33.441558\n",
            "discarded index [0, 7, 8, 4, 9, 3, 6, 2, 5, 1]\n",
            "10 [0 7 8 4 9 3 6 2 5 1]\n",
            "discarded index [0, 7, 8, 4, 9, 3, 6, 2, 5, 1]\n",
            "10 [0 7 8 4 9 3 6 2 5 1]\n",
            "discarded index [0, 7, 8, 4, 9, 3, 6, 2, 5, 1]\n",
            "10 [0 7 8 4 9 3 6 2 5 1]\n",
            "discarded index [0, 7, 8, 4, 9, 3, 6, 2, 5, 1]\n",
            "10 [0 7 8 4 9 3 6 2 5 1]\n",
            "discarded index [0, 7, 8, 4, 9, 3, 6, 2, 5, 1]\n",
            "10 [0 7 8 4 9 3 6 2 5 1]\n",
            "discarded index [0, 7, 8, 4, 9, 3, 6, 2, 5, 1]\n",
            "10 [0 7 8 4 9 3 6 2 5 1]\n",
            "discarded index [0, 7, 8, 4, 9, 3, 6, 2, 5, 1]\n",
            "10 [0 7 8 4 9 3 6 2 5 1]\n",
            "discarded index [0, 7, 8, 4, 9, 3, 6, 2, 5, 1]\n",
            "10 [0 7 8 4 9 3 6 2 5 1]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 271, bulyan: at fang n_at 10 e 271 | val loss 1.7814 val acc 31.9805 best val_acc 33.441558\n",
            "discarded index [0, 3, 1, 6, 2, 5, 7, 8, 9, 4]\n",
            "10 [0 3 1 6 2 5 7 8 9 4]\n",
            "discarded index [0, 3, 1, 6, 2, 5, 7, 8, 9, 4]\n",
            "10 [0 3 1 6 2 5 7 8 9 4]\n",
            "discarded index [0, 3, 1, 6, 2, 5, 7, 8, 9, 4]\n",
            "10 [0 3 1 6 2 5 7 8 9 4]\n",
            "discarded index [0, 3, 1, 6, 2, 5, 7, 8, 9, 4]\n",
            "10 [0 3 1 6 2 5 7 8 9 4]\n",
            "discarded index [0, 3, 1, 6, 2, 5, 7, 8, 9, 4]\n",
            "10 [0 3 1 6 2 5 7 8 9 4]\n",
            "discarded index [0, 3, 1, 6, 2, 5, 7, 8, 9, 4]\n",
            "10 [0 3 1 6 2 5 7 8 9 4]\n",
            "discarded index [0, 3, 1, 6, 2, 5, 7, 8, 9, 4]\n",
            "10 [0 3 1 6 2 5 7 8 9 4]\n",
            "discarded index [0, 3, 1, 6, 2, 5, 7, 8, 9, 4]\n",
            "10 [0 3 1 6 2 5 7 8 9 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 272, bulyan: at fang n_at 10 e 272 | val loss 1.8803 val acc 28.9570 best val_acc 33.441558\n",
            "discarded index [7, 1, 0, 8, 9, 3, 2, 5, 6, 4]\n",
            "10 [7 1 0 8 9 3 2 5 6 4]\n",
            "discarded index [7, 1, 0, 8, 9, 3, 2, 5, 6, 4]\n",
            "10 [7 1 0 8 9 3 2 5 6 4]\n",
            "discarded index [7, 1, 0, 8, 9, 3, 2, 5, 6, 4]\n",
            "10 [7 1 0 8 9 3 2 5 6 4]\n",
            "discarded index [7, 1, 0, 8, 9, 3, 2, 5, 6, 4]\n",
            "10 [7 1 0 8 9 3 2 5 6 4]\n",
            "discarded index [7, 1, 0, 8, 9, 3, 2, 5, 6, 4]\n",
            "10 [7 1 0 8 9 3 2 5 6 4]\n",
            "discarded index [7, 1, 0, 8, 9, 3, 2, 5, 6, 4]\n",
            "10 [7 1 0 8 9 3 2 5 6 4]\n",
            "discarded index [7, 1, 0, 8, 9, 3, 2, 5, 6, 4]\n",
            "10 [7 1 0 8 9 3 2 5 6 4]\n",
            "discarded index [7, 1, 0, 8, 9, 3, 2, 5, 6, 4]\n",
            "10 [7 1 0 8 9 3 2 5 6 4]\n",
            "discarded index [7, 1, 0, 8, 9, 3, 2, 5, 6, 4]\n",
            "10 [7 1 0 8 9 3 2 5 6 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 273, bulyan: at fang n_at 10 e 273 | val loss 1.9253 val acc 25.5682 best val_acc 33.441558\n",
            "discarded index [7, 0, 9, 1, 6, 2, 3, 8, 5, 4]\n",
            "10 [7 0 9 1 6 2 3 8 5 4]\n",
            "discarded index [7, 0, 9, 1, 6, 2, 3, 8, 5, 4]\n",
            "10 [7 0 9 1 6 2 3 8 5 4]\n",
            "discarded index [7, 0, 9, 1, 6, 2, 3, 8, 5, 4]\n",
            "10 [7 0 9 1 6 2 3 8 5 4]\n",
            "discarded index [7, 0, 9, 1, 6, 2, 3, 8, 5, 4]\n",
            "10 [7 0 9 1 6 2 3 8 5 4]\n",
            "discarded index [7, 0, 9, 1, 6, 2, 3, 8, 5, 4]\n",
            "10 [7 0 9 1 6 2 3 8 5 4]\n",
            "discarded index [7, 0, 9, 1, 6, 2, 3, 8, 5, 4]\n",
            "10 [7 0 9 1 6 2 3 8 5 4]\n",
            "discarded index [7, 0, 9, 1, 6, 2, 3, 8, 5, 4]\n",
            "10 [7 0 9 1 6 2 3 8 5 4]\n",
            "discarded index [7, 0, 9, 1, 6, 2, 3, 8, 5, 4]\n",
            "10 [7 0 9 1 6 2 3 8 5 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 274, bulyan: at fang n_at 10 e 274 | val loss 1.8076 val acc 35.3490 best val_acc 35.349026\n",
            "discarded index [6, 0, 9, 1, 7, 2, 4, 5, 8, 3]\n",
            "10 [6 0 9 1 7 2 4 5 8 3]\n",
            "discarded index [6, 0, 9, 1, 7, 2, 4, 5, 8, 3]\n",
            "10 [6 0 9 1 7 2 4 5 8 3]\n",
            "discarded index [6, 0, 9, 1, 7, 2, 4, 5, 8, 3]\n",
            "10 [6 0 9 1 7 2 4 5 8 3]\n",
            "discarded index [6, 0, 9, 1, 7, 2, 4, 5, 8, 3]\n",
            "10 [6 0 9 1 7 2 4 5 8 3]\n",
            "discarded index [6, 0, 9, 1, 7, 2, 4, 5, 8, 3]\n",
            "10 [6 0 9 1 7 2 4 5 8 3]\n",
            "discarded index [6, 0, 9, 1, 7, 2, 4, 5, 8, 3]\n",
            "10 [6 0 9 1 7 2 4 5 8 3]\n",
            "discarded index [6, 0, 9, 1, 7, 2, 4, 5, 8, 3]\n",
            "10 [6 0 9 1 7 2 4 5 8 3]\n",
            "discarded index [6, 0, 9, 1, 7, 2, 4, 5, 8, 3]\n",
            "10 [6 0 9 1 7 2 4 5 8 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 275, bulyan: at fang n_at 10 e 275 | val loss 1.7583 val acc 34.6185 best val_acc 35.349026\n",
            "discarded index [3, 4, 1, 9, 8, 6, 5, 2, 0, 7]\n",
            "10 [3 4 1 9 8 6 5 2 0 7]\n",
            "discarded index [3, 4, 1, 9, 8, 6, 5, 2, 0, 7]\n",
            "10 [3 4 1 9 8 6 5 2 0 7]\n",
            "discarded index [3, 4, 1, 9, 8, 6, 5, 2, 0, 7]\n",
            "10 [3 4 1 9 8 6 5 2 0 7]\n",
            "discarded index [3, 4, 1, 9, 8, 6, 5, 2, 0, 7]\n",
            "10 [3 4 1 9 8 6 5 2 0 7]\n",
            "discarded index [3, 4, 1, 9, 8, 6, 5, 2, 0, 7]\n",
            "10 [3 4 1 9 8 6 5 2 0 7]\n",
            "discarded index [3, 4, 1, 9, 8, 6, 5, 2, 0, 7]\n",
            "10 [3 4 1 9 8 6 5 2 0 7]\n",
            "discarded index [3, 4, 1, 9, 8, 6, 5, 2, 0, 7]\n",
            "10 [3 4 1 9 8 6 5 2 0 7]\n",
            "discarded index [3, 4, 1, 9, 8, 6, 5, 2, 0, 7]\n",
            "10 [3 4 1 9 8 6 5 2 0 7]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 276, bulyan: at fang n_at 10 e 276 | val loss 1.7827 val acc 33.2995 best val_acc 35.349026\n",
            "discarded index [0, 1, 6, 5, 4, 7, 9, 8, 2, 3]\n",
            "10 [0 1 6 5 4 7 9 8 2 3]\n",
            "discarded index [0, 1, 6, 5, 4, 7, 9, 8, 2, 3]\n",
            "10 [0 1 6 5 4 7 9 8 2 3]\n",
            "discarded index [0, 1, 6, 5, 4, 7, 9, 8, 2, 3]\n",
            "10 [0 1 6 5 4 7 9 8 2 3]\n",
            "discarded index [0, 1, 6, 5, 4, 7, 9, 8, 2, 3]\n",
            "10 [0 1 6 5 4 7 9 8 2 3]\n",
            "discarded index [0, 1, 6, 5, 4, 7, 9, 8, 2, 3]\n",
            "10 [0 1 6 5 4 7 9 8 2 3]\n",
            "discarded index [0, 1, 6, 5, 4, 7, 9, 8, 2, 3]\n",
            "10 [0 1 6 5 4 7 9 8 2 3]\n",
            "discarded index [0, 1, 6, 5, 4, 7, 9, 8, 2, 3]\n",
            "10 [0 1 6 5 4 7 9 8 2 3]\n",
            "discarded index [0, 1, 6, 5, 4, 7, 9, 8, 2, 3]\n",
            "10 [0 1 6 5 4 7 9 8 2 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 277, bulyan: at fang n_at 10 e 277 | val loss 1.8952 val acc 30.0731 best val_acc 35.349026\n",
            "discarded index [1, 0, 5, 7, 3, 8, 4, 2, 6, 9]\n",
            "10 [1 0 5 7 3 8 4 2 6 9]\n",
            "discarded index [1, 0, 5, 7, 3, 8, 4, 2, 6, 9]\n",
            "10 [1 0 5 7 3 8 4 2 6 9]\n",
            "discarded index [1, 0, 5, 7, 3, 8, 4, 2, 6, 9]\n",
            "10 [1 0 5 7 3 8 4 2 6 9]\n",
            "discarded index [1, 0, 5, 7, 3, 8, 4, 2, 6, 9]\n",
            "10 [1 0 5 7 3 8 4 2 6 9]\n",
            "discarded index [1, 0, 5, 7, 3, 8, 4, 2, 6, 9]\n",
            "10 [1 0 5 7 3 8 4 2 6 9]\n",
            "discarded index [1, 0, 5, 7, 3, 8, 4, 2, 6, 9]\n",
            "10 [1 0 5 7 3 8 4 2 6 9]\n",
            "discarded index [1, 0, 5, 7, 3, 8, 4, 2, 6, 9]\n",
            "10 [1 0 5 7 3 8 4 2 6 9]\n",
            "discarded index [1, 0, 5, 7, 3, 8, 4, 2, 6, 9]\n",
            "10 [1 0 5 7 3 8 4 2 6 9]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 278, bulyan: at fang n_at 10 e 278 | val loss 2.0084 val acc 27.2524 best val_acc 35.349026\n",
            "discarded index [6, 8, 5, 1, 0, 9, 4, 2, 3, 7]\n",
            "10 [6 8 5 1 0 9 4 2 3 7]\n",
            "discarded index [6, 8, 5, 1, 0, 9, 4, 2, 3, 7]\n",
            "10 [6 8 5 1 0 9 4 2 3 7]\n",
            "discarded index [6, 8, 5, 1, 0, 9, 4, 2, 3, 7]\n",
            "10 [6 8 5 1 0 9 4 2 3 7]\n",
            "discarded index [6, 8, 5, 1, 0, 9, 4, 2, 3, 7]\n",
            "10 [6 8 5 1 0 9 4 2 3 7]\n",
            "discarded index [6, 8, 5, 1, 0, 9, 4, 2, 3, 7]\n",
            "10 [6 8 5 1 0 9 4 2 3 7]\n",
            "discarded index [6, 8, 5, 1, 0, 9, 4, 2, 3, 7]\n",
            "10 [6 8 5 1 0 9 4 2 3 7]\n",
            "discarded index [6, 8, 5, 1, 0, 9, 4, 2, 3, 7]\n",
            "10 [6 8 5 1 0 9 4 2 3 7]\n",
            "discarded index [6, 8, 5, 1, 0, 9, 4, 2, 3, 7]\n",
            "10 [6 8 5 1 0 9 4 2 3 7]\n",
            "discarded index [6, 8, 5, 1, 0, 9, 4, 2, 3, 7]\n",
            "10 [6 8 5 1 0 9 4 2 3 7]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 279, bulyan: at fang n_at 10 e 279 | val loss 1.8723 val acc 29.9716 best val_acc 35.349026\n",
            "discarded index [7, 6, 0, 8, 1, 3, 9, 4, 5, 2]\n",
            "10 [7 6 0 8 1 3 9 4 5 2]\n",
            "discarded index [7, 6, 0, 8, 1, 3, 9, 4, 5, 2]\n",
            "10 [7 6 0 8 1 3 9 4 5 2]\n",
            "discarded index [7, 6, 0, 8, 1, 3, 9, 4, 5, 2]\n",
            "10 [7 6 0 8 1 3 9 4 5 2]\n",
            "discarded index [7, 6, 0, 8, 1, 3, 9, 4, 5, 2]\n",
            "10 [7 6 0 8 1 3 9 4 5 2]\n",
            "discarded index [7, 6, 0, 8, 1, 3, 9, 4, 5, 2]\n",
            "10 [7 6 0 8 1 3 9 4 5 2]\n",
            "discarded index [7, 6, 0, 8, 1, 3, 9, 4, 5, 2]\n",
            "10 [7 6 0 8 1 3 9 4 5 2]\n",
            "discarded index [7, 6, 0, 8, 1, 3, 9, 4, 5, 2]\n",
            "10 [7 6 0 8 1 3 9 4 5 2]\n",
            "discarded index [7, 6, 0, 8, 1, 3, 9, 4, 5, 2]\n",
            "10 [7 6 0 8 1 3 9 4 5 2]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 280, bulyan: at fang n_at 10 e 280 | val loss 1.7847 val acc 36.6274 best val_acc 36.627435\n",
            "discarded index [6, 1, 0, 5, 2, 7, 3, 4, 8, 9]\n",
            "10 [6 1 0 5 2 7 3 4 8 9]\n",
            "discarded index [6, 1, 0, 5, 2, 7, 3, 4, 8, 9]\n",
            "10 [6 1 0 5 2 7 3 4 8 9]\n",
            "discarded index [6, 1, 0, 5, 2, 7, 3, 4, 8, 9]\n",
            "10 [6 1 0 5 2 7 3 4 8 9]\n",
            "discarded index [6, 1, 0, 5, 2, 7, 3, 4, 8, 9]\n",
            "10 [6 1 0 5 2 7 3 4 8 9]\n",
            "discarded index [6, 1, 0, 5, 2, 7, 3, 4, 8, 9]\n",
            "10 [6 1 0 5 2 7 3 4 8 9]\n",
            "discarded index [6, 1, 0, 5, 2, 7, 3, 4, 8, 9]\n",
            "10 [6 1 0 5 2 7 3 4 8 9]\n",
            "discarded index [6, 1, 0, 5, 2, 7, 3, 4, 8, 9]\n",
            "10 [6 1 0 5 2 7 3 4 8 9]\n",
            "discarded index [6, 1, 0, 5, 2, 7, 3, 4, 8, 9]\n",
            "10 [6 1 0 5 2 7 3 4 8 9]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 281, bulyan: at fang n_at 10 e 281 | val loss 1.7077 val acc 37.0333 best val_acc 37.033279\n",
            "discarded index [8, 5, 4, 6, 3, 0, 7, 9, 2, 1]\n",
            "10 [8 5 4 6 3 0 7 9 2 1]\n",
            "discarded index [8, 5, 4, 6, 3, 0, 7, 9, 2, 1]\n",
            "10 [8 5 4 6 3 0 7 9 2 1]\n",
            "discarded index [8, 5, 4, 6, 3, 0, 7, 9, 2, 1]\n",
            "10 [8 5 4 6 3 0 7 9 2 1]\n",
            "discarded index [8, 5, 4, 6, 3, 0, 7, 9, 2, 1]\n",
            "10 [8 5 4 6 3 0 7 9 2 1]\n",
            "discarded index [8, 5, 4, 6, 3, 0, 7, 9, 2, 1]\n",
            "10 [8 5 4 6 3 0 7 9 2 1]\n",
            "discarded index [8, 5, 4, 6, 3, 0, 7, 9, 2, 1]\n",
            "10 [8 5 4 6 3 0 7 9 2 1]\n",
            "discarded index [8, 5, 4, 6, 3, 0, 7, 9, 2, 1]\n",
            "10 [8 5 4 6 3 0 7 9 2 1]\n",
            "discarded index [8, 5, 4, 6, 3, 0, 7, 9, 2, 1]\n",
            "10 [8 5 4 6 3 0 7 9 2 1]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 282, bulyan: at fang n_at 10 e 282 | val loss 1.6992 val acc 36.6071 best val_acc 37.033279\n",
            "discarded index [0, 1, 6, 9, 7, 8, 2, 3, 4, 5]\n",
            "10 [0 1 6 9 7 8 2 3 4 5]\n",
            "discarded index [0, 1, 6, 9, 7, 8, 2, 3, 4, 5]\n",
            "10 [0 1 6 9 7 8 2 3 4 5]\n",
            "discarded index [0, 1, 6, 9, 7, 8, 2, 3, 4, 5]\n",
            "10 [0 1 6 9 7 8 2 3 4 5]\n",
            "discarded index [0, 1, 6, 9, 7, 8, 2, 3, 4, 5]\n",
            "10 [0 1 6 9 7 8 2 3 4 5]\n",
            "discarded index [0, 1, 6, 9, 7, 8, 2, 3, 4, 5]\n",
            "10 [0 1 6 9 7 8 2 3 4 5]\n",
            "discarded index [0, 1, 6, 9, 7, 8, 2, 3, 4, 5]\n",
            "10 [0 1 6 9 7 8 2 3 4 5]\n",
            "discarded index [0, 1, 6, 9, 7, 8, 2, 3, 4, 5]\n",
            "10 [0 1 6 9 7 8 2 3 4 5]\n",
            "discarded index [0, 1, 6, 9, 7, 8, 2, 3, 4, 5]\n",
            "10 [0 1 6 9 7 8 2 3 4 5]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 283, bulyan: at fang n_at 10 e 283 | val loss 1.7546 val acc 36.3231 best val_acc 37.033279\n",
            "discarded index [0, 1, 3, 6, 5, 2, 9, 8, 7, 4]\n",
            "10 [0 1 3 6 5 2 9 8 7 4]\n",
            "discarded index [0, 1, 3, 6, 5, 2, 9, 8, 7, 4]\n",
            "10 [0 1 3 6 5 2 9 8 7 4]\n",
            "discarded index [0, 1, 3, 6, 5, 2, 9, 8, 7, 4]\n",
            "10 [0 1 3 6 5 2 9 8 7 4]\n",
            "discarded index [0, 1, 3, 6, 5, 2, 9, 8, 7, 4]\n",
            "10 [0 1 3 6 5 2 9 8 7 4]\n",
            "discarded index [0, 1, 3, 6, 5, 2, 9, 8, 7, 4]\n",
            "10 [0 1 3 6 5 2 9 8 7 4]\n",
            "discarded index [0, 1, 3, 6, 5, 2, 9, 8, 7, 4]\n",
            "10 [0 1 3 6 5 2 9 8 7 4]\n",
            "discarded index [0, 1, 3, 6, 5, 2, 9, 8, 7, 4]\n",
            "10 [0 1 3 6 5 2 9 8 7 4]\n",
            "discarded index [0, 1, 3, 6, 5, 2, 9, 8, 7, 4]\n",
            "10 [0 1 3 6 5 2 9 8 7 4]\n",
            "discarded index [0, 1, 3, 6, 5, 2, 9, 8, 7, 4]\n",
            "10 [0 1 3 6 5 2 9 8 7 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 284, bulyan: at fang n_at 10 e 284 | val loss 1.8269 val acc 32.4472 best val_acc 37.033279\n",
            "discarded index [0, 7, 1, 9, 8, 5, 3, 4, 6, 2]\n",
            "10 [0 7 1 9 8 5 3 4 6 2]\n",
            "discarded index [0, 7, 1, 9, 8, 5, 3, 4, 6, 2]\n",
            "10 [0 7 1 9 8 5 3 4 6 2]\n",
            "discarded index [0, 7, 1, 9, 8, 5, 3, 4, 6, 2]\n",
            "10 [0 7 1 9 8 5 3 4 6 2]\n",
            "discarded index [0, 7, 1, 9, 8, 5, 3, 4, 6, 2]\n",
            "10 [0 7 1 9 8 5 3 4 6 2]\n",
            "discarded index [0, 7, 1, 9, 8, 5, 3, 4, 6, 2]\n",
            "10 [0 7 1 9 8 5 3 4 6 2]\n",
            "discarded index [0, 7, 1, 9, 8, 5, 3, 4, 6, 2]\n",
            "10 [0 7 1 9 8 5 3 4 6 2]\n",
            "discarded index [0, 7, 1, 9, 8, 5, 3, 4, 6, 2]\n",
            "10 [0 7 1 9 8 5 3 4 6 2]\n",
            "discarded index [0, 7, 1, 9, 8, 5, 3, 4, 6, 2]\n",
            "10 [0 7 1 9 8 5 3 4 6 2]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 285, bulyan: at fang n_at 10 e 285 | val loss 1.7374 val acc 37.6218 best val_acc 37.621753\n",
            "discarded index [6, 5, 3, 2, 1, 9, 4, 7, 8, 0]\n",
            "10 [6 5 3 2 1 9 4 7 8 0]\n",
            "discarded index [6, 5, 3, 2, 1, 9, 4, 7, 8, 0]\n",
            "10 [6 5 3 2 1 9 4 7 8 0]\n",
            "discarded index [6, 5, 3, 2, 1, 9, 4, 7, 8, 0]\n",
            "10 [6 5 3 2 1 9 4 7 8 0]\n",
            "discarded index [6, 5, 3, 2, 1, 9, 4, 7, 8, 0]\n",
            "10 [6 5 3 2 1 9 4 7 8 0]\n",
            "discarded index [6, 5, 3, 2, 1, 9, 4, 7, 8, 0]\n",
            "10 [6 5 3 2 1 9 4 7 8 0]\n",
            "discarded index [6, 5, 3, 2, 1, 9, 4, 7, 8, 0]\n",
            "10 [6 5 3 2 1 9 4 7 8 0]\n",
            "discarded index [6, 5, 3, 2, 1, 9, 4, 7, 8, 0]\n",
            "10 [6 5 3 2 1 9 4 7 8 0]\n",
            "discarded index [6, 5, 3, 2, 1, 9, 4, 7, 8, 0]\n",
            "10 [6 5 3 2 1 9 4 7 8 0]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 286, bulyan: at fang n_at 10 e 286 | val loss 1.7239 val acc 34.0503 best val_acc 37.621753\n",
            "discarded index [0, 1, 6, 4, 3, 2, 8, 9, 5, 7]\n",
            "10 [0 1 6 4 3 2 8 9 5 7]\n",
            "discarded index [0, 1, 6, 4, 3, 2, 8, 9, 5, 7]\n",
            "10 [0 1 6 4 3 2 8 9 5 7]\n",
            "discarded index [0, 1, 6, 4, 3, 2, 8, 9, 5, 7]\n",
            "10 [0 1 6 4 3 2 8 9 5 7]\n",
            "discarded index [0, 1, 6, 4, 3, 2, 8, 9, 5, 7]\n",
            "10 [0 1 6 4 3 2 8 9 5 7]\n",
            "discarded index [0, 1, 6, 4, 3, 2, 8, 9, 5, 7]\n",
            "10 [0 1 6 4 3 2 8 9 5 7]\n",
            "discarded index [0, 1, 6, 4, 3, 2, 8, 9, 5, 7]\n",
            "10 [0 1 6 4 3 2 8 9 5 7]\n",
            "discarded index [0, 1, 6, 4, 3, 2, 8, 9, 5, 7]\n",
            "10 [0 1 6 4 3 2 8 9 5 7]\n",
            "discarded index [0, 1, 6, 4, 3, 2, 8, 9, 5, 7]\n",
            "10 [0 1 6 4 3 2 8 9 5 7]\n",
            "discarded index [0, 1, 6, 4, 3, 2, 8, 9, 5, 7]\n",
            "10 [0 1 6 4 3 2 8 9 5 7]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 287, bulyan: at fang n_at 10 e 287 | val loss 1.7685 val acc 32.2849 best val_acc 37.621753\n",
            "discarded index [9, 0, 1, 8, 7, 6, 2, 3, 5, 4]\n",
            "10 [9 0 1 8 7 6 2 3 5 4]\n",
            "discarded index [9, 0, 1, 8, 7, 6, 2, 3, 5, 4]\n",
            "10 [9 0 1 8 7 6 2 3 5 4]\n",
            "discarded index [9, 0, 1, 8, 7, 6, 2, 3, 5, 4]\n",
            "10 [9 0 1 8 7 6 2 3 5 4]\n",
            "discarded index [9, 0, 1, 8, 7, 6, 2, 3, 5, 4]\n",
            "10 [9 0 1 8 7 6 2 3 5 4]\n",
            "discarded index [9, 0, 1, 8, 7, 6, 2, 3, 5, 4]\n",
            "10 [9 0 1 8 7 6 2 3 5 4]\n",
            "discarded index [9, 0, 1, 8, 7, 6, 2, 3, 5, 4]\n",
            "10 [9 0 1 8 7 6 2 3 5 4]\n",
            "discarded index [9, 0, 1, 8, 7, 6, 2, 3, 5, 4]\n",
            "10 [9 0 1 8 7 6 2 3 5 4]\n",
            "discarded index [9, 0, 1, 8, 7, 6, 2, 3, 5, 4]\n",
            "10 [9 0 1 8 7 6 2 3 5 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 288, bulyan: at fang n_at 10 e 288 | val loss 1.7199 val acc 32.7922 best val_acc 37.621753\n",
            "discarded index [0, 1, 6, 4, 2, 5, 9, 7, 3, 8]\n",
            "10 [0 1 6 4 2 5 9 7 3 8]\n",
            "discarded index [0, 1, 6, 4, 2, 5, 9, 7, 3, 8]\n",
            "10 [0 1 6 4 2 5 9 7 3 8]\n",
            "discarded index [0, 1, 6, 4, 2, 5, 9, 7, 3, 8]\n",
            "10 [0 1 6 4 2 5 9 7 3 8]\n",
            "discarded index [0, 1, 6, 4, 2, 5, 9, 7, 3, 8]\n",
            "10 [0 1 6 4 2 5 9 7 3 8]\n",
            "discarded index [0, 1, 6, 4, 2, 5, 9, 7, 3, 8]\n",
            "10 [0 1 6 4 2 5 9 7 3 8]\n",
            "discarded index [0, 1, 6, 4, 2, 5, 9, 7, 3, 8]\n",
            "10 [0 1 6 4 2 5 9 7 3 8]\n",
            "discarded index [0, 1, 6, 4, 2, 5, 9, 7, 3, 8]\n",
            "10 [0 1 6 4 2 5 9 7 3 8]\n",
            "discarded index [0, 1, 6, 4, 2, 5, 9, 7, 3, 8]\n",
            "10 [0 1 6 4 2 5 9 7 3 8]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 289, bulyan: at fang n_at 10 e 289 | val loss 1.7296 val acc 35.8563 best val_acc 37.621753\n",
            "discarded index [1, 0, 6, 8, 5, 9, 4, 7, 2, 3]\n",
            "10 [1 0 6 8 5 9 4 7 2 3]\n",
            "discarded index [1, 0, 6, 8, 5, 9, 4, 7, 2, 3]\n",
            "10 [1 0 6 8 5 9 4 7 2 3]\n",
            "discarded index [1, 0, 6, 8, 5, 9, 4, 7, 2, 3]\n",
            "10 [1 0 6 8 5 9 4 7 2 3]\n",
            "discarded index [1, 0, 6, 8, 5, 9, 4, 7, 2, 3]\n",
            "10 [1 0 6 8 5 9 4 7 2 3]\n",
            "discarded index [1, 0, 6, 8, 5, 9, 4, 7, 2, 3]\n",
            "10 [1 0 6 8 5 9 4 7 2 3]\n",
            "discarded index [1, 0, 6, 8, 5, 9, 4, 7, 2, 3]\n",
            "10 [1 0 6 8 5 9 4 7 2 3]\n",
            "discarded index [1, 0, 6, 8, 5, 9, 4, 7, 2, 3]\n",
            "10 [1 0 6 8 5 9 4 7 2 3]\n",
            "discarded index [1, 0, 6, 8, 5, 9, 4, 7, 2, 3]\n",
            "10 [1 0 6 8 5 9 4 7 2 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 290, bulyan: at fang n_at 10 e 290 | val loss 1.7383 val acc 36.0390 best val_acc 37.621753\n",
            "discarded index [6, 8, 0, 4, 3, 9, 2, 5, 1, 7]\n",
            "10 [6 8 0 4 3 9 2 5 1 7]\n",
            "discarded index [6, 8, 0, 4, 3, 9, 2, 5, 1, 7]\n",
            "10 [6 8 0 4 3 9 2 5 1 7]\n",
            "discarded index [6, 8, 0, 4, 3, 9, 2, 5, 1, 7]\n",
            "10 [6 8 0 4 3 9 2 5 1 7]\n",
            "discarded index [6, 8, 0, 4, 3, 9, 2, 5, 1, 7]\n",
            "10 [6 8 0 4 3 9 2 5 1 7]\n",
            "discarded index [6, 8, 0, 4, 3, 9, 2, 5, 1, 7]\n",
            "10 [6 8 0 4 3 9 2 5 1 7]\n",
            "discarded index [6, 8, 0, 4, 3, 9, 2, 5, 1, 7]\n",
            "10 [6 8 0 4 3 9 2 5 1 7]\n",
            "discarded index [6, 8, 0, 4, 3, 9, 2, 5, 1, 7]\n",
            "10 [6 8 0 4 3 9 2 5 1 7]\n",
            "discarded index [6, 8, 0, 4, 3, 9, 2, 5, 1, 7]\n",
            "10 [6 8 0 4 3 9 2 5 1 7]\n",
            "discarded index [6, 8, 0, 4, 3, 9, 2, 5, 1, 7]\n",
            "10 [6 8 0 4 3 9 2 5 1 7]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 291, bulyan: at fang n_at 10 e 291 | val loss 1.7467 val acc 36.4448 best val_acc 37.621753\n",
            "discarded index [6, 3, 9, 1, 4, 0, 2, 5, 7, 8]\n",
            "10 [6 3 9 1 4 0 2 5 7 8]\n",
            "discarded index [6, 3, 9, 1, 4, 0, 2, 5, 7, 8]\n",
            "10 [6 3 9 1 4 0 2 5 7 8]\n",
            "discarded index [6, 3, 9, 1, 4, 0, 2, 5, 7, 8]\n",
            "10 [6 3 9 1 4 0 2 5 7 8]\n",
            "discarded index [6, 3, 9, 1, 4, 0, 2, 5, 7, 8]\n",
            "10 [6 3 9 1 4 0 2 5 7 8]\n",
            "discarded index [6, 3, 9, 1, 4, 0, 2, 5, 7, 8]\n",
            "10 [6 3 9 1 4 0 2 5 7 8]\n",
            "discarded index [6, 3, 9, 1, 4, 0, 2, 5, 7, 8]\n",
            "10 [6 3 9 1 4 0 2 5 7 8]\n",
            "discarded index [6, 3, 9, 1, 4, 0, 2, 5, 7, 8]\n",
            "10 [6 3 9 1 4 0 2 5 7 8]\n",
            "discarded index [6, 3, 9, 1, 4, 0, 2, 5, 7, 8]\n",
            "10 [6 3 9 1 4 0 2 5 7 8]\n",
            "discarded index [6, 3, 9, 1, 4, 0, 2, 5, 7, 8]\n",
            "10 [6 3 9 1 4 0 2 5 7 8]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 292, bulyan: at fang n_at 10 e 292 | val loss 1.8945 val acc 30.3977 best val_acc 37.621753\n",
            "discarded index [0, 8, 9, 6, 7, 1, 4, 5, 3, 2]\n",
            "10 [0 8 9 6 7 1 4 5 3 2]\n",
            "discarded index [0, 8, 9, 6, 7, 1, 4, 5, 3, 2]\n",
            "10 [0 8 9 6 7 1 4 5 3 2]\n",
            "discarded index [0, 8, 9, 6, 7, 1, 4, 5, 3, 2]\n",
            "10 [0 8 9 6 7 1 4 5 3 2]\n",
            "discarded index [0, 8, 9, 6, 7, 1, 4, 5, 3, 2]\n",
            "10 [0 8 9 6 7 1 4 5 3 2]\n",
            "discarded index [0, 8, 9, 6, 7, 1, 4, 5, 3, 2]\n",
            "10 [0 8 9 6 7 1 4 5 3 2]\n",
            "discarded index [0, 8, 9, 6, 7, 1, 4, 5, 3, 2]\n",
            "10 [0 8 9 6 7 1 4 5 3 2]\n",
            "discarded index [0, 8, 9, 6, 7, 1, 4, 5, 3, 2]\n",
            "10 [0 8 9 6 7 1 4 5 3 2]\n",
            "discarded index [0, 8, 9, 6, 7, 1, 4, 5, 3, 2]\n",
            "10 [0 8 9 6 7 1 4 5 3 2]\n",
            "discarded index [0, 8, 9, 6, 7, 1, 4, 5, 3, 2]\n",
            "10 [0 8 9 6 7 1 4 5 3 2]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 293, bulyan: at fang n_at 10 e 293 | val loss 1.8583 val acc 29.0381 best val_acc 37.621753\n",
            "discarded index [1, 8, 2, 5, 6, 9, 4, 3, 7, 0]\n",
            "10 [1 8 2 5 6 9 4 3 7 0]\n",
            "discarded index [1, 8, 2, 5, 6, 9, 4, 3, 7, 0]\n",
            "10 [1 8 2 5 6 9 4 3 7 0]\n",
            "discarded index [1, 8, 2, 5, 6, 9, 4, 3, 7, 0]\n",
            "10 [1 8 2 5 6 9 4 3 7 0]\n",
            "discarded index [1, 8, 2, 5, 6, 9, 4, 3, 7, 0]\n",
            "10 [1 8 2 5 6 9 4 3 7 0]\n",
            "discarded index [1, 8, 2, 5, 6, 9, 4, 3, 7, 0]\n",
            "10 [1 8 2 5 6 9 4 3 7 0]\n",
            "discarded index [1, 8, 2, 5, 6, 9, 4, 3, 7, 0]\n",
            "10 [1 8 2 5 6 9 4 3 7 0]\n",
            "discarded index [1, 8, 2, 5, 6, 9, 4, 3, 7, 0]\n",
            "10 [1 8 2 5 6 9 4 3 7 0]\n",
            "discarded index [1, 8, 2, 5, 6, 9, 4, 3, 7, 0]\n",
            "10 [1 8 2 5 6 9 4 3 7 0]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 294, bulyan: at fang n_at 10 e 294 | val loss 1.8153 val acc 33.5430 best val_acc 37.621753\n",
            "discarded index [5, 6, 8, 9, 7, 1, 4, 2, 3, 0]\n",
            "10 [5 6 8 9 7 1 4 2 3 0]\n",
            "discarded index [5, 6, 8, 9, 7, 1, 4, 2, 3, 0]\n",
            "10 [5 6 8 9 7 1 4 2 3 0]\n",
            "discarded index [5, 6, 8, 9, 7, 1, 4, 2, 3, 0]\n",
            "10 [5 6 8 9 7 1 4 2 3 0]\n",
            "discarded index [5, 6, 8, 9, 7, 1, 4, 2, 3, 0]\n",
            "10 [5 6 8 9 7 1 4 2 3 0]\n",
            "discarded index [5, 6, 8, 9, 7, 1, 4, 2, 3, 0]\n",
            "10 [5 6 8 9 7 1 4 2 3 0]\n",
            "discarded index [5, 6, 8, 9, 7, 1, 4, 2, 3, 0]\n",
            "10 [5 6 8 9 7 1 4 2 3 0]\n",
            "discarded index [5, 6, 8, 9, 7, 1, 4, 2, 3, 0]\n",
            "10 [5 6 8 9 7 1 4 2 3 0]\n",
            "discarded index [5, 6, 8, 9, 7, 1, 4, 2, 3, 0]\n",
            "10 [5 6 8 9 7 1 4 2 3 0]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 295, bulyan: at fang n_at 10 e 295 | val loss 1.7524 val acc 34.6794 best val_acc 37.621753\n",
            "discarded index [9, 7, 2, 6, 8, 4, 5, 0, 3, 1]\n",
            "10 [9 7 2 6 8 4 5 0 3 1]\n",
            "discarded index [9, 7, 2, 6, 8, 4, 5, 0, 3, 1]\n",
            "10 [9 7 2 6 8 4 5 0 3 1]\n",
            "discarded index [9, 7, 2, 6, 8, 4, 5, 0, 3, 1]\n",
            "10 [9 7 2 6 8 4 5 0 3 1]\n",
            "discarded index [9, 7, 2, 6, 8, 4, 5, 0, 3, 1]\n",
            "10 [9 7 2 6 8 4 5 0 3 1]\n",
            "discarded index [9, 7, 2, 6, 8, 4, 5, 0, 3, 1]\n",
            "10 [9 7 2 6 8 4 5 0 3 1]\n",
            "discarded index [9, 7, 2, 6, 8, 4, 5, 0, 3, 1]\n",
            "10 [9 7 2 6 8 4 5 0 3 1]\n",
            "discarded index [9, 7, 2, 6, 8, 4, 5, 0, 3, 1]\n",
            "10 [9 7 2 6 8 4 5 0 3 1]\n",
            "discarded index [9, 7, 2, 6, 8, 4, 5, 0, 3, 1]\n",
            "10 [9 7 2 6 8 4 5 0 3 1]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 296, bulyan: at fang n_at 10 e 296 | val loss 1.7964 val acc 33.3401 best val_acc 37.621753\n",
            "discarded index [4, 1, 6, 2, 3, 0, 8, 9, 5, 7]\n",
            "10 [4 1 6 2 3 0 8 9 5 7]\n",
            "discarded index [4, 1, 6, 2, 3, 0, 8, 9, 5, 7]\n",
            "10 [4 1 6 2 3 0 8 9 5 7]\n",
            "discarded index [4, 1, 6, 2, 3, 0, 8, 9, 5, 7]\n",
            "10 [4 1 6 2 3 0 8 9 5 7]\n",
            "discarded index [4, 1, 6, 2, 3, 0, 8, 9, 5, 7]\n",
            "10 [4 1 6 2 3 0 8 9 5 7]\n",
            "discarded index [4, 1, 6, 2, 3, 0, 8, 9, 5, 7]\n",
            "10 [4 1 6 2 3 0 8 9 5 7]\n",
            "discarded index [4, 1, 6, 2, 3, 0, 8, 9, 5, 7]\n",
            "10 [4 1 6 2 3 0 8 9 5 7]\n",
            "discarded index [4, 1, 6, 2, 3, 0, 8, 9, 5, 7]\n",
            "10 [4 1 6 2 3 0 8 9 5 7]\n",
            "discarded index [4, 1, 6, 2, 3, 0, 8, 9, 5, 7]\n",
            "10 [4 1 6 2 3 0 8 9 5 7]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 297, bulyan: at fang n_at 10 e 297 | val loss 1.9299 val acc 29.5049 best val_acc 37.621753\n",
            "discarded index [7, 0, 1, 9, 3, 2, 5, 8, 6, 4]\n",
            "10 [7 0 1 9 3 2 5 8 6 4]\n",
            "discarded index [7, 0, 1, 9, 3, 2, 5, 8, 6, 4]\n",
            "10 [7 0 1 9 3 2 5 8 6 4]\n",
            "discarded index [7, 0, 1, 9, 3, 2, 5, 8, 6, 4]\n",
            "10 [7 0 1 9 3 2 5 8 6 4]\n",
            "discarded index [7, 0, 1, 9, 3, 2, 5, 8, 6, 4]\n",
            "10 [7 0 1 9 3 2 5 8 6 4]\n",
            "discarded index [7, 0, 1, 9, 3, 2, 5, 8, 6, 4]\n",
            "10 [7 0 1 9 3 2 5 8 6 4]\n",
            "discarded index [7, 0, 1, 9, 3, 2, 5, 8, 6, 4]\n",
            "10 [7 0 1 9 3 2 5 8 6 4]\n",
            "discarded index [7, 0, 1, 9, 3, 2, 5, 8, 6, 4]\n",
            "10 [7 0 1 9 3 2 5 8 6 4]\n",
            "discarded index [7, 0, 1, 9, 3, 2, 5, 8, 6, 4]\n",
            "10 [7 0 1 9 3 2 5 8 6 4]\n",
            "discarded index [7, 0, 1, 9, 3, 2, 5, 8, 6, 4]\n",
            "10 [7 0 1 9 3 2 5 8 6 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 298, bulyan: at fang n_at 10 e 298 | val loss 1.7889 val acc 33.3807 best val_acc 37.621753\n",
            "discarded index [4, 2, 8, 6, 7, 9, 0, 3, 1, 5]\n",
            "10 [4 2 8 6 7 9 0 3 1 5]\n",
            "discarded index [4, 2, 8, 6, 7, 9, 0, 3, 1, 5]\n",
            "10 [4 2 8 6 7 9 0 3 1 5]\n",
            "discarded index [4, 2, 8, 6, 7, 9, 0, 3, 1, 5]\n",
            "10 [4 2 8 6 7 9 0 3 1 5]\n",
            "discarded index [4, 2, 8, 6, 7, 9, 0, 3, 1, 5]\n",
            "10 [4 2 8 6 7 9 0 3 1 5]\n",
            "discarded index [4, 2, 8, 6, 7, 9, 0, 3, 1, 5]\n",
            "10 [4 2 8 6 7 9 0 3 1 5]\n",
            "discarded index [4, 2, 8, 6, 7, 9, 0, 3, 1, 5]\n",
            "10 [4 2 8 6 7 9 0 3 1 5]\n",
            "discarded index [4, 2, 8, 6, 7, 9, 0, 3, 1, 5]\n",
            "10 [4 2 8 6 7 9 0 3 1 5]\n",
            "discarded index [4, 2, 8, 6, 7, 9, 0, 3, 1, 5]\n",
            "10 [4 2 8 6 7 9 0 3 1 5]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 299, bulyan: at fang n_at 10 e 299 | val loss 1.7481 val acc 34.0300 best val_acc 37.621753\n",
            "discarded index [7, 8, 9, 0, 2, 1, 3, 4, 5, 6]\n",
            "10 [7 8 9 0 2 1 3 4 5 6]\n",
            "discarded index [7, 8, 9, 0, 2, 1, 3, 4, 5, 6]\n",
            "10 [7 8 9 0 2 1 3 4 5 6]\n",
            "discarded index [7, 8, 9, 0, 2, 1, 3, 4, 5, 6]\n",
            "10 [7 8 9 0 2 1 3 4 5 6]\n",
            "discarded index [7, 8, 9, 0, 2, 1, 3, 4, 5, 6]\n",
            "10 [7 8 9 0 2 1 3 4 5 6]\n",
            "discarded index [7, 8, 9, 0, 2, 1, 3, 4, 5, 6]\n",
            "10 [7 8 9 0 2 1 3 4 5 6]\n",
            "discarded index [7, 8, 9, 0, 2, 1, 3, 4, 5, 6]\n",
            "10 [7 8 9 0 2 1 3 4 5 6]\n",
            "discarded index [7, 8, 9, 0, 2, 1, 3, 4, 5, 6]\n",
            "10 [7 8 9 0 2 1 3 4 5 6]\n",
            "discarded index [7, 8, 9, 0, 2, 1, 3, 4, 5, 6]\n",
            "10 [7 8 9 0 2 1 3 4 5 6]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 300, bulyan: at fang n_at 10 e 300 | val loss 1.7710 val acc 33.4010 best val_acc 37.621753\n"
          ]
        }
      ],
      "source": [
        "batch_size=250\n",
        "resume=0\n",
        "\n",
        "schedule=[1000]\n",
        "\n",
        "gamma=.5\n",
        "opt = 'sgd'\n",
        "fed_lr=0.5\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "use_cuda = torch.cuda.is_available()\n",
        "\n",
        "aggregation='bulyan'\n",
        "multi_k = False\n",
        "candidates = []\n",
        "\n",
        "at_type='fang'\n",
        "n_attackers=[10]\n",
        "\n",
        "arch='alexnet'\n",
        "chkpt='./'+aggregation\n",
        "\n",
        "title = \"Fang attack on our defense\"\n",
        "\n",
        "for n_attacker in n_attackers:\n",
        "    epoch_num = 0\n",
        "    best_global_acc = 0\n",
        "    best_global_te_acc = 0\n",
        "    \n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    fed_model, _ = return_model(arch, 0.1, 0.9, parallel=False)\n",
        "    optimizer_fed = SGD(fed_model.parameters(), lr=fed_lr)\n",
        "\n",
        "    df = pd.DataFrame(columns = ['epoch', 'loss', 'validation accuracy', 'best validation accuracy'])\n",
        "\n",
        "    ####\n",
        "    history = torch.zeros((n_users, nepochs + 1), dtype=torch.float32).cuda()\n",
        "    ####\n",
        "    model_grads = []\n",
        "\n",
        "    while epoch_num <= nepochs:\n",
        "        user_grads=[]\n",
        "\n",
        "        # for i in range(n_attacker, nusers):\n",
        "        for i in range(n_users):\n",
        "            nbatches = user_tr_len[i]//batch_size\n",
        "\n",
        "            inputs = user_train_data_tensors[i][(epoch_num%nbatches)*batch_size:((epoch_num%nbatches) + 1) * batch_size]\n",
        "            targets = user_train_label_tensors[i][(epoch_num%nbatches)*batch_size:((epoch_num%nbatches) + 1) * batch_size]\n",
        "            targets = targets.type(torch.LongTensor)   \n",
        "            \n",
        "            inputs, targets = inputs.cuda(), targets.cuda()\n",
        "            inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
        "\n",
        "            outputs = fed_model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            fed_model.zero_grad()\n",
        "            loss.backward(retain_graph=True)\n",
        "\n",
        "            param_grad=[]\n",
        "            for param in fed_model.parameters():\n",
        "                param_grad=param.grad.data.view(-1) if not len(param_grad) else torch.cat((param_grad,param.grad.view(-1)))\n",
        "\n",
        "            user_grads=param_grad[None, :] if len(user_grads)==0 else torch.cat((user_grads,param_grad[None,:]), 0)\n",
        "\n",
        "        if epoch_num in schedule:\n",
        "            for param_group in optimizer_fed.param_groups:\n",
        "                param_group['lr'] *= gamma\n",
        "                print('New learnin rate ', param_group['lr'])\n",
        "\n",
        "        if n_attacker > 0:\n",
        "            agg_grads = torch.mean(user_grads, 0)\n",
        "            deviation = torch.sign(agg_grads)\n",
        "            mal_update = get_malicious_updates_fang(user_grads, agg_grads, deviation, n_attacker, history, epoch_num)\n",
        "\n",
        "            malicious_grads = torch.cat((torch.stack([mal_update] * n_attacker), user_grads[n_attacker:]), 0)\n",
        "\n",
        "        \n",
        "        if not (malicious_grads.shape[0]==50):\n",
        "            print(malicious_grads.shape)\n",
        "            sys.exit()\n",
        "            \n",
        "\n",
        "        if not (malicious_grads.shape[0]==50):\n",
        "            print(malicious_grads.shape)\n",
        "\n",
        "        updates_abs_mean = malicious_grads.abs().mean(dim=1, keepdim=True)\n",
        "\n",
        "        history[:, epoch_num] = updates_abs_mean.squeeze()\n",
        "        agg_grads, _ = our_mean_defense(malicious_grads, n_attacker, history)\n",
        "\n",
        "        del user_grads\n",
        "\n",
        "        start_idx=0\n",
        "\n",
        "        optimizer_fed.zero_grad()\n",
        "\n",
        "        model_grads=[]\n",
        "\n",
        "        for i, param in enumerate(fed_model.parameters()):\n",
        "            param_=agg_grads[start_idx:start_idx+len(param.data.view(-1))].reshape(param.data.shape)\n",
        "            start_idx=start_idx+len(param.data.view(-1))\n",
        "            param_=param_.cuda()\n",
        "            model_grads.append(param_)\n",
        "\n",
        "        optimizer_fed.step(model_grads)\n",
        "\n",
        "        val_loss, val_acc = test(val_data_tensor,val_label_tensor,fed_model,criterion,use_cuda)\n",
        "        te_loss, te_acc = test(te_data_tensor,te_label_tensor, fed_model, criterion, use_cuda)\n",
        "\n",
        "        is_best = best_global_acc < val_acc\n",
        "\n",
        "        best_global_acc = max(best_global_acc, val_acc)\n",
        "\n",
        "        if is_best:\n",
        "            best_global_te_acc = te_acc\n",
        "\n",
        "        \n",
        "        print('epoch: %d, %s: at %s n_at %d e %d | val loss %.4f val acc %.4f best val_acc %f'%(epoch_num, aggregation, at_type, n_attacker, epoch_num, val_loss, val_acc, best_global_acc))\n",
        "        new_row = pd.DataFrame([{\n",
        "            'epoch': epoch_num, \n",
        "            'loss': val_loss, \n",
        "            'validation accuracy': val_acc, \n",
        "            'best validation accuracy': best_global_acc\n",
        "            }])\n",
        "        df = pd.concat([df, new_row], ignore_index=True)\n",
        "        df.to_csv(f'{title}.csv', index=False)\n",
        "        epoch_num+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plotting the data\n",
        "for col in ['loss', 'validation accuracy', 'best validation accuracy']:\n",
        "    plt.plot(df['epoch'].tolist(), df[col].tolist())\n",
        "    plt.title(f\"{title} {col}\")\n",
        "    plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "ilTYNiZMlvp4",
        "8mZBn-_AaaTL"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
