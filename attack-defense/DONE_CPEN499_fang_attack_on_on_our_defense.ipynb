{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMUR8ODgnrc3"
      },
      "source": [
        "# The notebook contains\n",
        "### Code for _Bulyan_ aggregation algorithm, *when gradient updates of benign clients are unknown to adversary*\n",
        "### Evaluation of all of the attacks (Fang, LIE, and our SOTA AGR-tailored and AGR-agnstic) on Bulyan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJu2Edmbnrc5"
      },
      "source": [
        "## Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "wGSIzpf_nrc5",
        "outputId": "5563fc08-740b-4522-8ba9-41e940ec060e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>.container { width:90% !important; }</style>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import display, HTML\n",
        "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "AAU3fosynrc6"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import argparse, os, sys, csv, shutil, time, random, operator, pickle, ast, math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.optim import Optimizer\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import pickle\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torch.multiprocessing as mp\n",
        "import math\n",
        "sys.path.insert(0,'./../utils/')\n",
        "from logger import *\n",
        "from eval import *\n",
        "from misc import *\n",
        "\n",
        "from cifar10_normal_train import *\n",
        "from cifar10_util import *\n",
        "from adam import Adam\n",
        "from sgd import SGD\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGABIvW6nrc6"
      },
      "source": [
        "## Load Data\n",
        "Divide cifar10 data among 50 clients in Non-IID fashion using Dirichlet distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1Nyn5Xlnrc6",
        "outputId": "2148c44a-9897-41f6-bf92-67d798026810"
      },
      "outputs": [],
      "source": [
        "n_users = 50\n",
        "user_tr_len = pickle.load(open('./data/user_tr_len.pkl','rb'))\n",
        "\n",
        "user_train_data_tensors = pickle.load(open('./data/user_train_data_tensors.pkl','rb'))\n",
        "user_train_label_tensors = pickle.load(open('./data/user_train_label_tensors.pkl','rb'))\n",
        "\n",
        "val_data_tensor = pickle.load(open('./data/val_data_tensor.pkl','rb'))\n",
        "val_label_tensor = pickle.load(open('./data/val_label_tensor.pkl','rb'))\n",
        "te_data_tensor = pickle.load(open('./data/te_data_tensor.pkl','rb'))\n",
        "te_label_tensor = pickle.load(open('./data/te_label_tensor.pkl','rb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOVMqc_9nrc8"
      },
      "source": [
        "## Our Aggregation Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LMgKiRnynrc8"
      },
      "outputs": [],
      "source": [
        "def our_mean_defense(all_updates, n_attackers, history_updates):\n",
        "    discarded_history = get_discarded_index(n_attackers, history_updates)\n",
        "\n",
        "    mask = torch.ones(all_updates.size(0), dtype=torch.bool)\n",
        "    mask[discarded_history] = False\n",
        "    remaining_updates = all_updates[mask]\n",
        "\n",
        "    print('discarded index', discarded_history)\n",
        "\n",
        "    return torch.nanmean(remaining_updates, dim=0), np.array(discarded_history)\n",
        "\n",
        "####\n",
        "def euclidean_distance(row1, row2):\n",
        "    return torch.sqrt(torch.sum((row1 - row2) ** 2))\n",
        "####\n",
        "\n",
        "def get_discarded_index(n_attackers, history_updates):\n",
        "    n_users = history_updates.shape[0]\n",
        "\n",
        "    ####\n",
        "    distance_matrix = [[0 if i == j else euclidean_distance(history_updates[i, :], history_updates[j, :]) for j in range(n_users)] for i in range(n_users)]\n",
        "    ####\n",
        "\n",
        "    sum_of_distances = [sum(row) for row in distance_matrix]\n",
        "\n",
        "    discarded_history = []\n",
        "    for _ in range(n_attackers):\n",
        "        max_distance = max(sum_of_distances)\n",
        "        index_of_max_distance = sum_of_distances.index(max_distance)\n",
        "        discarded_history.append(index_of_max_distance)\n",
        "\n",
        "        for i in range(n_users):\n",
        "            sum_of_distances[i] -= distance_matrix[i][index_of_max_distance]\n",
        "        sum_of_distances[index_of_max_distance] = -1\n",
        "\n",
        "    return discarded_history\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set nepochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "nepochs= 300"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fang attack and our defense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_lambda_fang(all_updates, model_re, n_attacker):\n",
        "\n",
        "    distances = []\n",
        "    n_benign, d = all_updates.shape\n",
        "    for update in all_updates:\n",
        "        distance = torch.norm((all_updates - update), dim=1)\n",
        "        distances = distance[None, :] if not len(distances) else torch.cat((distances, distance[None, :]), 0)\n",
        "\n",
        "    distances[distances == 0] = 10000\n",
        "    distances = torch.sort(distances, dim=1)[0]\n",
        "    scores = torch.sum(distances[:, :n_benign - 2 - n_attacker], dim=1)\n",
        "    min_score = torch.min(scores)\n",
        "    term_1 = min_score / ((n_benign - n_attacker - 1) * torch.sqrt(torch.Tensor([d]))[0])\n",
        "    max_wre_dist = torch.max(torch.norm((all_updates - model_re), dim=1)) / (torch.sqrt(torch.Tensor([d]))[0])\n",
        "    # print(term_1 + max_wre_dist) # tensor(0.0001, device='cuda:0')\n",
        "    return (term_1 + max_wre_dist)\n",
        "\n",
        "\n",
        "def get_malicious_updates_fang(all_updates, model_re, deviation, n_attacker, history, epoch_num):\n",
        "\n",
        "    lamda = compute_lambda_fang(all_updates, model_re, n_attacker) # tensor(0.0001, device='cuda:0')\n",
        "    \n",
        "    threshold = 1e-5\n",
        "\n",
        "    mal_updates = []\n",
        "    \n",
        "    ####\n",
        "    history_updates = history.clone().detach()\n",
        "    ####\n",
        "\n",
        "    while lamda > threshold:\n",
        "        # print(\"lamda: \", lamda)\n",
        "        mal_update = (- lamda * deviation) # torch.Size([2472266])\n",
        "        mal_updates = torch.stack([mal_update] * n_attacker)   # torch.Size([2, 2472266])\n",
        "        mal_updates = torch.cat((mal_updates, all_updates[n_attacker:]), 0)  # torch.Size([12, 2472266])\n",
        "\n",
        "        history_updates[:, epoch_num] = all_updates.mean(dim=1, keepdim=True).squeeze()\n",
        "\n",
        "        agg_grads, discard_history = our_mean_defense(mal_updates, n_attacker, history_updates) # agg_grads.shape torch.Size([2472266]) # krum_candidate.shape torch.Size(1,)\n",
        "\n",
        "        count = np.sum(discard_history < n_attacker)\n",
        "        print(count, discard_history)\n",
        "        if count < n_attacker:\n",
        "            return mal_update\n",
        "        \n",
        "        lamda *= 0.5\n",
        "    print(\"lamda < threshold\")\n",
        "    if not len(mal_updates):\n",
        "        # print(lamda, threshold)\n",
        "        mal_update = (model_re - lamda * deviation)\n",
        "    return mal_update  # len(mal_update) 2472266"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "discarded index [19, 22, 5, 40, 2, 44, 45, 47, 43, 26]\n",
            "2 [19 22  5 40  2 44 45 47 43 26]\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Hizan\\Desktop\\CPEN497-FL\\attack-defense\\sgd.py:109: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\python_arg_parser.cpp:1630.)\n",
            "  p.data.add_(-group['lr'], d_p)\n",
            "C:\\Users\\Hizan\\AppData\\Local\\Temp\\ipykernel_1716\\190507742.py:126: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df = pd.concat([df, new_row], ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 0, bulyan: at fang n_at 10 e 0 | val loss 2.3023 val acc 9.8620 best val_acc 9.862013\n",
            "discarded index [1, 0, 4, 6, 2, 3, 5, 7, 8, 9]\n",
            "10 [1 0 4 6 2 3 5 7 8 9]\n",
            "discarded index [1, 0, 4, 6, 2, 3, 5, 7, 8, 9]\n",
            "10 [1 0 4 6 2 3 5 7 8 9]\n",
            "discarded index [1, 0, 4, 6, 2, 3, 5, 7, 8, 9]\n",
            "10 [1 0 4 6 2 3 5 7 8 9]\n",
            "discarded index [1, 0, 4, 6, 2, 3, 5, 7, 8, 9]\n",
            "10 [1 0 4 6 2 3 5 7 8 9]\n",
            "discarded index [1, 0, 4, 6, 2, 3, 5, 7, 8, 9]\n",
            "10 [1 0 4 6 2 3 5 7 8 9]\n",
            "discarded index [1, 0, 4, 6, 2, 3, 5, 7, 8, 9]\n",
            "10 [1 0 4 6 2 3 5 7 8 9]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 1, bulyan: at fang n_at 10 e 1 | val loss 2.3018 val acc 9.8620 best val_acc 9.862013\n",
            "discarded index [1, 0, 4, 7, 5, 8, 9, 3, 6, 2]\n",
            "10 [1 0 4 7 5 8 9 3 6 2]\n",
            "discarded index [1, 0, 4, 7, 5, 8, 9, 3, 6, 2]\n",
            "10 [1 0 4 7 5 8 9 3 6 2]\n",
            "discarded index [1, 0, 4, 7, 5, 8, 9, 3, 6, 2]\n",
            "10 [1 0 4 7 5 8 9 3 6 2]\n",
            "discarded index [1, 0, 4, 7, 5, 8, 9, 3, 6, 2]\n",
            "10 [1 0 4 7 5 8 9 3 6 2]\n",
            "discarded index [1, 0, 4, 7, 5, 8, 9, 3, 6, 2]\n",
            "10 [1 0 4 7 5 8 9 3 6 2]\n",
            "discarded index [1, 0, 4, 7, 5, 8, 9, 3, 6, 2]\n",
            "10 [1 0 4 7 5 8 9 3 6 2]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 2, bulyan: at fang n_at 10 e 2 | val loss 2.3013 val acc 9.8620 best val_acc 9.862013\n",
            "discarded index [1, 4, 5, 7, 0, 9, 2, 8, 3, 6]\n",
            "10 [1 4 5 7 0 9 2 8 3 6]\n",
            "discarded index [1, 4, 5, 7, 0, 9, 2, 8, 3, 6]\n",
            "10 [1 4 5 7 0 9 2 8 3 6]\n",
            "discarded index [1, 4, 5, 7, 0, 9, 2, 8, 3, 6]\n",
            "10 [1 4 5 7 0 9 2 8 3 6]\n",
            "discarded index [1, 4, 5, 7, 0, 9, 2, 8, 3, 6]\n",
            "10 [1 4 5 7 0 9 2 8 3 6]\n",
            "discarded index [1, 4, 5, 7, 0, 9, 2, 8, 3, 6]\n",
            "10 [1 4 5 7 0 9 2 8 3 6]\n",
            "discarded index [1, 4, 5, 7, 0, 9, 2, 8, 3, 6]\n",
            "10 [1 4 5 7 0 9 2 8 3 6]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 3, bulyan: at fang n_at 10 e 3 | val loss 2.3008 val acc 9.8620 best val_acc 9.862013\n",
            "discarded index [1, 4, 5, 0, 6, 7, 2, 3, 8, 9]\n",
            "10 [1 4 5 0 6 7 2 3 8 9]\n",
            "discarded index [1, 4, 5, 0, 6, 7, 2, 3, 8, 9]\n",
            "10 [1 4 5 0 6 7 2 3 8 9]\n",
            "discarded index [1, 4, 5, 0, 6, 7, 2, 3, 8, 9]\n",
            "10 [1 4 5 0 6 7 2 3 8 9]\n",
            "discarded index [1, 4, 5, 0, 6, 7, 2, 3, 8, 9]\n",
            "10 [1 4 5 0 6 7 2 3 8 9]\n",
            "discarded index [1, 4, 5, 0, 6, 7, 2, 3, 8, 9]\n",
            "10 [1 4 5 0 6 7 2 3 8 9]\n",
            "discarded index [1, 4, 5, 0, 6, 7, 2, 3, 8, 9]\n",
            "10 [1 4 5 0 6 7 2 3 8 9]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 4, bulyan: at fang n_at 10 e 4 | val loss 2.3004 val acc 9.8620 best val_acc 9.862013\n",
            "discarded index [1, 4, 6, 5, 0, 7, 9, 3, 2, 8]\n",
            "10 [1 4 6 5 0 7 9 3 2 8]\n",
            "discarded index [1, 4, 6, 5, 0, 7, 9, 3, 2, 8]\n",
            "10 [1 4 6 5 0 7 9 3 2 8]\n",
            "discarded index [1, 4, 6, 5, 0, 7, 9, 3, 2, 8]\n",
            "10 [1 4 6 5 0 7 9 3 2 8]\n",
            "discarded index [1, 4, 6, 5, 0, 7, 9, 3, 2, 8]\n",
            "10 [1 4 6 5 0 7 9 3 2 8]\n",
            "discarded index [1, 4, 6, 5, 0, 7, 9, 3, 2, 8]\n",
            "10 [1 4 6 5 0 7 9 3 2 8]\n",
            "discarded index [1, 4, 6, 5, 0, 7, 9, 3, 2, 8]\n",
            "10 [1 4 6 5 0 7 9 3 2 8]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 5, bulyan: at fang n_at 10 e 5 | val loss 2.2998 val acc 9.8620 best val_acc 9.862013\n",
            "discarded index [4, 1, 5, 7, 0, 6, 3, 2, 8, 9]\n",
            "10 [4 1 5 7 0 6 3 2 8 9]\n",
            "discarded index [4, 1, 5, 7, 0, 6, 3, 2, 8, 9]\n",
            "10 [4 1 5 7 0 6 3 2 8 9]\n",
            "discarded index [4, 1, 5, 7, 0, 6, 3, 2, 8, 9]\n",
            "10 [4 1 5 7 0 6 3 2 8 9]\n",
            "discarded index [4, 1, 5, 7, 0, 6, 3, 2, 8, 9]\n",
            "10 [4 1 5 7 0 6 3 2 8 9]\n",
            "discarded index [4, 1, 5, 7, 0, 6, 3, 2, 8, 9]\n",
            "10 [4 1 5 7 0 6 3 2 8 9]\n",
            "discarded index [4, 1, 5, 7, 0, 6, 3, 2, 8, 9]\n",
            "10 [4 1 5 7 0 6 3 2 8 9]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 6, bulyan: at fang n_at 10 e 6 | val loss 2.2991 val acc 11.8506 best val_acc 11.850649\n",
            "discarded index [1, 5, 9, 0, 4, 6, 7, 2, 8, 3]\n",
            "10 [1 5 9 0 4 6 7 2 8 3]\n",
            "discarded index [1, 5, 9, 0, 4, 6, 7, 2, 8, 3]\n",
            "10 [1 5 9 0 4 6 7 2 8 3]\n",
            "discarded index [1, 5, 9, 0, 4, 6, 7, 2, 8, 3]\n",
            "10 [1 5 9 0 4 6 7 2 8 3]\n",
            "discarded index [1, 5, 9, 0, 4, 6, 7, 2, 8, 3]\n",
            "10 [1 5 9 0 4 6 7 2 8 3]\n",
            "discarded index [1, 5, 9, 0, 4, 6, 7, 2, 8, 3]\n",
            "10 [1 5 9 0 4 6 7 2 8 3]\n",
            "discarded index [1, 5, 9, 0, 4, 6, 7, 2, 8, 3]\n",
            "10 [1 5 9 0 4 6 7 2 8 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 7, bulyan: at fang n_at 10 e 7 | val loss 2.2984 val acc 14.2248 best val_acc 14.224838\n",
            "discarded index [4, 1, 5, 6, 0, 7, 9, 8, 3, 2]\n",
            "10 [4 1 5 6 0 7 9 8 3 2]\n",
            "discarded index [4, 1, 5, 6, 0, 7, 9, 8, 3, 2]\n",
            "10 [4 1 5 6 0 7 9 8 3 2]\n",
            "discarded index [4, 1, 5, 6, 0, 7, 9, 8, 3, 2]\n",
            "10 [4 1 5 6 0 7 9 8 3 2]\n",
            "discarded index [4, 1, 5, 6, 0, 7, 9, 8, 3, 2]\n",
            "10 [4 1 5 6 0 7 9 8 3 2]\n",
            "discarded index [4, 1, 5, 6, 0, 7, 9, 8, 3, 2]\n",
            "10 [4 1 5 6 0 7 9 8 3 2]\n",
            "discarded index [4, 1, 5, 6, 0, 7, 9, 8, 3, 2]\n",
            "10 [4 1 5 6 0 7 9 8 3 2]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 8, bulyan: at fang n_at 10 e 8 | val loss 2.2976 val acc 16.4164 best val_acc 16.416396\n",
            "discarded index [4, 1, 5, 6, 7, 9, 0, 3, 2, 8]\n",
            "10 [4 1 5 6 7 9 0 3 2 8]\n",
            "discarded index [4, 1, 5, 6, 7, 9, 0, 3, 2, 8]\n",
            "10 [4 1 5 6 7 9 0 3 2 8]\n",
            "discarded index [4, 1, 5, 6, 7, 9, 0, 3, 2, 8]\n",
            "10 [4 1 5 6 7 9 0 3 2 8]\n",
            "discarded index [4, 1, 5, 6, 7, 9, 0, 3, 2, 8]\n",
            "10 [4 1 5 6 7 9 0 3 2 8]\n",
            "discarded index [4, 1, 5, 6, 7, 9, 0, 3, 2, 8]\n",
            "10 [4 1 5 6 7 9 0 3 2 8]\n",
            "discarded index [4, 1, 5, 6, 7, 9, 0, 3, 2, 8]\n",
            "10 [4 1 5 6 7 9 0 3 2 8]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 9, bulyan: at fang n_at 10 e 9 | val loss 2.2965 val acc 20.8807 best val_acc 20.880682\n",
            "discarded index [5, 4, 1, 6, 0, 9, 3, 7, 8, 2]\n",
            "10 [5 4 1 6 0 9 3 7 8 2]\n",
            "discarded index [5, 4, 1, 6, 0, 9, 3, 7, 8, 2]\n",
            "10 [5 4 1 6 0 9 3 7 8 2]\n",
            "discarded index [5, 4, 1, 6, 0, 9, 3, 7, 8, 2]\n",
            "10 [5 4 1 6 0 9 3 7 8 2]\n",
            "discarded index [5, 4, 1, 6, 0, 9, 3, 7, 8, 2]\n",
            "10 [5 4 1 6 0 9 3 7 8 2]\n",
            "discarded index [5, 4, 1, 6, 0, 9, 3, 7, 8, 2]\n",
            "10 [5 4 1 6 0 9 3 7 8 2]\n",
            "discarded index [5, 4, 1, 6, 0, 9, 3, 7, 8, 2]\n",
            "10 [5 4 1 6 0 9 3 7 8 2]\n",
            "discarded index [5, 4, 1, 6, 0, 9, 3, 7, 8, 2]\n",
            "10 [5 4 1 6 0 9 3 7 8 2]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 10, bulyan: at fang n_at 10 e 10 | val loss 2.2951 val acc 18.6891 best val_acc 20.880682\n",
            "discarded index [5, 1, 9, 0, 6, 4, 8, 7, 2, 3]\n",
            "10 [5 1 9 0 6 4 8 7 2 3]\n",
            "discarded index [5, 1, 9, 0, 6, 4, 8, 7, 2, 3]\n",
            "10 [5 1 9 0 6 4 8 7 2 3]\n",
            "discarded index [5, 1, 9, 0, 6, 4, 8, 7, 2, 3]\n",
            "10 [5 1 9 0 6 4 8 7 2 3]\n",
            "discarded index [5, 1, 9, 0, 6, 4, 8, 7, 2, 3]\n",
            "10 [5 1 9 0 6 4 8 7 2 3]\n",
            "discarded index [5, 1, 9, 0, 6, 4, 8, 7, 2, 3]\n",
            "10 [5 1 9 0 6 4 8 7 2 3]\n",
            "discarded index [5, 1, 9, 0, 6, 4, 8, 7, 2, 3]\n",
            "10 [5 1 9 0 6 4 8 7 2 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 11, bulyan: at fang n_at 10 e 11 | val loss 2.2932 val acc 16.2744 best val_acc 20.880682\n",
            "discarded index [4, 1, 5, 6, 9, 7, 2, 0, 3, 8]\n",
            "10 [4 1 5 6 9 7 2 0 3 8]\n",
            "discarded index [4, 1, 5, 6, 9, 7, 2, 0, 3, 8]\n",
            "10 [4 1 5 6 9 7 2 0 3 8]\n",
            "discarded index [4, 1, 5, 6, 9, 7, 2, 0, 3, 8]\n",
            "10 [4 1 5 6 9 7 2 0 3 8]\n",
            "discarded index [4, 1, 5, 6, 9, 7, 2, 0, 3, 8]\n",
            "10 [4 1 5 6 9 7 2 0 3 8]\n",
            "discarded index [4, 1, 5, 6, 9, 7, 2, 0, 3, 8]\n",
            "10 [4 1 5 6 9 7 2 0 3 8]\n",
            "discarded index [4, 1, 5, 6, 9, 7, 2, 0, 3, 8]\n",
            "10 [4 1 5 6 9 7 2 0 3 8]\n",
            "discarded index [4, 1, 5, 6, 9, 7, 2, 0, 3, 8]\n",
            "10 [4 1 5 6 9 7 2 0 3 8]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 12, bulyan: at fang n_at 10 e 12 | val loss 2.2907 val acc 15.9700 best val_acc 20.880682\n",
            "discarded index [5, 1, 4, 6, 9, 7, 0, 8, 2, 3]\n",
            "10 [5 1 4 6 9 7 0 8 2 3]\n",
            "discarded index [5, 1, 4, 6, 9, 7, 0, 8, 2, 3]\n",
            "10 [5 1 4 6 9 7 0 8 2 3]\n",
            "discarded index [5, 1, 4, 6, 9, 7, 0, 8, 2, 3]\n",
            "10 [5 1 4 6 9 7 0 8 2 3]\n",
            "discarded index [5, 1, 4, 6, 9, 7, 0, 8, 2, 3]\n",
            "10 [5 1 4 6 9 7 0 8 2 3]\n",
            "discarded index [5, 1, 4, 6, 9, 7, 0, 8, 2, 3]\n",
            "10 [5 1 4 6 9 7 0 8 2 3]\n",
            "discarded index [5, 1, 4, 6, 9, 7, 0, 8, 2, 3]\n",
            "10 [5 1 4 6 9 7 0 8 2 3]\n",
            "discarded index [5, 1, 4, 6, 9, 7, 0, 8, 2, 3]\n",
            "10 [5 1 4 6 9 7 0 8 2 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 13, bulyan: at fang n_at 10 e 13 | val loss 2.2873 val acc 15.0974 best val_acc 20.880682\n",
            "discarded index [5, 1, 6, 4, 9, 0, 3, 8, 7, 2]\n",
            "10 [5 1 6 4 9 0 3 8 7 2]\n",
            "discarded index [5, 1, 6, 4, 9, 0, 3, 8, 7, 2]\n",
            "10 [5 1 6 4 9 0 3 8 7 2]\n",
            "discarded index [5, 1, 6, 4, 9, 0, 3, 8, 7, 2]\n",
            "10 [5 1 6 4 9 0 3 8 7 2]\n",
            "discarded index [5, 1, 6, 4, 9, 0, 3, 8, 7, 2]\n",
            "10 [5 1 6 4 9 0 3 8 7 2]\n",
            "discarded index [5, 1, 6, 4, 9, 0, 3, 8, 7, 2]\n",
            "10 [5 1 6 4 9 0 3 8 7 2]\n",
            "discarded index [5, 1, 6, 4, 9, 0, 3, 8, 7, 2]\n",
            "10 [5 1 6 4 9 0 3 8 7 2]\n",
            "discarded index [5, 1, 6, 4, 9, 0, 3, 8, 7, 2]\n",
            "10 [5 1 6 4 9 0 3 8 7 2]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 14, bulyan: at fang n_at 10 e 14 | val loss 2.2826 val acc 14.2857 best val_acc 20.880682\n",
            "discarded index [5, 1, 9, 4, 6, 8, 2, 7, 3, 0]\n",
            "10 [5 1 9 4 6 8 2 7 3 0]\n",
            "discarded index [5, 1, 9, 4, 6, 8, 2, 7, 3, 0]\n",
            "10 [5 1 9 4 6 8 2 7 3 0]\n",
            "discarded index [5, 1, 9, 4, 6, 8, 2, 7, 3, 0]\n",
            "10 [5 1 9 4 6 8 2 7 3 0]\n",
            "discarded index [5, 1, 9, 4, 6, 8, 2, 7, 3, 0]\n",
            "10 [5 1 9 4 6 8 2 7 3 0]\n",
            "discarded index [5, 1, 9, 4, 6, 8, 2, 7, 3, 0]\n",
            "10 [5 1 9 4 6 8 2 7 3 0]\n",
            "discarded index [5, 1, 9, 4, 6, 8, 2, 7, 3, 0]\n",
            "10 [5 1 9 4 6 8 2 7 3 0]\n",
            "discarded index [5, 1, 9, 4, 6, 8, 2, 7, 3, 0]\n",
            "10 [5 1 9 4 6 8 2 7 3 0]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 15, bulyan: at fang n_at 10 e 15 | val loss 2.2762 val acc 13.9205 best val_acc 20.880682\n",
            "discarded index [5, 1, 4, 6, 7, 9, 2, 8, 3, 0]\n",
            "10 [5 1 4 6 7 9 2 8 3 0]\n",
            "discarded index [5, 1, 4, 6, 7, 9, 2, 8, 3, 0]\n",
            "10 [5 1 4 6 7 9 2 8 3 0]\n",
            "discarded index [5, 1, 4, 6, 7, 9, 2, 8, 3, 0]\n",
            "10 [5 1 4 6 7 9 2 8 3 0]\n",
            "discarded index [5, 1, 4, 6, 7, 9, 2, 8, 3, 0]\n",
            "10 [5 1 4 6 7 9 2 8 3 0]\n",
            "discarded index [5, 1, 4, 6, 7, 9, 2, 8, 3, 0]\n",
            "10 [5 1 4 6 7 9 2 8 3 0]\n",
            "discarded index [5, 1, 4, 6, 7, 9, 2, 8, 3, 0]\n",
            "10 [5 1 4 6 7 9 2 8 3 0]\n",
            "discarded index [5, 1, 4, 6, 7, 9, 2, 8, 3, 0]\n",
            "10 [5 1 4 6 7 9 2 8 3 0]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 16, bulyan: at fang n_at 10 e 16 | val loss 2.2673 val acc 13.3117 best val_acc 20.880682\n",
            "discarded index [5, 6, 1, 9, 4, 7, 2, 3, 0, 8]\n",
            "10 [5 6 1 9 4 7 2 3 0 8]\n",
            "discarded index [5, 6, 1, 9, 4, 7, 2, 3, 0, 8]\n",
            "10 [5 6 1 9 4 7 2 3 0 8]\n",
            "discarded index [5, 6, 1, 9, 4, 7, 2, 3, 0, 8]\n",
            "10 [5 6 1 9 4 7 2 3 0 8]\n",
            "discarded index [5, 6, 1, 9, 4, 7, 2, 3, 0, 8]\n",
            "10 [5 6 1 9 4 7 2 3 0 8]\n",
            "discarded index [5, 6, 1, 9, 4, 7, 2, 3, 0, 8]\n",
            "10 [5 6 1 9 4 7 2 3 0 8]\n",
            "discarded index [5, 6, 1, 9, 4, 7, 2, 3, 0, 8]\n",
            "10 [5 6 1 9 4 7 2 3 0 8]\n",
            "discarded index [5, 6, 1, 9, 4, 7, 2, 3, 0, 8]\n",
            "10 [5 6 1 9 4 7 2 3 0 8]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 17, bulyan: at fang n_at 10 e 17 | val loss 2.2561 val acc 13.5958 best val_acc 20.880682\n",
            "discarded index [5, 1, 4, 9, 6, 3, 2, 0, 7, 8]\n",
            "10 [5 1 4 9 6 3 2 0 7 8]\n",
            "discarded index [5, 1, 4, 9, 6, 3, 2, 0, 7, 8]\n",
            "10 [5 1 4 9 6 3 2 0 7 8]\n",
            "discarded index [5, 1, 4, 9, 6, 3, 2, 0, 7, 8]\n",
            "10 [5 1 4 9 6 3 2 0 7 8]\n",
            "discarded index [5, 1, 4, 9, 6, 3, 2, 0, 7, 8]\n",
            "10 [5 1 4 9 6 3 2 0 7 8]\n",
            "discarded index [5, 1, 4, 9, 6, 3, 2, 0, 7, 8]\n",
            "10 [5 1 4 9 6 3 2 0 7 8]\n",
            "discarded index [5, 1, 4, 9, 6, 3, 2, 0, 7, 8]\n",
            "10 [5 1 4 9 6 3 2 0 7 8]\n",
            "discarded index [5, 1, 4, 9, 6, 3, 2, 0, 7, 8]\n",
            "10 [5 1 4 9 6 3 2 0 7 8]\n",
            "discarded index [5, 1, 4, 9, 6, 3, 2, 0, 7, 8]\n",
            "10 [5 1 4 9 6 3 2 0 7 8]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 18, bulyan: at fang n_at 10 e 18 | val loss 2.2426 val acc 14.8336 best val_acc 20.880682\n",
            "discarded index [5, 9, 1, 6, 7, 4, 0, 8, 2, 3]\n",
            "10 [5 9 1 6 7 4 0 8 2 3]\n",
            "discarded index [5, 9, 1, 6, 7, 4, 0, 8, 2, 3]\n",
            "10 [5 9 1 6 7 4 0 8 2 3]\n",
            "discarded index [5, 9, 1, 6, 7, 4, 0, 8, 2, 3]\n",
            "10 [5 9 1 6 7 4 0 8 2 3]\n",
            "discarded index [5, 9, 1, 6, 7, 4, 0, 8, 2, 3]\n",
            "10 [5 9 1 6 7 4 0 8 2 3]\n",
            "discarded index [5, 9, 1, 6, 7, 4, 0, 8, 2, 3]\n",
            "10 [5 9 1 6 7 4 0 8 2 3]\n",
            "discarded index [5, 9, 1, 6, 7, 4, 0, 8, 2, 3]\n",
            "10 [5 9 1 6 7 4 0 8 2 3]\n",
            "discarded index [5, 9, 1, 6, 7, 4, 0, 8, 2, 3]\n",
            "10 [5 9 1 6 7 4 0 8 2 3]\n",
            "discarded index [5, 9, 1, 6, 7, 4, 0, 8, 2, 3]\n",
            "10 [5 9 1 6 7 4 0 8 2 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 19, bulyan: at fang n_at 10 e 19 | val loss 2.2290 val acc 16.4976 best val_acc 20.880682\n",
            "discarded index [5, 1, 4, 6, 9, 7, 0, 2, 8, 3]\n",
            "10 [5 1 4 6 9 7 0 2 8 3]\n",
            "discarded index [5, 1, 4, 6, 9, 7, 0, 2, 8, 3]\n",
            "10 [5 1 4 6 9 7 0 2 8 3]\n",
            "discarded index [5, 1, 4, 6, 9, 7, 0, 2, 8, 3]\n",
            "10 [5 1 4 6 9 7 0 2 8 3]\n",
            "discarded index [5, 1, 4, 6, 9, 7, 0, 2, 8, 3]\n",
            "10 [5 1 4 6 9 7 0 2 8 3]\n",
            "discarded index [5, 1, 4, 6, 9, 7, 0, 2, 8, 3]\n",
            "10 [5 1 4 6 9 7 0 2 8 3]\n",
            "discarded index [5, 1, 4, 6, 9, 7, 0, 2, 8, 3]\n",
            "10 [5 1 4 6 9 7 0 2 8 3]\n",
            "discarded index [5, 1, 4, 6, 9, 7, 0, 2, 8, 3]\n",
            "10 [5 1 4 6 9 7 0 2 8 3]\n",
            "discarded index [5, 1, 4, 6, 9, 7, 0, 2, 8, 3]\n",
            "10 [5 1 4 6 9 7 0 2 8 3]\n",
            "lamda < threshold\n",
            "discarded index [20, 0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
            "epoch: 20, bulyan: at fang n_at 10 e 20 | val loss 2.2172 val acc 16.5787 best val_acc 20.880682\n",
            "discarded index [20, 5, 4, 6, 1, 9, 2, 7, 8, 3]\n",
            "9 [20  5  4  6  1  9  2  7  8  3]\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 21, bulyan: at fang n_at 10 e 21 | val loss 2.1985 val acc 22.2200 best val_acc 22.219968\n",
            "discarded index [5, 9, 0, 3, 1, 8, 4, 6, 7, 2]\n",
            "10 [5 9 0 3 1 8 4 6 7 2]\n",
            "discarded index [5, 9, 0, 3, 1, 8, 4, 6, 7, 2]\n",
            "10 [5 9 0 3 1 8 4 6 7 2]\n",
            "discarded index [5, 9, 0, 3, 1, 8, 4, 6, 7, 2]\n",
            "10 [5 9 0 3 1 8 4 6 7 2]\n",
            "discarded index [5, 9, 0, 3, 1, 8, 4, 6, 7, 2]\n",
            "10 [5 9 0 3 1 8 4 6 7 2]\n",
            "discarded index [5, 9, 0, 3, 1, 8, 4, 6, 7, 2]\n",
            "10 [5 9 0 3 1 8 4 6 7 2]\n",
            "discarded index [5, 9, 0, 3, 1, 8, 4, 6, 7, 2]\n",
            "10 [5 9 0 3 1 8 4 6 7 2]\n",
            "discarded index [5, 9, 0, 3, 1, 8, 4, 6, 7, 2]\n",
            "10 [5 9 0 3 1 8 4 6 7 2]\n",
            "discarded index [5, 9, 0, 3, 1, 8, 4, 6, 7, 2]\n",
            "10 [5 9 0 3 1 8 4 6 7 2]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 22, bulyan: at fang n_at 10 e 22 | val loss 2.1929 val acc 17.3904 best val_acc 22.219968\n",
            "discarded index [5, 9, 1, 6, 4, 8, 7, 2, 3, 0]\n",
            "10 [5 9 1 6 4 8 7 2 3 0]\n",
            "discarded index [5, 9, 1, 6, 4, 8, 7, 2, 3, 0]\n",
            "10 [5 9 1 6 4 8 7 2 3 0]\n",
            "discarded index [5, 9, 1, 6, 4, 8, 7, 2, 3, 0]\n",
            "10 [5 9 1 6 4 8 7 2 3 0]\n",
            "discarded index [5, 9, 1, 6, 4, 8, 7, 2, 3, 0]\n",
            "10 [5 9 1 6 4 8 7 2 3 0]\n",
            "discarded index [5, 9, 1, 6, 4, 8, 7, 2, 3, 0]\n",
            "10 [5 9 1 6 4 8 7 2 3 0]\n",
            "discarded index [5, 9, 1, 6, 4, 8, 7, 2, 3, 0]\n",
            "10 [5 9 1 6 4 8 7 2 3 0]\n",
            "discarded index [5, 9, 1, 6, 4, 8, 7, 2, 3, 0]\n",
            "10 [5 9 1 6 4 8 7 2 3 0]\n",
            "discarded index [5, 9, 1, 6, 4, 8, 7, 2, 3, 0]\n",
            "10 [5 9 1 6 4 8 7 2 3 0]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 23, bulyan: at fang n_at 10 e 23 | val loss 2.2890 val acc 13.7784 best val_acc 22.219968\n",
            "discarded index [7, 9, 6, 0, 4, 2, 3, 5, 1, 8]\n",
            "10 [7 9 6 0 4 2 3 5 1 8]\n",
            "discarded index [7, 9, 6, 0, 4, 2, 3, 5, 1, 8]\n",
            "10 [7 9 6 0 4 2 3 5 1 8]\n",
            "discarded index [7, 9, 6, 0, 4, 2, 3, 5, 1, 8]\n",
            "10 [7 9 6 0 4 2 3 5 1 8]\n",
            "discarded index [7, 9, 6, 0, 4, 2, 3, 5, 1, 8]\n",
            "10 [7 9 6 0 4 2 3 5 1 8]\n",
            "discarded index [7, 9, 6, 0, 4, 2, 3, 5, 1, 8]\n",
            "10 [7 9 6 0 4 2 3 5 1 8]\n",
            "discarded index [7, 9, 6, 0, 4, 2, 3, 5, 1, 8]\n",
            "10 [7 9 6 0 4 2 3 5 1 8]\n",
            "discarded index [7, 9, 6, 0, 4, 2, 3, 5, 1, 8]\n",
            "10 [7 9 6 0 4 2 3 5 1 8]\n",
            "discarded index [7, 9, 6, 0, 4, 2, 3, 5, 1, 8]\n",
            "10 [7 9 6 0 4 2 3 5 1 8]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 24, bulyan: at fang n_at 10 e 24 | val loss 2.2826 val acc 13.9813 best val_acc 22.219968\n",
            "discarded index [0, 5, 9, 7, 1, 6, 2, 4, 8, 3]\n",
            "10 [0 5 9 7 1 6 2 4 8 3]\n",
            "discarded index [0, 5, 9, 7, 1, 6, 2, 4, 8, 3]\n",
            "10 [0 5 9 7 1 6 2 4 8 3]\n",
            "discarded index [0, 5, 9, 7, 1, 6, 2, 4, 8, 3]\n",
            "10 [0 5 9 7 1 6 2 4 8 3]\n",
            "discarded index [0, 5, 9, 7, 1, 6, 2, 4, 8, 3]\n",
            "10 [0 5 9 7 1 6 2 4 8 3]\n",
            "discarded index [0, 5, 9, 7, 1, 6, 2, 4, 8, 3]\n",
            "10 [0 5 9 7 1 6 2 4 8 3]\n",
            "discarded index [0, 5, 9, 7, 1, 6, 2, 4, 8, 3]\n",
            "10 [0 5 9 7 1 6 2 4 8 3]\n",
            "discarded index [0, 5, 9, 7, 1, 6, 2, 4, 8, 3]\n",
            "10 [0 5 9 7 1 6 2 4 8 3]\n",
            "discarded index [0, 5, 9, 7, 1, 6, 2, 4, 8, 3]\n",
            "10 [0 5 9 7 1 6 2 4 8 3]\n",
            "discarded index [0, 5, 9, 7, 1, 6, 2, 4, 8, 3]\n",
            "10 [0 5 9 7 1 6 2 4 8 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 25, bulyan: at fang n_at 10 e 25 | val loss 2.3018 val acc 10.2273 best val_acc 22.219968\n",
            "discarded index [0, 1, 7, 2, 4, 9, 6, 3, 5, 8]\n",
            "10 [0 1 7 2 4 9 6 3 5 8]\n",
            "discarded index [0, 1, 7, 2, 4, 9, 6, 3, 5, 8]\n",
            "10 [0 1 7 2 4 9 6 3 5 8]\n",
            "discarded index [0, 1, 7, 2, 4, 9, 6, 3, 5, 8]\n",
            "10 [0 1 7 2 4 9 6 3 5 8]\n",
            "discarded index [0, 1, 7, 2, 4, 9, 6, 3, 5, 8]\n",
            "10 [0 1 7 2 4 9 6 3 5 8]\n",
            "discarded index [0, 1, 7, 2, 4, 9, 6, 3, 5, 8]\n",
            "10 [0 1 7 2 4 9 6 3 5 8]\n",
            "discarded index [0, 1, 7, 2, 4, 9, 6, 3, 5, 8]\n",
            "10 [0 1 7 2 4 9 6 3 5 8]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 26, bulyan: at fang n_at 10 e 26 | val loss 2.2970 val acc 10.7143 best val_acc 22.219968\n",
            "discarded index [0, 7, 1, 2, 3, 4, 6, 9, 5, 8]\n",
            "10 [0 7 1 2 3 4 6 9 5 8]\n",
            "discarded index [0, 7, 1, 2, 3, 4, 6, 9, 5, 8]\n",
            "10 [0 7 1 2 3 4 6 9 5 8]\n",
            "discarded index [0, 7, 1, 2, 3, 4, 6, 9, 5, 8]\n",
            "10 [0 7 1 2 3 4 6 9 5 8]\n",
            "discarded index [0, 7, 1, 2, 3, 4, 6, 9, 5, 8]\n",
            "10 [0 7 1 2 3 4 6 9 5 8]\n",
            "discarded index [0, 7, 1, 2, 3, 4, 6, 9, 5, 8]\n",
            "10 [0 7 1 2 3 4 6 9 5 8]\n",
            "discarded index [0, 7, 1, 2, 3, 4, 6, 9, 5, 8]\n",
            "10 [0 7 1 2 3 4 6 9 5 8]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 27, bulyan: at fang n_at 10 e 27 | val loss 2.2892 val acc 12.0739 best val_acc 22.219968\n",
            "discarded index [0, 1, 6, 4, 9, 2, 7, 5, 3, 8]\n",
            "10 [0 1 6 4 9 2 7 5 3 8]\n",
            "discarded index [0, 1, 6, 4, 9, 2, 7, 5, 3, 8]\n",
            "10 [0 1 6 4 9 2 7 5 3 8]\n",
            "discarded index [0, 1, 6, 4, 9, 2, 7, 5, 3, 8]\n",
            "10 [0 1 6 4 9 2 7 5 3 8]\n",
            "discarded index [0, 1, 6, 4, 9, 2, 7, 5, 3, 8]\n",
            "10 [0 1 6 4 9 2 7 5 3 8]\n",
            "discarded index [0, 1, 6, 4, 9, 2, 7, 5, 3, 8]\n",
            "10 [0 1 6 4 9 2 7 5 3 8]\n",
            "discarded index [0, 1, 6, 4, 9, 2, 7, 5, 3, 8]\n",
            "10 [0 1 6 4 9 2 7 5 3 8]\n",
            "discarded index [0, 1, 6, 4, 9, 2, 7, 5, 3, 8]\n",
            "10 [0 1 6 4 9 2 7 5 3 8]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 28, bulyan: at fang n_at 10 e 28 | val loss 2.2752 val acc 14.6510 best val_acc 22.219968\n",
            "discarded index [0, 6, 1, 4, 8, 9, 3, 7, 5, 2]\n",
            "10 [0 6 1 4 8 9 3 7 5 2]\n",
            "discarded index [0, 6, 1, 4, 8, 9, 3, 7, 5, 2]\n",
            "10 [0 6 1 4 8 9 3 7 5 2]\n",
            "discarded index [0, 6, 1, 4, 8, 9, 3, 7, 5, 2]\n",
            "10 [0 6 1 4 8 9 3 7 5 2]\n",
            "discarded index [0, 6, 1, 4, 8, 9, 3, 7, 5, 2]\n",
            "10 [0 6 1 4 8 9 3 7 5 2]\n",
            "discarded index [0, 6, 1, 4, 8, 9, 3, 7, 5, 2]\n",
            "10 [0 6 1 4 8 9 3 7 5 2]\n",
            "discarded index [0, 6, 1, 4, 8, 9, 3, 7, 5, 2]\n",
            "10 [0 6 1 4 8 9 3 7 5 2]\n",
            "discarded index [0, 6, 1, 4, 8, 9, 3, 7, 5, 2]\n",
            "10 [0 6 1 4 8 9 3 7 5 2]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 29, bulyan: at fang n_at 10 e 29 | val loss 2.2502 val acc 17.9383 best val_acc 22.219968\n",
            "discarded index [0, 6, 4, 1, 2, 5, 8, 9, 7, 3]\n",
            "10 [0 6 4 1 2 5 8 9 7 3]\n",
            "discarded index [0, 6, 4, 1, 2, 5, 8, 9, 7, 3]\n",
            "10 [0 6 4 1 2 5 8 9 7 3]\n",
            "discarded index [0, 6, 4, 1, 2, 5, 8, 9, 7, 3]\n",
            "10 [0 6 4 1 2 5 8 9 7 3]\n",
            "discarded index [0, 6, 4, 1, 2, 5, 8, 9, 7, 3]\n",
            "10 [0 6 4 1 2 5 8 9 7 3]\n",
            "discarded index [0, 6, 4, 1, 2, 5, 8, 9, 7, 3]\n",
            "10 [0 6 4 1 2 5 8 9 7 3]\n",
            "discarded index [0, 6, 4, 1, 2, 5, 8, 9, 7, 3]\n",
            "10 [0 6 4 1 2 5 8 9 7 3]\n",
            "discarded index [0, 6, 4, 1, 2, 5, 8, 9, 7, 3]\n",
            "10 [0 6 4 1 2 5 8 9 7 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 30, bulyan: at fang n_at 10 e 30 | val loss 2.2121 val acc 19.5617 best val_acc 22.219968\n",
            "discarded index [6, 1, 4, 0, 8, 7, 5, 2, 9, 3]\n",
            "10 [6 1 4 0 8 7 5 2 9 3]\n",
            "discarded index [6, 1, 4, 0, 8, 7, 5, 2, 9, 3]\n",
            "10 [6 1 4 0 8 7 5 2 9 3]\n",
            "discarded index [6, 1, 4, 0, 8, 7, 5, 2, 9, 3]\n",
            "10 [6 1 4 0 8 7 5 2 9 3]\n",
            "discarded index [6, 1, 4, 0, 8, 7, 5, 2, 9, 3]\n",
            "10 [6 1 4 0 8 7 5 2 9 3]\n",
            "discarded index [6, 1, 4, 0, 8, 7, 5, 2, 9, 3]\n",
            "10 [6 1 4 0 8 7 5 2 9 3]\n",
            "discarded index [6, 1, 4, 0, 8, 7, 5, 2, 9, 3]\n",
            "10 [6 1 4 0 8 7 5 2 9 3]\n",
            "discarded index [6, 1, 4, 0, 8, 7, 5, 2, 9, 3]\n",
            "10 [6 1 4 0 8 7 5 2 9 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 31, bulyan: at fang n_at 10 e 31 | val loss 2.1758 val acc 17.9586 best val_acc 22.219968\n",
            "discarded index [6, 1, 0, 5, 4, 8, 9, 2, 3, 7]\n",
            "10 [6 1 0 5 4 8 9 2 3 7]\n",
            "discarded index [6, 1, 0, 5, 4, 8, 9, 2, 3, 7]\n",
            "10 [6 1 0 5 4 8 9 2 3 7]\n",
            "discarded index [6, 1, 0, 5, 4, 8, 9, 2, 3, 7]\n",
            "10 [6 1 0 5 4 8 9 2 3 7]\n",
            "discarded index [6, 1, 0, 5, 4, 8, 9, 2, 3, 7]\n",
            "10 [6 1 0 5 4 8 9 2 3 7]\n",
            "discarded index [6, 1, 0, 5, 4, 8, 9, 2, 3, 7]\n",
            "10 [6 1 0 5 4 8 9 2 3 7]\n",
            "discarded index [6, 1, 0, 5, 4, 8, 9, 2, 3, 7]\n",
            "10 [6 1 0 5 4 8 9 2 3 7]\n",
            "discarded index [6, 1, 0, 5, 4, 8, 9, 2, 3, 7]\n",
            "10 [6 1 0 5 4 8 9 2 3 7]\n",
            "discarded index [6, 1, 0, 5, 4, 8, 9, 2, 3, 7]\n",
            "10 [6 1 0 5 4 8 9 2 3 7]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 32, bulyan: at fang n_at 10 e 32 | val loss 2.1325 val acc 20.5357 best val_acc 22.219968\n",
            "discarded index [5, 6, 4, 1, 7, 2, 8, 3, 0, 9]\n",
            "10 [5 6 4 1 7 2 8 3 0 9]\n",
            "discarded index [5, 6, 4, 1, 7, 2, 8, 3, 0, 9]\n",
            "10 [5 6 4 1 7 2 8 3 0 9]\n",
            "discarded index [5, 6, 4, 1, 7, 2, 8, 3, 0, 9]\n",
            "10 [5 6 4 1 7 2 8 3 0 9]\n",
            "discarded index [5, 6, 4, 1, 7, 2, 8, 3, 0, 9]\n",
            "10 [5 6 4 1 7 2 8 3 0 9]\n",
            "discarded index [5, 6, 4, 1, 7, 2, 8, 3, 0, 9]\n",
            "10 [5 6 4 1 7 2 8 3 0 9]\n",
            "discarded index [5, 6, 4, 1, 7, 2, 8, 3, 0, 9]\n",
            "10 [5 6 4 1 7 2 8 3 0 9]\n",
            "discarded index [5, 6, 4, 1, 7, 2, 8, 3, 0, 9]\n",
            "10 [5 6 4 1 7 2 8 3 0 9]\n",
            "discarded index [5, 6, 4, 1, 7, 2, 8, 3, 0, 9]\n",
            "10 [5 6 4 1 7 2 8 3 0 9]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 33, bulyan: at fang n_at 10 e 33 | val loss 2.1127 val acc 18.2021 best val_acc 22.219968\n",
            "discarded index [5, 4, 6, 7, 0, 8, 2, 3, 1, 9]\n",
            "10 [5 4 6 7 0 8 2 3 1 9]\n",
            "discarded index [5, 4, 6, 7, 0, 8, 2, 3, 1, 9]\n",
            "10 [5 4 6 7 0 8 2 3 1 9]\n",
            "discarded index [5, 4, 6, 7, 0, 8, 2, 3, 1, 9]\n",
            "10 [5 4 6 7 0 8 2 3 1 9]\n",
            "discarded index [5, 4, 6, 7, 0, 8, 2, 3, 1, 9]\n",
            "10 [5 4 6 7 0 8 2 3 1 9]\n",
            "discarded index [5, 4, 6, 7, 0, 8, 2, 3, 1, 9]\n",
            "10 [5 4 6 7 0 8 2 3 1 9]\n",
            "discarded index [5, 4, 6, 7, 0, 8, 2, 3, 1, 9]\n",
            "10 [5 4 6 7 0 8 2 3 1 9]\n",
            "discarded index [5, 4, 6, 7, 0, 8, 2, 3, 1, 9]\n",
            "10 [5 4 6 7 0 8 2 3 1 9]\n",
            "discarded index [5, 4, 6, 7, 0, 8, 2, 3, 1, 9]\n",
            "10 [5 4 6 7 0 8 2 3 1 9]\n",
            "discarded index [5, 4, 6, 7, 0, 8, 2, 3, 1, 9]\n",
            "10 [5 4 6 7 0 8 2 3 1 9]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 34, bulyan: at fang n_at 10 e 34 | val loss 2.3122 val acc 13.1088 best val_acc 22.219968\n",
            "discarded index [7, 9, 0, 6, 5, 3, 1, 2, 4, 8]\n",
            "10 [7 9 0 6 5 3 1 2 4 8]\n",
            "discarded index [7, 9, 0, 6, 5, 3, 1, 2, 4, 8]\n",
            "10 [7 9 0 6 5 3 1 2 4 8]\n",
            "discarded index [7, 9, 0, 6, 5, 3, 1, 2, 4, 8]\n",
            "10 [7 9 0 6 5 3 1 2 4 8]\n",
            "discarded index [7, 9, 0, 6, 5, 3, 1, 2, 4, 8]\n",
            "10 [7 9 0 6 5 3 1 2 4 8]\n",
            "discarded index [7, 9, 0, 6, 5, 3, 1, 2, 4, 8]\n",
            "10 [7 9 0 6 5 3 1 2 4 8]\n",
            "discarded index [7, 9, 0, 6, 5, 3, 1, 2, 4, 8]\n",
            "10 [7 9 0 6 5 3 1 2 4 8]\n",
            "discarded index [7, 9, 0, 6, 5, 3, 1, 2, 4, 8]\n",
            "10 [7 9 0 6 5 3 1 2 4 8]\n",
            "discarded index [7, 9, 0, 6, 5, 3, 1, 2, 4, 8]\n",
            "10 [7 9 0 6 5 3 1 2 4 8]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 35, bulyan: at fang n_at 10 e 35 | val loss 2.3786 val acc 12.0130 best val_acc 22.219968\n",
            "discarded index [5, 0, 7, 9, 2, 1, 3, 6, 4, 8]\n",
            "10 [5 0 7 9 2 1 3 6 4 8]\n",
            "discarded index [5, 0, 7, 9, 2, 1, 3, 6, 4, 8]\n",
            "10 [5 0 7 9 2 1 3 6 4 8]\n",
            "discarded index [5, 0, 7, 9, 2, 1, 3, 6, 4, 8]\n",
            "10 [5 0 7 9 2 1 3 6 4 8]\n",
            "discarded index [5, 0, 7, 9, 2, 1, 3, 6, 4, 8]\n",
            "10 [5 0 7 9 2 1 3 6 4 8]\n",
            "discarded index [5, 0, 7, 9, 2, 1, 3, 6, 4, 8]\n",
            "10 [5 0 7 9 2 1 3 6 4 8]\n",
            "discarded index [5, 0, 7, 9, 2, 1, 3, 6, 4, 8]\n",
            "10 [5 0 7 9 2 1 3 6 4 8]\n",
            "discarded index [5, 0, 7, 9, 2, 1, 3, 6, 4, 8]\n",
            "10 [5 0 7 9 2 1 3 6 4 8]\n",
            "discarded index [5, 0, 7, 9, 2, 1, 3, 6, 4, 8]\n",
            "10 [5 0 7 9 2 1 3 6 4 8]\n",
            "discarded index [5, 0, 7, 9, 2, 1, 3, 6, 4, 8]\n",
            "10 [5 0 7 9 2 1 3 6 4 8]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 36, bulyan: at fang n_at 10 e 36 | val loss 2.3047 val acc 10.1867 best val_acc 22.219968\n",
            "discarded index [0, 7, 9, 5, 3, 8, 4, 1, 2, 6]\n",
            "10 [0 7 9 5 3 8 4 1 2 6]\n",
            "discarded index [0, 7, 9, 5, 3, 8, 4, 1, 2, 6]\n",
            "10 [0 7 9 5 3 8 4 1 2 6]\n",
            "discarded index [0, 7, 9, 5, 3, 8, 4, 1, 2, 6]\n",
            "10 [0 7 9 5 3 8 4 1 2 6]\n",
            "discarded index [0, 7, 9, 5, 3, 8, 4, 1, 2, 6]\n",
            "10 [0 7 9 5 3 8 4 1 2 6]\n",
            "discarded index [0, 7, 9, 5, 3, 8, 4, 1, 2, 6]\n",
            "10 [0 7 9 5 3 8 4 1 2 6]\n",
            "discarded index [0, 7, 9, 5, 3, 8, 4, 1, 2, 6]\n",
            "10 [0 7 9 5 3 8 4 1 2 6]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 37, bulyan: at fang n_at 10 e 37 | val loss 2.3018 val acc 10.1867 best val_acc 22.219968\n",
            "discarded index [0, 7, 9, 5, 3, 8, 4, 6, 2, 1]\n",
            "10 [0 7 9 5 3 8 4 6 2 1]\n",
            "discarded index [0, 7, 9, 5, 3, 8, 4, 6, 2, 1]\n",
            "10 [0 7 9 5 3 8 4 6 2 1]\n",
            "discarded index [0, 7, 9, 5, 3, 8, 4, 6, 2, 1]\n",
            "10 [0 7 9 5 3 8 4 6 2 1]\n",
            "discarded index [0, 7, 9, 5, 3, 8, 4, 6, 2, 1]\n",
            "10 [0 7 9 5 3 8 4 6 2 1]\n",
            "discarded index [0, 7, 9, 5, 3, 8, 4, 6, 2, 1]\n",
            "10 [0 7 9 5 3 8 4 6 2 1]\n",
            "discarded index [0, 7, 9, 5, 3, 8, 4, 6, 2, 1]\n",
            "10 [0 7 9 5 3 8 4 6 2 1]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 38, bulyan: at fang n_at 10 e 38 | val loss 2.2985 val acc 10.1867 best val_acc 22.219968\n",
            "discarded index [0, 7, 9, 5, 3, 1, 4, 6, 8, 2]\n",
            "10 [0 7 9 5 3 1 4 6 8 2]\n",
            "discarded index [0, 7, 9, 5, 3, 1, 4, 6, 8, 2]\n",
            "10 [0 7 9 5 3 1 4 6 8 2]\n",
            "discarded index [0, 7, 9, 5, 3, 1, 4, 6, 8, 2]\n",
            "10 [0 7 9 5 3 1 4 6 8 2]\n",
            "discarded index [0, 7, 9, 5, 3, 1, 4, 6, 8, 2]\n",
            "10 [0 7 9 5 3 1 4 6 8 2]\n",
            "discarded index [0, 7, 9, 5, 3, 1, 4, 6, 8, 2]\n",
            "10 [0 7 9 5 3 1 4 6 8 2]\n",
            "discarded index [0, 7, 9, 5, 3, 1, 4, 6, 8, 2]\n",
            "10 [0 7 9 5 3 1 4 6 8 2]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 39, bulyan: at fang n_at 10 e 39 | val loss 2.2944 val acc 10.2070 best val_acc 22.219968\n",
            "discarded index [0, 7, 9, 5, 3, 4, 6, 2, 1, 8]\n",
            "10 [0 7 9 5 3 4 6 2 1 8]\n",
            "discarded index [0, 7, 9, 5, 3, 4, 6, 2, 1, 8]\n",
            "10 [0 7 9 5 3 4 6 2 1 8]\n",
            "discarded index [0, 7, 9, 5, 3, 4, 6, 2, 1, 8]\n",
            "10 [0 7 9 5 3 4 6 2 1 8]\n",
            "discarded index [0, 7, 9, 5, 3, 4, 6, 2, 1, 8]\n",
            "10 [0 7 9 5 3 4 6 2 1 8]\n",
            "discarded index [0, 7, 9, 5, 3, 4, 6, 2, 1, 8]\n",
            "10 [0 7 9 5 3 4 6 2 1 8]\n",
            "discarded index [0, 7, 9, 5, 3, 4, 6, 2, 1, 8]\n",
            "10 [0 7 9 5 3 4 6 2 1 8]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 40, bulyan: at fang n_at 10 e 40 | val loss 2.2896 val acc 10.5519 best val_acc 22.219968\n",
            "discarded index [0, 7, 9, 3, 5, 8, 6, 4, 1, 2]\n",
            "10 [0 7 9 3 5 8 6 4 1 2]\n",
            "discarded index [0, 7, 9, 3, 5, 8, 6, 4, 1, 2]\n",
            "10 [0 7 9 3 5 8 6 4 1 2]\n",
            "discarded index [0, 7, 9, 3, 5, 8, 6, 4, 1, 2]\n",
            "10 [0 7 9 3 5 8 6 4 1 2]\n",
            "discarded index [0, 7, 9, 3, 5, 8, 6, 4, 1, 2]\n",
            "10 [0 7 9 3 5 8 6 4 1 2]\n",
            "discarded index [0, 7, 9, 3, 5, 8, 6, 4, 1, 2]\n",
            "10 [0 7 9 3 5 8 6 4 1 2]\n",
            "discarded index [0, 7, 9, 3, 5, 8, 6, 4, 1, 2]\n",
            "10 [0 7 9 3 5 8 6 4 1 2]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 41, bulyan: at fang n_at 10 e 41 | val loss 2.2833 val acc 11.5260 best val_acc 22.219968\n",
            "discarded index [0, 7, 9, 4, 2, 6, 8, 1, 3, 5]\n",
            "10 [0 7 9 4 2 6 8 1 3 5]\n",
            "discarded index [0, 7, 9, 4, 2, 6, 8, 1, 3, 5]\n",
            "10 [0 7 9 4 2 6 8 1 3 5]\n",
            "discarded index [0, 7, 9, 4, 2, 6, 8, 1, 3, 5]\n",
            "10 [0 7 9 4 2 6 8 1 3 5]\n",
            "discarded index [0, 7, 9, 4, 2, 6, 8, 1, 3, 5]\n",
            "10 [0 7 9 4 2 6 8 1 3 5]\n",
            "discarded index [0, 7, 9, 4, 2, 6, 8, 1, 3, 5]\n",
            "10 [0 7 9 4 2 6 8 1 3 5]\n",
            "discarded index [0, 7, 9, 4, 2, 6, 8, 1, 3, 5]\n",
            "10 [0 7 9 4 2 6 8 1 3 5]\n",
            "discarded index [0, 7, 9, 4, 2, 6, 8, 1, 3, 5]\n",
            "10 [0 7 9 4 2 6 8 1 3 5]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 42, bulyan: at fang n_at 10 e 42 | val loss 2.2747 val acc 11.7492 best val_acc 22.219968\n",
            "discarded index [0, 7, 9, 5, 4, 1, 2, 8, 3, 6]\n",
            "10 [0 7 9 5 4 1 2 8 3 6]\n",
            "discarded index [0, 7, 9, 5, 4, 1, 2, 8, 3, 6]\n",
            "10 [0 7 9 5 4 1 2 8 3 6]\n",
            "discarded index [0, 7, 9, 5, 4, 1, 2, 8, 3, 6]\n",
            "10 [0 7 9 5 4 1 2 8 3 6]\n",
            "discarded index [0, 7, 9, 5, 4, 1, 2, 8, 3, 6]\n",
            "10 [0 7 9 5 4 1 2 8 3 6]\n",
            "discarded index [0, 7, 9, 5, 4, 1, 2, 8, 3, 6]\n",
            "10 [0 7 9 5 4 1 2 8 3 6]\n",
            "discarded index [0, 7, 9, 5, 4, 1, 2, 8, 3, 6]\n",
            "10 [0 7 9 5 4 1 2 8 3 6]\n",
            "discarded index [0, 7, 9, 5, 4, 1, 2, 8, 3, 6]\n",
            "10 [0 7 9 5 4 1 2 8 3 6]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 43, bulyan: at fang n_at 10 e 43 | val loss 2.2645 val acc 11.4651 best val_acc 22.219968\n",
            "discarded index [0, 7, 9, 5, 3, 1, 4, 6, 8, 2]\n",
            "10 [0 7 9 5 3 1 4 6 8 2]\n",
            "discarded index [0, 7, 9, 5, 3, 1, 4, 6, 8, 2]\n",
            "10 [0 7 9 5 3 1 4 6 8 2]\n",
            "discarded index [0, 7, 9, 5, 3, 1, 4, 6, 8, 2]\n",
            "10 [0 7 9 5 3 1 4 6 8 2]\n",
            "discarded index [0, 7, 9, 5, 3, 1, 4, 6, 8, 2]\n",
            "10 [0 7 9 5 3 1 4 6 8 2]\n",
            "discarded index [0, 7, 9, 5, 3, 1, 4, 6, 8, 2]\n",
            "10 [0 7 9 5 3 1 4 6 8 2]\n",
            "discarded index [0, 7, 9, 5, 3, 1, 4, 6, 8, 2]\n",
            "10 [0 7 9 5 3 1 4 6 8 2]\n",
            "discarded index [0, 7, 9, 5, 3, 1, 4, 6, 8, 2]\n",
            "10 [0 7 9 5 3 1 4 6 8 2]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 44, bulyan: at fang n_at 10 e 44 | val loss 2.2522 val acc 11.1201 best val_acc 22.219968\n",
            "discarded index [0, 7, 9, 4, 2, 6, 1, 8, 3, 5]\n",
            "10 [0 7 9 4 2 6 1 8 3 5]\n",
            "discarded index [0, 7, 9, 4, 2, 6, 1, 8, 3, 5]\n",
            "10 [0 7 9 4 2 6 1 8 3 5]\n",
            "discarded index [0, 7, 9, 4, 2, 6, 1, 8, 3, 5]\n",
            "10 [0 7 9 4 2 6 1 8 3 5]\n",
            "discarded index [0, 7, 9, 4, 2, 6, 1, 8, 3, 5]\n",
            "10 [0 7 9 4 2 6 1 8 3 5]\n",
            "discarded index [0, 7, 9, 4, 2, 6, 1, 8, 3, 5]\n",
            "10 [0 7 9 4 2 6 1 8 3 5]\n",
            "discarded index [0, 7, 9, 4, 2, 6, 1, 8, 3, 5]\n",
            "10 [0 7 9 4 2 6 1 8 3 5]\n",
            "discarded index [0, 7, 9, 4, 2, 6, 1, 8, 3, 5]\n",
            "10 [0 7 9 4 2 6 1 8 3 5]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 45, bulyan: at fang n_at 10 e 45 | val loss 2.2385 val acc 11.0593 best val_acc 22.219968\n",
            "discarded index [0, 7, 9, 8, 6, 5, 3, 2, 4, 1]\n",
            "10 [0 7 9 8 6 5 3 2 4 1]\n",
            "discarded index [0, 7, 9, 8, 6, 5, 3, 2, 4, 1]\n",
            "10 [0 7 9 8 6 5 3 2 4 1]\n",
            "discarded index [0, 7, 9, 8, 6, 5, 3, 2, 4, 1]\n",
            "10 [0 7 9 8 6 5 3 2 4 1]\n",
            "discarded index [0, 7, 9, 8, 6, 5, 3, 2, 4, 1]\n",
            "10 [0 7 9 8 6 5 3 2 4 1]\n",
            "discarded index [0, 7, 9, 8, 6, 5, 3, 2, 4, 1]\n",
            "10 [0 7 9 8 6 5 3 2 4 1]\n",
            "discarded index [0, 7, 9, 8, 6, 5, 3, 2, 4, 1]\n",
            "10 [0 7 9 8 6 5 3 2 4 1]\n",
            "discarded index [0, 7, 9, 8, 6, 5, 3, 2, 4, 1]\n",
            "10 [0 7 9 8 6 5 3 2 4 1]\n",
            "discarded index [0, 7, 9, 8, 6, 5, 3, 2, 4, 1]\n",
            "10 [0 7 9 8 6 5 3 2 4 1]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 46, bulyan: at fang n_at 10 e 46 | val loss 2.2256 val acc 12.2971 best val_acc 22.219968\n",
            "discarded index [0, 7, 1, 9, 2, 4, 3, 8, 6, 5]\n",
            "10 [0 7 1 9 2 4 3 8 6 5]\n",
            "discarded index [0, 7, 1, 9, 2, 4, 3, 8, 6, 5]\n",
            "10 [0 7 1 9 2 4 3 8 6 5]\n",
            "discarded index [0, 7, 1, 9, 2, 4, 3, 8, 6, 5]\n",
            "10 [0 7 1 9 2 4 3 8 6 5]\n",
            "discarded index [0, 7, 1, 9, 2, 4, 3, 8, 6, 5]\n",
            "10 [0 7 1 9 2 4 3 8 6 5]\n",
            "discarded index [0, 7, 1, 9, 2, 4, 3, 8, 6, 5]\n",
            "10 [0 7 1 9 2 4 3 8 6 5]\n",
            "discarded index [0, 7, 1, 9, 2, 4, 3, 8, 6, 5]\n",
            "10 [0 7 1 9 2 4 3 8 6 5]\n",
            "discarded index [0, 7, 1, 9, 2, 4, 3, 8, 6, 5]\n",
            "10 [0 7 1 9 2 4 3 8 6 5]\n",
            "discarded index [0, 7, 1, 9, 2, 4, 3, 8, 6, 5]\n",
            "10 [0 7 1 9 2 4 3 8 6 5]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 47, bulyan: at fang n_at 10 e 47 | val loss 2.2125 val acc 16.3961 best val_acc 22.219968\n",
            "discarded index [9, 0, 7, 1, 2, 3, 4, 6, 8, 5]\n",
            "10 [9 0 7 1 2 3 4 6 8 5]\n",
            "discarded index [9, 0, 7, 1, 2, 3, 4, 6, 8, 5]\n",
            "10 [9 0 7 1 2 3 4 6 8 5]\n",
            "discarded index [9, 0, 7, 1, 2, 3, 4, 6, 8, 5]\n",
            "10 [9 0 7 1 2 3 4 6 8 5]\n",
            "discarded index [9, 0, 7, 1, 2, 3, 4, 6, 8, 5]\n",
            "10 [9 0 7 1 2 3 4 6 8 5]\n",
            "discarded index [9, 0, 7, 1, 2, 3, 4, 6, 8, 5]\n",
            "10 [9 0 7 1 2 3 4 6 8 5]\n",
            "discarded index [9, 0, 7, 1, 2, 3, 4, 6, 8, 5]\n",
            "10 [9 0 7 1 2 3 4 6 8 5]\n",
            "discarded index [9, 0, 7, 1, 2, 3, 4, 6, 8, 5]\n",
            "10 [9 0 7 1 2 3 4 6 8 5]\n",
            "discarded index [9, 0, 7, 1, 2, 3, 4, 6, 8, 5]\n",
            "10 [9 0 7 1 2 3 4 6 8 5]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 48, bulyan: at fang n_at 10 e 48 | val loss 2.1968 val acc 20.2313 best val_acc 22.219968\n",
            "discarded index [0, 7, 1, 2, 9, 8, 6, 3, 5, 4]\n",
            "10 [0 7 1 2 9 8 6 3 5 4]\n",
            "discarded index [0, 7, 1, 2, 9, 8, 6, 3, 5, 4]\n",
            "10 [0 7 1 2 9 8 6 3 5 4]\n",
            "discarded index [0, 7, 1, 2, 9, 8, 6, 3, 5, 4]\n",
            "10 [0 7 1 2 9 8 6 3 5 4]\n",
            "discarded index [0, 7, 1, 2, 9, 8, 6, 3, 5, 4]\n",
            "10 [0 7 1 2 9 8 6 3 5 4]\n",
            "discarded index [0, 7, 1, 2, 9, 8, 6, 3, 5, 4]\n",
            "10 [0 7 1 2 9 8 6 3 5 4]\n",
            "discarded index [0, 7, 1, 2, 9, 8, 6, 3, 5, 4]\n",
            "10 [0 7 1 2 9 8 6 3 5 4]\n",
            "discarded index [0, 7, 1, 2, 9, 8, 6, 3, 5, 4]\n",
            "10 [0 7 1 2 9 8 6 3 5 4]\n",
            "discarded index [0, 7, 1, 2, 9, 8, 6, 3, 5, 4]\n",
            "10 [0 7 1 2 9 8 6 3 5 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 49, bulyan: at fang n_at 10 e 49 | val loss 2.1788 val acc 21.2054 best val_acc 22.219968\n",
            "discarded index [0, 7, 1, 6, 9, 8, 2, 5, 4, 3]\n",
            "10 [0 7 1 6 9 8 2 5 4 3]\n",
            "discarded index [0, 7, 1, 6, 9, 8, 2, 5, 4, 3]\n",
            "10 [0 7 1 6 9 8 2 5 4 3]\n",
            "discarded index [0, 7, 1, 6, 9, 8, 2, 5, 4, 3]\n",
            "10 [0 7 1 6 9 8 2 5 4 3]\n",
            "discarded index [0, 7, 1, 6, 9, 8, 2, 5, 4, 3]\n",
            "10 [0 7 1 6 9 8 2 5 4 3]\n",
            "discarded index [0, 7, 1, 6, 9, 8, 2, 5, 4, 3]\n",
            "10 [0 7 1 6 9 8 2 5 4 3]\n",
            "discarded index [0, 7, 1, 6, 9, 8, 2, 5, 4, 3]\n",
            "10 [0 7 1 6 9 8 2 5 4 3]\n",
            "discarded index [0, 7, 1, 6, 9, 8, 2, 5, 4, 3]\n",
            "10 [0 7 1 6 9 8 2 5 4 3]\n",
            "discarded index [0, 7, 1, 6, 9, 8, 2, 5, 4, 3]\n",
            "10 [0 7 1 6 9 8 2 5 4 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 50, bulyan: at fang n_at 10 e 50 | val loss 2.1603 val acc 23.5998 best val_acc 23.599838\n",
            "discarded index [1, 7, 0, 2, 5, 3, 8, 6, 9, 4]\n",
            "10 [1 7 0 2 5 3 8 6 9 4]\n",
            "discarded index [1, 7, 0, 2, 5, 3, 8, 6, 9, 4]\n",
            "10 [1 7 0 2 5 3 8 6 9 4]\n",
            "discarded index [1, 7, 0, 2, 5, 3, 8, 6, 9, 4]\n",
            "10 [1 7 0 2 5 3 8 6 9 4]\n",
            "discarded index [1, 7, 0, 2, 5, 3, 8, 6, 9, 4]\n",
            "10 [1 7 0 2 5 3 8 6 9 4]\n",
            "discarded index [1, 7, 0, 2, 5, 3, 8, 6, 9, 4]\n",
            "10 [1 7 0 2 5 3 8 6 9 4]\n",
            "discarded index [1, 7, 0, 2, 5, 3, 8, 6, 9, 4]\n",
            "10 [1 7 0 2 5 3 8 6 9 4]\n",
            "discarded index [1, 7, 0, 2, 5, 3, 8, 6, 9, 4]\n",
            "10 [1 7 0 2 5 3 8 6 9 4]\n",
            "discarded index [1, 7, 0, 2, 5, 3, 8, 6, 9, 4]\n",
            "10 [1 7 0 2 5 3 8 6 9 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 51, bulyan: at fang n_at 10 e 51 | val loss 2.1370 val acc 21.1648 best val_acc 23.599838\n",
            "discarded index [9, 6, 4, 0, 8, 1, 7, 2, 3, 5]\n",
            "10 [9 6 4 0 8 1 7 2 3 5]\n",
            "discarded index [9, 6, 4, 0, 8, 1, 7, 2, 3, 5]\n",
            "10 [9 6 4 0 8 1 7 2 3 5]\n",
            "discarded index [9, 6, 4, 0, 8, 1, 7, 2, 3, 5]\n",
            "10 [9 6 4 0 8 1 7 2 3 5]\n",
            "discarded index [9, 6, 4, 0, 8, 1, 7, 2, 3, 5]\n",
            "10 [9 6 4 0 8 1 7 2 3 5]\n",
            "discarded index [9, 6, 4, 0, 8, 1, 7, 2, 3, 5]\n",
            "10 [9 6 4 0 8 1 7 2 3 5]\n",
            "discarded index [9, 6, 4, 0, 8, 1, 7, 2, 3, 5]\n",
            "10 [9 6 4 0 8 1 7 2 3 5]\n",
            "discarded index [9, 6, 4, 0, 8, 1, 7, 2, 3, 5]\n",
            "10 [9 6 4 0 8 1 7 2 3 5]\n",
            "discarded index [9, 6, 4, 0, 8, 1, 7, 2, 3, 5]\n",
            "10 [9 6 4 0 8 1 7 2 3 5]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 52, bulyan: at fang n_at 10 e 52 | val loss 2.1739 val acc 17.6339 best val_acc 23.599838\n",
            "discarded index [1, 6, 0, 8, 4, 3, 5, 9, 2, 7]\n",
            "10 [1 6 0 8 4 3 5 9 2 7]\n",
            "discarded index [1, 6, 0, 8, 4, 3, 5, 9, 2, 7]\n",
            "10 [1 6 0 8 4 3 5 9 2 7]\n",
            "discarded index [1, 6, 0, 8, 4, 3, 5, 9, 2, 7]\n",
            "10 [1 6 0 8 4 3 5 9 2 7]\n",
            "discarded index [1, 6, 0, 8, 4, 3, 5, 9, 2, 7]\n",
            "10 [1 6 0 8 4 3 5 9 2 7]\n",
            "discarded index [1, 6, 0, 8, 4, 3, 5, 9, 2, 7]\n",
            "10 [1 6 0 8 4 3 5 9 2 7]\n",
            "discarded index [1, 6, 0, 8, 4, 3, 5, 9, 2, 7]\n",
            "10 [1 6 0 8 4 3 5 9 2 7]\n",
            "discarded index [1, 6, 0, 8, 4, 3, 5, 9, 2, 7]\n",
            "10 [1 6 0 8 4 3 5 9 2 7]\n",
            "discarded index [1, 6, 0, 8, 4, 3, 5, 9, 2, 7]\n",
            "10 [1 6 0 8 4 3 5 9 2 7]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 53, bulyan: at fang n_at 10 e 53 | val loss 2.1499 val acc 17.7557 best val_acc 23.599838\n",
            "discarded index [0, 1, 9, 6, 8, 4, 3, 7, 5, 2]\n",
            "10 [0 1 9 6 8 4 3 7 5 2]\n",
            "discarded index [0, 1, 9, 6, 8, 4, 3, 7, 5, 2]\n",
            "10 [0 1 9 6 8 4 3 7 5 2]\n",
            "discarded index [0, 1, 9, 6, 8, 4, 3, 7, 5, 2]\n",
            "10 [0 1 9 6 8 4 3 7 5 2]\n",
            "discarded index [0, 1, 9, 6, 8, 4, 3, 7, 5, 2]\n",
            "10 [0 1 9 6 8 4 3 7 5 2]\n",
            "discarded index [0, 1, 9, 6, 8, 4, 3, 7, 5, 2]\n",
            "10 [0 1 9 6 8 4 3 7 5 2]\n",
            "discarded index [0, 1, 9, 6, 8, 4, 3, 7, 5, 2]\n",
            "10 [0 1 9 6 8 4 3 7 5 2]\n",
            "discarded index [0, 1, 9, 6, 8, 4, 3, 7, 5, 2]\n",
            "10 [0 1 9 6 8 4 3 7 5 2]\n",
            "discarded index [0, 1, 9, 6, 8, 4, 3, 7, 5, 2]\n",
            "10 [0 1 9 6 8 4 3 7 5 2]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 54, bulyan: at fang n_at 10 e 54 | val loss 2.1304 val acc 19.0544 best val_acc 23.599838\n",
            "discarded index [6, 5, 1, 3, 2, 9, 0, 7, 4, 8]\n",
            "10 [6 5 1 3 2 9 0 7 4 8]\n",
            "discarded index [6, 5, 1, 3, 2, 9, 0, 7, 4, 8]\n",
            "10 [6 5 1 3 2 9 0 7 4 8]\n",
            "discarded index [6, 5, 1, 3, 2, 9, 0, 7, 4, 8]\n",
            "10 [6 5 1 3 2 9 0 7 4 8]\n",
            "discarded index [6, 5, 1, 3, 2, 9, 0, 7, 4, 8]\n",
            "10 [6 5 1 3 2 9 0 7 4 8]\n",
            "discarded index [6, 5, 1, 3, 2, 9, 0, 7, 4, 8]\n",
            "10 [6 5 1 3 2 9 0 7 4 8]\n",
            "discarded index [6, 5, 1, 3, 2, 9, 0, 7, 4, 8]\n",
            "10 [6 5 1 3 2 9 0 7 4 8]\n",
            "discarded index [6, 5, 1, 3, 2, 9, 0, 7, 4, 8]\n",
            "10 [6 5 1 3 2 9 0 7 4 8]\n",
            "discarded index [6, 5, 1, 3, 2, 9, 0, 7, 4, 8]\n",
            "10 [6 5 1 3 2 9 0 7 4 8]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 55, bulyan: at fang n_at 10 e 55 | val loss 2.0664 val acc 22.9505 best val_acc 23.599838\n",
            "discarded index [9, 6, 8, 3, 1, 7, 5, 2, 0, 4]\n",
            "10 [9 6 8 3 1 7 5 2 0 4]\n",
            "discarded index [9, 6, 8, 3, 1, 7, 5, 2, 0, 4]\n",
            "10 [9 6 8 3 1 7 5 2 0 4]\n",
            "discarded index [9, 6, 8, 3, 1, 7, 5, 2, 0, 4]\n",
            "10 [9 6 8 3 1 7 5 2 0 4]\n",
            "discarded index [9, 6, 8, 3, 1, 7, 5, 2, 0, 4]\n",
            "10 [9 6 8 3 1 7 5 2 0 4]\n",
            "discarded index [9, 6, 8, 3, 1, 7, 5, 2, 0, 4]\n",
            "10 [9 6 8 3 1 7 5 2 0 4]\n",
            "discarded index [9, 6, 8, 3, 1, 7, 5, 2, 0, 4]\n",
            "10 [9 6 8 3 1 7 5 2 0 4]\n",
            "discarded index [9, 6, 8, 3, 1, 7, 5, 2, 0, 4]\n",
            "10 [9 6 8 3 1 7 5 2 0 4]\n",
            "discarded index [9, 6, 8, 3, 1, 7, 5, 2, 0, 4]\n",
            "10 [9 6 8 3 1 7 5 2 0 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 56, bulyan: at fang n_at 10 e 56 | val loss 2.0684 val acc 22.2403 best val_acc 23.599838\n",
            "discarded index [5, 7, 2, 4, 6, 9, 1, 3, 8, 0]\n",
            "10 [5 7 2 4 6 9 1 3 8 0]\n",
            "discarded index [5, 7, 2, 4, 6, 9, 1, 3, 8, 0]\n",
            "10 [5 7 2 4 6 9 1 3 8 0]\n",
            "discarded index [5, 7, 2, 4, 6, 9, 1, 3, 8, 0]\n",
            "10 [5 7 2 4 6 9 1 3 8 0]\n",
            "discarded index [5, 7, 2, 4, 6, 9, 1, 3, 8, 0]\n",
            "10 [5 7 2 4 6 9 1 3 8 0]\n",
            "discarded index [5, 7, 2, 4, 6, 9, 1, 3, 8, 0]\n",
            "10 [5 7 2 4 6 9 1 3 8 0]\n",
            "discarded index [5, 7, 2, 4, 6, 9, 1, 3, 8, 0]\n",
            "10 [5 7 2 4 6 9 1 3 8 0]\n",
            "discarded index [5, 7, 2, 4, 6, 9, 1, 3, 8, 0]\n",
            "10 [5 7 2 4 6 9 1 3 8 0]\n",
            "discarded index [5, 7, 2, 4, 6, 9, 1, 3, 8, 0]\n",
            "10 [5 7 2 4 6 9 1 3 8 0]\n",
            "discarded index [5, 7, 2, 4, 6, 9, 1, 3, 8, 0]\n",
            "10 [5 7 2 4 6 9 1 3 8 0]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 57, bulyan: at fang n_at 10 e 57 | val loss 2.1865 val acc 16.4570 best val_acc 23.599838\n",
            "discarded index [7, 9, 5, 0, 4, 8, 3, 1, 6, 2]\n",
            "10 [7 9 5 0 4 8 3 1 6 2]\n",
            "discarded index [7, 9, 5, 0, 4, 8, 3, 1, 6, 2]\n",
            "10 [7 9 5 0 4 8 3 1 6 2]\n",
            "discarded index [7, 9, 5, 0, 4, 8, 3, 1, 6, 2]\n",
            "10 [7 9 5 0 4 8 3 1 6 2]\n",
            "discarded index [7, 9, 5, 0, 4, 8, 3, 1, 6, 2]\n",
            "10 [7 9 5 0 4 8 3 1 6 2]\n",
            "discarded index [7, 9, 5, 0, 4, 8, 3, 1, 6, 2]\n",
            "10 [7 9 5 0 4 8 3 1 6 2]\n",
            "discarded index [7, 9, 5, 0, 4, 8, 3, 1, 6, 2]\n",
            "10 [7 9 5 0 4 8 3 1 6 2]\n",
            "discarded index [7, 9, 5, 0, 4, 8, 3, 1, 6, 2]\n",
            "10 [7 9 5 0 4 8 3 1 6 2]\n",
            "discarded index [7, 9, 5, 0, 4, 8, 3, 1, 6, 2]\n",
            "10 [7 9 5 0 4 8 3 1 6 2]\n",
            "discarded index [7, 9, 5, 0, 4, 8, 3, 1, 6, 2]\n",
            "10 [7 9 5 0 4 8 3 1 6 2]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 58, bulyan: at fang n_at 10 e 58 | val loss 2.1840 val acc 15.2597 best val_acc 23.599838\n",
            "discarded index [9, 5, 1, 0, 2, 4, 6, 7, 8, 3]\n",
            "10 [9 5 1 0 2 4 6 7 8 3]\n",
            "discarded index [9, 5, 1, 0, 2, 4, 6, 7, 8, 3]\n",
            "10 [9 5 1 0 2 4 6 7 8 3]\n",
            "discarded index [9, 5, 1, 0, 2, 4, 6, 7, 8, 3]\n",
            "10 [9 5 1 0 2 4 6 7 8 3]\n",
            "discarded index [9, 5, 1, 0, 2, 4, 6, 7, 8, 3]\n",
            "10 [9 5 1 0 2 4 6 7 8 3]\n",
            "discarded index [9, 5, 1, 0, 2, 4, 6, 7, 8, 3]\n",
            "10 [9 5 1 0 2 4 6 7 8 3]\n",
            "discarded index [9, 5, 1, 0, 2, 4, 6, 7, 8, 3]\n",
            "10 [9 5 1 0 2 4 6 7 8 3]\n",
            "discarded index [9, 5, 1, 0, 2, 4, 6, 7, 8, 3]\n",
            "10 [9 5 1 0 2 4 6 7 8 3]\n",
            "discarded index [9, 5, 1, 0, 2, 4, 6, 7, 8, 3]\n",
            "10 [9 5 1 0 2 4 6 7 8 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 59, bulyan: at fang n_at 10 e 59 | val loss 2.1172 val acc 19.7849 best val_acc 23.599838\n",
            "discarded index [4, 7, 1, 9, 8, 2, 5, 0, 6, 3]\n",
            "10 [4 7 1 9 8 2 5 0 6 3]\n",
            "discarded index [4, 7, 1, 9, 8, 2, 5, 0, 6, 3]\n",
            "10 [4 7 1 9 8 2 5 0 6 3]\n",
            "discarded index [4, 7, 1, 9, 8, 2, 5, 0, 6, 3]\n",
            "10 [4 7 1 9 8 2 5 0 6 3]\n",
            "discarded index [4, 7, 1, 9, 8, 2, 5, 0, 6, 3]\n",
            "10 [4 7 1 9 8 2 5 0 6 3]\n",
            "discarded index [4, 7, 1, 9, 8, 2, 5, 0, 6, 3]\n",
            "10 [4 7 1 9 8 2 5 0 6 3]\n",
            "discarded index [4, 7, 1, 9, 8, 2, 5, 0, 6, 3]\n",
            "10 [4 7 1 9 8 2 5 0 6 3]\n",
            "discarded index [4, 7, 1, 9, 8, 2, 5, 0, 6, 3]\n",
            "10 [4 7 1 9 8 2 5 0 6 3]\n",
            "discarded index [4, 7, 1, 9, 8, 2, 5, 0, 6, 3]\n",
            "10 [4 7 1 9 8 2 5 0 6 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 60, bulyan: at fang n_at 10 e 60 | val loss 2.0595 val acc 22.7679 best val_acc 23.599838\n",
            "discarded index [6, 8, 1, 5, 2, 3, 0, 9, 7, 4]\n",
            "10 [6 8 1 5 2 3 0 9 7 4]\n",
            "discarded index [6, 8, 1, 5, 2, 3, 0, 9, 7, 4]\n",
            "10 [6 8 1 5 2 3 0 9 7 4]\n",
            "discarded index [6, 8, 1, 5, 2, 3, 0, 9, 7, 4]\n",
            "10 [6 8 1 5 2 3 0 9 7 4]\n",
            "discarded index [6, 8, 1, 5, 2, 3, 0, 9, 7, 4]\n",
            "10 [6 8 1 5 2 3 0 9 7 4]\n",
            "discarded index [6, 8, 1, 5, 2, 3, 0, 9, 7, 4]\n",
            "10 [6 8 1 5 2 3 0 9 7 4]\n",
            "discarded index [6, 8, 1, 5, 2, 3, 0, 9, 7, 4]\n",
            "10 [6 8 1 5 2 3 0 9 7 4]\n",
            "discarded index [6, 8, 1, 5, 2, 3, 0, 9, 7, 4]\n",
            "10 [6 8 1 5 2 3 0 9 7 4]\n",
            "discarded index [6, 8, 1, 5, 2, 3, 0, 9, 7, 4]\n",
            "10 [6 8 1 5 2 3 0 9 7 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 61, bulyan: at fang n_at 10 e 61 | val loss 2.0391 val acc 23.4375 best val_acc 23.599838\n",
            "discarded index [5, 6, 1, 2, 8, 4, 0, 7, 3, 9]\n",
            "10 [5 6 1 2 8 4 0 7 3 9]\n",
            "discarded index [5, 6, 1, 2, 8, 4, 0, 7, 3, 9]\n",
            "10 [5 6 1 2 8 4 0 7 3 9]\n",
            "discarded index [5, 6, 1, 2, 8, 4, 0, 7, 3, 9]\n",
            "10 [5 6 1 2 8 4 0 7 3 9]\n",
            "discarded index [5, 6, 1, 2, 8, 4, 0, 7, 3, 9]\n",
            "10 [5 6 1 2 8 4 0 7 3 9]\n",
            "discarded index [5, 6, 1, 2, 8, 4, 0, 7, 3, 9]\n",
            "10 [5 6 1 2 8 4 0 7 3 9]\n",
            "discarded index [5, 6, 1, 2, 8, 4, 0, 7, 3, 9]\n",
            "10 [5 6 1 2 8 4 0 7 3 9]\n",
            "discarded index [5, 6, 1, 2, 8, 4, 0, 7, 3, 9]\n",
            "10 [5 6 1 2 8 4 0 7 3 9]\n",
            "discarded index [5, 6, 1, 2, 8, 4, 0, 7, 3, 9]\n",
            "10 [5 6 1 2 8 4 0 7 3 9]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 62, bulyan: at fang n_at 10 e 62 | val loss 2.0465 val acc 22.9099 best val_acc 23.599838\n",
            "discarded index [8, 9, 0, 7, 5, 4, 6, 1, 2, 3]\n",
            "10 [8 9 0 7 5 4 6 1 2 3]\n",
            "discarded index [8, 9, 0, 7, 5, 4, 6, 1, 2, 3]\n",
            "10 [8 9 0 7 5 4 6 1 2 3]\n",
            "discarded index [8, 9, 0, 7, 5, 4, 6, 1, 2, 3]\n",
            "10 [8 9 0 7 5 4 6 1 2 3]\n",
            "discarded index [8, 9, 0, 7, 5, 4, 6, 1, 2, 3]\n",
            "10 [8 9 0 7 5 4 6 1 2 3]\n",
            "discarded index [8, 9, 0, 7, 5, 4, 6, 1, 2, 3]\n",
            "10 [8 9 0 7 5 4 6 1 2 3]\n",
            "discarded index [8, 9, 0, 7, 5, 4, 6, 1, 2, 3]\n",
            "10 [8 9 0 7 5 4 6 1 2 3]\n",
            "discarded index [8, 9, 0, 7, 5, 4, 6, 1, 2, 3]\n",
            "10 [8 9 0 7 5 4 6 1 2 3]\n",
            "discarded index [8, 9, 0, 7, 5, 4, 6, 1, 2, 3]\n",
            "10 [8 9 0 7 5 4 6 1 2 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 63, bulyan: at fang n_at 10 e 63 | val loss 2.1384 val acc 20.1705 best val_acc 23.599838\n",
            "discarded index [6, 1, 9, 0, 7, 8, 5, 2, 3, 4]\n",
            "10 [6 1 9 0 7 8 5 2 3 4]\n",
            "discarded index [6, 1, 9, 0, 7, 8, 5, 2, 3, 4]\n",
            "10 [6 1 9 0 7 8 5 2 3 4]\n",
            "discarded index [6, 1, 9, 0, 7, 8, 5, 2, 3, 4]\n",
            "10 [6 1 9 0 7 8 5 2 3 4]\n",
            "discarded index [6, 1, 9, 0, 7, 8, 5, 2, 3, 4]\n",
            "10 [6 1 9 0 7 8 5 2 3 4]\n",
            "discarded index [6, 1, 9, 0, 7, 8, 5, 2, 3, 4]\n",
            "10 [6 1 9 0 7 8 5 2 3 4]\n",
            "discarded index [6, 1, 9, 0, 7, 8, 5, 2, 3, 4]\n",
            "10 [6 1 9 0 7 8 5 2 3 4]\n",
            "discarded index [6, 1, 9, 0, 7, 8, 5, 2, 3, 4]\n",
            "10 [6 1 9 0 7 8 5 2 3 4]\n",
            "discarded index [6, 1, 9, 0, 7, 8, 5, 2, 3, 4]\n",
            "10 [6 1 9 0 7 8 5 2 3 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 64, bulyan: at fang n_at 10 e 64 | val loss 2.0606 val acc 21.9765 best val_acc 23.599838\n",
            "discarded index [5, 6, 4, 1, 3, 7, 2, 0, 9, 8]\n",
            "10 [5 6 4 1 3 7 2 0 9 8]\n",
            "discarded index [5, 6, 4, 1, 3, 7, 2, 0, 9, 8]\n",
            "10 [5 6 4 1 3 7 2 0 9 8]\n",
            "discarded index [5, 6, 4, 1, 3, 7, 2, 0, 9, 8]\n",
            "10 [5 6 4 1 3 7 2 0 9 8]\n",
            "discarded index [5, 6, 4, 1, 3, 7, 2, 0, 9, 8]\n",
            "10 [5 6 4 1 3 7 2 0 9 8]\n",
            "discarded index [5, 6, 4, 1, 3, 7, 2, 0, 9, 8]\n",
            "10 [5 6 4 1 3 7 2 0 9 8]\n",
            "discarded index [5, 6, 4, 1, 3, 7, 2, 0, 9, 8]\n",
            "10 [5 6 4 1 3 7 2 0 9 8]\n",
            "discarded index [5, 6, 4, 1, 3, 7, 2, 0, 9, 8]\n",
            "10 [5 6 4 1 3 7 2 0 9 8]\n",
            "discarded index [5, 6, 4, 1, 3, 7, 2, 0, 9, 8]\n",
            "10 [5 6 4 1 3 7 2 0 9 8]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 65, bulyan: at fang n_at 10 e 65 | val loss 2.0126 val acc 24.3304 best val_acc 24.330357\n",
            "discarded index [8, 5, 2, 7, 3, 4, 9, 0, 6, 1]\n",
            "10 [8 5 2 7 3 4 9 0 6 1]\n",
            "discarded index [8, 5, 2, 7, 3, 4, 9, 0, 6, 1]\n",
            "10 [8 5 2 7 3 4 9 0 6 1]\n",
            "discarded index [8, 5, 2, 7, 3, 4, 9, 0, 6, 1]\n",
            "10 [8 5 2 7 3 4 9 0 6 1]\n",
            "discarded index [8, 5, 2, 7, 3, 4, 9, 0, 6, 1]\n",
            "10 [8 5 2 7 3 4 9 0 6 1]\n",
            "discarded index [8, 5, 2, 7, 3, 4, 9, 0, 6, 1]\n",
            "10 [8 5 2 7 3 4 9 0 6 1]\n",
            "discarded index [8, 5, 2, 7, 3, 4, 9, 0, 6, 1]\n",
            "10 [8 5 2 7 3 4 9 0 6 1]\n",
            "discarded index [8, 5, 2, 7, 3, 4, 9, 0, 6, 1]\n",
            "10 [8 5 2 7 3 4 9 0 6 1]\n",
            "discarded index [8, 5, 2, 7, 3, 4, 9, 0, 6, 1]\n",
            "10 [8 5 2 7 3 4 9 0 6 1]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 66, bulyan: at fang n_at 10 e 66 | val loss 2.0107 val acc 22.4635 best val_acc 24.330357\n",
            "discarded index [6, 5, 1, 4, 8, 9, 2, 7, 0, 3]\n",
            "10 [6 5 1 4 8 9 2 7 0 3]\n",
            "discarded index [6, 5, 1, 4, 8, 9, 2, 7, 0, 3]\n",
            "10 [6 5 1 4 8 9 2 7 0 3]\n",
            "discarded index [6, 5, 1, 4, 8, 9, 2, 7, 0, 3]\n",
            "10 [6 5 1 4 8 9 2 7 0 3]\n",
            "discarded index [6, 5, 1, 4, 8, 9, 2, 7, 0, 3]\n",
            "10 [6 5 1 4 8 9 2 7 0 3]\n",
            "discarded index [6, 5, 1, 4, 8, 9, 2, 7, 0, 3]\n",
            "10 [6 5 1 4 8 9 2 7 0 3]\n",
            "discarded index [6, 5, 1, 4, 8, 9, 2, 7, 0, 3]\n",
            "10 [6 5 1 4 8 9 2 7 0 3]\n",
            "discarded index [6, 5, 1, 4, 8, 9, 2, 7, 0, 3]\n",
            "10 [6 5 1 4 8 9 2 7 0 3]\n",
            "discarded index [6, 5, 1, 4, 8, 9, 2, 7, 0, 3]\n",
            "10 [6 5 1 4 8 9 2 7 0 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 67, bulyan: at fang n_at 10 e 67 | val loss 2.0276 val acc 24.2289 best val_acc 24.330357\n",
            "discarded index [0, 7, 1, 3, 9, 5, 2, 6, 4, 8]\n",
            "10 [0 7 1 3 9 5 2 6 4 8]\n",
            "discarded index [0, 7, 1, 3, 9, 5, 2, 6, 4, 8]\n",
            "10 [0 7 1 3 9 5 2 6 4 8]\n",
            "discarded index [0, 7, 1, 3, 9, 5, 2, 6, 4, 8]\n",
            "10 [0 7 1 3 9 5 2 6 4 8]\n",
            "discarded index [0, 7, 1, 3, 9, 5, 2, 6, 4, 8]\n",
            "10 [0 7 1 3 9 5 2 6 4 8]\n",
            "discarded index [0, 7, 1, 3, 9, 5, 2, 6, 4, 8]\n",
            "10 [0 7 1 3 9 5 2 6 4 8]\n",
            "discarded index [0, 7, 1, 3, 9, 5, 2, 6, 4, 8]\n",
            "10 [0 7 1 3 9 5 2 6 4 8]\n",
            "discarded index [0, 7, 1, 3, 9, 5, 2, 6, 4, 8]\n",
            "10 [0 7 1 3 9 5 2 6 4 8]\n",
            "discarded index [0, 7, 1, 3, 9, 5, 2, 6, 4, 8]\n",
            "10 [0 7 1 3 9 5 2 6 4 8]\n",
            "discarded index [0, 7, 1, 3, 9, 5, 2, 6, 4, 8]\n",
            "10 [0 7 1 3 9 5 2 6 4 8]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 68, bulyan: at fang n_at 10 e 68 | val loss 2.1983 val acc 18.8920 best val_acc 24.330357\n",
            "discarded index [5, 0, 6, 2, 7, 1, 8, 9, 4, 3]\n",
            "10 [5 0 6 2 7 1 8 9 4 3]\n",
            "discarded index [5, 0, 6, 2, 7, 1, 8, 9, 4, 3]\n",
            "10 [5 0 6 2 7 1 8 9 4 3]\n",
            "discarded index [5, 0, 6, 2, 7, 1, 8, 9, 4, 3]\n",
            "10 [5 0 6 2 7 1 8 9 4 3]\n",
            "discarded index [5, 0, 6, 2, 7, 1, 8, 9, 4, 3]\n",
            "10 [5 0 6 2 7 1 8 9 4 3]\n",
            "discarded index [5, 0, 6, 2, 7, 1, 8, 9, 4, 3]\n",
            "10 [5 0 6 2 7 1 8 9 4 3]\n",
            "discarded index [5, 0, 6, 2, 7, 1, 8, 9, 4, 3]\n",
            "10 [5 0 6 2 7 1 8 9 4 3]\n",
            "discarded index [5, 0, 6, 2, 7, 1, 8, 9, 4, 3]\n",
            "10 [5 0 6 2 7 1 8 9 4 3]\n",
            "discarded index [5, 0, 6, 2, 7, 1, 8, 9, 4, 3]\n",
            "10 [5 0 6 2 7 1 8 9 4 3]\n",
            "discarded index [5, 0, 6, 2, 7, 1, 8, 9, 4, 3]\n",
            "10 [5 0 6 2 7 1 8 9 4 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 69, bulyan: at fang n_at 10 e 69 | val loss 2.2119 val acc 16.7005 best val_acc 24.330357\n",
            "discarded index [0, 7, 5, 3, 9, 6, 2, 1, 4, 8]\n",
            "10 [0 7 5 3 9 6 2 1 4 8]\n",
            "discarded index [0, 7, 5, 3, 9, 6, 2, 1, 4, 8]\n",
            "10 [0 7 5 3 9 6 2 1 4 8]\n",
            "discarded index [0, 7, 5, 3, 9, 6, 2, 1, 4, 8]\n",
            "10 [0 7 5 3 9 6 2 1 4 8]\n",
            "discarded index [0, 7, 5, 3, 9, 6, 2, 1, 4, 8]\n",
            "10 [0 7 5 3 9 6 2 1 4 8]\n",
            "discarded index [0, 7, 5, 3, 9, 6, 2, 1, 4, 8]\n",
            "10 [0 7 5 3 9 6 2 1 4 8]\n",
            "discarded index [0, 7, 5, 3, 9, 6, 2, 1, 4, 8]\n",
            "10 [0 7 5 3 9 6 2 1 4 8]\n",
            "discarded index [0, 7, 5, 3, 9, 6, 2, 1, 4, 8]\n",
            "10 [0 7 5 3 9 6 2 1 4 8]\n",
            "discarded index [0, 7, 5, 3, 9, 6, 2, 1, 4, 8]\n",
            "10 [0 7 5 3 9 6 2 1 4 8]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 70, bulyan: at fang n_at 10 e 70 | val loss 2.1232 val acc 24.0869 best val_acc 24.330357\n",
            "discarded index [0, 1, 7, 6, 9, 4, 8, 3, 5, 2]\n",
            "10 [0 1 7 6 9 4 8 3 5 2]\n",
            "discarded index [0, 1, 7, 6, 9, 4, 8, 3, 5, 2]\n",
            "10 [0 1 7 6 9 4 8 3 5 2]\n",
            "discarded index [0, 1, 7, 6, 9, 4, 8, 3, 5, 2]\n",
            "10 [0 1 7 6 9 4 8 3 5 2]\n",
            "discarded index [0, 1, 7, 6, 9, 4, 8, 3, 5, 2]\n",
            "10 [0 1 7 6 9 4 8 3 5 2]\n",
            "discarded index [0, 1, 7, 6, 9, 4, 8, 3, 5, 2]\n",
            "10 [0 1 7 6 9 4 8 3 5 2]\n",
            "discarded index [0, 1, 7, 6, 9, 4, 8, 3, 5, 2]\n",
            "10 [0 1 7 6 9 4 8 3 5 2]\n",
            "discarded index [0, 1, 7, 6, 9, 4, 8, 3, 5, 2]\n",
            "10 [0 1 7 6 9 4 8 3 5 2]\n",
            "discarded index [0, 1, 7, 6, 9, 4, 8, 3, 5, 2]\n",
            "10 [0 1 7 6 9 4 8 3 5 2]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 71, bulyan: at fang n_at 10 e 71 | val loss 2.0434 val acc 23.9651 best val_acc 24.330357\n",
            "discarded index [9, 4, 8, 6, 7, 0, 5, 2, 1, 3]\n",
            "10 [9 4 8 6 7 0 5 2 1 3]\n",
            "discarded index [9, 4, 8, 6, 7, 0, 5, 2, 1, 3]\n",
            "10 [9 4 8 6 7 0 5 2 1 3]\n",
            "discarded index [9, 4, 8, 6, 7, 0, 5, 2, 1, 3]\n",
            "10 [9 4 8 6 7 0 5 2 1 3]\n",
            "discarded index [9, 4, 8, 6, 7, 0, 5, 2, 1, 3]\n",
            "10 [9 4 8 6 7 0 5 2 1 3]\n",
            "discarded index [9, 4, 8, 6, 7, 0, 5, 2, 1, 3]\n",
            "10 [9 4 8 6 7 0 5 2 1 3]\n",
            "discarded index [9, 4, 8, 6, 7, 0, 5, 2, 1, 3]\n",
            "10 [9 4 8 6 7 0 5 2 1 3]\n",
            "discarded index [9, 4, 8, 6, 7, 0, 5, 2, 1, 3]\n",
            "10 [9 4 8 6 7 0 5 2 1 3]\n",
            "discarded index [9, 4, 8, 6, 7, 0, 5, 2, 1, 3]\n",
            "10 [9 4 8 6 7 0 5 2 1 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 72, bulyan: at fang n_at 10 e 72 | val loss 1.9960 val acc 24.1071 best val_acc 24.330357\n",
            "discarded index [6, 9, 8, 4, 5, 7, 1, 0, 3, 2]\n",
            "10 [6 9 8 4 5 7 1 0 3 2]\n",
            "discarded index [6, 9, 8, 4, 5, 7, 1, 0, 3, 2]\n",
            "10 [6 9 8 4 5 7 1 0 3 2]\n",
            "discarded index [6, 9, 8, 4, 5, 7, 1, 0, 3, 2]\n",
            "10 [6 9 8 4 5 7 1 0 3 2]\n",
            "discarded index [6, 9, 8, 4, 5, 7, 1, 0, 3, 2]\n",
            "10 [6 9 8 4 5 7 1 0 3 2]\n",
            "discarded index [6, 9, 8, 4, 5, 7, 1, 0, 3, 2]\n",
            "10 [6 9 8 4 5 7 1 0 3 2]\n",
            "discarded index [6, 9, 8, 4, 5, 7, 1, 0, 3, 2]\n",
            "10 [6 9 8 4 5 7 1 0 3 2]\n",
            "discarded index [6, 9, 8, 4, 5, 7, 1, 0, 3, 2]\n",
            "10 [6 9 8 4 5 7 1 0 3 2]\n",
            "discarded index [6, 9, 8, 4, 5, 7, 1, 0, 3, 2]\n",
            "10 [6 9 8 4 5 7 1 0 3 2]\n",
            "discarded index [6, 9, 8, 4, 5, 7, 1, 0, 3, 2]\n",
            "10 [6 9 8 4 5 7 1 0 3 2]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 73, bulyan: at fang n_at 10 e 73 | val loss 1.9844 val acc 25.0812 best val_acc 25.081169\n",
            "discarded index [7, 2, 3, 9, 8, 0, 1, 5, 4, 6]\n",
            "10 [7 2 3 9 8 0 1 5 4 6]\n",
            "discarded index [7, 2, 3, 9, 8, 0, 1, 5, 4, 6]\n",
            "10 [7 2 3 9 8 0 1 5 4 6]\n",
            "discarded index [7, 2, 3, 9, 8, 0, 1, 5, 4, 6]\n",
            "10 [7 2 3 9 8 0 1 5 4 6]\n",
            "discarded index [7, 2, 3, 9, 8, 0, 1, 5, 4, 6]\n",
            "10 [7 2 3 9 8 0 1 5 4 6]\n",
            "discarded index [7, 2, 3, 9, 8, 0, 1, 5, 4, 6]\n",
            "10 [7 2 3 9 8 0 1 5 4 6]\n",
            "discarded index [7, 2, 3, 9, 8, 0, 1, 5, 4, 6]\n",
            "10 [7 2 3 9 8 0 1 5 4 6]\n",
            "discarded index [7, 2, 3, 9, 8, 0, 1, 5, 4, 6]\n",
            "10 [7 2 3 9 8 0 1 5 4 6]\n",
            "discarded index [7, 2, 3, 9, 8, 0, 1, 5, 4, 6]\n",
            "10 [7 2 3 9 8 0 1 5 4 6]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 74, bulyan: at fang n_at 10 e 74 | val loss 2.0035 val acc 23.7825 best val_acc 25.081169\n",
            "discarded index [9, 8, 6, 4, 7, 3, 1, 2, 0, 5]\n",
            "10 [9 8 6 4 7 3 1 2 0 5]\n",
            "discarded index [9, 8, 6, 4, 7, 3, 1, 2, 0, 5]\n",
            "10 [9 8 6 4 7 3 1 2 0 5]\n",
            "discarded index [9, 8, 6, 4, 7, 3, 1, 2, 0, 5]\n",
            "10 [9 8 6 4 7 3 1 2 0 5]\n",
            "discarded index [9, 8, 6, 4, 7, 3, 1, 2, 0, 5]\n",
            "10 [9 8 6 4 7 3 1 2 0 5]\n",
            "discarded index [9, 8, 6, 4, 7, 3, 1, 2, 0, 5]\n",
            "10 [9 8 6 4 7 3 1 2 0 5]\n",
            "discarded index [9, 8, 6, 4, 7, 3, 1, 2, 0, 5]\n",
            "10 [9 8 6 4 7 3 1 2 0 5]\n",
            "discarded index [9, 8, 6, 4, 7, 3, 1, 2, 0, 5]\n",
            "10 [9 8 6 4 7 3 1 2 0 5]\n",
            "discarded index [9, 8, 6, 4, 7, 3, 1, 2, 0, 5]\n",
            "10 [9 8 6 4 7 3 1 2 0 5]\n",
            "discarded index [9, 8, 6, 4, 7, 3, 1, 2, 0, 5]\n",
            "10 [9 8 6 4 7 3 1 2 0 5]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 75, bulyan: at fang n_at 10 e 75 | val loss 2.2031 val acc 15.9903 best val_acc 25.081169\n",
            "discarded index [6, 9, 1, 3, 2, 5, 8, 0, 7, 4]\n",
            "10 [6 9 1 3 2 5 8 0 7 4]\n",
            "discarded index [6, 9, 1, 3, 2, 5, 8, 0, 7, 4]\n",
            "10 [6 9 1 3 2 5 8 0 7 4]\n",
            "discarded index [6, 9, 1, 3, 2, 5, 8, 0, 7, 4]\n",
            "10 [6 9 1 3 2 5 8 0 7 4]\n",
            "discarded index [6, 9, 1, 3, 2, 5, 8, 0, 7, 4]\n",
            "10 [6 9 1 3 2 5 8 0 7 4]\n",
            "discarded index [6, 9, 1, 3, 2, 5, 8, 0, 7, 4]\n",
            "10 [6 9 1 3 2 5 8 0 7 4]\n",
            "discarded index [6, 9, 1, 3, 2, 5, 8, 0, 7, 4]\n",
            "10 [6 9 1 3 2 5 8 0 7 4]\n",
            "discarded index [6, 9, 1, 3, 2, 5, 8, 0, 7, 4]\n",
            "10 [6 9 1 3 2 5 8 0 7 4]\n",
            "discarded index [6, 9, 1, 3, 2, 5, 8, 0, 7, 4]\n",
            "10 [6 9 1 3 2 5 8 0 7 4]\n",
            "discarded index [6, 9, 1, 3, 2, 5, 8, 0, 7, 4]\n",
            "10 [6 9 1 3 2 5 8 0 7 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 76, bulyan: at fang n_at 10 e 76 | val loss 2.0822 val acc 19.8052 best val_acc 25.081169\n",
            "discarded index [0, 7, 4, 6, 5, 3, 8, 2, 9, 1]\n",
            "10 [0 7 4 6 5 3 8 2 9 1]\n",
            "discarded index [0, 7, 4, 6, 5, 3, 8, 2, 9, 1]\n",
            "10 [0 7 4 6 5 3 8 2 9 1]\n",
            "discarded index [0, 7, 4, 6, 5, 3, 8, 2, 9, 1]\n",
            "10 [0 7 4 6 5 3 8 2 9 1]\n",
            "discarded index [0, 7, 4, 6, 5, 3, 8, 2, 9, 1]\n",
            "10 [0 7 4 6 5 3 8 2 9 1]\n",
            "discarded index [0, 7, 4, 6, 5, 3, 8, 2, 9, 1]\n",
            "10 [0 7 4 6 5 3 8 2 9 1]\n",
            "discarded index [0, 7, 4, 6, 5, 3, 8, 2, 9, 1]\n",
            "10 [0 7 4 6 5 3 8 2 9 1]\n",
            "discarded index [0, 7, 4, 6, 5, 3, 8, 2, 9, 1]\n",
            "10 [0 7 4 6 5 3 8 2 9 1]\n",
            "discarded index [0, 7, 4, 6, 5, 3, 8, 2, 9, 1]\n",
            "10 [0 7 4 6 5 3 8 2 9 1]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 77, bulyan: at fang n_at 10 e 77 | val loss 2.0392 val acc 22.7273 best val_acc 25.081169\n",
            "discarded index [5, 2, 3, 4, 9, 1, 8, 0, 6, 7]\n",
            "10 [5 2 3 4 9 1 8 0 6 7]\n",
            "discarded index [5, 2, 3, 4, 9, 1, 8, 0, 6, 7]\n",
            "10 [5 2 3 4 9 1 8 0 6 7]\n",
            "discarded index [5, 2, 3, 4, 9, 1, 8, 0, 6, 7]\n",
            "10 [5 2 3 4 9 1 8 0 6 7]\n",
            "discarded index [5, 2, 3, 4, 9, 1, 8, 0, 6, 7]\n",
            "10 [5 2 3 4 9 1 8 0 6 7]\n",
            "discarded index [5, 2, 3, 4, 9, 1, 8, 0, 6, 7]\n",
            "10 [5 2 3 4 9 1 8 0 6 7]\n",
            "discarded index [5, 2, 3, 4, 9, 1, 8, 0, 6, 7]\n",
            "10 [5 2 3 4 9 1 8 0 6 7]\n",
            "discarded index [5, 2, 3, 4, 9, 1, 8, 0, 6, 7]\n",
            "10 [5 2 3 4 9 1 8 0 6 7]\n",
            "discarded index [5, 2, 3, 4, 9, 1, 8, 0, 6, 7]\n",
            "10 [5 2 3 4 9 1 8 0 6 7]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 78, bulyan: at fang n_at 10 e 78 | val loss 1.9854 val acc 26.0552 best val_acc 26.055195\n",
            "discarded index [5, 6, 9, 2, 0, 4, 3, 1, 8, 7]\n",
            "10 [5 6 9 2 0 4 3 1 8 7]\n",
            "discarded index [5, 6, 9, 2, 0, 4, 3, 1, 8, 7]\n",
            "10 [5 6 9 2 0 4 3 1 8 7]\n",
            "discarded index [5, 6, 9, 2, 0, 4, 3, 1, 8, 7]\n",
            "10 [5 6 9 2 0 4 3 1 8 7]\n",
            "discarded index [5, 6, 9, 2, 0, 4, 3, 1, 8, 7]\n",
            "10 [5 6 9 2 0 4 3 1 8 7]\n",
            "discarded index [5, 6, 9, 2, 0, 4, 3, 1, 8, 7]\n",
            "10 [5 6 9 2 0 4 3 1 8 7]\n",
            "discarded index [5, 6, 9, 2, 0, 4, 3, 1, 8, 7]\n",
            "10 [5 6 9 2 0 4 3 1 8 7]\n",
            "discarded index [5, 6, 9, 2, 0, 4, 3, 1, 8, 7]\n",
            "10 [5 6 9 2 0 4 3 1 8 7]\n",
            "discarded index [5, 6, 9, 2, 0, 4, 3, 1, 8, 7]\n",
            "10 [5 6 9 2 0 4 3 1 8 7]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 79, bulyan: at fang n_at 10 e 79 | val loss 1.9929 val acc 22.3417 best val_acc 26.055195\n",
            "discarded index [6, 1, 8, 2, 9, 4, 0, 5, 7, 3]\n",
            "10 [6 1 8 2 9 4 0 5 7 3]\n",
            "discarded index [6, 1, 8, 2, 9, 4, 0, 5, 7, 3]\n",
            "10 [6 1 8 2 9 4 0 5 7 3]\n",
            "discarded index [6, 1, 8, 2, 9, 4, 0, 5, 7, 3]\n",
            "10 [6 1 8 2 9 4 0 5 7 3]\n",
            "discarded index [6, 1, 8, 2, 9, 4, 0, 5, 7, 3]\n",
            "10 [6 1 8 2 9 4 0 5 7 3]\n",
            "discarded index [6, 1, 8, 2, 9, 4, 0, 5, 7, 3]\n",
            "10 [6 1 8 2 9 4 0 5 7 3]\n",
            "discarded index [6, 1, 8, 2, 9, 4, 0, 5, 7, 3]\n",
            "10 [6 1 8 2 9 4 0 5 7 3]\n",
            "discarded index [6, 1, 8, 2, 9, 4, 0, 5, 7, 3]\n",
            "10 [6 1 8 2 9 4 0 5 7 3]\n",
            "discarded index [6, 1, 8, 2, 9, 4, 0, 5, 7, 3]\n",
            "10 [6 1 8 2 9 4 0 5 7 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 80, bulyan: at fang n_at 10 e 80 | val loss 2.0393 val acc 22.7070 best val_acc 26.055195\n",
            "discarded index [9, 7, 5, 8, 6, 0, 4, 1, 2, 3]\n",
            "10 [9 7 5 8 6 0 4 1 2 3]\n",
            "discarded index [9, 7, 5, 8, 6, 0, 4, 1, 2, 3]\n",
            "10 [9 7 5 8 6 0 4 1 2 3]\n",
            "discarded index [9, 7, 5, 8, 6, 0, 4, 1, 2, 3]\n",
            "10 [9 7 5 8 6 0 4 1 2 3]\n",
            "discarded index [9, 7, 5, 8, 6, 0, 4, 1, 2, 3]\n",
            "10 [9 7 5 8 6 0 4 1 2 3]\n",
            "discarded index [9, 7, 5, 8, 6, 0, 4, 1, 2, 3]\n",
            "10 [9 7 5 8 6 0 4 1 2 3]\n",
            "discarded index [9, 7, 5, 8, 6, 0, 4, 1, 2, 3]\n",
            "10 [9 7 5 8 6 0 4 1 2 3]\n",
            "discarded index [9, 7, 5, 8, 6, 0, 4, 1, 2, 3]\n",
            "10 [9 7 5 8 6 0 4 1 2 3]\n",
            "discarded index [9, 7, 5, 8, 6, 0, 4, 1, 2, 3]\n",
            "10 [9 7 5 8 6 0 4 1 2 3]\n",
            "discarded index [9, 7, 5, 8, 6, 0, 4, 1, 2, 3]\n",
            "10 [9 7 5 8 6 0 4 1 2 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 81, bulyan: at fang n_at 10 e 81 | val loss 2.1745 val acc 17.4716 best val_acc 26.055195\n",
            "discarded index [7, 9, 5, 0, 1, 4, 3, 2, 8, 6]\n",
            "10 [7 9 5 0 1 4 3 2 8 6]\n",
            "discarded index [7, 9, 5, 0, 1, 4, 3, 2, 8, 6]\n",
            "10 [7 9 5 0 1 4 3 2 8 6]\n",
            "discarded index [7, 9, 5, 0, 1, 4, 3, 2, 8, 6]\n",
            "10 [7 9 5 0 1 4 3 2 8 6]\n",
            "discarded index [7, 9, 5, 0, 1, 4, 3, 2, 8, 6]\n",
            "10 [7 9 5 0 1 4 3 2 8 6]\n",
            "discarded index [7, 9, 5, 0, 1, 4, 3, 2, 8, 6]\n",
            "10 [7 9 5 0 1 4 3 2 8 6]\n",
            "discarded index [7, 9, 5, 0, 1, 4, 3, 2, 8, 6]\n",
            "10 [7 9 5 0 1 4 3 2 8 6]\n",
            "discarded index [7, 9, 5, 0, 1, 4, 3, 2, 8, 6]\n",
            "10 [7 9 5 0 1 4 3 2 8 6]\n",
            "discarded index [7, 9, 5, 0, 1, 4, 3, 2, 8, 6]\n",
            "10 [7 9 5 0 1 4 3 2 8 6]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 82, bulyan: at fang n_at 10 e 82 | val loss 2.1111 val acc 20.3734 best val_acc 26.055195\n",
            "discarded index [7, 0, 6, 8, 4, 1, 2, 9, 3, 5]\n",
            "10 [7 0 6 8 4 1 2 9 3 5]\n",
            "discarded index [7, 0, 6, 8, 4, 1, 2, 9, 3, 5]\n",
            "10 [7 0 6 8 4 1 2 9 3 5]\n",
            "discarded index [7, 0, 6, 8, 4, 1, 2, 9, 3, 5]\n",
            "10 [7 0 6 8 4 1 2 9 3 5]\n",
            "discarded index [7, 0, 6, 8, 4, 1, 2, 9, 3, 5]\n",
            "10 [7 0 6 8 4 1 2 9 3 5]\n",
            "discarded index [7, 0, 6, 8, 4, 1, 2, 9, 3, 5]\n",
            "10 [7 0 6 8 4 1 2 9 3 5]\n",
            "discarded index [7, 0, 6, 8, 4, 1, 2, 9, 3, 5]\n",
            "10 [7 0 6 8 4 1 2 9 3 5]\n",
            "discarded index [7, 0, 6, 8, 4, 1, 2, 9, 3, 5]\n",
            "10 [7 0 6 8 4 1 2 9 3 5]\n",
            "discarded index [7, 0, 6, 8, 4, 1, 2, 9, 3, 5]\n",
            "10 [7 0 6 8 4 1 2 9 3 5]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 83, bulyan: at fang n_at 10 e 83 | val loss 2.0415 val acc 20.5357 best val_acc 26.055195\n",
            "discarded index [9, 8, 7, 0, 6, 1, 3, 2, 5, 4]\n",
            "10 [9 8 7 0 6 1 3 2 5 4]\n",
            "discarded index [9, 8, 7, 0, 6, 1, 3, 2, 5, 4]\n",
            "10 [9 8 7 0 6 1 3 2 5 4]\n",
            "discarded index [9, 8, 7, 0, 6, 1, 3, 2, 5, 4]\n",
            "10 [9 8 7 0 6 1 3 2 5 4]\n",
            "discarded index [9, 8, 7, 0, 6, 1, 3, 2, 5, 4]\n",
            "10 [9 8 7 0 6 1 3 2 5 4]\n",
            "discarded index [9, 8, 7, 0, 6, 1, 3, 2, 5, 4]\n",
            "10 [9 8 7 0 6 1 3 2 5 4]\n",
            "discarded index [9, 8, 7, 0, 6, 1, 3, 2, 5, 4]\n",
            "10 [9 8 7 0 6 1 3 2 5 4]\n",
            "discarded index [9, 8, 7, 0, 6, 1, 3, 2, 5, 4]\n",
            "10 [9 8 7 0 6 1 3 2 5 4]\n",
            "discarded index [9, 8, 7, 0, 6, 1, 3, 2, 5, 4]\n",
            "10 [9 8 7 0 6 1 3 2 5 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 84, bulyan: at fang n_at 10 e 84 | val loss 2.0030 val acc 26.9481 best val_acc 26.948052\n",
            "discarded index [1, 5, 2, 7, 6, 4, 9, 3, 0, 8]\n",
            "10 [1 5 2 7 6 4 9 3 0 8]\n",
            "discarded index [1, 5, 2, 7, 6, 4, 9, 3, 0, 8]\n",
            "10 [1 5 2 7 6 4 9 3 0 8]\n",
            "discarded index [1, 5, 2, 7, 6, 4, 9, 3, 0, 8]\n",
            "10 [1 5 2 7 6 4 9 3 0 8]\n",
            "discarded index [1, 5, 2, 7, 6, 4, 9, 3, 0, 8]\n",
            "10 [1 5 2 7 6 4 9 3 0 8]\n",
            "discarded index [1, 5, 2, 7, 6, 4, 9, 3, 0, 8]\n",
            "10 [1 5 2 7 6 4 9 3 0 8]\n",
            "discarded index [1, 5, 2, 7, 6, 4, 9, 3, 0, 8]\n",
            "10 [1 5 2 7 6 4 9 3 0 8]\n",
            "discarded index [1, 5, 2, 7, 6, 4, 9, 3, 0, 8]\n",
            "10 [1 5 2 7 6 4 9 3 0 8]\n",
            "discarded index [1, 5, 2, 7, 6, 4, 9, 3, 0, 8]\n",
            "10 [1 5 2 7 6 4 9 3 0 8]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 85, bulyan: at fang n_at 10 e 85 | val loss 2.0032 val acc 26.2175 best val_acc 26.948052\n",
            "discarded index [5, 1, 8, 6, 9, 7, 2, 3, 4, 0]\n",
            "10 [5 1 8 6 9 7 2 3 4 0]\n",
            "discarded index [5, 1, 8, 6, 9, 7, 2, 3, 4, 0]\n",
            "10 [5 1 8 6 9 7 2 3 4 0]\n",
            "discarded index [5, 1, 8, 6, 9, 7, 2, 3, 4, 0]\n",
            "10 [5 1 8 6 9 7 2 3 4 0]\n",
            "discarded index [5, 1, 8, 6, 9, 7, 2, 3, 4, 0]\n",
            "10 [5 1 8 6 9 7 2 3 4 0]\n",
            "discarded index [5, 1, 8, 6, 9, 7, 2, 3, 4, 0]\n",
            "10 [5 1 8 6 9 7 2 3 4 0]\n",
            "discarded index [5, 1, 8, 6, 9, 7, 2, 3, 4, 0]\n",
            "10 [5 1 8 6 9 7 2 3 4 0]\n",
            "discarded index [5, 1, 8, 6, 9, 7, 2, 3, 4, 0]\n",
            "10 [5 1 8 6 9 7 2 3 4 0]\n",
            "discarded index [5, 1, 8, 6, 9, 7, 2, 3, 4, 0]\n",
            "10 [5 1 8 6 9 7 2 3 4 0]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 86, bulyan: at fang n_at 10 e 86 | val loss 2.0695 val acc 20.0487 best val_acc 26.948052\n",
            "discarded index [3, 2, 4, 1, 5, 9, 6, 0, 7, 8]\n",
            "10 [3 2 4 1 5 9 6 0 7 8]\n",
            "discarded index [3, 2, 4, 1, 5, 9, 6, 0, 7, 8]\n",
            "10 [3 2 4 1 5 9 6 0 7 8]\n",
            "discarded index [3, 2, 4, 1, 5, 9, 6, 0, 7, 8]\n",
            "10 [3 2 4 1 5 9 6 0 7 8]\n",
            "discarded index [3, 2, 4, 1, 5, 9, 6, 0, 7, 8]\n",
            "10 [3 2 4 1 5 9 6 0 7 8]\n",
            "discarded index [3, 2, 4, 1, 5, 9, 6, 0, 7, 8]\n",
            "10 [3 2 4 1 5 9 6 0 7 8]\n",
            "discarded index [3, 2, 4, 1, 5, 9, 6, 0, 7, 8]\n",
            "10 [3 2 4 1 5 9 6 0 7 8]\n",
            "discarded index [3, 2, 4, 1, 5, 9, 6, 0, 7, 8]\n",
            "10 [3 2 4 1 5 9 6 0 7 8]\n",
            "discarded index [3, 2, 4, 1, 5, 9, 6, 0, 7, 8]\n",
            "10 [3 2 4 1 5 9 6 0 7 8]\n",
            "discarded index [3, 2, 4, 1, 5, 9, 6, 0, 7, 8]\n",
            "10 [3 2 4 1 5 9 6 0 7 8]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 87, bulyan: at fang n_at 10 e 87 | val loss 2.0781 val acc 23.2955 best val_acc 26.948052\n",
            "discarded index [6, 7, 5, 0, 9, 8, 4, 1, 2, 3]\n",
            "10 [6 7 5 0 9 8 4 1 2 3]\n",
            "discarded index [6, 7, 5, 0, 9, 8, 4, 1, 2, 3]\n",
            "10 [6 7 5 0 9 8 4 1 2 3]\n",
            "discarded index [6, 7, 5, 0, 9, 8, 4, 1, 2, 3]\n",
            "10 [6 7 5 0 9 8 4 1 2 3]\n",
            "discarded index [6, 7, 5, 0, 9, 8, 4, 1, 2, 3]\n",
            "10 [6 7 5 0 9 8 4 1 2 3]\n",
            "discarded index [6, 7, 5, 0, 9, 8, 4, 1, 2, 3]\n",
            "10 [6 7 5 0 9 8 4 1 2 3]\n",
            "discarded index [6, 7, 5, 0, 9, 8, 4, 1, 2, 3]\n",
            "10 [6 7 5 0 9 8 4 1 2 3]\n",
            "discarded index [6, 7, 5, 0, 9, 8, 4, 1, 2, 3]\n",
            "10 [6 7 5 0 9 8 4 1 2 3]\n",
            "discarded index [6, 7, 5, 0, 9, 8, 4, 1, 2, 3]\n",
            "10 [6 7 5 0 9 8 4 1 2 3]\n",
            "discarded index [6, 7, 5, 0, 9, 8, 4, 1, 2, 3]\n",
            "10 [6 7 5 0 9 8 4 1 2 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 88, bulyan: at fang n_at 10 e 88 | val loss 2.0555 val acc 24.6753 best val_acc 26.948052\n",
            "discarded index [6, 9, 8, 5, 2, 1, 7, 0, 3, 4]\n",
            "10 [6 9 8 5 2 1 7 0 3 4]\n",
            "discarded index [6, 9, 8, 5, 2, 1, 7, 0, 3, 4]\n",
            "10 [6 9 8 5 2 1 7 0 3 4]\n",
            "discarded index [6, 9, 8, 5, 2, 1, 7, 0, 3, 4]\n",
            "10 [6 9 8 5 2 1 7 0 3 4]\n",
            "discarded index [6, 9, 8, 5, 2, 1, 7, 0, 3, 4]\n",
            "10 [6 9 8 5 2 1 7 0 3 4]\n",
            "discarded index [6, 9, 8, 5, 2, 1, 7, 0, 3, 4]\n",
            "10 [6 9 8 5 2 1 7 0 3 4]\n",
            "discarded index [6, 9, 8, 5, 2, 1, 7, 0, 3, 4]\n",
            "10 [6 9 8 5 2 1 7 0 3 4]\n",
            "discarded index [6, 9, 8, 5, 2, 1, 7, 0, 3, 4]\n",
            "10 [6 9 8 5 2 1 7 0 3 4]\n",
            "discarded index [6, 9, 8, 5, 2, 1, 7, 0, 3, 4]\n",
            "10 [6 9 8 5 2 1 7 0 3 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 89, bulyan: at fang n_at 10 e 89 | val loss 1.9571 val acc 28.4497 best val_acc 28.449675\n",
            "discarded index [7, 5, 8, 9, 2, 1, 3, 0, 6, 4]\n",
            "10 [7 5 8 9 2 1 3 0 6 4]\n",
            "discarded index [7, 5, 8, 9, 2, 1, 3, 0, 6, 4]\n",
            "10 [7 5 8 9 2 1 3 0 6 4]\n",
            "discarded index [7, 5, 8, 9, 2, 1, 3, 0, 6, 4]\n",
            "10 [7 5 8 9 2 1 3 0 6 4]\n",
            "discarded index [7, 5, 8, 9, 2, 1, 3, 0, 6, 4]\n",
            "10 [7 5 8 9 2 1 3 0 6 4]\n",
            "discarded index [7, 5, 8, 9, 2, 1, 3, 0, 6, 4]\n",
            "10 [7 5 8 9 2 1 3 0 6 4]\n",
            "discarded index [7, 5, 8, 9, 2, 1, 3, 0, 6, 4]\n",
            "10 [7 5 8 9 2 1 3 0 6 4]\n",
            "discarded index [7, 5, 8, 9, 2, 1, 3, 0, 6, 4]\n",
            "10 [7 5 8 9 2 1 3 0 6 4]\n",
            "discarded index [7, 5, 8, 9, 2, 1, 3, 0, 6, 4]\n",
            "10 [7 5 8 9 2 1 3 0 6 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 90, bulyan: at fang n_at 10 e 90 | val loss 1.9202 val acc 26.7045 best val_acc 28.449675\n",
            "discarded index [6, 9, 5, 0, 7, 8, 1, 4, 3, 2]\n",
            "10 [6 9 5 0 7 8 1 4 3 2]\n",
            "discarded index [6, 9, 5, 0, 7, 8, 1, 4, 3, 2]\n",
            "10 [6 9 5 0 7 8 1 4 3 2]\n",
            "discarded index [6, 9, 5, 0, 7, 8, 1, 4, 3, 2]\n",
            "10 [6 9 5 0 7 8 1 4 3 2]\n",
            "discarded index [6, 9, 5, 0, 7, 8, 1, 4, 3, 2]\n",
            "10 [6 9 5 0 7 8 1 4 3 2]\n",
            "discarded index [6, 9, 5, 0, 7, 8, 1, 4, 3, 2]\n",
            "10 [6 9 5 0 7 8 1 4 3 2]\n",
            "discarded index [6, 9, 5, 0, 7, 8, 1, 4, 3, 2]\n",
            "10 [6 9 5 0 7 8 1 4 3 2]\n",
            "discarded index [6, 9, 5, 0, 7, 8, 1, 4, 3, 2]\n",
            "10 [6 9 5 0 7 8 1 4 3 2]\n",
            "discarded index [6, 9, 5, 0, 7, 8, 1, 4, 3, 2]\n",
            "10 [6 9 5 0 7 8 1 4 3 2]\n",
            "discarded index [6, 9, 5, 0, 7, 8, 1, 4, 3, 2]\n",
            "10 [6 9 5 0 7 8 1 4 3 2]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 91, bulyan: at fang n_at 10 e 91 | val loss 2.0227 val acc 22.6867 best val_acc 28.449675\n",
            "discarded index [5, 2, 3, 8, 6, 4, 9, 0, 7, 1]\n",
            "10 [5 2 3 8 6 4 9 0 7 1]\n",
            "discarded index [5, 2, 3, 8, 6, 4, 9, 0, 7, 1]\n",
            "10 [5 2 3 8 6 4 9 0 7 1]\n",
            "discarded index [5, 2, 3, 8, 6, 4, 9, 0, 7, 1]\n",
            "10 [5 2 3 8 6 4 9 0 7 1]\n",
            "discarded index [5, 2, 3, 8, 6, 4, 9, 0, 7, 1]\n",
            "10 [5 2 3 8 6 4 9 0 7 1]\n",
            "discarded index [5, 2, 3, 8, 6, 4, 9, 0, 7, 1]\n",
            "10 [5 2 3 8 6 4 9 0 7 1]\n",
            "discarded index [5, 2, 3, 8, 6, 4, 9, 0, 7, 1]\n",
            "10 [5 2 3 8 6 4 9 0 7 1]\n",
            "discarded index [5, 2, 3, 8, 6, 4, 9, 0, 7, 1]\n",
            "10 [5 2 3 8 6 4 9 0 7 1]\n",
            "discarded index [5, 2, 3, 8, 6, 4, 9, 0, 7, 1]\n",
            "10 [5 2 3 8 6 4 9 0 7 1]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 92, bulyan: at fang n_at 10 e 92 | val loss 2.0552 val acc 20.8604 best val_acc 28.449675\n",
            "discarded index [9, 8, 7, 6, 0, 5, 3, 1, 4, 2]\n",
            "10 [9 8 7 6 0 5 3 1 4 2]\n",
            "discarded index [9, 8, 7, 6, 0, 5, 3, 1, 4, 2]\n",
            "10 [9 8 7 6 0 5 3 1 4 2]\n",
            "discarded index [9, 8, 7, 6, 0, 5, 3, 1, 4, 2]\n",
            "10 [9 8 7 6 0 5 3 1 4 2]\n",
            "discarded index [9, 8, 7, 6, 0, 5, 3, 1, 4, 2]\n",
            "10 [9 8 7 6 0 5 3 1 4 2]\n",
            "discarded index [9, 8, 7, 6, 0, 5, 3, 1, 4, 2]\n",
            "10 [9 8 7 6 0 5 3 1 4 2]\n",
            "discarded index [9, 8, 7, 6, 0, 5, 3, 1, 4, 2]\n",
            "10 [9 8 7 6 0 5 3 1 4 2]\n",
            "discarded index [9, 8, 7, 6, 0, 5, 3, 1, 4, 2]\n",
            "10 [9 8 7 6 0 5 3 1 4 2]\n",
            "discarded index [9, 8, 7, 6, 0, 5, 3, 1, 4, 2]\n",
            "10 [9 8 7 6 0 5 3 1 4 2]\n",
            "discarded index [9, 8, 7, 6, 0, 5, 3, 1, 4, 2]\n",
            "10 [9 8 7 6 0 5 3 1 4 2]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 93, bulyan: at fang n_at 10 e 93 | val loss 2.1626 val acc 18.8920 best val_acc 28.449675\n",
            "discarded index [6, 8, 9, 0, 1, 2, 5, 7, 3, 4]\n",
            "10 [6 8 9 0 1 2 5 7 3 4]\n",
            "discarded index [6, 8, 9, 0, 1, 2, 5, 7, 3, 4]\n",
            "10 [6 8 9 0 1 2 5 7 3 4]\n",
            "discarded index [6, 8, 9, 0, 1, 2, 5, 7, 3, 4]\n",
            "10 [6 8 9 0 1 2 5 7 3 4]\n",
            "discarded index [6, 8, 9, 0, 1, 2, 5, 7, 3, 4]\n",
            "10 [6 8 9 0 1 2 5 7 3 4]\n",
            "discarded index [6, 8, 9, 0, 1, 2, 5, 7, 3, 4]\n",
            "10 [6 8 9 0 1 2 5 7 3 4]\n",
            "discarded index [6, 8, 9, 0, 1, 2, 5, 7, 3, 4]\n",
            "10 [6 8 9 0 1 2 5 7 3 4]\n",
            "discarded index [6, 8, 9, 0, 1, 2, 5, 7, 3, 4]\n",
            "10 [6 8 9 0 1 2 5 7 3 4]\n",
            "discarded index [6, 8, 9, 0, 1, 2, 5, 7, 3, 4]\n",
            "10 [6 8 9 0 1 2 5 7 3 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 94, bulyan: at fang n_at 10 e 94 | val loss 2.0688 val acc 21.5503 best val_acc 28.449675\n",
            "discarded index [1, 2, 3, 0, 7, 6, 8, 5, 9, 4]\n",
            "10 [1 2 3 0 7 6 8 5 9 4]\n",
            "discarded index [1, 2, 3, 0, 7, 6, 8, 5, 9, 4]\n",
            "10 [1 2 3 0 7 6 8 5 9 4]\n",
            "discarded index [1, 2, 3, 0, 7, 6, 8, 5, 9, 4]\n",
            "10 [1 2 3 0 7 6 8 5 9 4]\n",
            "discarded index [1, 2, 3, 0, 7, 6, 8, 5, 9, 4]\n",
            "10 [1 2 3 0 7 6 8 5 9 4]\n",
            "discarded index [1, 2, 3, 0, 7, 6, 8, 5, 9, 4]\n",
            "10 [1 2 3 0 7 6 8 5 9 4]\n",
            "discarded index [1, 2, 3, 0, 7, 6, 8, 5, 9, 4]\n",
            "10 [1 2 3 0 7 6 8 5 9 4]\n",
            "discarded index [1, 2, 3, 0, 7, 6, 8, 5, 9, 4]\n",
            "10 [1 2 3 0 7 6 8 5 9 4]\n",
            "discarded index [1, 2, 3, 0, 7, 6, 8, 5, 9, 4]\n",
            "10 [1 2 3 0 7 6 8 5 9 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 95, bulyan: at fang n_at 10 e 95 | val loss 2.0465 val acc 21.3271 best val_acc 28.449675\n",
            "discarded index [1, 2, 3, 0, 6, 9, 4, 5, 8, 7]\n",
            "10 [1 2 3 0 6 9 4 5 8 7]\n",
            "discarded index [1, 2, 3, 0, 6, 9, 4, 5, 8, 7]\n",
            "10 [1 2 3 0 6 9 4 5 8 7]\n",
            "discarded index [1, 2, 3, 0, 6, 9, 4, 5, 8, 7]\n",
            "10 [1 2 3 0 6 9 4 5 8 7]\n",
            "discarded index [1, 2, 3, 0, 6, 9, 4, 5, 8, 7]\n",
            "10 [1 2 3 0 6 9 4 5 8 7]\n",
            "discarded index [1, 2, 3, 0, 6, 9, 4, 5, 8, 7]\n",
            "10 [1 2 3 0 6 9 4 5 8 7]\n",
            "discarded index [1, 2, 3, 0, 6, 9, 4, 5, 8, 7]\n",
            "10 [1 2 3 0 6 9 4 5 8 7]\n",
            "discarded index [1, 2, 3, 0, 6, 9, 4, 5, 8, 7]\n",
            "10 [1 2 3 0 6 9 4 5 8 7]\n",
            "discarded index [1, 2, 3, 0, 6, 9, 4, 5, 8, 7]\n",
            "10 [1 2 3 0 6 9 4 5 8 7]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 96, bulyan: at fang n_at 10 e 96 | val loss 2.0549 val acc 20.3328 best val_acc 28.449675\n",
            "discarded index [1, 0, 6, 8, 3, 2, 5, 4, 9, 7]\n",
            "10 [1 0 6 8 3 2 5 4 9 7]\n",
            "discarded index [1, 0, 6, 8, 3, 2, 5, 4, 9, 7]\n",
            "10 [1 0 6 8 3 2 5 4 9 7]\n",
            "discarded index [1, 0, 6, 8, 3, 2, 5, 4, 9, 7]\n",
            "10 [1 0 6 8 3 2 5 4 9 7]\n",
            "discarded index [1, 0, 6, 8, 3, 2, 5, 4, 9, 7]\n",
            "10 [1 0 6 8 3 2 5 4 9 7]\n",
            "discarded index [1, 0, 6, 8, 3, 2, 5, 4, 9, 7]\n",
            "10 [1 0 6 8 3 2 5 4 9 7]\n",
            "discarded index [1, 0, 6, 8, 3, 2, 5, 4, 9, 7]\n",
            "10 [1 0 6 8 3 2 5 4 9 7]\n",
            "discarded index [1, 0, 6, 8, 3, 2, 5, 4, 9, 7]\n",
            "10 [1 0 6 8 3 2 5 4 9 7]\n",
            "discarded index [1, 0, 6, 8, 3, 2, 5, 4, 9, 7]\n",
            "10 [1 0 6 8 3 2 5 4 9 7]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 97, bulyan: at fang n_at 10 e 97 | val loss 2.1699 val acc 17.7354 best val_acc 28.449675\n",
            "discarded index [2, 4, 9, 5, 1, 0, 3, 6, 7, 8]\n",
            "10 [2 4 9 5 1 0 3 6 7 8]\n",
            "discarded index [2, 4, 9, 5, 1, 0, 3, 6, 7, 8]\n",
            "10 [2 4 9 5 1 0 3 6 7 8]\n",
            "discarded index [2, 4, 9, 5, 1, 0, 3, 6, 7, 8]\n",
            "10 [2 4 9 5 1 0 3 6 7 8]\n",
            "discarded index [2, 4, 9, 5, 1, 0, 3, 6, 7, 8]\n",
            "10 [2 4 9 5 1 0 3 6 7 8]\n",
            "discarded index [2, 4, 9, 5, 1, 0, 3, 6, 7, 8]\n",
            "10 [2 4 9 5 1 0 3 6 7 8]\n",
            "discarded index [2, 4, 9, 5, 1, 0, 3, 6, 7, 8]\n",
            "10 [2 4 9 5 1 0 3 6 7 8]\n",
            "discarded index [2, 4, 9, 5, 1, 0, 3, 6, 7, 8]\n",
            "10 [2 4 9 5 1 0 3 6 7 8]\n",
            "discarded index [2, 4, 9, 5, 1, 0, 3, 6, 7, 8]\n",
            "10 [2 4 9 5 1 0 3 6 7 8]\n",
            "discarded index [2, 4, 9, 5, 1, 0, 3, 6, 7, 8]\n",
            "10 [2 4 9 5 1 0 3 6 7 8]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 98, bulyan: at fang n_at 10 e 98 | val loss 2.1450 val acc 19.2370 best val_acc 28.449675\n",
            "discarded index [9, 5, 3, 2, 1, 7, 6, 8, 0, 4]\n",
            "10 [9 5 3 2 1 7 6 8 0 4]\n",
            "discarded index [9, 5, 3, 2, 1, 7, 6, 8, 0, 4]\n",
            "10 [9 5 3 2 1 7 6 8 0 4]\n",
            "discarded index [9, 5, 3, 2, 1, 7, 6, 8, 0, 4]\n",
            "10 [9 5 3 2 1 7 6 8 0 4]\n",
            "discarded index [9, 5, 3, 2, 1, 7, 6, 8, 0, 4]\n",
            "10 [9 5 3 2 1 7 6 8 0 4]\n",
            "discarded index [9, 5, 3, 2, 1, 7, 6, 8, 0, 4]\n",
            "10 [9 5 3 2 1 7 6 8 0 4]\n",
            "discarded index [9, 5, 3, 2, 1, 7, 6, 8, 0, 4]\n",
            "10 [9 5 3 2 1 7 6 8 0 4]\n",
            "discarded index [9, 5, 3, 2, 1, 7, 6, 8, 0, 4]\n",
            "10 [9 5 3 2 1 7 6 8 0 4]\n",
            "discarded index [9, 5, 3, 2, 1, 7, 6, 8, 0, 4]\n",
            "10 [9 5 3 2 1 7 6 8 0 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 99, bulyan: at fang n_at 10 e 99 | val loss 2.0879 val acc 22.9505 best val_acc 28.449675\n",
            "discarded index [7, 2, 3, 1, 9, 8, 0, 6, 5, 4]\n",
            "10 [7 2 3 1 9 8 0 6 5 4]\n",
            "discarded index [7, 2, 3, 1, 9, 8, 0, 6, 5, 4]\n",
            "10 [7 2 3 1 9 8 0 6 5 4]\n",
            "discarded index [7, 2, 3, 1, 9, 8, 0, 6, 5, 4]\n",
            "10 [7 2 3 1 9 8 0 6 5 4]\n",
            "discarded index [7, 2, 3, 1, 9, 8, 0, 6, 5, 4]\n",
            "10 [7 2 3 1 9 8 0 6 5 4]\n",
            "discarded index [7, 2, 3, 1, 9, 8, 0, 6, 5, 4]\n",
            "10 [7 2 3 1 9 8 0 6 5 4]\n",
            "discarded index [7, 2, 3, 1, 9, 8, 0, 6, 5, 4]\n",
            "10 [7 2 3 1 9 8 0 6 5 4]\n",
            "discarded index [7, 2, 3, 1, 9, 8, 0, 6, 5, 4]\n",
            "10 [7 2 3 1 9 8 0 6 5 4]\n",
            "discarded index [7, 2, 3, 1, 9, 8, 0, 6, 5, 4]\n",
            "10 [7 2 3 1 9 8 0 6 5 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 100, bulyan: at fang n_at 10 e 100 | val loss 2.0094 val acc 24.9594 best val_acc 28.449675\n",
            "discarded index [9, 0, 7, 4, 1, 8, 3, 2, 6, 5]\n",
            "10 [9 0 7 4 1 8 3 2 6 5]\n",
            "discarded index [9, 0, 7, 4, 1, 8, 3, 2, 6, 5]\n",
            "10 [9 0 7 4 1 8 3 2 6 5]\n",
            "discarded index [9, 0, 7, 4, 1, 8, 3, 2, 6, 5]\n",
            "10 [9 0 7 4 1 8 3 2 6 5]\n",
            "discarded index [9, 0, 7, 4, 1, 8, 3, 2, 6, 5]\n",
            "10 [9 0 7 4 1 8 3 2 6 5]\n",
            "discarded index [9, 0, 7, 4, 1, 8, 3, 2, 6, 5]\n",
            "10 [9 0 7 4 1 8 3 2 6 5]\n",
            "discarded index [9, 0, 7, 4, 1, 8, 3, 2, 6, 5]\n",
            "10 [9 0 7 4 1 8 3 2 6 5]\n",
            "discarded index [9, 0, 7, 4, 1, 8, 3, 2, 6, 5]\n",
            "10 [9 0 7 4 1 8 3 2 6 5]\n",
            "discarded index [9, 0, 7, 4, 1, 8, 3, 2, 6, 5]\n",
            "10 [9 0 7 4 1 8 3 2 6 5]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 101, bulyan: at fang n_at 10 e 101 | val loss 2.0803 val acc 21.2662 best val_acc 28.449675\n",
            "discarded index [7, 6, 5, 3, 2, 8, 4, 9, 1, 0]\n",
            "10 [7 6 5 3 2 8 4 9 1 0]\n",
            "discarded index [7, 6, 5, 3, 2, 8, 4, 9, 1, 0]\n",
            "10 [7 6 5 3 2 8 4 9 1 0]\n",
            "discarded index [7, 6, 5, 3, 2, 8, 4, 9, 1, 0]\n",
            "10 [7 6 5 3 2 8 4 9 1 0]\n",
            "discarded index [7, 6, 5, 3, 2, 8, 4, 9, 1, 0]\n",
            "10 [7 6 5 3 2 8 4 9 1 0]\n",
            "discarded index [7, 6, 5, 3, 2, 8, 4, 9, 1, 0]\n",
            "10 [7 6 5 3 2 8 4 9 1 0]\n",
            "discarded index [7, 6, 5, 3, 2, 8, 4, 9, 1, 0]\n",
            "10 [7 6 5 3 2 8 4 9 1 0]\n",
            "discarded index [7, 6, 5, 3, 2, 8, 4, 9, 1, 0]\n",
            "10 [7 6 5 3 2 8 4 9 1 0]\n",
            "discarded index [7, 6, 5, 3, 2, 8, 4, 9, 1, 0]\n",
            "10 [7 6 5 3 2 8 4 9 1 0]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 102, bulyan: at fang n_at 10 e 102 | val loss 2.0622 val acc 22.7273 best val_acc 28.449675\n",
            "discarded index [7, 4, 5, 1, 9, 6, 0, 3, 2, 8]\n",
            "10 [7 4 5 1 9 6 0 3 2 8]\n",
            "discarded index [7, 4, 5, 1, 9, 6, 0, 3, 2, 8]\n",
            "10 [7 4 5 1 9 6 0 3 2 8]\n",
            "discarded index [7, 4, 5, 1, 9, 6, 0, 3, 2, 8]\n",
            "10 [7 4 5 1 9 6 0 3 2 8]\n",
            "discarded index [7, 4, 5, 1, 9, 6, 0, 3, 2, 8]\n",
            "10 [7 4 5 1 9 6 0 3 2 8]\n",
            "discarded index [7, 4, 5, 1, 9, 6, 0, 3, 2, 8]\n",
            "10 [7 4 5 1 9 6 0 3 2 8]\n",
            "discarded index [7, 4, 5, 1, 9, 6, 0, 3, 2, 8]\n",
            "10 [7 4 5 1 9 6 0 3 2 8]\n",
            "discarded index [7, 4, 5, 1, 9, 6, 0, 3, 2, 8]\n",
            "10 [7 4 5 1 9 6 0 3 2 8]\n",
            "discarded index [7, 4, 5, 1, 9, 6, 0, 3, 2, 8]\n",
            "10 [7 4 5 1 9 6 0 3 2 8]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 103, bulyan: at fang n_at 10 e 103 | val loss 2.0833 val acc 18.6080 best val_acc 28.449675\n",
            "discarded index [5, 2, 3, 8, 9, 6, 0, 7, 1, 4]\n",
            "10 [5 2 3 8 9 6 0 7 1 4]\n",
            "discarded index [5, 2, 3, 8, 9, 6, 0, 7, 1, 4]\n",
            "10 [5 2 3 8 9 6 0 7 1 4]\n",
            "discarded index [5, 2, 3, 8, 9, 6, 0, 7, 1, 4]\n",
            "10 [5 2 3 8 9 6 0 7 1 4]\n",
            "discarded index [5, 2, 3, 8, 9, 6, 0, 7, 1, 4]\n",
            "10 [5 2 3 8 9 6 0 7 1 4]\n",
            "discarded index [5, 2, 3, 8, 9, 6, 0, 7, 1, 4]\n",
            "10 [5 2 3 8 9 6 0 7 1 4]\n",
            "discarded index [5, 2, 3, 8, 9, 6, 0, 7, 1, 4]\n",
            "10 [5 2 3 8 9 6 0 7 1 4]\n",
            "discarded index [5, 2, 3, 8, 9, 6, 0, 7, 1, 4]\n",
            "10 [5 2 3 8 9 6 0 7 1 4]\n",
            "discarded index [5, 2, 3, 8, 9, 6, 0, 7, 1, 4]\n",
            "10 [5 2 3 8 9 6 0 7 1 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 104, bulyan: at fang n_at 10 e 104 | val loss 2.0849 val acc 22.2808 best val_acc 28.449675\n",
            "discarded index [7, 6, 3, 2, 0, 4, 1, 8, 9, 5]\n",
            "10 [7 6 3 2 0 4 1 8 9 5]\n",
            "discarded index [7, 6, 3, 2, 0, 4, 1, 8, 9, 5]\n",
            "10 [7 6 3 2 0 4 1 8 9 5]\n",
            "discarded index [7, 6, 3, 2, 0, 4, 1, 8, 9, 5]\n",
            "10 [7 6 3 2 0 4 1 8 9 5]\n",
            "discarded index [7, 6, 3, 2, 0, 4, 1, 8, 9, 5]\n",
            "10 [7 6 3 2 0 4 1 8 9 5]\n",
            "discarded index [7, 6, 3, 2, 0, 4, 1, 8, 9, 5]\n",
            "10 [7 6 3 2 0 4 1 8 9 5]\n",
            "discarded index [7, 6, 3, 2, 0, 4, 1, 8, 9, 5]\n",
            "10 [7 6 3 2 0 4 1 8 9 5]\n",
            "discarded index [7, 6, 3, 2, 0, 4, 1, 8, 9, 5]\n",
            "10 [7 6 3 2 0 4 1 8 9 5]\n",
            "discarded index [7, 6, 3, 2, 0, 4, 1, 8, 9, 5]\n",
            "10 [7 6 3 2 0 4 1 8 9 5]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 105, bulyan: at fang n_at 10 e 105 | val loss 2.1814 val acc 15.5641 best val_acc 28.449675\n",
            "discarded index [5, 7, 6, 0, 8, 2, 3, 4, 1, 9]\n",
            "10 [5 7 6 0 8 2 3 4 1 9]\n",
            "discarded index [5, 7, 6, 0, 8, 2, 3, 4, 1, 9]\n",
            "10 [5 7 6 0 8 2 3 4 1 9]\n",
            "discarded index [5, 7, 6, 0, 8, 2, 3, 4, 1, 9]\n",
            "10 [5 7 6 0 8 2 3 4 1 9]\n",
            "discarded index [5, 7, 6, 0, 8, 2, 3, 4, 1, 9]\n",
            "10 [5 7 6 0 8 2 3 4 1 9]\n",
            "discarded index [5, 7, 6, 0, 8, 2, 3, 4, 1, 9]\n",
            "10 [5 7 6 0 8 2 3 4 1 9]\n",
            "discarded index [5, 7, 6, 0, 8, 2, 3, 4, 1, 9]\n",
            "10 [5 7 6 0 8 2 3 4 1 9]\n",
            "discarded index [5, 7, 6, 0, 8, 2, 3, 4, 1, 9]\n",
            "10 [5 7 6 0 8 2 3 4 1 9]\n",
            "discarded index [5, 7, 6, 0, 8, 2, 3, 4, 1, 9]\n",
            "10 [5 7 6 0 8 2 3 4 1 9]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 106, bulyan: at fang n_at 10 e 106 | val loss 2.1072 val acc 21.6721 best val_acc 28.449675\n",
            "discarded index [6, 9, 7, 8, 1, 3, 2, 5, 4, 0]\n",
            "10 [6 9 7 8 1 3 2 5 4 0]\n",
            "discarded index [6, 9, 7, 8, 1, 3, 2, 5, 4, 0]\n",
            "10 [6 9 7 8 1 3 2 5 4 0]\n",
            "discarded index [6, 9, 7, 8, 1, 3, 2, 5, 4, 0]\n",
            "10 [6 9 7 8 1 3 2 5 4 0]\n",
            "discarded index [6, 9, 7, 8, 1, 3, 2, 5, 4, 0]\n",
            "10 [6 9 7 8 1 3 2 5 4 0]\n",
            "discarded index [6, 9, 7, 8, 1, 3, 2, 5, 4, 0]\n",
            "10 [6 9 7 8 1 3 2 5 4 0]\n",
            "discarded index [6, 9, 7, 8, 1, 3, 2, 5, 4, 0]\n",
            "10 [6 9 7 8 1 3 2 5 4 0]\n",
            "discarded index [6, 9, 7, 8, 1, 3, 2, 5, 4, 0]\n",
            "10 [6 9 7 8 1 3 2 5 4 0]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 107, bulyan: at fang n_at 10 e 107 | val loss 1.9901 val acc 24.5130 best val_acc 28.449675\n",
            "discarded index [6, 9, 8, 7, 0, 4, 5, 3, 2, 1]\n",
            "10 [6 9 8 7 0 4 5 3 2 1]\n",
            "discarded index [6, 9, 8, 7, 0, 4, 5, 3, 2, 1]\n",
            "10 [6 9 8 7 0 4 5 3 2 1]\n",
            "discarded index [6, 9, 8, 7, 0, 4, 5, 3, 2, 1]\n",
            "10 [6 9 8 7 0 4 5 3 2 1]\n",
            "discarded index [6, 9, 8, 7, 0, 4, 5, 3, 2, 1]\n",
            "10 [6 9 8 7 0 4 5 3 2 1]\n",
            "discarded index [6, 9, 8, 7, 0, 4, 5, 3, 2, 1]\n",
            "10 [6 9 8 7 0 4 5 3 2 1]\n",
            "discarded index [6, 9, 8, 7, 0, 4, 5, 3, 2, 1]\n",
            "10 [6 9 8 7 0 4 5 3 2 1]\n",
            "discarded index [6, 9, 8, 7, 0, 4, 5, 3, 2, 1]\n",
            "10 [6 9 8 7 0 4 5 3 2 1]\n",
            "discarded index [6, 9, 8, 7, 0, 4, 5, 3, 2, 1]\n",
            "10 [6 9 8 7 0 4 5 3 2 1]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 108, bulyan: at fang n_at 10 e 108 | val loss 1.9459 val acc 26.5422 best val_acc 28.449675\n",
            "discarded index [6, 7, 9, 5, 4, 2, 3, 8, 0, 1]\n",
            "10 [6 7 9 5 4 2 3 8 0 1]\n",
            "discarded index [6, 7, 9, 5, 4, 2, 3, 8, 0, 1]\n",
            "10 [6 7 9 5 4 2 3 8 0 1]\n",
            "discarded index [6, 7, 9, 5, 4, 2, 3, 8, 0, 1]\n",
            "10 [6 7 9 5 4 2 3 8 0 1]\n",
            "discarded index [6, 7, 9, 5, 4, 2, 3, 8, 0, 1]\n",
            "10 [6 7 9 5 4 2 3 8 0 1]\n",
            "discarded index [6, 7, 9, 5, 4, 2, 3, 8, 0, 1]\n",
            "10 [6 7 9 5 4 2 3 8 0 1]\n",
            "discarded index [6, 7, 9, 5, 4, 2, 3, 8, 0, 1]\n",
            "10 [6 7 9 5 4 2 3 8 0 1]\n",
            "discarded index [6, 7, 9, 5, 4, 2, 3, 8, 0, 1]\n",
            "10 [6 7 9 5 4 2 3 8 0 1]\n",
            "discarded index [6, 7, 9, 5, 4, 2, 3, 8, 0, 1]\n",
            "10 [6 7 9 5 4 2 3 8 0 1]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 109, bulyan: at fang n_at 10 e 109 | val loss 1.9194 val acc 27.2727 best val_acc 28.449675\n",
            "discarded index [6, 1, 0, 8, 9, 7, 5, 4, 3, 2]\n",
            "10 [6 1 0 8 9 7 5 4 3 2]\n",
            "discarded index [6, 1, 0, 8, 9, 7, 5, 4, 3, 2]\n",
            "10 [6 1 0 8 9 7 5 4 3 2]\n",
            "discarded index [6, 1, 0, 8, 9, 7, 5, 4, 3, 2]\n",
            "10 [6 1 0 8 9 7 5 4 3 2]\n",
            "discarded index [6, 1, 0, 8, 9, 7, 5, 4, 3, 2]\n",
            "10 [6 1 0 8 9 7 5 4 3 2]\n",
            "discarded index [6, 1, 0, 8, 9, 7, 5, 4, 3, 2]\n",
            "10 [6 1 0 8 9 7 5 4 3 2]\n",
            "discarded index [6, 1, 0, 8, 9, 7, 5, 4, 3, 2]\n",
            "10 [6 1 0 8 9 7 5 4 3 2]\n",
            "discarded index [6, 1, 0, 8, 9, 7, 5, 4, 3, 2]\n",
            "10 [6 1 0 8 9 7 5 4 3 2]\n",
            "discarded index [6, 1, 0, 8, 9, 7, 5, 4, 3, 2]\n",
            "10 [6 1 0 8 9 7 5 4 3 2]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 110, bulyan: at fang n_at 10 e 110 | val loss 1.9222 val acc 28.1859 best val_acc 28.449675\n",
            "discarded index [5, 7, 1, 2, 9, 6, 8, 0, 4, 3]\n",
            "10 [5 7 1 2 9 6 8 0 4 3]\n",
            "discarded index [5, 7, 1, 2, 9, 6, 8, 0, 4, 3]\n",
            "10 [5 7 1 2 9 6 8 0 4 3]\n",
            "discarded index [5, 7, 1, 2, 9, 6, 8, 0, 4, 3]\n",
            "10 [5 7 1 2 9 6 8 0 4 3]\n",
            "discarded index [5, 7, 1, 2, 9, 6, 8, 0, 4, 3]\n",
            "10 [5 7 1 2 9 6 8 0 4 3]\n",
            "discarded index [5, 7, 1, 2, 9, 6, 8, 0, 4, 3]\n",
            "10 [5 7 1 2 9 6 8 0 4 3]\n",
            "discarded index [5, 7, 1, 2, 9, 6, 8, 0, 4, 3]\n",
            "10 [5 7 1 2 9 6 8 0 4 3]\n",
            "discarded index [5, 7, 1, 2, 9, 6, 8, 0, 4, 3]\n",
            "10 [5 7 1 2 9 6 8 0 4 3]\n",
            "discarded index [5, 7, 1, 2, 9, 6, 8, 0, 4, 3]\n",
            "10 [5 7 1 2 9 6 8 0 4 3]\n",
            "discarded index [5, 7, 1, 2, 9, 6, 8, 0, 4, 3]\n",
            "10 [5 7 1 2 9 6 8 0 4 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 111, bulyan: at fang n_at 10 e 111 | val loss 2.0013 val acc 23.9651 best val_acc 28.449675\n",
            "discarded index [0, 3, 9, 8, 1, 4, 7, 6, 2, 5]\n",
            "10 [0 3 9 8 1 4 7 6 2 5]\n",
            "discarded index [0, 3, 9, 8, 1, 4, 7, 6, 2, 5]\n",
            "10 [0 3 9 8 1 4 7 6 2 5]\n",
            "discarded index [0, 3, 9, 8, 1, 4, 7, 6, 2, 5]\n",
            "10 [0 3 9 8 1 4 7 6 2 5]\n",
            "discarded index [0, 3, 9, 8, 1, 4, 7, 6, 2, 5]\n",
            "10 [0 3 9 8 1 4 7 6 2 5]\n",
            "discarded index [0, 3, 9, 8, 1, 4, 7, 6, 2, 5]\n",
            "10 [0 3 9 8 1 4 7 6 2 5]\n",
            "discarded index [0, 3, 9, 8, 1, 4, 7, 6, 2, 5]\n",
            "10 [0 3 9 8 1 4 7 6 2 5]\n",
            "discarded index [0, 3, 9, 8, 1, 4, 7, 6, 2, 5]\n",
            "10 [0 3 9 8 1 4 7 6 2 5]\n",
            "discarded index [0, 3, 9, 8, 1, 4, 7, 6, 2, 5]\n",
            "10 [0 3 9 8 1 4 7 6 2 5]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 112, bulyan: at fang n_at 10 e 112 | val loss 2.1018 val acc 23.0925 best val_acc 28.449675\n",
            "discarded index [5, 1, 6, 0, 4, 3, 9, 8, 7, 2]\n",
            "10 [5 1 6 0 4 3 9 8 7 2]\n",
            "discarded index [5, 1, 6, 0, 4, 3, 9, 8, 7, 2]\n",
            "10 [5 1 6 0 4 3 9 8 7 2]\n",
            "discarded index [5, 1, 6, 0, 4, 3, 9, 8, 7, 2]\n",
            "10 [5 1 6 0 4 3 9 8 7 2]\n",
            "discarded index [5, 1, 6, 0, 4, 3, 9, 8, 7, 2]\n",
            "10 [5 1 6 0 4 3 9 8 7 2]\n",
            "discarded index [5, 1, 6, 0, 4, 3, 9, 8, 7, 2]\n",
            "10 [5 1 6 0 4 3 9 8 7 2]\n",
            "discarded index [5, 1, 6, 0, 4, 3, 9, 8, 7, 2]\n",
            "10 [5 1 6 0 4 3 9 8 7 2]\n",
            "discarded index [5, 1, 6, 0, 4, 3, 9, 8, 7, 2]\n",
            "10 [5 1 6 0 4 3 9 8 7 2]\n",
            "discarded index [5, 1, 6, 0, 4, 3, 9, 8, 7, 2]\n",
            "10 [5 1 6 0 4 3 9 8 7 2]\n",
            "discarded index [5, 1, 6, 0, 4, 3, 9, 8, 7, 2]\n",
            "10 [5 1 6 0 4 3 9 8 7 2]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 113, bulyan: at fang n_at 10 e 113 | val loss 2.0967 val acc 20.6981 best val_acc 28.449675\n",
            "discarded index [0, 7, 6, 5, 3, 4, 1, 9, 8, 2]\n",
            "10 [0 7 6 5 3 4 1 9 8 2]\n",
            "discarded index [0, 7, 6, 5, 3, 4, 1, 9, 8, 2]\n",
            "10 [0 7 6 5 3 4 1 9 8 2]\n",
            "discarded index [0, 7, 6, 5, 3, 4, 1, 9, 8, 2]\n",
            "10 [0 7 6 5 3 4 1 9 8 2]\n",
            "discarded index [0, 7, 6, 5, 3, 4, 1, 9, 8, 2]\n",
            "10 [0 7 6 5 3 4 1 9 8 2]\n",
            "discarded index [0, 7, 6, 5, 3, 4, 1, 9, 8, 2]\n",
            "10 [0 7 6 5 3 4 1 9 8 2]\n",
            "discarded index [0, 7, 6, 5, 3, 4, 1, 9, 8, 2]\n",
            "10 [0 7 6 5 3 4 1 9 8 2]\n",
            "discarded index [0, 7, 6, 5, 3, 4, 1, 9, 8, 2]\n",
            "10 [0 7 6 5 3 4 1 9 8 2]\n",
            "discarded index [0, 7, 6, 5, 3, 4, 1, 9, 8, 2]\n",
            "10 [0 7 6 5 3 4 1 9 8 2]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 114, bulyan: at fang n_at 10 e 114 | val loss 1.9535 val acc 30.0528 best val_acc 30.052760\n",
            "discarded index [6, 9, 0, 3, 8, 5, 7, 1, 2, 4]\n",
            "10 [6 9 0 3 8 5 7 1 2 4]\n",
            "discarded index [6, 9, 0, 3, 8, 5, 7, 1, 2, 4]\n",
            "10 [6 9 0 3 8 5 7 1 2 4]\n",
            "discarded index [6, 9, 0, 3, 8, 5, 7, 1, 2, 4]\n",
            "10 [6 9 0 3 8 5 7 1 2 4]\n",
            "discarded index [6, 9, 0, 3, 8, 5, 7, 1, 2, 4]\n",
            "10 [6 9 0 3 8 5 7 1 2 4]\n",
            "discarded index [6, 9, 0, 3, 8, 5, 7, 1, 2, 4]\n",
            "10 [6 9 0 3 8 5 7 1 2 4]\n",
            "discarded index [6, 9, 0, 3, 8, 5, 7, 1, 2, 4]\n",
            "10 [6 9 0 3 8 5 7 1 2 4]\n",
            "discarded index [6, 9, 0, 3, 8, 5, 7, 1, 2, 4]\n",
            "10 [6 9 0 3 8 5 7 1 2 4]\n",
            "discarded index [6, 9, 0, 3, 8, 5, 7, 1, 2, 4]\n",
            "10 [6 9 0 3 8 5 7 1 2 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 115, bulyan: at fang n_at 10 e 115 | val loss 1.8748 val acc 29.7890 best val_acc 30.052760\n",
            "discarded index [9, 8, 6, 2, 4, 0, 1, 7, 5, 3]\n",
            "10 [9 8 6 2 4 0 1 7 5 3]\n",
            "discarded index [9, 8, 6, 2, 4, 0, 1, 7, 5, 3]\n",
            "10 [9 8 6 2 4 0 1 7 5 3]\n",
            "discarded index [9, 8, 6, 2, 4, 0, 1, 7, 5, 3]\n",
            "10 [9 8 6 2 4 0 1 7 5 3]\n",
            "discarded index [9, 8, 6, 2, 4, 0, 1, 7, 5, 3]\n",
            "10 [9 8 6 2 4 0 1 7 5 3]\n",
            "discarded index [9, 8, 6, 2, 4, 0, 1, 7, 5, 3]\n",
            "10 [9 8 6 2 4 0 1 7 5 3]\n",
            "discarded index [9, 8, 6, 2, 4, 0, 1, 7, 5, 3]\n",
            "10 [9 8 6 2 4 0 1 7 5 3]\n",
            "discarded index [9, 8, 6, 2, 4, 0, 1, 7, 5, 3]\n",
            "10 [9 8 6 2 4 0 1 7 5 3]\n",
            "discarded index [9, 8, 6, 2, 4, 0, 1, 7, 5, 3]\n",
            "10 [9 8 6 2 4 0 1 7 5 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 116, bulyan: at fang n_at 10 e 116 | val loss 1.8605 val acc 30.0122 best val_acc 30.052760\n",
            "discarded index [7, 1, 9, 0, 8, 2, 4, 5, 3, 6]\n",
            "10 [7 1 9 0 8 2 4 5 3 6]\n",
            "discarded index [7, 1, 9, 0, 8, 2, 4, 5, 3, 6]\n",
            "10 [7 1 9 0 8 2 4 5 3 6]\n",
            "discarded index [7, 1, 9, 0, 8, 2, 4, 5, 3, 6]\n",
            "10 [7 1 9 0 8 2 4 5 3 6]\n",
            "discarded index [7, 1, 9, 0, 8, 2, 4, 5, 3, 6]\n",
            "10 [7 1 9 0 8 2 4 5 3 6]\n",
            "discarded index [7, 1, 9, 0, 8, 2, 4, 5, 3, 6]\n",
            "10 [7 1 9 0 8 2 4 5 3 6]\n",
            "discarded index [7, 1, 9, 0, 8, 2, 4, 5, 3, 6]\n",
            "10 [7 1 9 0 8 2 4 5 3 6]\n",
            "discarded index [7, 1, 9, 0, 8, 2, 4, 5, 3, 6]\n",
            "10 [7 1 9 0 8 2 4 5 3 6]\n",
            "discarded index [7, 1, 9, 0, 8, 2, 4, 5, 3, 6]\n",
            "10 [7 1 9 0 8 2 4 5 3 6]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 117, bulyan: at fang n_at 10 e 117 | val loss 1.8504 val acc 30.9659 best val_acc 30.965909\n",
            "discarded index [5, 8, 9, 6, 1, 0, 4, 2, 7, 3]\n",
            "10 [5 8 9 6 1 0 4 2 7 3]\n",
            "discarded index [5, 8, 9, 6, 1, 0, 4, 2, 7, 3]\n",
            "10 [5 8 9 6 1 0 4 2 7 3]\n",
            "discarded index [5, 8, 9, 6, 1, 0, 4, 2, 7, 3]\n",
            "10 [5 8 9 6 1 0 4 2 7 3]\n",
            "discarded index [5, 8, 9, 6, 1, 0, 4, 2, 7, 3]\n",
            "10 [5 8 9 6 1 0 4 2 7 3]\n",
            "discarded index [5, 8, 9, 6, 1, 0, 4, 2, 7, 3]\n",
            "10 [5 8 9 6 1 0 4 2 7 3]\n",
            "discarded index [5, 8, 9, 6, 1, 0, 4, 2, 7, 3]\n",
            "10 [5 8 9 6 1 0 4 2 7 3]\n",
            "discarded index [5, 8, 9, 6, 1, 0, 4, 2, 7, 3]\n",
            "10 [5 8 9 6 1 0 4 2 7 3]\n",
            "discarded index [5, 8, 9, 6, 1, 0, 4, 2, 7, 3]\n",
            "10 [5 8 9 6 1 0 4 2 7 3]\n",
            "discarded index [5, 8, 9, 6, 1, 0, 4, 2, 7, 3]\n",
            "10 [5 8 9 6 1 0 4 2 7 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 118, bulyan: at fang n_at 10 e 118 | val loss 1.8963 val acc 28.7946 best val_acc 30.965909\n",
            "discarded index [0, 7, 1, 9, 6, 3, 4, 8, 5, 2]\n",
            "10 [0 7 1 9 6 3 4 8 5 2]\n",
            "discarded index [0, 7, 1, 9, 6, 3, 4, 8, 5, 2]\n",
            "10 [0 7 1 9 6 3 4 8 5 2]\n",
            "discarded index [0, 7, 1, 9, 6, 3, 4, 8, 5, 2]\n",
            "10 [0 7 1 9 6 3 4 8 5 2]\n",
            "discarded index [0, 7, 1, 9, 6, 3, 4, 8, 5, 2]\n",
            "10 [0 7 1 9 6 3 4 8 5 2]\n",
            "discarded index [0, 7, 1, 9, 6, 3, 4, 8, 5, 2]\n",
            "10 [0 7 1 9 6 3 4 8 5 2]\n",
            "discarded index [0, 7, 1, 9, 6, 3, 4, 8, 5, 2]\n",
            "10 [0 7 1 9 6 3 4 8 5 2]\n",
            "discarded index [0, 7, 1, 9, 6, 3, 4, 8, 5, 2]\n",
            "10 [0 7 1 9 6 3 4 8 5 2]\n",
            "discarded index [0, 7, 1, 9, 6, 3, 4, 8, 5, 2]\n",
            "10 [0 7 1 9 6 3 4 8 5 2]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 119, bulyan: at fang n_at 10 e 119 | val loss 1.9424 val acc 29.9716 best val_acc 30.965909\n",
            "discarded index [9, 6, 0, 8, 5, 3, 1, 4, 2, 7]\n",
            "10 [9 6 0 8 5 3 1 4 2 7]\n",
            "discarded index [9, 6, 0, 8, 5, 3, 1, 4, 2, 7]\n",
            "10 [9 6 0 8 5 3 1 4 2 7]\n",
            "discarded index [9, 6, 0, 8, 5, 3, 1, 4, 2, 7]\n",
            "10 [9 6 0 8 5 3 1 4 2 7]\n",
            "discarded index [9, 6, 0, 8, 5, 3, 1, 4, 2, 7]\n",
            "10 [9 6 0 8 5 3 1 4 2 7]\n",
            "discarded index [9, 6, 0, 8, 5, 3, 1, 4, 2, 7]\n",
            "10 [9 6 0 8 5 3 1 4 2 7]\n",
            "discarded index [9, 6, 0, 8, 5, 3, 1, 4, 2, 7]\n",
            "10 [9 6 0 8 5 3 1 4 2 7]\n",
            "discarded index [9, 6, 0, 8, 5, 3, 1, 4, 2, 7]\n",
            "10 [9 6 0 8 5 3 1 4 2 7]\n",
            "discarded index [9, 6, 0, 8, 5, 3, 1, 4, 2, 7]\n",
            "10 [9 6 0 8 5 3 1 4 2 7]\n",
            "discarded index [9, 6, 0, 8, 5, 3, 1, 4, 2, 7]\n",
            "10 [9 6 0 8 5 3 1 4 2 7]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 120, bulyan: at fang n_at 10 e 120 | val loss 2.1165 val acc 20.4343 best val_acc 30.965909\n",
            "discarded index [6, 4, 0, 5, 2, 1, 3, 7, 8, 9]\n",
            "10 [6 4 0 5 2 1 3 7 8 9]\n",
            "discarded index [6, 4, 0, 5, 2, 1, 3, 7, 8, 9]\n",
            "10 [6 4 0 5 2 1 3 7 8 9]\n",
            "discarded index [6, 4, 0, 5, 2, 1, 3, 7, 8, 9]\n",
            "10 [6 4 0 5 2 1 3 7 8 9]\n",
            "discarded index [6, 4, 0, 5, 2, 1, 3, 7, 8, 9]\n",
            "10 [6 4 0 5 2 1 3 7 8 9]\n",
            "discarded index [6, 4, 0, 5, 2, 1, 3, 7, 8, 9]\n",
            "10 [6 4 0 5 2 1 3 7 8 9]\n",
            "discarded index [6, 4, 0, 5, 2, 1, 3, 7, 8, 9]\n",
            "10 [6 4 0 5 2 1 3 7 8 9]\n",
            "discarded index [6, 4, 0, 5, 2, 1, 3, 7, 8, 9]\n",
            "10 [6 4 0 5 2 1 3 7 8 9]\n",
            "discarded index [6, 4, 0, 5, 2, 1, 3, 7, 8, 9]\n",
            "10 [6 4 0 5 2 1 3 7 8 9]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 121, bulyan: at fang n_at 10 e 121 | val loss 1.9706 val acc 24.8782 best val_acc 30.965909\n",
            "discarded index [0, 6, 4, 7, 8, 2, 9, 1, 5, 3]\n",
            "10 [0 6 4 7 8 2 9 1 5 3]\n",
            "discarded index [0, 6, 4, 7, 8, 2, 9, 1, 5, 3]\n",
            "10 [0 6 4 7 8 2 9 1 5 3]\n",
            "discarded index [0, 6, 4, 7, 8, 2, 9, 1, 5, 3]\n",
            "10 [0 6 4 7 8 2 9 1 5 3]\n",
            "discarded index [0, 6, 4, 7, 8, 2, 9, 1, 5, 3]\n",
            "10 [0 6 4 7 8 2 9 1 5 3]\n",
            "discarded index [0, 6, 4, 7, 8, 2, 9, 1, 5, 3]\n",
            "10 [0 6 4 7 8 2 9 1 5 3]\n",
            "discarded index [0, 6, 4, 7, 8, 2, 9, 1, 5, 3]\n",
            "10 [0 6 4 7 8 2 9 1 5 3]\n",
            "discarded index [0, 6, 4, 7, 8, 2, 9, 1, 5, 3]\n",
            "10 [0 6 4 7 8 2 9 1 5 3]\n",
            "discarded index [0, 6, 4, 7, 8, 2, 9, 1, 5, 3]\n",
            "10 [0 6 4 7 8 2 9 1 5 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 122, bulyan: at fang n_at 10 e 122 | val loss 1.8489 val acc 29.5860 best val_acc 30.965909\n",
            "discarded index [3, 9, 0, 6, 7, 5, 1, 4, 8, 2]\n",
            "10 [3 9 0 6 7 5 1 4 8 2]\n",
            "discarded index [3, 9, 0, 6, 7, 5, 1, 4, 8, 2]\n",
            "10 [3 9 0 6 7 5 1 4 8 2]\n",
            "discarded index [3, 9, 0, 6, 7, 5, 1, 4, 8, 2]\n",
            "10 [3 9 0 6 7 5 1 4 8 2]\n",
            "discarded index [3, 9, 0, 6, 7, 5, 1, 4, 8, 2]\n",
            "10 [3 9 0 6 7 5 1 4 8 2]\n",
            "discarded index [3, 9, 0, 6, 7, 5, 1, 4, 8, 2]\n",
            "10 [3 9 0 6 7 5 1 4 8 2]\n",
            "discarded index [3, 9, 0, 6, 7, 5, 1, 4, 8, 2]\n",
            "10 [3 9 0 6 7 5 1 4 8 2]\n",
            "discarded index [3, 9, 0, 6, 7, 5, 1, 4, 8, 2]\n",
            "10 [3 9 0 6 7 5 1 4 8 2]\n",
            "discarded index [3, 9, 0, 6, 7, 5, 1, 4, 8, 2]\n",
            "10 [3 9 0 6 7 5 1 4 8 2]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 123, bulyan: at fang n_at 10 e 123 | val loss 1.8134 val acc 32.1023 best val_acc 32.102273\n",
            "discarded index [9, 8, 6, 0, 3, 4, 2, 1, 5, 7]\n",
            "10 [9 8 6 0 3 4 2 1 5 7]\n",
            "discarded index [9, 8, 6, 0, 3, 4, 2, 1, 5, 7]\n",
            "10 [9 8 6 0 3 4 2 1 5 7]\n",
            "discarded index [9, 8, 6, 0, 3, 4, 2, 1, 5, 7]\n",
            "10 [9 8 6 0 3 4 2 1 5 7]\n",
            "discarded index [9, 8, 6, 0, 3, 4, 2, 1, 5, 7]\n",
            "10 [9 8 6 0 3 4 2 1 5 7]\n",
            "discarded index [9, 8, 6, 0, 3, 4, 2, 1, 5, 7]\n",
            "10 [9 8 6 0 3 4 2 1 5 7]\n",
            "discarded index [9, 8, 6, 0, 3, 4, 2, 1, 5, 7]\n",
            "10 [9 8 6 0 3 4 2 1 5 7]\n",
            "discarded index [9, 8, 6, 0, 3, 4, 2, 1, 5, 7]\n",
            "10 [9 8 6 0 3 4 2 1 5 7]\n",
            "discarded index [9, 8, 6, 0, 3, 4, 2, 1, 5, 7]\n",
            "10 [9 8 6 0 3 4 2 1 5 7]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 124, bulyan: at fang n_at 10 e 124 | val loss 1.8901 val acc 28.3482 best val_acc 32.102273\n",
            "discarded index [0, 7, 1, 5, 3, 4, 9, 8, 6, 2]\n",
            "10 [0 7 1 5 3 4 9 8 6 2]\n",
            "discarded index [0, 7, 1, 5, 3, 4, 9, 8, 6, 2]\n",
            "10 [0 7 1 5 3 4 9 8 6 2]\n",
            "discarded index [0, 7, 1, 5, 3, 4, 9, 8, 6, 2]\n",
            "10 [0 7 1 5 3 4 9 8 6 2]\n",
            "discarded index [0, 7, 1, 5, 3, 4, 9, 8, 6, 2]\n",
            "10 [0 7 1 5 3 4 9 8 6 2]\n",
            "discarded index [0, 7, 1, 5, 3, 4, 9, 8, 6, 2]\n",
            "10 [0 7 1 5 3 4 9 8 6 2]\n",
            "discarded index [0, 7, 1, 5, 3, 4, 9, 8, 6, 2]\n",
            "10 [0 7 1 5 3 4 9 8 6 2]\n",
            "discarded index [0, 7, 1, 5, 3, 4, 9, 8, 6, 2]\n",
            "10 [0 7 1 5 3 4 9 8 6 2]\n",
            "discarded index [0, 7, 1, 5, 3, 4, 9, 8, 6, 2]\n",
            "10 [0 7 1 5 3 4 9 8 6 2]\n",
            "discarded index [0, 7, 1, 5, 3, 4, 9, 8, 6, 2]\n",
            "10 [0 7 1 5 3 4 9 8 6 2]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 125, bulyan: at fang n_at 10 e 125 | val loss 2.0431 val acc 22.1997 best val_acc 32.102273\n",
            "discarded index [7, 9, 3, 6, 0, 8, 2, 4, 5, 1]\n",
            "10 [7 9 3 6 0 8 2 4 5 1]\n",
            "discarded index [7, 9, 3, 6, 0, 8, 2, 4, 5, 1]\n",
            "10 [7 9 3 6 0 8 2 4 5 1]\n",
            "discarded index [7, 9, 3, 6, 0, 8, 2, 4, 5, 1]\n",
            "10 [7 9 3 6 0 8 2 4 5 1]\n",
            "discarded index [7, 9, 3, 6, 0, 8, 2, 4, 5, 1]\n",
            "10 [7 9 3 6 0 8 2 4 5 1]\n",
            "discarded index [7, 9, 3, 6, 0, 8, 2, 4, 5, 1]\n",
            "10 [7 9 3 6 0 8 2 4 5 1]\n",
            "discarded index [7, 9, 3, 6, 0, 8, 2, 4, 5, 1]\n",
            "10 [7 9 3 6 0 8 2 4 5 1]\n",
            "discarded index [7, 9, 3, 6, 0, 8, 2, 4, 5, 1]\n",
            "10 [7 9 3 6 0 8 2 4 5 1]\n",
            "discarded index [7, 9, 3, 6, 0, 8, 2, 4, 5, 1]\n",
            "10 [7 9 3 6 0 8 2 4 5 1]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 126, bulyan: at fang n_at 10 e 126 | val loss 2.0138 val acc 23.4984 best val_acc 32.102273\n",
            "discarded index [5, 9, 6, 2, 3, 0, 7, 8, 1, 4]\n",
            "10 [5 9 6 2 3 0 7 8 1 4]\n",
            "discarded index [5, 9, 6, 2, 3, 0, 7, 8, 1, 4]\n",
            "10 [5 9 6 2 3 0 7 8 1 4]\n",
            "discarded index [5, 9, 6, 2, 3, 0, 7, 8, 1, 4]\n",
            "10 [5 9 6 2 3 0 7 8 1 4]\n",
            "discarded index [5, 9, 6, 2, 3, 0, 7, 8, 1, 4]\n",
            "10 [5 9 6 2 3 0 7 8 1 4]\n",
            "discarded index [5, 9, 6, 2, 3, 0, 7, 8, 1, 4]\n",
            "10 [5 9 6 2 3 0 7 8 1 4]\n",
            "discarded index [5, 9, 6, 2, 3, 0, 7, 8, 1, 4]\n",
            "10 [5 9 6 2 3 0 7 8 1 4]\n",
            "discarded index [5, 9, 6, 2, 3, 0, 7, 8, 1, 4]\n",
            "10 [5 9 6 2 3 0 7 8 1 4]\n",
            "discarded index [5, 9, 6, 2, 3, 0, 7, 8, 1, 4]\n",
            "10 [5 9 6 2 3 0 7 8 1 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 127, bulyan: at fang n_at 10 e 127 | val loss 1.9043 val acc 27.4351 best val_acc 32.102273\n",
            "discarded index [0, 7, 1, 6, 9, 8, 3, 2, 5, 4]\n",
            "10 [0 7 1 6 9 8 3 2 5 4]\n",
            "discarded index [0, 7, 1, 6, 9, 8, 3, 2, 5, 4]\n",
            "10 [0 7 1 6 9 8 3 2 5 4]\n",
            "discarded index [0, 7, 1, 6, 9, 8, 3, 2, 5, 4]\n",
            "10 [0 7 1 6 9 8 3 2 5 4]\n",
            "discarded index [0, 7, 1, 6, 9, 8, 3, 2, 5, 4]\n",
            "10 [0 7 1 6 9 8 3 2 5 4]\n",
            "discarded index [0, 7, 1, 6, 9, 8, 3, 2, 5, 4]\n",
            "10 [0 7 1 6 9 8 3 2 5 4]\n",
            "discarded index [0, 7, 1, 6, 9, 8, 3, 2, 5, 4]\n",
            "10 [0 7 1 6 9 8 3 2 5 4]\n",
            "discarded index [0, 7, 1, 6, 9, 8, 3, 2, 5, 4]\n",
            "10 [0 7 1 6 9 8 3 2 5 4]\n",
            "discarded index [0, 7, 1, 6, 9, 8, 3, 2, 5, 4]\n",
            "10 [0 7 1 6 9 8 3 2 5 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 128, bulyan: at fang n_at 10 e 128 | val loss 2.0687 val acc 26.6437 best val_acc 32.102273\n",
            "discarded index [1, 0, 6, 3, 8, 7, 2, 9, 5, 4]\n",
            "10 [1 0 6 3 8 7 2 9 5 4]\n",
            "discarded index [1, 0, 6, 3, 8, 7, 2, 9, 5, 4]\n",
            "10 [1 0 6 3 8 7 2 9 5 4]\n",
            "discarded index [1, 0, 6, 3, 8, 7, 2, 9, 5, 4]\n",
            "10 [1 0 6 3 8 7 2 9 5 4]\n",
            "discarded index [1, 0, 6, 3, 8, 7, 2, 9, 5, 4]\n",
            "10 [1 0 6 3 8 7 2 9 5 4]\n",
            "discarded index [1, 0, 6, 3, 8, 7, 2, 9, 5, 4]\n",
            "10 [1 0 6 3 8 7 2 9 5 4]\n",
            "discarded index [1, 0, 6, 3, 8, 7, 2, 9, 5, 4]\n",
            "10 [1 0 6 3 8 7 2 9 5 4]\n",
            "discarded index [1, 0, 6, 3, 8, 7, 2, 9, 5, 4]\n",
            "10 [1 0 6 3 8 7 2 9 5 4]\n",
            "discarded index [1, 0, 6, 3, 8, 7, 2, 9, 5, 4]\n",
            "10 [1 0 6 3 8 7 2 9 5 4]\n",
            "discarded index [1, 0, 6, 3, 8, 7, 2, 9, 5, 4]\n",
            "10 [1 0 6 3 8 7 2 9 5 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 129, bulyan: at fang n_at 10 e 129 | val loss 2.2474 val acc 21.6315 best val_acc 32.102273\n",
            "discarded index [7, 0, 9, 5, 1, 3, 8, 6, 2, 4]\n",
            "10 [7 0 9 5 1 3 8 6 2 4]\n",
            "discarded index [7, 0, 9, 5, 1, 3, 8, 6, 2, 4]\n",
            "10 [7 0 9 5 1 3 8 6 2 4]\n",
            "discarded index [7, 0, 9, 5, 1, 3, 8, 6, 2, 4]\n",
            "10 [7 0 9 5 1 3 8 6 2 4]\n",
            "discarded index [7, 0, 9, 5, 1, 3, 8, 6, 2, 4]\n",
            "10 [7 0 9 5 1 3 8 6 2 4]\n",
            "discarded index [7, 0, 9, 5, 1, 3, 8, 6, 2, 4]\n",
            "10 [7 0 9 5 1 3 8 6 2 4]\n",
            "discarded index [7, 0, 9, 5, 1, 3, 8, 6, 2, 4]\n",
            "10 [7 0 9 5 1 3 8 6 2 4]\n",
            "discarded index [7, 0, 9, 5, 1, 3, 8, 6, 2, 4]\n",
            "10 [7 0 9 5 1 3 8 6 2 4]\n",
            "discarded index [7, 0, 9, 5, 1, 3, 8, 6, 2, 4]\n",
            "10 [7 0 9 5 1 3 8 6 2 4]\n",
            "discarded index [7, 0, 9, 5, 1, 3, 8, 6, 2, 4]\n",
            "10 [7 0 9 5 1 3 8 6 2 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 130, bulyan: at fang n_at 10 e 130 | val loss 2.1762 val acc 17.2484 best val_acc 32.102273\n",
            "discarded index [9, 1, 7, 0, 2, 3, 5, 4, 8, 6]\n",
            "10 [9 1 7 0 2 3 5 4 8 6]\n",
            "discarded index [9, 1, 7, 0, 2, 3, 5, 4, 8, 6]\n",
            "10 [9 1 7 0 2 3 5 4 8 6]\n",
            "discarded index [9, 1, 7, 0, 2, 3, 5, 4, 8, 6]\n",
            "10 [9 1 7 0 2 3 5 4 8 6]\n",
            "discarded index [9, 1, 7, 0, 2, 3, 5, 4, 8, 6]\n",
            "10 [9 1 7 0 2 3 5 4 8 6]\n",
            "discarded index [9, 1, 7, 0, 2, 3, 5, 4, 8, 6]\n",
            "10 [9 1 7 0 2 3 5 4 8 6]\n",
            "discarded index [9, 1, 7, 0, 2, 3, 5, 4, 8, 6]\n",
            "10 [9 1 7 0 2 3 5 4 8 6]\n",
            "discarded index [9, 1, 7, 0, 2, 3, 5, 4, 8, 6]\n",
            "10 [9 1 7 0 2 3 5 4 8 6]\n",
            "discarded index [9, 1, 7, 0, 2, 3, 5, 4, 8, 6]\n",
            "10 [9 1 7 0 2 3 5 4 8 6]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 131, bulyan: at fang n_at 10 e 131 | val loss 2.1391 val acc 21.6721 best val_acc 32.102273\n",
            "discarded index [9, 4, 8, 1, 7, 2, 0, 3, 6, 5]\n",
            "10 [9 4 8 1 7 2 0 3 6 5]\n",
            "discarded index [9, 4, 8, 1, 7, 2, 0, 3, 6, 5]\n",
            "10 [9 4 8 1 7 2 0 3 6 5]\n",
            "discarded index [9, 4, 8, 1, 7, 2, 0, 3, 6, 5]\n",
            "10 [9 4 8 1 7 2 0 3 6 5]\n",
            "discarded index [9, 4, 8, 1, 7, 2, 0, 3, 6, 5]\n",
            "10 [9 4 8 1 7 2 0 3 6 5]\n",
            "discarded index [9, 4, 8, 1, 7, 2, 0, 3, 6, 5]\n",
            "10 [9 4 8 1 7 2 0 3 6 5]\n",
            "discarded index [9, 4, 8, 1, 7, 2, 0, 3, 6, 5]\n",
            "10 [9 4 8 1 7 2 0 3 6 5]\n",
            "discarded index [9, 4, 8, 1, 7, 2, 0, 3, 6, 5]\n",
            "10 [9 4 8 1 7 2 0 3 6 5]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 132, bulyan: at fang n_at 10 e 132 | val loss 1.9888 val acc 26.2175 best val_acc 32.102273\n",
            "discarded index [1, 6, 9, 8, 0, 7, 2, 3, 4, 5]\n",
            "10 [1 6 9 8 0 7 2 3 4 5]\n",
            "discarded index [1, 6, 9, 8, 0, 7, 2, 3, 4, 5]\n",
            "10 [1 6 9 8 0 7 2 3 4 5]\n",
            "discarded index [1, 6, 9, 8, 0, 7, 2, 3, 4, 5]\n",
            "10 [1 6 9 8 0 7 2 3 4 5]\n",
            "discarded index [1, 6, 9, 8, 0, 7, 2, 3, 4, 5]\n",
            "10 [1 6 9 8 0 7 2 3 4 5]\n",
            "discarded index [1, 6, 9, 8, 0, 7, 2, 3, 4, 5]\n",
            "10 [1 6 9 8 0 7 2 3 4 5]\n",
            "discarded index [1, 6, 9, 8, 0, 7, 2, 3, 4, 5]\n",
            "10 [1 6 9 8 0 7 2 3 4 5]\n",
            "discarded index [1, 6, 9, 8, 0, 7, 2, 3, 4, 5]\n",
            "10 [1 6 9 8 0 7 2 3 4 5]\n",
            "discarded index [1, 6, 9, 8, 0, 7, 2, 3, 4, 5]\n",
            "10 [1 6 9 8 0 7 2 3 4 5]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 133, bulyan: at fang n_at 10 e 133 | val loss 1.9218 val acc 26.4407 best val_acc 32.102273\n",
            "discarded index [9, 8, 0, 7, 1, 5, 2, 3, 4, 6]\n",
            "10 [9 8 0 7 1 5 2 3 4 6]\n",
            "discarded index [9, 8, 0, 7, 1, 5, 2, 3, 4, 6]\n",
            "10 [9 8 0 7 1 5 2 3 4 6]\n",
            "discarded index [9, 8, 0, 7, 1, 5, 2, 3, 4, 6]\n",
            "10 [9 8 0 7 1 5 2 3 4 6]\n",
            "discarded index [9, 8, 0, 7, 1, 5, 2, 3, 4, 6]\n",
            "10 [9 8 0 7 1 5 2 3 4 6]\n",
            "discarded index [9, 8, 0, 7, 1, 5, 2, 3, 4, 6]\n",
            "10 [9 8 0 7 1 5 2 3 4 6]\n",
            "discarded index [9, 8, 0, 7, 1, 5, 2, 3, 4, 6]\n",
            "10 [9 8 0 7 1 5 2 3 4 6]\n",
            "discarded index [9, 8, 0, 7, 1, 5, 2, 3, 4, 6]\n",
            "10 [9 8 0 7 1 5 2 3 4 6]\n",
            "discarded index [9, 8, 0, 7, 1, 5, 2, 3, 4, 6]\n",
            "10 [9 8 0 7 1 5 2 3 4 6]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 134, bulyan: at fang n_at 10 e 134 | val loss 1.9012 val acc 30.3977 best val_acc 32.102273\n",
            "discarded index [9, 7, 1, 3, 8, 6, 2, 4, 5, 0]\n",
            "10 [9 7 1 3 8 6 2 4 5 0]\n",
            "discarded index [9, 7, 1, 3, 8, 6, 2, 4, 5, 0]\n",
            "10 [9 7 1 3 8 6 2 4 5 0]\n",
            "discarded index [9, 7, 1, 3, 8, 6, 2, 4, 5, 0]\n",
            "10 [9 7 1 3 8 6 2 4 5 0]\n",
            "discarded index [9, 7, 1, 3, 8, 6, 2, 4, 5, 0]\n",
            "10 [9 7 1 3 8 6 2 4 5 0]\n",
            "discarded index [9, 7, 1, 3, 8, 6, 2, 4, 5, 0]\n",
            "10 [9 7 1 3 8 6 2 4 5 0]\n",
            "discarded index [9, 7, 1, 3, 8, 6, 2, 4, 5, 0]\n",
            "10 [9 7 1 3 8 6 2 4 5 0]\n",
            "discarded index [9, 7, 1, 3, 8, 6, 2, 4, 5, 0]\n",
            "10 [9 7 1 3 8 6 2 4 5 0]\n",
            "discarded index [9, 7, 1, 3, 8, 6, 2, 4, 5, 0]\n",
            "10 [9 7 1 3 8 6 2 4 5 0]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 135, bulyan: at fang n_at 10 e 135 | val loss 2.0445 val acc 23.7419 best val_acc 32.102273\n",
            "discarded index [9, 6, 8, 1, 0, 4, 3, 2, 5, 7]\n",
            "10 [9 6 8 1 0 4 3 2 5 7]\n",
            "discarded index [9, 6, 8, 1, 0, 4, 3, 2, 5, 7]\n",
            "10 [9 6 8 1 0 4 3 2 5 7]\n",
            "discarded index [9, 6, 8, 1, 0, 4, 3, 2, 5, 7]\n",
            "10 [9 6 8 1 0 4 3 2 5 7]\n",
            "discarded index [9, 6, 8, 1, 0, 4, 3, 2, 5, 7]\n",
            "10 [9 6 8 1 0 4 3 2 5 7]\n",
            "discarded index [9, 6, 8, 1, 0, 4, 3, 2, 5, 7]\n",
            "10 [9 6 8 1 0 4 3 2 5 7]\n",
            "discarded index [9, 6, 8, 1, 0, 4, 3, 2, 5, 7]\n",
            "10 [9 6 8 1 0 4 3 2 5 7]\n",
            "discarded index [9, 6, 8, 1, 0, 4, 3, 2, 5, 7]\n",
            "10 [9 6 8 1 0 4 3 2 5 7]\n",
            "discarded index [9, 6, 8, 1, 0, 4, 3, 2, 5, 7]\n",
            "10 [9 6 8 1 0 4 3 2 5 7]\n",
            "discarded index [9, 6, 8, 1, 0, 4, 3, 2, 5, 7]\n",
            "10 [9 6 8 1 0 4 3 2 5 7]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 136, bulyan: at fang n_at 10 e 136 | val loss 2.4723 val acc 18.9123 best val_acc 32.102273\n",
            "discarded index [5, 9, 6, 8, 0, 2, 1, 7, 4, 3]\n",
            "10 [5 9 6 8 0 2 1 7 4 3]\n",
            "discarded index [5, 9, 6, 8, 0, 2, 1, 7, 4, 3]\n",
            "10 [5 9 6 8 0 2 1 7 4 3]\n",
            "discarded index [5, 9, 6, 8, 0, 2, 1, 7, 4, 3]\n",
            "10 [5 9 6 8 0 2 1 7 4 3]\n",
            "discarded index [5, 9, 6, 8, 0, 2, 1, 7, 4, 3]\n",
            "10 [5 9 6 8 0 2 1 7 4 3]\n",
            "discarded index [5, 9, 6, 8, 0, 2, 1, 7, 4, 3]\n",
            "10 [5 9 6 8 0 2 1 7 4 3]\n",
            "discarded index [5, 9, 6, 8, 0, 2, 1, 7, 4, 3]\n",
            "10 [5 9 6 8 0 2 1 7 4 3]\n",
            "discarded index [5, 9, 6, 8, 0, 2, 1, 7, 4, 3]\n",
            "10 [5 9 6 8 0 2 1 7 4 3]\n",
            "discarded index [5, 9, 6, 8, 0, 2, 1, 7, 4, 3]\n",
            "10 [5 9 6 8 0 2 1 7 4 3]\n",
            "discarded index [5, 9, 6, 8, 0, 2, 1, 7, 4, 3]\n",
            "10 [5 9 6 8 0 2 1 7 4 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 137, bulyan: at fang n_at 10 e 137 | val loss 2.2048 val acc 14.4075 best val_acc 32.102273\n",
            "discarded index [6, 7, 4, 8, 0, 9, 1, 2, 3, 5]\n",
            "10 [6 7 4 8 0 9 1 2 3 5]\n",
            "discarded index [6, 7, 4, 8, 0, 9, 1, 2, 3, 5]\n",
            "10 [6 7 4 8 0 9 1 2 3 5]\n",
            "discarded index [6, 7, 4, 8, 0, 9, 1, 2, 3, 5]\n",
            "10 [6 7 4 8 0 9 1 2 3 5]\n",
            "discarded index [6, 7, 4, 8, 0, 9, 1, 2, 3, 5]\n",
            "10 [6 7 4 8 0 9 1 2 3 5]\n",
            "discarded index [6, 7, 4, 8, 0, 9, 1, 2, 3, 5]\n",
            "10 [6 7 4 8 0 9 1 2 3 5]\n",
            "discarded index [6, 7, 4, 8, 0, 9, 1, 2, 3, 5]\n",
            "10 [6 7 4 8 0 9 1 2 3 5]\n",
            "discarded index [6, 7, 4, 8, 0, 9, 1, 2, 3, 5]\n",
            "10 [6 7 4 8 0 9 1 2 3 5]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 138, bulyan: at fang n_at 10 e 138 | val loss 2.1507 val acc 20.0284 best val_acc 32.102273\n",
            "discarded index [6, 7, 4, 8, 0, 9, 5, 1, 3, 2]\n",
            "10 [6 7 4 8 0 9 5 1 3 2]\n",
            "discarded index [6, 7, 4, 8, 0, 9, 5, 1, 3, 2]\n",
            "10 [6 7 4 8 0 9 5 1 3 2]\n",
            "discarded index [6, 7, 4, 8, 0, 9, 5, 1, 3, 2]\n",
            "10 [6 7 4 8 0 9 5 1 3 2]\n",
            "discarded index [6, 7, 4, 8, 0, 9, 5, 1, 3, 2]\n",
            "10 [6 7 4 8 0 9 5 1 3 2]\n",
            "discarded index [6, 7, 4, 8, 0, 9, 5, 1, 3, 2]\n",
            "10 [6 7 4 8 0 9 5 1 3 2]\n",
            "discarded index [6, 7, 4, 8, 0, 9, 5, 1, 3, 2]\n",
            "10 [6 7 4 8 0 9 5 1 3 2]\n",
            "discarded index [6, 7, 4, 8, 0, 9, 5, 1, 3, 2]\n",
            "10 [6 7 4 8 0 9 5 1 3 2]\n",
            "discarded index [6, 7, 4, 8, 0, 9, 5, 1, 3, 2]\n",
            "10 [6 7 4 8 0 9 5 1 3 2]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 139, bulyan: at fang n_at 10 e 139 | val loss 2.1007 val acc 24.1680 best val_acc 32.102273\n",
            "discarded index [6, 7, 1, 5, 3, 9, 4, 0, 8, 2]\n",
            "10 [6 7 1 5 3 9 4 0 8 2]\n",
            "discarded index [6, 7, 1, 5, 3, 9, 4, 0, 8, 2]\n",
            "10 [6 7 1 5 3 9 4 0 8 2]\n",
            "discarded index [6, 7, 1, 5, 3, 9, 4, 0, 8, 2]\n",
            "10 [6 7 1 5 3 9 4 0 8 2]\n",
            "discarded index [6, 7, 1, 5, 3, 9, 4, 0, 8, 2]\n",
            "10 [6 7 1 5 3 9 4 0 8 2]\n",
            "discarded index [6, 7, 1, 5, 3, 9, 4, 0, 8, 2]\n",
            "10 [6 7 1 5 3 9 4 0 8 2]\n",
            "discarded index [6, 7, 1, 5, 3, 9, 4, 0, 8, 2]\n",
            "10 [6 7 1 5 3 9 4 0 8 2]\n",
            "discarded index [6, 7, 1, 5, 3, 9, 4, 0, 8, 2]\n",
            "10 [6 7 1 5 3 9 4 0 8 2]\n",
            "discarded index [6, 7, 1, 5, 3, 9, 4, 0, 8, 2]\n",
            "10 [6 7 1 5 3 9 4 0 8 2]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 140, bulyan: at fang n_at 10 e 140 | val loss 2.0722 val acc 24.6550 best val_acc 32.102273\n",
            "discarded index [5, 6, 0, 7, 9, 2, 8, 4, 3, 1]\n",
            "10 [5 6 0 7 9 2 8 4 3 1]\n",
            "discarded index [5, 6, 0, 7, 9, 2, 8, 4, 3, 1]\n",
            "10 [5 6 0 7 9 2 8 4 3 1]\n",
            "discarded index [5, 6, 0, 7, 9, 2, 8, 4, 3, 1]\n",
            "10 [5 6 0 7 9 2 8 4 3 1]\n",
            "discarded index [5, 6, 0, 7, 9, 2, 8, 4, 3, 1]\n",
            "10 [5 6 0 7 9 2 8 4 3 1]\n",
            "discarded index [5, 6, 0, 7, 9, 2, 8, 4, 3, 1]\n",
            "10 [5 6 0 7 9 2 8 4 3 1]\n",
            "discarded index [5, 6, 0, 7, 9, 2, 8, 4, 3, 1]\n",
            "10 [5 6 0 7 9 2 8 4 3 1]\n",
            "discarded index [5, 6, 0, 7, 9, 2, 8, 4, 3, 1]\n",
            "10 [5 6 0 7 9 2 8 4 3 1]\n",
            "discarded index [5, 6, 0, 7, 9, 2, 8, 4, 3, 1]\n",
            "10 [5 6 0 7 9 2 8 4 3 1]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 141, bulyan: at fang n_at 10 e 141 | val loss 2.0556 val acc 26.8263 best val_acc 32.102273\n",
            "discarded index [6, 5, 8, 7, 0, 1, 9, 2, 4, 3]\n",
            "10 [6 5 8 7 0 1 9 2 4 3]\n",
            "discarded index [6, 5, 8, 7, 0, 1, 9, 2, 4, 3]\n",
            "10 [6 5 8 7 0 1 9 2 4 3]\n",
            "discarded index [6, 5, 8, 7, 0, 1, 9, 2, 4, 3]\n",
            "10 [6 5 8 7 0 1 9 2 4 3]\n",
            "discarded index [6, 5, 8, 7, 0, 1, 9, 2, 4, 3]\n",
            "10 [6 5 8 7 0 1 9 2 4 3]\n",
            "discarded index [6, 5, 8, 7, 0, 1, 9, 2, 4, 3]\n",
            "10 [6 5 8 7 0 1 9 2 4 3]\n",
            "discarded index [6, 5, 8, 7, 0, 1, 9, 2, 4, 3]\n",
            "10 [6 5 8 7 0 1 9 2 4 3]\n",
            "discarded index [6, 5, 8, 7, 0, 1, 9, 2, 4, 3]\n",
            "10 [6 5 8 7 0 1 9 2 4 3]\n",
            "discarded index [6, 5, 8, 7, 0, 1, 9, 2, 4, 3]\n",
            "10 [6 5 8 7 0 1 9 2 4 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 142, bulyan: at fang n_at 10 e 142 | val loss 2.0913 val acc 24.5130 best val_acc 32.102273\n",
            "discarded index [1, 9, 5, 3, 6, 2, 4, 8, 7, 0]\n",
            "10 [1 9 5 3 6 2 4 8 7 0]\n",
            "discarded index [1, 9, 5, 3, 6, 2, 4, 8, 7, 0]\n",
            "10 [1 9 5 3 6 2 4 8 7 0]\n",
            "discarded index [1, 9, 5, 3, 6, 2, 4, 8, 7, 0]\n",
            "10 [1 9 5 3 6 2 4 8 7 0]\n",
            "discarded index [1, 9, 5, 3, 6, 2, 4, 8, 7, 0]\n",
            "10 [1 9 5 3 6 2 4 8 7 0]\n",
            "discarded index [1, 9, 5, 3, 6, 2, 4, 8, 7, 0]\n",
            "10 [1 9 5 3 6 2 4 8 7 0]\n",
            "discarded index [1, 9, 5, 3, 6, 2, 4, 8, 7, 0]\n",
            "10 [1 9 5 3 6 2 4 8 7 0]\n",
            "discarded index [1, 9, 5, 3, 6, 2, 4, 8, 7, 0]\n",
            "10 [1 9 5 3 6 2 4 8 7 0]\n",
            "discarded index [1, 9, 5, 3, 6, 2, 4, 8, 7, 0]\n",
            "10 [1 9 5 3 6 2 4 8 7 0]\n",
            "discarded index [1, 9, 5, 3, 6, 2, 4, 8, 7, 0]\n",
            "10 [1 9 5 3 6 2 4 8 7 0]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 143, bulyan: at fang n_at 10 e 143 | val loss 2.1431 val acc 20.9619 best val_acc 32.102273\n",
            "discarded index [6, 9, 8, 1, 5, 7, 2, 4, 0, 3]\n",
            "10 [6 9 8 1 5 7 2 4 0 3]\n",
            "discarded index [6, 9, 8, 1, 5, 7, 2, 4, 0, 3]\n",
            "10 [6 9 8 1 5 7 2 4 0 3]\n",
            "discarded index [6, 9, 8, 1, 5, 7, 2, 4, 0, 3]\n",
            "10 [6 9 8 1 5 7 2 4 0 3]\n",
            "discarded index [6, 9, 8, 1, 5, 7, 2, 4, 0, 3]\n",
            "10 [6 9 8 1 5 7 2 4 0 3]\n",
            "discarded index [6, 9, 8, 1, 5, 7, 2, 4, 0, 3]\n",
            "10 [6 9 8 1 5 7 2 4 0 3]\n",
            "discarded index [6, 9, 8, 1, 5, 7, 2, 4, 0, 3]\n",
            "10 [6 9 8 1 5 7 2 4 0 3]\n",
            "discarded index [6, 9, 8, 1, 5, 7, 2, 4, 0, 3]\n",
            "10 [6 9 8 1 5 7 2 4 0 3]\n",
            "discarded index [6, 9, 8, 1, 5, 7, 2, 4, 0, 3]\n",
            "10 [6 9 8 1 5 7 2 4 0 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 144, bulyan: at fang n_at 10 e 144 | val loss 2.0214 val acc 25.1826 best val_acc 32.102273\n",
            "discarded index [6, 8, 9, 1, 4, 5, 3, 2, 0, 7]\n",
            "10 [6 8 9 1 4 5 3 2 0 7]\n",
            "discarded index [6, 8, 9, 1, 4, 5, 3, 2, 0, 7]\n",
            "10 [6 8 9 1 4 5 3 2 0 7]\n",
            "discarded index [6, 8, 9, 1, 4, 5, 3, 2, 0, 7]\n",
            "10 [6 8 9 1 4 5 3 2 0 7]\n",
            "discarded index [6, 8, 9, 1, 4, 5, 3, 2, 0, 7]\n",
            "10 [6 8 9 1 4 5 3 2 0 7]\n",
            "discarded index [6, 8, 9, 1, 4, 5, 3, 2, 0, 7]\n",
            "10 [6 8 9 1 4 5 3 2 0 7]\n",
            "discarded index [6, 8, 9, 1, 4, 5, 3, 2, 0, 7]\n",
            "10 [6 8 9 1 4 5 3 2 0 7]\n",
            "discarded index [6, 8, 9, 1, 4, 5, 3, 2, 0, 7]\n",
            "10 [6 8 9 1 4 5 3 2 0 7]\n",
            "discarded index [6, 8, 9, 1, 4, 5, 3, 2, 0, 7]\n",
            "10 [6 8 9 1 4 5 3 2 0 7]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 145, bulyan: at fang n_at 10 e 145 | val loss 1.9521 val acc 28.9570 best val_acc 32.102273\n",
            "discarded index [8, 6, 5, 1, 3, 9, 0, 7, 2, 4]\n",
            "10 [8 6 5 1 3 9 0 7 2 4]\n",
            "discarded index [8, 6, 5, 1, 3, 9, 0, 7, 2, 4]\n",
            "10 [8 6 5 1 3 9 0 7 2 4]\n",
            "discarded index [8, 6, 5, 1, 3, 9, 0, 7, 2, 4]\n",
            "10 [8 6 5 1 3 9 0 7 2 4]\n",
            "discarded index [8, 6, 5, 1, 3, 9, 0, 7, 2, 4]\n",
            "10 [8 6 5 1 3 9 0 7 2 4]\n",
            "discarded index [8, 6, 5, 1, 3, 9, 0, 7, 2, 4]\n",
            "10 [8 6 5 1 3 9 0 7 2 4]\n",
            "discarded index [8, 6, 5, 1, 3, 9, 0, 7, 2, 4]\n",
            "10 [8 6 5 1 3 9 0 7 2 4]\n",
            "discarded index [8, 6, 5, 1, 3, 9, 0, 7, 2, 4]\n",
            "10 [8 6 5 1 3 9 0 7 2 4]\n",
            "discarded index [8, 6, 5, 1, 3, 9, 0, 7, 2, 4]\n",
            "10 [8 6 5 1 3 9 0 7 2 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 146, bulyan: at fang n_at 10 e 146 | val loss 1.9039 val acc 29.8093 best val_acc 32.102273\n",
            "discarded index [6, 8, 0, 9, 5, 7, 1, 2, 3, 4]\n",
            "10 [6 8 0 9 5 7 1 2 3 4]\n",
            "discarded index [6, 8, 0, 9, 5, 7, 1, 2, 3, 4]\n",
            "10 [6 8 0 9 5 7 1 2 3 4]\n",
            "discarded index [6, 8, 0, 9, 5, 7, 1, 2, 3, 4]\n",
            "10 [6 8 0 9 5 7 1 2 3 4]\n",
            "discarded index [6, 8, 0, 9, 5, 7, 1, 2, 3, 4]\n",
            "10 [6 8 0 9 5 7 1 2 3 4]\n",
            "discarded index [6, 8, 0, 9, 5, 7, 1, 2, 3, 4]\n",
            "10 [6 8 0 9 5 7 1 2 3 4]\n",
            "discarded index [6, 8, 0, 9, 5, 7, 1, 2, 3, 4]\n",
            "10 [6 8 0 9 5 7 1 2 3 4]\n",
            "discarded index [6, 8, 0, 9, 5, 7, 1, 2, 3, 4]\n",
            "10 [6 8 0 9 5 7 1 2 3 4]\n",
            "discarded index [6, 8, 0, 9, 5, 7, 1, 2, 3, 4]\n",
            "10 [6 8 0 9 5 7 1 2 3 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 147, bulyan: at fang n_at 10 e 147 | val loss 1.9122 val acc 29.0179 best val_acc 32.102273\n",
            "discarded index [6, 7, 8, 9, 4, 3, 2, 1, 5, 0]\n",
            "10 [6 7 8 9 4 3 2 1 5 0]\n",
            "discarded index [6, 7, 8, 9, 4, 3, 2, 1, 5, 0]\n",
            "10 [6 7 8 9 4 3 2 1 5 0]\n",
            "discarded index [6, 7, 8, 9, 4, 3, 2, 1, 5, 0]\n",
            "10 [6 7 8 9 4 3 2 1 5 0]\n",
            "discarded index [6, 7, 8, 9, 4, 3, 2, 1, 5, 0]\n",
            "10 [6 7 8 9 4 3 2 1 5 0]\n",
            "discarded index [6, 7, 8, 9, 4, 3, 2, 1, 5, 0]\n",
            "10 [6 7 8 9 4 3 2 1 5 0]\n",
            "discarded index [6, 7, 8, 9, 4, 3, 2, 1, 5, 0]\n",
            "10 [6 7 8 9 4 3 2 1 5 0]\n",
            "discarded index [6, 7, 8, 9, 4, 3, 2, 1, 5, 0]\n",
            "10 [6 7 8 9 4 3 2 1 5 0]\n",
            "discarded index [6, 7, 8, 9, 4, 3, 2, 1, 5, 0]\n",
            "10 [6 7 8 9 4 3 2 1 5 0]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 148, bulyan: at fang n_at 10 e 148 | val loss 1.9693 val acc 27.6786 best val_acc 32.102273\n",
            "discarded index [9, 6, 8, 1, 5, 4, 7, 0, 3, 2]\n",
            "10 [9 6 8 1 5 4 7 0 3 2]\n",
            "discarded index [9, 6, 8, 1, 5, 4, 7, 0, 3, 2]\n",
            "10 [9 6 8 1 5 4 7 0 3 2]\n",
            "discarded index [9, 6, 8, 1, 5, 4, 7, 0, 3, 2]\n",
            "10 [9 6 8 1 5 4 7 0 3 2]\n",
            "discarded index [9, 6, 8, 1, 5, 4, 7, 0, 3, 2]\n",
            "10 [9 6 8 1 5 4 7 0 3 2]\n",
            "discarded index [9, 6, 8, 1, 5, 4, 7, 0, 3, 2]\n",
            "10 [9 6 8 1 5 4 7 0 3 2]\n",
            "discarded index [9, 6, 8, 1, 5, 4, 7, 0, 3, 2]\n",
            "10 [9 6 8 1 5 4 7 0 3 2]\n",
            "discarded index [9, 6, 8, 1, 5, 4, 7, 0, 3, 2]\n",
            "10 [9 6 8 1 5 4 7 0 3 2]\n",
            "discarded index [9, 6, 8, 1, 5, 4, 7, 0, 3, 2]\n",
            "10 [9 6 8 1 5 4 7 0 3 2]\n",
            "discarded index [9, 6, 8, 1, 5, 4, 7, 0, 3, 2]\n",
            "10 [9 6 8 1 5 4 7 0 3 2]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 149, bulyan: at fang n_at 10 e 149 | val loss 2.1665 val acc 19.5414 best val_acc 32.102273\n",
            "discarded index [0, 3, 5, 1, 6, 4, 2, 9, 7, 8]\n",
            "10 [0 3 5 1 6 4 2 9 7 8]\n",
            "discarded index [0, 3, 5, 1, 6, 4, 2, 9, 7, 8]\n",
            "10 [0 3 5 1 6 4 2 9 7 8]\n",
            "discarded index [0, 3, 5, 1, 6, 4, 2, 9, 7, 8]\n",
            "10 [0 3 5 1 6 4 2 9 7 8]\n",
            "discarded index [0, 3, 5, 1, 6, 4, 2, 9, 7, 8]\n",
            "10 [0 3 5 1 6 4 2 9 7 8]\n",
            "discarded index [0, 3, 5, 1, 6, 4, 2, 9, 7, 8]\n",
            "10 [0 3 5 1 6 4 2 9 7 8]\n",
            "discarded index [0, 3, 5, 1, 6, 4, 2, 9, 7, 8]\n",
            "10 [0 3 5 1 6 4 2 9 7 8]\n",
            "discarded index [0, 3, 5, 1, 6, 4, 2, 9, 7, 8]\n",
            "10 [0 3 5 1 6 4 2 9 7 8]\n",
            "discarded index [0, 3, 5, 1, 6, 4, 2, 9, 7, 8]\n",
            "10 [0 3 5 1 6 4 2 9 7 8]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 150, bulyan: at fang n_at 10 e 150 | val loss 2.0359 val acc 21.4692 best val_acc 32.102273\n",
            "discarded index [7, 6, 9, 8, 2, 4, 3, 5, 1, 0]\n",
            "10 [7 6 9 8 2 4 3 5 1 0]\n",
            "discarded index [7, 6, 9, 8, 2, 4, 3, 5, 1, 0]\n",
            "10 [7 6 9 8 2 4 3 5 1 0]\n",
            "discarded index [7, 6, 9, 8, 2, 4, 3, 5, 1, 0]\n",
            "10 [7 6 9 8 2 4 3 5 1 0]\n",
            "discarded index [7, 6, 9, 8, 2, 4, 3, 5, 1, 0]\n",
            "10 [7 6 9 8 2 4 3 5 1 0]\n",
            "discarded index [7, 6, 9, 8, 2, 4, 3, 5, 1, 0]\n",
            "10 [7 6 9 8 2 4 3 5 1 0]\n",
            "discarded index [7, 6, 9, 8, 2, 4, 3, 5, 1, 0]\n",
            "10 [7 6 9 8 2 4 3 5 1 0]\n",
            "discarded index [7, 6, 9, 8, 2, 4, 3, 5, 1, 0]\n",
            "10 [7 6 9 8 2 4 3 5 1 0]\n",
            "discarded index [7, 6, 9, 8, 2, 4, 3, 5, 1, 0]\n",
            "10 [7 6 9 8 2 4 3 5 1 0]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 151, bulyan: at fang n_at 10 e 151 | val loss 1.9813 val acc 25.9740 best val_acc 32.102273\n",
            "discarded index [0, 6, 1, 7, 8, 9, 4, 5, 2, 3]\n",
            "10 [0 6 1 7 8 9 4 5 2 3]\n",
            "discarded index [0, 6, 1, 7, 8, 9, 4, 5, 2, 3]\n",
            "10 [0 6 1 7 8 9 4 5 2 3]\n",
            "discarded index [0, 6, 1, 7, 8, 9, 4, 5, 2, 3]\n",
            "10 [0 6 1 7 8 9 4 5 2 3]\n",
            "discarded index [0, 6, 1, 7, 8, 9, 4, 5, 2, 3]\n",
            "10 [0 6 1 7 8 9 4 5 2 3]\n",
            "discarded index [0, 6, 1, 7, 8, 9, 4, 5, 2, 3]\n",
            "10 [0 6 1 7 8 9 4 5 2 3]\n",
            "discarded index [0, 6, 1, 7, 8, 9, 4, 5, 2, 3]\n",
            "10 [0 6 1 7 8 9 4 5 2 3]\n",
            "discarded index [0, 6, 1, 7, 8, 9, 4, 5, 2, 3]\n",
            "10 [0 6 1 7 8 9 4 5 2 3]\n",
            "discarded index [0, 6, 1, 7, 8, 9, 4, 5, 2, 3]\n",
            "10 [0 6 1 7 8 9 4 5 2 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 152, bulyan: at fang n_at 10 e 152 | val loss 1.9019 val acc 31.7370 best val_acc 32.102273\n",
            "discarded index [6, 1, 5, 4, 2, 9, 0, 7, 8, 3]\n",
            "10 [6 1 5 4 2 9 0 7 8 3]\n",
            "discarded index [6, 1, 5, 4, 2, 9, 0, 7, 8, 3]\n",
            "10 [6 1 5 4 2 9 0 7 8 3]\n",
            "discarded index [6, 1, 5, 4, 2, 9, 0, 7, 8, 3]\n",
            "10 [6 1 5 4 2 9 0 7 8 3]\n",
            "discarded index [6, 1, 5, 4, 2, 9, 0, 7, 8, 3]\n",
            "10 [6 1 5 4 2 9 0 7 8 3]\n",
            "discarded index [6, 1, 5, 4, 2, 9, 0, 7, 8, 3]\n",
            "10 [6 1 5 4 2 9 0 7 8 3]\n",
            "discarded index [6, 1, 5, 4, 2, 9, 0, 7, 8, 3]\n",
            "10 [6 1 5 4 2 9 0 7 8 3]\n",
            "discarded index [6, 1, 5, 4, 2, 9, 0, 7, 8, 3]\n",
            "10 [6 1 5 4 2 9 0 7 8 3]\n",
            "discarded index [6, 1, 5, 4, 2, 9, 0, 7, 8, 3]\n",
            "10 [6 1 5 4 2 9 0 7 8 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 153, bulyan: at fang n_at 10 e 153 | val loss 1.8908 val acc 31.6356 best val_acc 32.102273\n",
            "discarded index [5, 0, 8, 3, 1, 7, 6, 4, 9, 2]\n",
            "10 [5 0 8 3 1 7 6 4 9 2]\n",
            "discarded index [5, 0, 8, 3, 1, 7, 6, 4, 9, 2]\n",
            "10 [5 0 8 3 1 7 6 4 9 2]\n",
            "discarded index [5, 0, 8, 3, 1, 7, 6, 4, 9, 2]\n",
            "10 [5 0 8 3 1 7 6 4 9 2]\n",
            "discarded index [5, 0, 8, 3, 1, 7, 6, 4, 9, 2]\n",
            "10 [5 0 8 3 1 7 6 4 9 2]\n",
            "discarded index [5, 0, 8, 3, 1, 7, 6, 4, 9, 2]\n",
            "10 [5 0 8 3 1 7 6 4 9 2]\n",
            "discarded index [5, 0, 8, 3, 1, 7, 6, 4, 9, 2]\n",
            "10 [5 0 8 3 1 7 6 4 9 2]\n",
            "discarded index [5, 0, 8, 3, 1, 7, 6, 4, 9, 2]\n",
            "10 [5 0 8 3 1 7 6 4 9 2]\n",
            "discarded index [5, 0, 8, 3, 1, 7, 6, 4, 9, 2]\n",
            "10 [5 0 8 3 1 7 6 4 9 2]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 154, bulyan: at fang n_at 10 e 154 | val loss 1.9012 val acc 29.4237 best val_acc 32.102273\n",
            "discarded index [6, 9, 8, 0, 1, 7, 3, 2, 5, 4]\n",
            "10 [6 9 8 0 1 7 3 2 5 4]\n",
            "discarded index [6, 9, 8, 0, 1, 7, 3, 2, 5, 4]\n",
            "10 [6 9 8 0 1 7 3 2 5 4]\n",
            "discarded index [6, 9, 8, 0, 1, 7, 3, 2, 5, 4]\n",
            "10 [6 9 8 0 1 7 3 2 5 4]\n",
            "discarded index [6, 9, 8, 0, 1, 7, 3, 2, 5, 4]\n",
            "10 [6 9 8 0 1 7 3 2 5 4]\n",
            "discarded index [6, 9, 8, 0, 1, 7, 3, 2, 5, 4]\n",
            "10 [6 9 8 0 1 7 3 2 5 4]\n",
            "discarded index [6, 9, 8, 0, 1, 7, 3, 2, 5, 4]\n",
            "10 [6 9 8 0 1 7 3 2 5 4]\n",
            "discarded index [6, 9, 8, 0, 1, 7, 3, 2, 5, 4]\n",
            "10 [6 9 8 0 1 7 3 2 5 4]\n",
            "discarded index [6, 9, 8, 0, 1, 7, 3, 2, 5, 4]\n",
            "10 [6 9 8 0 1 7 3 2 5 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 155, bulyan: at fang n_at 10 e 155 | val loss 2.0287 val acc 25.4261 best val_acc 32.102273\n",
            "discarded index [5, 7, 2, 9, 8, 3, 0, 4, 1, 6]\n",
            "10 [5 7 2 9 8 3 0 4 1 6]\n",
            "discarded index [5, 7, 2, 9, 8, 3, 0, 4, 1, 6]\n",
            "10 [5 7 2 9 8 3 0 4 1 6]\n",
            "discarded index [5, 7, 2, 9, 8, 3, 0, 4, 1, 6]\n",
            "10 [5 7 2 9 8 3 0 4 1 6]\n",
            "discarded index [5, 7, 2, 9, 8, 3, 0, 4, 1, 6]\n",
            "10 [5 7 2 9 8 3 0 4 1 6]\n",
            "discarded index [5, 7, 2, 9, 8, 3, 0, 4, 1, 6]\n",
            "10 [5 7 2 9 8 3 0 4 1 6]\n",
            "discarded index [5, 7, 2, 9, 8, 3, 0, 4, 1, 6]\n",
            "10 [5 7 2 9 8 3 0 4 1 6]\n",
            "discarded index [5, 7, 2, 9, 8, 3, 0, 4, 1, 6]\n",
            "10 [5 7 2 9 8 3 0 4 1 6]\n",
            "discarded index [5, 7, 2, 9, 8, 3, 0, 4, 1, 6]\n",
            "10 [5 7 2 9 8 3 0 4 1 6]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 156, bulyan: at fang n_at 10 e 156 | val loss 1.9623 val acc 29.2411 best val_acc 32.102273\n",
            "discarded index [6, 8, 0, 5, 1, 2, 9, 7, 4, 3]\n",
            "10 [6 8 0 5 1 2 9 7 4 3]\n",
            "discarded index [6, 8, 0, 5, 1, 2, 9, 7, 4, 3]\n",
            "10 [6 8 0 5 1 2 9 7 4 3]\n",
            "discarded index [6, 8, 0, 5, 1, 2, 9, 7, 4, 3]\n",
            "10 [6 8 0 5 1 2 9 7 4 3]\n",
            "discarded index [6, 8, 0, 5, 1, 2, 9, 7, 4, 3]\n",
            "10 [6 8 0 5 1 2 9 7 4 3]\n",
            "discarded index [6, 8, 0, 5, 1, 2, 9, 7, 4, 3]\n",
            "10 [6 8 0 5 1 2 9 7 4 3]\n",
            "discarded index [6, 8, 0, 5, 1, 2, 9, 7, 4, 3]\n",
            "10 [6 8 0 5 1 2 9 7 4 3]\n",
            "discarded index [6, 8, 0, 5, 1, 2, 9, 7, 4, 3]\n",
            "10 [6 8 0 5 1 2 9 7 4 3]\n",
            "discarded index [6, 8, 0, 5, 1, 2, 9, 7, 4, 3]\n",
            "10 [6 8 0 5 1 2 9 7 4 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 157, bulyan: at fang n_at 10 e 157 | val loss 1.8591 val acc 31.4935 best val_acc 32.102273\n",
            "discarded index [1, 8, 6, 4, 0, 9, 2, 3, 5, 7]\n",
            "10 [1 8 6 4 0 9 2 3 5 7]\n",
            "discarded index [1, 8, 6, 4, 0, 9, 2, 3, 5, 7]\n",
            "10 [1 8 6 4 0 9 2 3 5 7]\n",
            "discarded index [1, 8, 6, 4, 0, 9, 2, 3, 5, 7]\n",
            "10 [1 8 6 4 0 9 2 3 5 7]\n",
            "discarded index [1, 8, 6, 4, 0, 9, 2, 3, 5, 7]\n",
            "10 [1 8 6 4 0 9 2 3 5 7]\n",
            "discarded index [1, 8, 6, 4, 0, 9, 2, 3, 5, 7]\n",
            "10 [1 8 6 4 0 9 2 3 5 7]\n",
            "discarded index [1, 8, 6, 4, 0, 9, 2, 3, 5, 7]\n",
            "10 [1 8 6 4 0 9 2 3 5 7]\n",
            "discarded index [1, 8, 6, 4, 0, 9, 2, 3, 5, 7]\n",
            "10 [1 8 6 4 0 9 2 3 5 7]\n",
            "discarded index [1, 8, 6, 4, 0, 9, 2, 3, 5, 7]\n",
            "10 [1 8 6 4 0 9 2 3 5 7]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 158, bulyan: at fang n_at 10 e 158 | val loss 1.8584 val acc 32.7110 best val_acc 32.711039\n",
            "discarded index [3, 9, 5, 7, 1, 0, 4, 2, 8, 6]\n",
            "10 [3 9 5 7 1 0 4 2 8 6]\n",
            "discarded index [3, 9, 5, 7, 1, 0, 4, 2, 8, 6]\n",
            "10 [3 9 5 7 1 0 4 2 8 6]\n",
            "discarded index [3, 9, 5, 7, 1, 0, 4, 2, 8, 6]\n",
            "10 [3 9 5 7 1 0 4 2 8 6]\n",
            "discarded index [3, 9, 5, 7, 1, 0, 4, 2, 8, 6]\n",
            "10 [3 9 5 7 1 0 4 2 8 6]\n",
            "discarded index [3, 9, 5, 7, 1, 0, 4, 2, 8, 6]\n",
            "10 [3 9 5 7 1 0 4 2 8 6]\n",
            "discarded index [3, 9, 5, 7, 1, 0, 4, 2, 8, 6]\n",
            "10 [3 9 5 7 1 0 4 2 8 6]\n",
            "discarded index [3, 9, 5, 7, 1, 0, 4, 2, 8, 6]\n",
            "10 [3 9 5 7 1 0 4 2 8 6]\n",
            "discarded index [3, 9, 5, 7, 1, 0, 4, 2, 8, 6]\n",
            "10 [3 9 5 7 1 0 4 2 8 6]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 159, bulyan: at fang n_at 10 e 159 | val loss 1.8687 val acc 32.3458 best val_acc 32.711039\n",
            "discarded index [5, 3, 9, 6, 7, 8, 0, 4, 2, 1]\n",
            "10 [5 3 9 6 7 8 0 4 2 1]\n",
            "discarded index [5, 3, 9, 6, 7, 8, 0, 4, 2, 1]\n",
            "10 [5 3 9 6 7 8 0 4 2 1]\n",
            "discarded index [5, 3, 9, 6, 7, 8, 0, 4, 2, 1]\n",
            "10 [5 3 9 6 7 8 0 4 2 1]\n",
            "discarded index [5, 3, 9, 6, 7, 8, 0, 4, 2, 1]\n",
            "10 [5 3 9 6 7 8 0 4 2 1]\n",
            "discarded index [5, 3, 9, 6, 7, 8, 0, 4, 2, 1]\n",
            "10 [5 3 9 6 7 8 0 4 2 1]\n",
            "discarded index [5, 3, 9, 6, 7, 8, 0, 4, 2, 1]\n",
            "10 [5 3 9 6 7 8 0 4 2 1]\n",
            "discarded index [5, 3, 9, 6, 7, 8, 0, 4, 2, 1]\n",
            "10 [5 3 9 6 7 8 0 4 2 1]\n",
            "discarded index [5, 3, 9, 6, 7, 8, 0, 4, 2, 1]\n",
            "10 [5 3 9 6 7 8 0 4 2 1]\n",
            "discarded index [5, 3, 9, 6, 7, 8, 0, 4, 2, 1]\n",
            "10 [5 3 9 6 7 8 0 4 2 1]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 160, bulyan: at fang n_at 10 e 160 | val loss 1.9718 val acc 27.7597 best val_acc 32.711039\n",
            "discarded index [0, 1, 6, 4, 7, 2, 5, 8, 9, 3]\n",
            "10 [0 1 6 4 7 2 5 8 9 3]\n",
            "discarded index [0, 1, 6, 4, 7, 2, 5, 8, 9, 3]\n",
            "10 [0 1 6 4 7 2 5 8 9 3]\n",
            "discarded index [0, 1, 6, 4, 7, 2, 5, 8, 9, 3]\n",
            "10 [0 1 6 4 7 2 5 8 9 3]\n",
            "discarded index [0, 1, 6, 4, 7, 2, 5, 8, 9, 3]\n",
            "10 [0 1 6 4 7 2 5 8 9 3]\n",
            "discarded index [0, 1, 6, 4, 7, 2, 5, 8, 9, 3]\n",
            "10 [0 1 6 4 7 2 5 8 9 3]\n",
            "discarded index [0, 1, 6, 4, 7, 2, 5, 8, 9, 3]\n",
            "10 [0 1 6 4 7 2 5 8 9 3]\n",
            "discarded index [0, 1, 6, 4, 7, 2, 5, 8, 9, 3]\n",
            "10 [0 1 6 4 7 2 5 8 9 3]\n",
            "discarded index [0, 1, 6, 4, 7, 2, 5, 8, 9, 3]\n",
            "10 [0 1 6 4 7 2 5 8 9 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 161, bulyan: at fang n_at 10 e 161 | val loss 1.8065 val acc 32.0008 best val_acc 32.711039\n",
            "discarded index [8, 6, 5, 1, 4, 2, 0, 7, 9, 3]\n",
            "10 [8 6 5 1 4 2 0 7 9 3]\n",
            "discarded index [8, 6, 5, 1, 4, 2, 0, 7, 9, 3]\n",
            "10 [8 6 5 1 4 2 0 7 9 3]\n",
            "discarded index [8, 6, 5, 1, 4, 2, 0, 7, 9, 3]\n",
            "10 [8 6 5 1 4 2 0 7 9 3]\n",
            "discarded index [8, 6, 5, 1, 4, 2, 0, 7, 9, 3]\n",
            "10 [8 6 5 1 4 2 0 7 9 3]\n",
            "discarded index [8, 6, 5, 1, 4, 2, 0, 7, 9, 3]\n",
            "10 [8 6 5 1 4 2 0 7 9 3]\n",
            "discarded index [8, 6, 5, 1, 4, 2, 0, 7, 9, 3]\n",
            "10 [8 6 5 1 4 2 0 7 9 3]\n",
            "discarded index [8, 6, 5, 1, 4, 2, 0, 7, 9, 3]\n",
            "10 [8 6 5 1 4 2 0 7 9 3]\n",
            "discarded index [8, 6, 5, 1, 4, 2, 0, 7, 9, 3]\n",
            "10 [8 6 5 1 4 2 0 7 9 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 162, bulyan: at fang n_at 10 e 162 | val loss 1.7535 val acc 35.1055 best val_acc 35.105519\n",
            "discarded index [6, 0, 3, 9, 8, 5, 1, 7, 4, 2]\n",
            "10 [6 0 3 9 8 5 1 7 4 2]\n",
            "discarded index [6, 0, 3, 9, 8, 5, 1, 7, 4, 2]\n",
            "10 [6 0 3 9 8 5 1 7 4 2]\n",
            "discarded index [6, 0, 3, 9, 8, 5, 1, 7, 4, 2]\n",
            "10 [6 0 3 9 8 5 1 7 4 2]\n",
            "discarded index [6, 0, 3, 9, 8, 5, 1, 7, 4, 2]\n",
            "10 [6 0 3 9 8 5 1 7 4 2]\n",
            "discarded index [6, 0, 3, 9, 8, 5, 1, 7, 4, 2]\n",
            "10 [6 0 3 9 8 5 1 7 4 2]\n",
            "discarded index [6, 0, 3, 9, 8, 5, 1, 7, 4, 2]\n",
            "10 [6 0 3 9 8 5 1 7 4 2]\n",
            "discarded index [6, 0, 3, 9, 8, 5, 1, 7, 4, 2]\n",
            "10 [6 0 3 9 8 5 1 7 4 2]\n",
            "discarded index [6, 0, 3, 9, 8, 5, 1, 7, 4, 2]\n",
            "10 [6 0 3 9 8 5 1 7 4 2]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 163, bulyan: at fang n_at 10 e 163 | val loss 1.8035 val acc 33.1778 best val_acc 35.105519\n",
            "discarded index [0, 2, 6, 8, 9, 1, 3, 7, 4, 5]\n",
            "10 [0 2 6 8 9 1 3 7 4 5]\n",
            "discarded index [0, 2, 6, 8, 9, 1, 3, 7, 4, 5]\n",
            "10 [0 2 6 8 9 1 3 7 4 5]\n",
            "discarded index [0, 2, 6, 8, 9, 1, 3, 7, 4, 5]\n",
            "10 [0 2 6 8 9 1 3 7 4 5]\n",
            "discarded index [0, 2, 6, 8, 9, 1, 3, 7, 4, 5]\n",
            "10 [0 2 6 8 9 1 3 7 4 5]\n",
            "discarded index [0, 2, 6, 8, 9, 1, 3, 7, 4, 5]\n",
            "10 [0 2 6 8 9 1 3 7 4 5]\n",
            "discarded index [0, 2, 6, 8, 9, 1, 3, 7, 4, 5]\n",
            "10 [0 2 6 8 9 1 3 7 4 5]\n",
            "discarded index [0, 2, 6, 8, 9, 1, 3, 7, 4, 5]\n",
            "10 [0 2 6 8 9 1 3 7 4 5]\n",
            "discarded index [0, 2, 6, 8, 9, 1, 3, 7, 4, 5]\n",
            "10 [0 2 6 8 9 1 3 7 4 5]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 164, bulyan: at fang n_at 10 e 164 | val loss 1.8843 val acc 30.7427 best val_acc 35.105519\n",
            "discarded index [9, 8, 7, 0, 1, 4, 2, 6, 3, 5]\n",
            "10 [9 8 7 0 1 4 2 6 3 5]\n",
            "discarded index [9, 8, 7, 0, 1, 4, 2, 6, 3, 5]\n",
            "10 [9 8 7 0 1 4 2 6 3 5]\n",
            "discarded index [9, 8, 7, 0, 1, 4, 2, 6, 3, 5]\n",
            "10 [9 8 7 0 1 4 2 6 3 5]\n",
            "discarded index [9, 8, 7, 0, 1, 4, 2, 6, 3, 5]\n",
            "10 [9 8 7 0 1 4 2 6 3 5]\n",
            "discarded index [9, 8, 7, 0, 1, 4, 2, 6, 3, 5]\n",
            "10 [9 8 7 0 1 4 2 6 3 5]\n",
            "discarded index [9, 8, 7, 0, 1, 4, 2, 6, 3, 5]\n",
            "10 [9 8 7 0 1 4 2 6 3 5]\n",
            "discarded index [9, 8, 7, 0, 1, 4, 2, 6, 3, 5]\n",
            "10 [9 8 7 0 1 4 2 6 3 5]\n",
            "discarded index [9, 8, 7, 0, 1, 4, 2, 6, 3, 5]\n",
            "10 [9 8 7 0 1 4 2 6 3 5]\n",
            "discarded index [9, 8, 7, 0, 1, 4, 2, 6, 3, 5]\n",
            "10 [9 8 7 0 1 4 2 6 3 5]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 165, bulyan: at fang n_at 10 e 165 | val loss 1.9802 val acc 25.3044 best val_acc 35.105519\n",
            "discarded index [9, 7, 1, 0, 2, 4, 5, 8, 3, 6]\n",
            "10 [9 7 1 0 2 4 5 8 3 6]\n",
            "discarded index [9, 7, 1, 0, 2, 4, 5, 8, 3, 6]\n",
            "10 [9 7 1 0 2 4 5 8 3 6]\n",
            "discarded index [9, 7, 1, 0, 2, 4, 5, 8, 3, 6]\n",
            "10 [9 7 1 0 2 4 5 8 3 6]\n",
            "discarded index [9, 7, 1, 0, 2, 4, 5, 8, 3, 6]\n",
            "10 [9 7 1 0 2 4 5 8 3 6]\n",
            "discarded index [9, 7, 1, 0, 2, 4, 5, 8, 3, 6]\n",
            "10 [9 7 1 0 2 4 5 8 3 6]\n",
            "discarded index [9, 7, 1, 0, 2, 4, 5, 8, 3, 6]\n",
            "10 [9 7 1 0 2 4 5 8 3 6]\n",
            "discarded index [9, 7, 1, 0, 2, 4, 5, 8, 3, 6]\n",
            "10 [9 7 1 0 2 4 5 8 3 6]\n",
            "discarded index [9, 7, 1, 0, 2, 4, 5, 8, 3, 6]\n",
            "10 [9 7 1 0 2 4 5 8 3 6]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 166, bulyan: at fang n_at 10 e 166 | val loss 1.9197 val acc 26.3799 best val_acc 35.105519\n",
            "discarded index [3, 2, 9, 8, 4, 6, 7, 1, 0, 5]\n",
            "10 [3 2 9 8 4 6 7 1 0 5]\n",
            "discarded index [3, 2, 9, 8, 4, 6, 7, 1, 0, 5]\n",
            "10 [3 2 9 8 4 6 7 1 0 5]\n",
            "discarded index [3, 2, 9, 8, 4, 6, 7, 1, 0, 5]\n",
            "10 [3 2 9 8 4 6 7 1 0 5]\n",
            "discarded index [3, 2, 9, 8, 4, 6, 7, 1, 0, 5]\n",
            "10 [3 2 9 8 4 6 7 1 0 5]\n",
            "discarded index [3, 2, 9, 8, 4, 6, 7, 1, 0, 5]\n",
            "10 [3 2 9 8 4 6 7 1 0 5]\n",
            "discarded index [3, 2, 9, 8, 4, 6, 7, 1, 0, 5]\n",
            "10 [3 2 9 8 4 6 7 1 0 5]\n",
            "discarded index [3, 2, 9, 8, 4, 6, 7, 1, 0, 5]\n",
            "10 [3 2 9 8 4 6 7 1 0 5]\n",
            "discarded index [3, 2, 9, 8, 4, 6, 7, 1, 0, 5]\n",
            "10 [3 2 9 8 4 6 7 1 0 5]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 167, bulyan: at fang n_at 10 e 167 | val loss 1.8353 val acc 33.3401 best val_acc 35.105519\n",
            "discarded index [6, 8, 9, 7, 0, 4, 2, 5, 1, 3]\n",
            "10 [6 8 9 7 0 4 2 5 1 3]\n",
            "discarded index [6, 8, 9, 7, 0, 4, 2, 5, 1, 3]\n",
            "10 [6 8 9 7 0 4 2 5 1 3]\n",
            "discarded index [6, 8, 9, 7, 0, 4, 2, 5, 1, 3]\n",
            "10 [6 8 9 7 0 4 2 5 1 3]\n",
            "discarded index [6, 8, 9, 7, 0, 4, 2, 5, 1, 3]\n",
            "10 [6 8 9 7 0 4 2 5 1 3]\n",
            "discarded index [6, 8, 9, 7, 0, 4, 2, 5, 1, 3]\n",
            "10 [6 8 9 7 0 4 2 5 1 3]\n",
            "discarded index [6, 8, 9, 7, 0, 4, 2, 5, 1, 3]\n",
            "10 [6 8 9 7 0 4 2 5 1 3]\n",
            "discarded index [6, 8, 9, 7, 0, 4, 2, 5, 1, 3]\n",
            "10 [6 8 9 7 0 4 2 5 1 3]\n",
            "discarded index [6, 8, 9, 7, 0, 4, 2, 5, 1, 3]\n",
            "10 [6 8 9 7 0 4 2 5 1 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 168, bulyan: at fang n_at 10 e 168 | val loss 1.7661 val acc 35.9781 best val_acc 35.978084\n",
            "discarded index [5, 6, 7, 0, 8, 3, 9, 4, 2, 1]\n",
            "10 [5 6 7 0 8 3 9 4 2 1]\n",
            "discarded index [5, 6, 7, 0, 8, 3, 9, 4, 2, 1]\n",
            "10 [5 6 7 0 8 3 9 4 2 1]\n",
            "discarded index [5, 6, 7, 0, 8, 3, 9, 4, 2, 1]\n",
            "10 [5 6 7 0 8 3 9 4 2 1]\n",
            "discarded index [5, 6, 7, 0, 8, 3, 9, 4, 2, 1]\n",
            "10 [5 6 7 0 8 3 9 4 2 1]\n",
            "discarded index [5, 6, 7, 0, 8, 3, 9, 4, 2, 1]\n",
            "10 [5 6 7 0 8 3 9 4 2 1]\n",
            "discarded index [5, 6, 7, 0, 8, 3, 9, 4, 2, 1]\n",
            "10 [5 6 7 0 8 3 9 4 2 1]\n",
            "discarded index [5, 6, 7, 0, 8, 3, 9, 4, 2, 1]\n",
            "10 [5 6 7 0 8 3 9 4 2 1]\n",
            "discarded index [5, 6, 7, 0, 8, 3, 9, 4, 2, 1]\n",
            "10 [5 6 7 0 8 3 9 4 2 1]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 169, bulyan: at fang n_at 10 e 169 | val loss 1.7644 val acc 34.9432 best val_acc 35.978084\n",
            "discarded index [0, 1, 7, 5, 2, 4, 8, 6, 3, 9]\n",
            "10 [0 1 7 5 2 4 8 6 3 9]\n",
            "discarded index [0, 1, 7, 5, 2, 4, 8, 6, 3, 9]\n",
            "10 [0 1 7 5 2 4 8 6 3 9]\n",
            "discarded index [0, 1, 7, 5, 2, 4, 8, 6, 3, 9]\n",
            "10 [0 1 7 5 2 4 8 6 3 9]\n",
            "discarded index [0, 1, 7, 5, 2, 4, 8, 6, 3, 9]\n",
            "10 [0 1 7 5 2 4 8 6 3 9]\n",
            "discarded index [0, 1, 7, 5, 2, 4, 8, 6, 3, 9]\n",
            "10 [0 1 7 5 2 4 8 6 3 9]\n",
            "discarded index [0, 1, 7, 5, 2, 4, 8, 6, 3, 9]\n",
            "10 [0 1 7 5 2 4 8 6 3 9]\n",
            "discarded index [0, 1, 7, 5, 2, 4, 8, 6, 3, 9]\n",
            "10 [0 1 7 5 2 4 8 6 3 9]\n",
            "discarded index [0, 1, 7, 5, 2, 4, 8, 6, 3, 9]\n",
            "10 [0 1 7 5 2 4 8 6 3 9]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 170, bulyan: at fang n_at 10 e 170 | val loss 1.7804 val acc 35.2476 best val_acc 35.978084\n",
            "discarded index [6, 0, 8, 9, 1, 5, 2, 7, 4, 3]\n",
            "10 [6 0 8 9 1 5 2 7 4 3]\n",
            "discarded index [6, 0, 8, 9, 1, 5, 2, 7, 4, 3]\n",
            "10 [6 0 8 9 1 5 2 7 4 3]\n",
            "discarded index [6, 0, 8, 9, 1, 5, 2, 7, 4, 3]\n",
            "10 [6 0 8 9 1 5 2 7 4 3]\n",
            "discarded index [6, 0, 8, 9, 1, 5, 2, 7, 4, 3]\n",
            "10 [6 0 8 9 1 5 2 7 4 3]\n",
            "discarded index [6, 0, 8, 9, 1, 5, 2, 7, 4, 3]\n",
            "10 [6 0 8 9 1 5 2 7 4 3]\n",
            "discarded index [6, 0, 8, 9, 1, 5, 2, 7, 4, 3]\n",
            "10 [6 0 8 9 1 5 2 7 4 3]\n",
            "discarded index [6, 0, 8, 9, 1, 5, 2, 7, 4, 3]\n",
            "10 [6 0 8 9 1 5 2 7 4 3]\n",
            "discarded index [6, 0, 8, 9, 1, 5, 2, 7, 4, 3]\n",
            "10 [6 0 8 9 1 5 2 7 4 3]\n",
            "discarded index [6, 0, 8, 9, 1, 5, 2, 7, 4, 3]\n",
            "10 [6 0 8 9 1 5 2 7 4 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 171, bulyan: at fang n_at 10 e 171 | val loss 1.9077 val acc 29.5455 best val_acc 35.978084\n",
            "discarded index [0, 7, 6, 9, 4, 8, 3, 1, 2, 5]\n",
            "10 [0 7 6 9 4 8 3 1 2 5]\n",
            "discarded index [0, 7, 6, 9, 4, 8, 3, 1, 2, 5]\n",
            "10 [0 7 6 9 4 8 3 1 2 5]\n",
            "discarded index [0, 7, 6, 9, 4, 8, 3, 1, 2, 5]\n",
            "10 [0 7 6 9 4 8 3 1 2 5]\n",
            "discarded index [0, 7, 6, 9, 4, 8, 3, 1, 2, 5]\n",
            "10 [0 7 6 9 4 8 3 1 2 5]\n",
            "discarded index [0, 7, 6, 9, 4, 8, 3, 1, 2, 5]\n",
            "10 [0 7 6 9 4 8 3 1 2 5]\n",
            "discarded index [0, 7, 6, 9, 4, 8, 3, 1, 2, 5]\n",
            "10 [0 7 6 9 4 8 3 1 2 5]\n",
            "discarded index [0, 7, 6, 9, 4, 8, 3, 1, 2, 5]\n",
            "10 [0 7 6 9 4 8 3 1 2 5]\n",
            "discarded index [0, 7, 6, 9, 4, 8, 3, 1, 2, 5]\n",
            "10 [0 7 6 9 4 8 3 1 2 5]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 172, bulyan: at fang n_at 10 e 172 | val loss 1.8263 val acc 32.7313 best val_acc 35.978084\n",
            "discarded index [6, 1, 7, 8, 9, 5, 0, 3, 2, 4]\n",
            "10 [6 1 7 8 9 5 0 3 2 4]\n",
            "discarded index [6, 1, 7, 8, 9, 5, 0, 3, 2, 4]\n",
            "10 [6 1 7 8 9 5 0 3 2 4]\n",
            "discarded index [6, 1, 7, 8, 9, 5, 0, 3, 2, 4]\n",
            "10 [6 1 7 8 9 5 0 3 2 4]\n",
            "discarded index [6, 1, 7, 8, 9, 5, 0, 3, 2, 4]\n",
            "10 [6 1 7 8 9 5 0 3 2 4]\n",
            "discarded index [6, 1, 7, 8, 9, 5, 0, 3, 2, 4]\n",
            "10 [6 1 7 8 9 5 0 3 2 4]\n",
            "discarded index [6, 1, 7, 8, 9, 5, 0, 3, 2, 4]\n",
            "10 [6 1 7 8 9 5 0 3 2 4]\n",
            "discarded index [6, 1, 7, 8, 9, 5, 0, 3, 2, 4]\n",
            "10 [6 1 7 8 9 5 0 3 2 4]\n",
            "discarded index [6, 1, 7, 8, 9, 5, 0, 3, 2, 4]\n",
            "10 [6 1 7 8 9 5 0 3 2 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 173, bulyan: at fang n_at 10 e 173 | val loss 1.8142 val acc 34.3750 best val_acc 35.978084\n",
            "discarded index [8, 6, 3, 4, 1, 7, 2, 5, 9, 0]\n",
            "10 [8 6 3 4 1 7 2 5 9 0]\n",
            "discarded index [8, 6, 3, 4, 1, 7, 2, 5, 9, 0]\n",
            "10 [8 6 3 4 1 7 2 5 9 0]\n",
            "discarded index [8, 6, 3, 4, 1, 7, 2, 5, 9, 0]\n",
            "10 [8 6 3 4 1 7 2 5 9 0]\n",
            "discarded index [8, 6, 3, 4, 1, 7, 2, 5, 9, 0]\n",
            "10 [8 6 3 4 1 7 2 5 9 0]\n",
            "discarded index [8, 6, 3, 4, 1, 7, 2, 5, 9, 0]\n",
            "10 [8 6 3 4 1 7 2 5 9 0]\n",
            "discarded index [8, 6, 3, 4, 1, 7, 2, 5, 9, 0]\n",
            "10 [8 6 3 4 1 7 2 5 9 0]\n",
            "discarded index [8, 6, 3, 4, 1, 7, 2, 5, 9, 0]\n",
            "10 [8 6 3 4 1 7 2 5 9 0]\n",
            "discarded index [8, 6, 3, 4, 1, 7, 2, 5, 9, 0]\n",
            "10 [8 6 3 4 1 7 2 5 9 0]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 174, bulyan: at fang n_at 10 e 174 | val loss 1.9325 val acc 32.0820 best val_acc 35.978084\n",
            "discarded index [5, 3, 2, 1, 8, 9, 7, 0, 4, 6]\n",
            "10 [5 3 2 1 8 9 7 0 4 6]\n",
            "discarded index [5, 3, 2, 1, 8, 9, 7, 0, 4, 6]\n",
            "10 [5 3 2 1 8 9 7 0 4 6]\n",
            "discarded index [5, 3, 2, 1, 8, 9, 7, 0, 4, 6]\n",
            "10 [5 3 2 1 8 9 7 0 4 6]\n",
            "discarded index [5, 3, 2, 1, 8, 9, 7, 0, 4, 6]\n",
            "10 [5 3 2 1 8 9 7 0 4 6]\n",
            "discarded index [5, 3, 2, 1, 8, 9, 7, 0, 4, 6]\n",
            "10 [5 3 2 1 8 9 7 0 4 6]\n",
            "discarded index [5, 3, 2, 1, 8, 9, 7, 0, 4, 6]\n",
            "10 [5 3 2 1 8 9 7 0 4 6]\n",
            "discarded index [5, 3, 2, 1, 8, 9, 7, 0, 4, 6]\n",
            "10 [5 3 2 1 8 9 7 0 4 6]\n",
            "discarded index [5, 3, 2, 1, 8, 9, 7, 0, 4, 6]\n",
            "10 [5 3 2 1 8 9 7 0 4 6]\n",
            "discarded index [5, 3, 2, 1, 8, 9, 7, 0, 4, 6]\n",
            "10 [5 3 2 1 8 9 7 0 4 6]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 175, bulyan: at fang n_at 10 e 175 | val loss 2.0444 val acc 24.8580 best val_acc 35.978084\n",
            "discarded index [0, 5, 1, 3, 9, 8, 7, 2, 6, 4]\n",
            "10 [0 5 1 3 9 8 7 2 6 4]\n",
            "discarded index [0, 5, 1, 3, 9, 8, 7, 2, 6, 4]\n",
            "10 [0 5 1 3 9 8 7 2 6 4]\n",
            "discarded index [0, 5, 1, 3, 9, 8, 7, 2, 6, 4]\n",
            "10 [0 5 1 3 9 8 7 2 6 4]\n",
            "discarded index [0, 5, 1, 3, 9, 8, 7, 2, 6, 4]\n",
            "10 [0 5 1 3 9 8 7 2 6 4]\n",
            "discarded index [0, 5, 1, 3, 9, 8, 7, 2, 6, 4]\n",
            "10 [0 5 1 3 9 8 7 2 6 4]\n",
            "discarded index [0, 5, 1, 3, 9, 8, 7, 2, 6, 4]\n",
            "10 [0 5 1 3 9 8 7 2 6 4]\n",
            "discarded index [0, 5, 1, 3, 9, 8, 7, 2, 6, 4]\n",
            "10 [0 5 1 3 9 8 7 2 6 4]\n",
            "discarded index [0, 5, 1, 3, 9, 8, 7, 2, 6, 4]\n",
            "10 [0 5 1 3 9 8 7 2 6 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 176, bulyan: at fang n_at 10 e 176 | val loss 1.9611 val acc 30.7224 best val_acc 35.978084\n",
            "discarded index [5, 9, 7, 1, 3, 4, 2, 8, 0, 6]\n",
            "10 [5 9 7 1 3 4 2 8 0 6]\n",
            "discarded index [5, 9, 7, 1, 3, 4, 2, 8, 0, 6]\n",
            "10 [5 9 7 1 3 4 2 8 0 6]\n",
            "discarded index [5, 9, 7, 1, 3, 4, 2, 8, 0, 6]\n",
            "10 [5 9 7 1 3 4 2 8 0 6]\n",
            "discarded index [5, 9, 7, 1, 3, 4, 2, 8, 0, 6]\n",
            "10 [5 9 7 1 3 4 2 8 0 6]\n",
            "discarded index [5, 9, 7, 1, 3, 4, 2, 8, 0, 6]\n",
            "10 [5 9 7 1 3 4 2 8 0 6]\n",
            "discarded index [5, 9, 7, 1, 3, 4, 2, 8, 0, 6]\n",
            "10 [5 9 7 1 3 4 2 8 0 6]\n",
            "discarded index [5, 9, 7, 1, 3, 4, 2, 8, 0, 6]\n",
            "10 [5 9 7 1 3 4 2 8 0 6]\n",
            "discarded index [5, 9, 7, 1, 3, 4, 2, 8, 0, 6]\n",
            "10 [5 9 7 1 3 4 2 8 0 6]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 177, bulyan: at fang n_at 10 e 177 | val loss 1.8457 val acc 34.3750 best val_acc 35.978084\n",
            "discarded index [6, 8, 4, 7, 3, 2, 1, 0, 9, 5]\n",
            "10 [6 8 4 7 3 2 1 0 9 5]\n",
            "discarded index [6, 8, 4, 7, 3, 2, 1, 0, 9, 5]\n",
            "10 [6 8 4 7 3 2 1 0 9 5]\n",
            "discarded index [6, 8, 4, 7, 3, 2, 1, 0, 9, 5]\n",
            "10 [6 8 4 7 3 2 1 0 9 5]\n",
            "discarded index [6, 8, 4, 7, 3, 2, 1, 0, 9, 5]\n",
            "10 [6 8 4 7 3 2 1 0 9 5]\n",
            "discarded index [6, 8, 4, 7, 3, 2, 1, 0, 9, 5]\n",
            "10 [6 8 4 7 3 2 1 0 9 5]\n",
            "discarded index [6, 8, 4, 7, 3, 2, 1, 0, 9, 5]\n",
            "10 [6 8 4 7 3 2 1 0 9 5]\n",
            "discarded index [6, 8, 4, 7, 3, 2, 1, 0, 9, 5]\n",
            "10 [6 8 4 7 3 2 1 0 9 5]\n",
            "discarded index [6, 8, 4, 7, 3, 2, 1, 0, 9, 5]\n",
            "10 [6 8 4 7 3 2 1 0 9 5]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 178, bulyan: at fang n_at 10 e 178 | val loss 1.7680 val acc 36.6071 best val_acc 36.607143\n",
            "discarded index [6, 3, 1, 0, 7, 5, 8, 9, 2, 4]\n",
            "10 [6 3 1 0 7 5 8 9 2 4]\n",
            "discarded index [6, 3, 1, 0, 7, 5, 8, 9, 2, 4]\n",
            "10 [6 3 1 0 7 5 8 9 2 4]\n",
            "discarded index [6, 3, 1, 0, 7, 5, 8, 9, 2, 4]\n",
            "10 [6 3 1 0 7 5 8 9 2 4]\n",
            "discarded index [6, 3, 1, 0, 7, 5, 8, 9, 2, 4]\n",
            "10 [6 3 1 0 7 5 8 9 2 4]\n",
            "discarded index [6, 3, 1, 0, 7, 5, 8, 9, 2, 4]\n",
            "10 [6 3 1 0 7 5 8 9 2 4]\n",
            "discarded index [6, 3, 1, 0, 7, 5, 8, 9, 2, 4]\n",
            "10 [6 3 1 0 7 5 8 9 2 4]\n",
            "discarded index [6, 3, 1, 0, 7, 5, 8, 9, 2, 4]\n",
            "10 [6 3 1 0 7 5 8 9 2 4]\n",
            "discarded index [6, 3, 1, 0, 7, 5, 8, 9, 2, 4]\n",
            "10 [6 3 1 0 7 5 8 9 2 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 179, bulyan: at fang n_at 10 e 179 | val loss 1.7463 val acc 37.1144 best val_acc 37.114448\n",
            "discarded index [6, 9, 8, 3, 4, 0, 7, 2, 5, 1]\n",
            "10 [6 9 8 3 4 0 7 2 5 1]\n",
            "discarded index [6, 9, 8, 3, 4, 0, 7, 2, 5, 1]\n",
            "10 [6 9 8 3 4 0 7 2 5 1]\n",
            "discarded index [6, 9, 8, 3, 4, 0, 7, 2, 5, 1]\n",
            "10 [6 9 8 3 4 0 7 2 5 1]\n",
            "discarded index [6, 9, 8, 3, 4, 0, 7, 2, 5, 1]\n",
            "10 [6 9 8 3 4 0 7 2 5 1]\n",
            "discarded index [6, 9, 8, 3, 4, 0, 7, 2, 5, 1]\n",
            "10 [6 9 8 3 4 0 7 2 5 1]\n",
            "discarded index [6, 9, 8, 3, 4, 0, 7, 2, 5, 1]\n",
            "10 [6 9 8 3 4 0 7 2 5 1]\n",
            "discarded index [6, 9, 8, 3, 4, 0, 7, 2, 5, 1]\n",
            "10 [6 9 8 3 4 0 7 2 5 1]\n",
            "discarded index [6, 9, 8, 3, 4, 0, 7, 2, 5, 1]\n",
            "10 [6 9 8 3 4 0 7 2 5 1]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 180, bulyan: at fang n_at 10 e 180 | val loss 1.7707 val acc 35.3693 best val_acc 37.114448\n",
            "discarded index [0, 9, 6, 8, 3, 1, 7, 2, 4, 5]\n",
            "10 [0 9 6 8 3 1 7 2 4 5]\n",
            "discarded index [0, 9, 6, 8, 3, 1, 7, 2, 4, 5]\n",
            "10 [0 9 6 8 3 1 7 2 4 5]\n",
            "discarded index [0, 9, 6, 8, 3, 1, 7, 2, 4, 5]\n",
            "10 [0 9 6 8 3 1 7 2 4 5]\n",
            "discarded index [0, 9, 6, 8, 3, 1, 7, 2, 4, 5]\n",
            "10 [0 9 6 8 3 1 7 2 4 5]\n",
            "discarded index [0, 9, 6, 8, 3, 1, 7, 2, 4, 5]\n",
            "10 [0 9 6 8 3 1 7 2 4 5]\n",
            "discarded index [0, 9, 6, 8, 3, 1, 7, 2, 4, 5]\n",
            "10 [0 9 6 8 3 1 7 2 4 5]\n",
            "discarded index [0, 9, 6, 8, 3, 1, 7, 2, 4, 5]\n",
            "10 [0 9 6 8 3 1 7 2 4 5]\n",
            "discarded index [0, 9, 6, 8, 3, 1, 7, 2, 4, 5]\n",
            "10 [0 9 6 8 3 1 7 2 4 5]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 181, bulyan: at fang n_at 10 e 181 | val loss 1.8407 val acc 33.3604 best val_acc 37.114448\n",
            "discarded index [9, 1, 5, 0, 3, 2, 7, 4, 8, 6]\n",
            "10 [9 1 5 0 3 2 7 4 8 6]\n",
            "discarded index [9, 1, 5, 0, 3, 2, 7, 4, 8, 6]\n",
            "10 [9 1 5 0 3 2 7 4 8 6]\n",
            "discarded index [9, 1, 5, 0, 3, 2, 7, 4, 8, 6]\n",
            "10 [9 1 5 0 3 2 7 4 8 6]\n",
            "discarded index [9, 1, 5, 0, 3, 2, 7, 4, 8, 6]\n",
            "10 [9 1 5 0 3 2 7 4 8 6]\n",
            "discarded index [9, 1, 5, 0, 3, 2, 7, 4, 8, 6]\n",
            "10 [9 1 5 0 3 2 7 4 8 6]\n",
            "discarded index [9, 1, 5, 0, 3, 2, 7, 4, 8, 6]\n",
            "10 [9 1 5 0 3 2 7 4 8 6]\n",
            "discarded index [9, 1, 5, 0, 3, 2, 7, 4, 8, 6]\n",
            "10 [9 1 5 0 3 2 7 4 8 6]\n",
            "discarded index [9, 1, 5, 0, 3, 2, 7, 4, 8, 6]\n",
            "10 [9 1 5 0 3 2 7 4 8 6]\n",
            "discarded index [9, 1, 5, 0, 3, 2, 7, 4, 8, 6]\n",
            "10 [9 1 5 0 3 2 7 4 8 6]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 182, bulyan: at fang n_at 10 e 182 | val loss 1.8759 val acc 31.0471 best val_acc 37.114448\n",
            "discarded index [9, 0, 7, 1, 6, 2, 4, 5, 8, 3]\n",
            "10 [9 0 7 1 6 2 4 5 8 3]\n",
            "discarded index [9, 0, 7, 1, 6, 2, 4, 5, 8, 3]\n",
            "10 [9 0 7 1 6 2 4 5 8 3]\n",
            "discarded index [9, 0, 7, 1, 6, 2, 4, 5, 8, 3]\n",
            "10 [9 0 7 1 6 2 4 5 8 3]\n",
            "discarded index [9, 0, 7, 1, 6, 2, 4, 5, 8, 3]\n",
            "10 [9 0 7 1 6 2 4 5 8 3]\n",
            "discarded index [9, 0, 7, 1, 6, 2, 4, 5, 8, 3]\n",
            "10 [9 0 7 1 6 2 4 5 8 3]\n",
            "discarded index [9, 0, 7, 1, 6, 2, 4, 5, 8, 3]\n",
            "10 [9 0 7 1 6 2 4 5 8 3]\n",
            "discarded index [9, 0, 7, 1, 6, 2, 4, 5, 8, 3]\n",
            "10 [9 0 7 1 6 2 4 5 8 3]\n",
            "discarded index [9, 0, 7, 1, 6, 2, 4, 5, 8, 3]\n",
            "10 [9 0 7 1 6 2 4 5 8 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 183, bulyan: at fang n_at 10 e 183 | val loss 1.8909 val acc 33.3401 best val_acc 37.114448\n",
            "discarded index [9, 7, 5, 3, 6, 2, 4, 1, 0, 8]\n",
            "10 [9 7 5 3 6 2 4 1 0 8]\n",
            "discarded index [9, 7, 5, 3, 6, 2, 4, 1, 0, 8]\n",
            "10 [9 7 5 3 6 2 4 1 0 8]\n",
            "discarded index [9, 7, 5, 3, 6, 2, 4, 1, 0, 8]\n",
            "10 [9 7 5 3 6 2 4 1 0 8]\n",
            "discarded index [9, 7, 5, 3, 6, 2, 4, 1, 0, 8]\n",
            "10 [9 7 5 3 6 2 4 1 0 8]\n",
            "discarded index [9, 7, 5, 3, 6, 2, 4, 1, 0, 8]\n",
            "10 [9 7 5 3 6 2 4 1 0 8]\n",
            "discarded index [9, 7, 5, 3, 6, 2, 4, 1, 0, 8]\n",
            "10 [9 7 5 3 6 2 4 1 0 8]\n",
            "discarded index [9, 7, 5, 3, 6, 2, 4, 1, 0, 8]\n",
            "10 [9 7 5 3 6 2 4 1 0 8]\n",
            "discarded index [9, 7, 5, 3, 6, 2, 4, 1, 0, 8]\n",
            "10 [9 7 5 3 6 2 4 1 0 8]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 184, bulyan: at fang n_at 10 e 184 | val loss 1.8048 val acc 34.0300 best val_acc 37.114448\n",
            "discarded index [3, 2, 7, 1, 0, 5, 8, 4, 9, 6]\n",
            "10 [3 2 7 1 0 5 8 4 9 6]\n",
            "discarded index [3, 2, 7, 1, 0, 5, 8, 4, 9, 6]\n",
            "10 [3 2 7 1 0 5 8 4 9 6]\n",
            "discarded index [3, 2, 7, 1, 0, 5, 8, 4, 9, 6]\n",
            "10 [3 2 7 1 0 5 8 4 9 6]\n",
            "discarded index [3, 2, 7, 1, 0, 5, 8, 4, 9, 6]\n",
            "10 [3 2 7 1 0 5 8 4 9 6]\n",
            "discarded index [3, 2, 7, 1, 0, 5, 8, 4, 9, 6]\n",
            "10 [3 2 7 1 0 5 8 4 9 6]\n",
            "discarded index [3, 2, 7, 1, 0, 5, 8, 4, 9, 6]\n",
            "10 [3 2 7 1 0 5 8 4 9 6]\n",
            "discarded index [3, 2, 7, 1, 0, 5, 8, 4, 9, 6]\n",
            "10 [3 2 7 1 0 5 8 4 9 6]\n",
            "discarded index [3, 2, 7, 1, 0, 5, 8, 4, 9, 6]\n",
            "10 [3 2 7 1 0 5 8 4 9 6]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 185, bulyan: at fang n_at 10 e 185 | val loss 1.7967 val acc 34.3141 best val_acc 37.114448\n",
            "discarded index [6, 1, 2, 8, 7, 4, 0, 5, 3, 9]\n",
            "10 [6 1 2 8 7 4 0 5 3 9]\n",
            "discarded index [6, 1, 2, 8, 7, 4, 0, 5, 3, 9]\n",
            "10 [6 1 2 8 7 4 0 5 3 9]\n",
            "discarded index [6, 1, 2, 8, 7, 4, 0, 5, 3, 9]\n",
            "10 [6 1 2 8 7 4 0 5 3 9]\n",
            "discarded index [6, 1, 2, 8, 7, 4, 0, 5, 3, 9]\n",
            "10 [6 1 2 8 7 4 0 5 3 9]\n",
            "discarded index [6, 1, 2, 8, 7, 4, 0, 5, 3, 9]\n",
            "10 [6 1 2 8 7 4 0 5 3 9]\n",
            "discarded index [6, 1, 2, 8, 7, 4, 0, 5, 3, 9]\n",
            "10 [6 1 2 8 7 4 0 5 3 9]\n",
            "discarded index [6, 1, 2, 8, 7, 4, 0, 5, 3, 9]\n",
            "10 [6 1 2 8 7 4 0 5 3 9]\n",
            "discarded index [6, 1, 2, 8, 7, 4, 0, 5, 3, 9]\n",
            "10 [6 1 2 8 7 4 0 5 3 9]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 186, bulyan: at fang n_at 10 e 186 | val loss 1.7643 val acc 35.0244 best val_acc 37.114448\n",
            "discarded index [6, 3, 8, 0, 7, 4, 5, 2, 9, 1]\n",
            "10 [6 3 8 0 7 4 5 2 9 1]\n",
            "discarded index [6, 3, 8, 0, 7, 4, 5, 2, 9, 1]\n",
            "10 [6 3 8 0 7 4 5 2 9 1]\n",
            "discarded index [6, 3, 8, 0, 7, 4, 5, 2, 9, 1]\n",
            "10 [6 3 8 0 7 4 5 2 9 1]\n",
            "discarded index [6, 3, 8, 0, 7, 4, 5, 2, 9, 1]\n",
            "10 [6 3 8 0 7 4 5 2 9 1]\n",
            "discarded index [6, 3, 8, 0, 7, 4, 5, 2, 9, 1]\n",
            "10 [6 3 8 0 7 4 5 2 9 1]\n",
            "discarded index [6, 3, 8, 0, 7, 4, 5, 2, 9, 1]\n",
            "10 [6 3 8 0 7 4 5 2 9 1]\n",
            "discarded index [6, 3, 8, 0, 7, 4, 5, 2, 9, 1]\n",
            "10 [6 3 8 0 7 4 5 2 9 1]\n",
            "discarded index [6, 3, 8, 0, 7, 4, 5, 2, 9, 1]\n",
            "10 [6 3 8 0 7 4 5 2 9 1]\n",
            "discarded index [6, 3, 8, 0, 7, 4, 5, 2, 9, 1]\n",
            "10 [6 3 8 0 7 4 5 2 9 1]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 187, bulyan: at fang n_at 10 e 187 | val loss 1.8636 val acc 31.3312 best val_acc 37.114448\n",
            "discarded index [0, 6, 1, 5, 8, 7, 3, 9, 2, 4]\n",
            "10 [0 6 1 5 8 7 3 9 2 4]\n",
            "discarded index [0, 6, 1, 5, 8, 7, 3, 9, 2, 4]\n",
            "10 [0 6 1 5 8 7 3 9 2 4]\n",
            "discarded index [0, 6, 1, 5, 8, 7, 3, 9, 2, 4]\n",
            "10 [0 6 1 5 8 7 3 9 2 4]\n",
            "discarded index [0, 6, 1, 5, 8, 7, 3, 9, 2, 4]\n",
            "10 [0 6 1 5 8 7 3 9 2 4]\n",
            "discarded index [0, 6, 1, 5, 8, 7, 3, 9, 2, 4]\n",
            "10 [0 6 1 5 8 7 3 9 2 4]\n",
            "discarded index [0, 6, 1, 5, 8, 7, 3, 9, 2, 4]\n",
            "10 [0 6 1 5 8 7 3 9 2 4]\n",
            "discarded index [0, 6, 1, 5, 8, 7, 3, 9, 2, 4]\n",
            "10 [0 6 1 5 8 7 3 9 2 4]\n",
            "discarded index [0, 6, 1, 5, 8, 7, 3, 9, 2, 4]\n",
            "10 [0 6 1 5 8 7 3 9 2 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 188, bulyan: at fang n_at 10 e 188 | val loss 1.8208 val acc 32.8734 best val_acc 37.114448\n",
            "discarded index [0, 6, 5, 8, 4, 7, 9, 3, 1, 2]\n",
            "10 [0 6 5 8 4 7 9 3 1 2]\n",
            "discarded index [0, 6, 5, 8, 4, 7, 9, 3, 1, 2]\n",
            "10 [0 6 5 8 4 7 9 3 1 2]\n",
            "discarded index [0, 6, 5, 8, 4, 7, 9, 3, 1, 2]\n",
            "10 [0 6 5 8 4 7 9 3 1 2]\n",
            "discarded index [0, 6, 5, 8, 4, 7, 9, 3, 1, 2]\n",
            "10 [0 6 5 8 4 7 9 3 1 2]\n",
            "discarded index [0, 6, 5, 8, 4, 7, 9, 3, 1, 2]\n",
            "10 [0 6 5 8 4 7 9 3 1 2]\n",
            "discarded index [0, 6, 5, 8, 4, 7, 9, 3, 1, 2]\n",
            "10 [0 6 5 8 4 7 9 3 1 2]\n",
            "discarded index [0, 6, 5, 8, 4, 7, 9, 3, 1, 2]\n",
            "10 [0 6 5 8 4 7 9 3 1 2]\n",
            "discarded index [0, 6, 5, 8, 4, 7, 9, 3, 1, 2]\n",
            "10 [0 6 5 8 4 7 9 3 1 2]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 189, bulyan: at fang n_at 10 e 189 | val loss 1.7818 val acc 32.8937 best val_acc 37.114448\n",
            "discarded index [0, 1, 7, 2, 5, 4, 9, 8, 6, 3]\n",
            "10 [0 1 7 2 5 4 9 8 6 3]\n",
            "discarded index [0, 1, 7, 2, 5, 4, 9, 8, 6, 3]\n",
            "10 [0 1 7 2 5 4 9 8 6 3]\n",
            "discarded index [0, 1, 7, 2, 5, 4, 9, 8, 6, 3]\n",
            "10 [0 1 7 2 5 4 9 8 6 3]\n",
            "discarded index [0, 1, 7, 2, 5, 4, 9, 8, 6, 3]\n",
            "10 [0 1 7 2 5 4 9 8 6 3]\n",
            "discarded index [0, 1, 7, 2, 5, 4, 9, 8, 6, 3]\n",
            "10 [0 1 7 2 5 4 9 8 6 3]\n",
            "discarded index [0, 1, 7, 2, 5, 4, 9, 8, 6, 3]\n",
            "10 [0 1 7 2 5 4 9 8 6 3]\n",
            "discarded index [0, 1, 7, 2, 5, 4, 9, 8, 6, 3]\n",
            "10 [0 1 7 2 5 4 9 8 6 3]\n",
            "discarded index [0, 1, 7, 2, 5, 4, 9, 8, 6, 3]\n",
            "10 [0 1 7 2 5 4 9 8 6 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 190, bulyan: at fang n_at 10 e 190 | val loss 1.7494 val acc 35.5722 best val_acc 37.114448\n",
            "discarded index [6, 1, 0, 5, 8, 2, 9, 4, 3, 7]\n",
            "10 [6 1 0 5 8 2 9 4 3 7]\n",
            "discarded index [6, 1, 0, 5, 8, 2, 9, 4, 3, 7]\n",
            "10 [6 1 0 5 8 2 9 4 3 7]\n",
            "discarded index [6, 1, 0, 5, 8, 2, 9, 4, 3, 7]\n",
            "10 [6 1 0 5 8 2 9 4 3 7]\n",
            "discarded index [6, 1, 0, 5, 8, 2, 9, 4, 3, 7]\n",
            "10 [6 1 0 5 8 2 9 4 3 7]\n",
            "discarded index [6, 1, 0, 5, 8, 2, 9, 4, 3, 7]\n",
            "10 [6 1 0 5 8 2 9 4 3 7]\n",
            "discarded index [6, 1, 0, 5, 8, 2, 9, 4, 3, 7]\n",
            "10 [6 1 0 5 8 2 9 4 3 7]\n",
            "discarded index [6, 1, 0, 5, 8, 2, 9, 4, 3, 7]\n",
            "10 [6 1 0 5 8 2 9 4 3 7]\n",
            "discarded index [6, 1, 0, 5, 8, 2, 9, 4, 3, 7]\n",
            "10 [6 1 0 5 8 2 9 4 3 7]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 191, bulyan: at fang n_at 10 e 191 | val loss 1.8198 val acc 33.5430 best val_acc 37.114448\n",
            "discarded index [7, 6, 5, 1, 0, 3, 9, 2, 8, 4]\n",
            "10 [7 6 5 1 0 3 9 2 8 4]\n",
            "discarded index [7, 6, 5, 1, 0, 3, 9, 2, 8, 4]\n",
            "10 [7 6 5 1 0 3 9 2 8 4]\n",
            "discarded index [7, 6, 5, 1, 0, 3, 9, 2, 8, 4]\n",
            "10 [7 6 5 1 0 3 9 2 8 4]\n",
            "discarded index [7, 6, 5, 1, 0, 3, 9, 2, 8, 4]\n",
            "10 [7 6 5 1 0 3 9 2 8 4]\n",
            "discarded index [7, 6, 5, 1, 0, 3, 9, 2, 8, 4]\n",
            "10 [7 6 5 1 0 3 9 2 8 4]\n",
            "discarded index [7, 6, 5, 1, 0, 3, 9, 2, 8, 4]\n",
            "10 [7 6 5 1 0 3 9 2 8 4]\n",
            "discarded index [7, 6, 5, 1, 0, 3, 9, 2, 8, 4]\n",
            "10 [7 6 5 1 0 3 9 2 8 4]\n",
            "discarded index [7, 6, 5, 1, 0, 3, 9, 2, 8, 4]\n",
            "10 [7 6 5 1 0 3 9 2 8 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 192, bulyan: at fang n_at 10 e 192 | val loss 1.8045 val acc 33.5227 best val_acc 37.114448\n",
            "discarded index [5, 6, 2, 0, 7, 9, 4, 3, 1, 8]\n",
            "10 [5 6 2 0 7 9 4 3 1 8]\n",
            "discarded index [5, 6, 2, 0, 7, 9, 4, 3, 1, 8]\n",
            "10 [5 6 2 0 7 9 4 3 1 8]\n",
            "discarded index [5, 6, 2, 0, 7, 9, 4, 3, 1, 8]\n",
            "10 [5 6 2 0 7 9 4 3 1 8]\n",
            "discarded index [5, 6, 2, 0, 7, 9, 4, 3, 1, 8]\n",
            "10 [5 6 2 0 7 9 4 3 1 8]\n",
            "discarded index [5, 6, 2, 0, 7, 9, 4, 3, 1, 8]\n",
            "10 [5 6 2 0 7 9 4 3 1 8]\n",
            "discarded index [5, 6, 2, 0, 7, 9, 4, 3, 1, 8]\n",
            "10 [5 6 2 0 7 9 4 3 1 8]\n",
            "discarded index [5, 6, 2, 0, 7, 9, 4, 3, 1, 8]\n",
            "10 [5 6 2 0 7 9 4 3 1 8]\n",
            "discarded index [5, 6, 2, 0, 7, 9, 4, 3, 1, 8]\n",
            "10 [5 6 2 0 7 9 4 3 1 8]\n",
            "discarded index [5, 6, 2, 0, 7, 9, 4, 3, 1, 8]\n",
            "10 [5 6 2 0 7 9 4 3 1 8]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 193, bulyan: at fang n_at 10 e 193 | val loss 1.7925 val acc 35.9781 best val_acc 37.114448\n",
            "discarded index [0, 1, 7, 9, 6, 4, 8, 2, 5, 3]\n",
            "10 [0 1 7 9 6 4 8 2 5 3]\n",
            "discarded index [0, 1, 7, 9, 6, 4, 8, 2, 5, 3]\n",
            "10 [0 1 7 9 6 4 8 2 5 3]\n",
            "discarded index [0, 1, 7, 9, 6, 4, 8, 2, 5, 3]\n",
            "10 [0 1 7 9 6 4 8 2 5 3]\n",
            "discarded index [0, 1, 7, 9, 6, 4, 8, 2, 5, 3]\n",
            "10 [0 1 7 9 6 4 8 2 5 3]\n",
            "discarded index [0, 1, 7, 9, 6, 4, 8, 2, 5, 3]\n",
            "10 [0 1 7 9 6 4 8 2 5 3]\n",
            "discarded index [0, 1, 7, 9, 6, 4, 8, 2, 5, 3]\n",
            "10 [0 1 7 9 6 4 8 2 5 3]\n",
            "discarded index [0, 1, 7, 9, 6, 4, 8, 2, 5, 3]\n",
            "10 [0 1 7 9 6 4 8 2 5 3]\n",
            "discarded index [0, 1, 7, 9, 6, 4, 8, 2, 5, 3]\n",
            "10 [0 1 7 9 6 4 8 2 5 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 194, bulyan: at fang n_at 10 e 194 | val loss 1.6990 val acc 38.2711 best val_acc 38.271104\n",
            "discarded index [5, 6, 9, 8, 1, 7, 2, 0, 4, 3]\n",
            "10 [5 6 9 8 1 7 2 0 4 3]\n",
            "discarded index [5, 6, 9, 8, 1, 7, 2, 0, 4, 3]\n",
            "10 [5 6 9 8 1 7 2 0 4 3]\n",
            "discarded index [5, 6, 9, 8, 1, 7, 2, 0, 4, 3]\n",
            "10 [5 6 9 8 1 7 2 0 4 3]\n",
            "discarded index [5, 6, 9, 8, 1, 7, 2, 0, 4, 3]\n",
            "10 [5 6 9 8 1 7 2 0 4 3]\n",
            "discarded index [5, 6, 9, 8, 1, 7, 2, 0, 4, 3]\n",
            "10 [5 6 9 8 1 7 2 0 4 3]\n",
            "discarded index [5, 6, 9, 8, 1, 7, 2, 0, 4, 3]\n",
            "10 [5 6 9 8 1 7 2 0 4 3]\n",
            "discarded index [5, 6, 9, 8, 1, 7, 2, 0, 4, 3]\n",
            "10 [5 6 9 8 1 7 2 0 4 3]\n",
            "discarded index [5, 6, 9, 8, 1, 7, 2, 0, 4, 3]\n",
            "10 [5 6 9 8 1 7 2 0 4 3]\n",
            "discarded index [5, 6, 9, 8, 1, 7, 2, 0, 4, 3]\n",
            "10 [5 6 9 8 1 7 2 0 4 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 195, bulyan: at fang n_at 10 e 195 | val loss 1.8158 val acc 34.3141 best val_acc 38.271104\n",
            "discarded index [7, 0, 9, 8, 4, 2, 1, 6, 3, 5]\n",
            "10 [7 0 9 8 4 2 1 6 3 5]\n",
            "discarded index [7, 0, 9, 8, 4, 2, 1, 6, 3, 5]\n",
            "10 [7 0 9 8 4 2 1 6 3 5]\n",
            "discarded index [7, 0, 9, 8, 4, 2, 1, 6, 3, 5]\n",
            "10 [7 0 9 8 4 2 1 6 3 5]\n",
            "discarded index [7, 0, 9, 8, 4, 2, 1, 6, 3, 5]\n",
            "10 [7 0 9 8 4 2 1 6 3 5]\n",
            "discarded index [7, 0, 9, 8, 4, 2, 1, 6, 3, 5]\n",
            "10 [7 0 9 8 4 2 1 6 3 5]\n",
            "discarded index [7, 0, 9, 8, 4, 2, 1, 6, 3, 5]\n",
            "10 [7 0 9 8 4 2 1 6 3 5]\n",
            "discarded index [7, 0, 9, 8, 4, 2, 1, 6, 3, 5]\n",
            "10 [7 0 9 8 4 2 1 6 3 5]\n",
            "discarded index [7, 0, 9, 8, 4, 2, 1, 6, 3, 5]\n",
            "10 [7 0 9 8 4 2 1 6 3 5]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 196, bulyan: at fang n_at 10 e 196 | val loss 1.7280 val acc 36.6071 best val_acc 38.271104\n",
            "discarded index [0, 1, 6, 9, 8, 3, 4, 7, 5, 2]\n",
            "10 [0 1 6 9 8 3 4 7 5 2]\n",
            "discarded index [0, 1, 6, 9, 8, 3, 4, 7, 5, 2]\n",
            "10 [0 1 6 9 8 3 4 7 5 2]\n",
            "discarded index [0, 1, 6, 9, 8, 3, 4, 7, 5, 2]\n",
            "10 [0 1 6 9 8 3 4 7 5 2]\n",
            "discarded index [0, 1, 6, 9, 8, 3, 4, 7, 5, 2]\n",
            "10 [0 1 6 9 8 3 4 7 5 2]\n",
            "discarded index [0, 1, 6, 9, 8, 3, 4, 7, 5, 2]\n",
            "10 [0 1 6 9 8 3 4 7 5 2]\n",
            "discarded index [0, 1, 6, 9, 8, 3, 4, 7, 5, 2]\n",
            "10 [0 1 6 9 8 3 4 7 5 2]\n",
            "discarded index [0, 1, 6, 9, 8, 3, 4, 7, 5, 2]\n",
            "10 [0 1 6 9 8 3 4 7 5 2]\n",
            "discarded index [0, 1, 6, 9, 8, 3, 4, 7, 5, 2]\n",
            "10 [0 1 6 9 8 3 4 7 5 2]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 197, bulyan: at fang n_at 10 e 197 | val loss 1.7055 val acc 37.9870 best val_acc 38.271104\n",
            "discarded index [8, 5, 9, 7, 1, 4, 6, 3, 2, 0]\n",
            "10 [8 5 9 7 1 4 6 3 2 0]\n",
            "discarded index [8, 5, 9, 7, 1, 4, 6, 3, 2, 0]\n",
            "10 [8 5 9 7 1 4 6 3 2 0]\n",
            "discarded index [8, 5, 9, 7, 1, 4, 6, 3, 2, 0]\n",
            "10 [8 5 9 7 1 4 6 3 2 0]\n",
            "discarded index [8, 5, 9, 7, 1, 4, 6, 3, 2, 0]\n",
            "10 [8 5 9 7 1 4 6 3 2 0]\n",
            "discarded index [8, 5, 9, 7, 1, 4, 6, 3, 2, 0]\n",
            "10 [8 5 9 7 1 4 6 3 2 0]\n",
            "discarded index [8, 5, 9, 7, 1, 4, 6, 3, 2, 0]\n",
            "10 [8 5 9 7 1 4 6 3 2 0]\n",
            "discarded index [8, 5, 9, 7, 1, 4, 6, 3, 2, 0]\n",
            "10 [8 5 9 7 1 4 6 3 2 0]\n",
            "discarded index [8, 5, 9, 7, 1, 4, 6, 3, 2, 0]\n",
            "10 [8 5 9 7 1 4 6 3 2 0]\n",
            "discarded index [8, 5, 9, 7, 1, 4, 6, 3, 2, 0]\n",
            "10 [8 5 9 7 1 4 6 3 2 0]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 198, bulyan: at fang n_at 10 e 198 | val loss 1.7923 val acc 31.7979 best val_acc 38.271104\n",
            "discarded index [6, 9, 1, 2, 0, 3, 5, 7, 8, 4]\n",
            "10 [6 9 1 2 0 3 5 7 8 4]\n",
            "discarded index [6, 9, 1, 2, 0, 3, 5, 7, 8, 4]\n",
            "10 [6 9 1 2 0 3 5 7 8 4]\n",
            "discarded index [6, 9, 1, 2, 0, 3, 5, 7, 8, 4]\n",
            "10 [6 9 1 2 0 3 5 7 8 4]\n",
            "discarded index [6, 9, 1, 2, 0, 3, 5, 7, 8, 4]\n",
            "10 [6 9 1 2 0 3 5 7 8 4]\n",
            "discarded index [6, 9, 1, 2, 0, 3, 5, 7, 8, 4]\n",
            "10 [6 9 1 2 0 3 5 7 8 4]\n",
            "discarded index [6, 9, 1, 2, 0, 3, 5, 7, 8, 4]\n",
            "10 [6 9 1 2 0 3 5 7 8 4]\n",
            "discarded index [6, 9, 1, 2, 0, 3, 5, 7, 8, 4]\n",
            "10 [6 9 1 2 0 3 5 7 8 4]\n",
            "discarded index [6, 9, 1, 2, 0, 3, 5, 7, 8, 4]\n",
            "10 [6 9 1 2 0 3 5 7 8 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 199, bulyan: at fang n_at 10 e 199 | val loss 1.8148 val acc 33.6445 best val_acc 38.271104\n",
            "discarded index [1, 6, 2, 8, 7, 4, 5, 3, 9, 0]\n",
            "10 [1 6 2 8 7 4 5 3 9 0]\n",
            "discarded index [1, 6, 2, 8, 7, 4, 5, 3, 9, 0]\n",
            "10 [1 6 2 8 7 4 5 3 9 0]\n",
            "discarded index [1, 6, 2, 8, 7, 4, 5, 3, 9, 0]\n",
            "10 [1 6 2 8 7 4 5 3 9 0]\n",
            "discarded index [1, 6, 2, 8, 7, 4, 5, 3, 9, 0]\n",
            "10 [1 6 2 8 7 4 5 3 9 0]\n",
            "discarded index [1, 6, 2, 8, 7, 4, 5, 3, 9, 0]\n",
            "10 [1 6 2 8 7 4 5 3 9 0]\n",
            "discarded index [1, 6, 2, 8, 7, 4, 5, 3, 9, 0]\n",
            "10 [1 6 2 8 7 4 5 3 9 0]\n",
            "discarded index [1, 6, 2, 8, 7, 4, 5, 3, 9, 0]\n",
            "10 [1 6 2 8 7 4 5 3 9 0]\n",
            "discarded index [1, 6, 2, 8, 7, 4, 5, 3, 9, 0]\n",
            "10 [1 6 2 8 7 4 5 3 9 0]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 200, bulyan: at fang n_at 10 e 200 | val loss 1.7551 val acc 34.9229 best val_acc 38.271104\n",
            "discarded index [7, 0, 1, 4, 8, 9, 2, 6, 5, 3]\n",
            "10 [7 0 1 4 8 9 2 6 5 3]\n",
            "discarded index [7, 0, 1, 4, 8, 9, 2, 6, 5, 3]\n",
            "10 [7 0 1 4 8 9 2 6 5 3]\n",
            "discarded index [7, 0, 1, 4, 8, 9, 2, 6, 5, 3]\n",
            "10 [7 0 1 4 8 9 2 6 5 3]\n",
            "discarded index [7, 0, 1, 4, 8, 9, 2, 6, 5, 3]\n",
            "10 [7 0 1 4 8 9 2 6 5 3]\n",
            "discarded index [7, 0, 1, 4, 8, 9, 2, 6, 5, 3]\n",
            "10 [7 0 1 4 8 9 2 6 5 3]\n",
            "discarded index [7, 0, 1, 4, 8, 9, 2, 6, 5, 3]\n",
            "10 [7 0 1 4 8 9 2 6 5 3]\n",
            "discarded index [7, 0, 1, 4, 8, 9, 2, 6, 5, 3]\n",
            "10 [7 0 1 4 8 9 2 6 5 3]\n",
            "discarded index [7, 0, 1, 4, 8, 9, 2, 6, 5, 3]\n",
            "10 [7 0 1 4 8 9 2 6 5 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 201, bulyan: at fang n_at 10 e 201 | val loss 1.6487 val acc 39.5901 best val_acc 39.590097\n",
            "discarded index [5, 8, 0, 6, 3, 4, 9, 1, 2, 7]\n",
            "10 [5 8 0 6 3 4 9 1 2 7]\n",
            "discarded index [5, 8, 0, 6, 3, 4, 9, 1, 2, 7]\n",
            "10 [5 8 0 6 3 4 9 1 2 7]\n",
            "discarded index [5, 8, 0, 6, 3, 4, 9, 1, 2, 7]\n",
            "10 [5 8 0 6 3 4 9 1 2 7]\n",
            "discarded index [5, 8, 0, 6, 3, 4, 9, 1, 2, 7]\n",
            "10 [5 8 0 6 3 4 9 1 2 7]\n",
            "discarded index [5, 8, 0, 6, 3, 4, 9, 1, 2, 7]\n",
            "10 [5 8 0 6 3 4 9 1 2 7]\n",
            "discarded index [5, 8, 0, 6, 3, 4, 9, 1, 2, 7]\n",
            "10 [5 8 0 6 3 4 9 1 2 7]\n",
            "discarded index [5, 8, 0, 6, 3, 4, 9, 1, 2, 7]\n",
            "10 [5 8 0 6 3 4 9 1 2 7]\n",
            "discarded index [5, 8, 0, 6, 3, 4, 9, 1, 2, 7]\n",
            "10 [5 8 0 6 3 4 9 1 2 7]\n",
            "discarded index [5, 8, 0, 6, 3, 4, 9, 1, 2, 7]\n",
            "10 [5 8 0 6 3 4 9 1 2 7]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 202, bulyan: at fang n_at 10 e 202 | val loss 1.6347 val acc 40.6859 best val_acc 40.685877\n",
            "discarded index [0, 1, 6, 9, 7, 5, 2, 3, 8, 4]\n",
            "10 [0 1 6 9 7 5 2 3 8 4]\n",
            "discarded index [0, 1, 6, 9, 7, 5, 2, 3, 8, 4]\n",
            "10 [0 1 6 9 7 5 2 3 8 4]\n",
            "discarded index [0, 1, 6, 9, 7, 5, 2, 3, 8, 4]\n",
            "10 [0 1 6 9 7 5 2 3 8 4]\n",
            "discarded index [0, 1, 6, 9, 7, 5, 2, 3, 8, 4]\n",
            "10 [0 1 6 9 7 5 2 3 8 4]\n",
            "discarded index [0, 1, 6, 9, 7, 5, 2, 3, 8, 4]\n",
            "10 [0 1 6 9 7 5 2 3 8 4]\n",
            "discarded index [0, 1, 6, 9, 7, 5, 2, 3, 8, 4]\n",
            "10 [0 1 6 9 7 5 2 3 8 4]\n",
            "discarded index [0, 1, 6, 9, 7, 5, 2, 3, 8, 4]\n",
            "10 [0 1 6 9 7 5 2 3 8 4]\n",
            "discarded index [0, 1, 6, 9, 7, 5, 2, 3, 8, 4]\n",
            "10 [0 1 6 9 7 5 2 3 8 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 203, bulyan: at fang n_at 10 e 203 | val loss 1.6567 val acc 38.0682 best val_acc 40.685877\n",
            "discarded index [8, 6, 9, 2, 5, 4, 0, 1, 3, 7]\n",
            "10 [8 6 9 2 5 4 0 1 3 7]\n",
            "discarded index [8, 6, 9, 2, 5, 4, 0, 1, 3, 7]\n",
            "10 [8 6 9 2 5 4 0 1 3 7]\n",
            "discarded index [8, 6, 9, 2, 5, 4, 0, 1, 3, 7]\n",
            "10 [8 6 9 2 5 4 0 1 3 7]\n",
            "discarded index [8, 6, 9, 2, 5, 4, 0, 1, 3, 7]\n",
            "10 [8 6 9 2 5 4 0 1 3 7]\n",
            "discarded index [8, 6, 9, 2, 5, 4, 0, 1, 3, 7]\n",
            "10 [8 6 9 2 5 4 0 1 3 7]\n",
            "discarded index [8, 6, 9, 2, 5, 4, 0, 1, 3, 7]\n",
            "10 [8 6 9 2 5 4 0 1 3 7]\n",
            "discarded index [8, 6, 9, 2, 5, 4, 0, 1, 3, 7]\n",
            "10 [8 6 9 2 5 4 0 1 3 7]\n",
            "discarded index [8, 6, 9, 2, 5, 4, 0, 1, 3, 7]\n",
            "10 [8 6 9 2 5 4 0 1 3 7]\n",
            "discarded index [8, 6, 9, 2, 5, 4, 0, 1, 3, 7]\n",
            "10 [8 6 9 2 5 4 0 1 3 7]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 204, bulyan: at fang n_at 10 e 204 | val loss 1.7765 val acc 32.6502 best val_acc 40.685877\n",
            "discarded index [6, 0, 1, 2, 9, 3, 7, 8, 5, 4]\n",
            "10 [6 0 1 2 9 3 7 8 5 4]\n",
            "discarded index [6, 0, 1, 2, 9, 3, 7, 8, 5, 4]\n",
            "10 [6 0 1 2 9 3 7 8 5 4]\n",
            "discarded index [6, 0, 1, 2, 9, 3, 7, 8, 5, 4]\n",
            "10 [6 0 1 2 9 3 7 8 5 4]\n",
            "discarded index [6, 0, 1, 2, 9, 3, 7, 8, 5, 4]\n",
            "10 [6 0 1 2 9 3 7 8 5 4]\n",
            "discarded index [6, 0, 1, 2, 9, 3, 7, 8, 5, 4]\n",
            "10 [6 0 1 2 9 3 7 8 5 4]\n",
            "discarded index [6, 0, 1, 2, 9, 3, 7, 8, 5, 4]\n",
            "10 [6 0 1 2 9 3 7 8 5 4]\n",
            "discarded index [6, 0, 1, 2, 9, 3, 7, 8, 5, 4]\n",
            "10 [6 0 1 2 9 3 7 8 5 4]\n",
            "discarded index [6, 0, 1, 2, 9, 3, 7, 8, 5, 4]\n",
            "10 [6 0 1 2 9 3 7 8 5 4]\n",
            "discarded index [6, 0, 1, 2, 9, 3, 7, 8, 5, 4]\n",
            "10 [6 0 1 2 9 3 7 8 5 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 205, bulyan: at fang n_at 10 e 205 | val loss 1.9746 val acc 28.6932 best val_acc 40.685877\n",
            "discarded index [3, 0, 2, 4, 9, 1, 7, 6, 5, 8]\n",
            "10 [3 0 2 4 9 1 7 6 5 8]\n",
            "discarded index [3, 0, 2, 4, 9, 1, 7, 6, 5, 8]\n",
            "10 [3 0 2 4 9 1 7 6 5 8]\n",
            "discarded index [3, 0, 2, 4, 9, 1, 7, 6, 5, 8]\n",
            "10 [3 0 2 4 9 1 7 6 5 8]\n",
            "discarded index [3, 0, 2, 4, 9, 1, 7, 6, 5, 8]\n",
            "10 [3 0 2 4 9 1 7 6 5 8]\n",
            "discarded index [3, 0, 2, 4, 9, 1, 7, 6, 5, 8]\n",
            "10 [3 0 2 4 9 1 7 6 5 8]\n",
            "discarded index [3, 0, 2, 4, 9, 1, 7, 6, 5, 8]\n",
            "10 [3 0 2 4 9 1 7 6 5 8]\n",
            "discarded index [3, 0, 2, 4, 9, 1, 7, 6, 5, 8]\n",
            "10 [3 0 2 4 9 1 7 6 5 8]\n",
            "discarded index [3, 0, 2, 4, 9, 1, 7, 6, 5, 8]\n",
            "10 [3 0 2 4 9 1 7 6 5 8]\n",
            "discarded index [3, 0, 2, 4, 9, 1, 7, 6, 5, 8]\n",
            "10 [3 0 2 4 9 1 7 6 5 8]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 206, bulyan: at fang n_at 10 e 206 | val loss 1.9390 val acc 27.0089 best val_acc 40.685877\n",
            "discarded index [1, 0, 7, 4, 2, 5, 9, 6, 3, 8]\n",
            "10 [1 0 7 4 2 5 9 6 3 8]\n",
            "discarded index [1, 0, 7, 4, 2, 5, 9, 6, 3, 8]\n",
            "10 [1 0 7 4 2 5 9 6 3 8]\n",
            "discarded index [1, 0, 7, 4, 2, 5, 9, 6, 3, 8]\n",
            "10 [1 0 7 4 2 5 9 6 3 8]\n",
            "discarded index [1, 0, 7, 4, 2, 5, 9, 6, 3, 8]\n",
            "10 [1 0 7 4 2 5 9 6 3 8]\n",
            "discarded index [1, 0, 7, 4, 2, 5, 9, 6, 3, 8]\n",
            "10 [1 0 7 4 2 5 9 6 3 8]\n",
            "discarded index [1, 0, 7, 4, 2, 5, 9, 6, 3, 8]\n",
            "10 [1 0 7 4 2 5 9 6 3 8]\n",
            "discarded index [1, 0, 7, 4, 2, 5, 9, 6, 3, 8]\n",
            "10 [1 0 7 4 2 5 9 6 3 8]\n",
            "discarded index [1, 0, 7, 4, 2, 5, 9, 6, 3, 8]\n",
            "10 [1 0 7 4 2 5 9 6 3 8]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 207, bulyan: at fang n_at 10 e 207 | val loss 2.1121 val acc 23.8636 best val_acc 40.685877\n",
            "discarded index [9, 6, 8, 0, 3, 5, 7, 2, 1, 4]\n",
            "10 [9 6 8 0 3 5 7 2 1 4]\n",
            "discarded index [9, 6, 8, 0, 3, 5, 7, 2, 1, 4]\n",
            "10 [9 6 8 0 3 5 7 2 1 4]\n",
            "discarded index [9, 6, 8, 0, 3, 5, 7, 2, 1, 4]\n",
            "10 [9 6 8 0 3 5 7 2 1 4]\n",
            "discarded index [9, 6, 8, 0, 3, 5, 7, 2, 1, 4]\n",
            "10 [9 6 8 0 3 5 7 2 1 4]\n",
            "discarded index [9, 6, 8, 0, 3, 5, 7, 2, 1, 4]\n",
            "10 [9 6 8 0 3 5 7 2 1 4]\n",
            "discarded index [9, 6, 8, 0, 3, 5, 7, 2, 1, 4]\n",
            "10 [9 6 8 0 3 5 7 2 1 4]\n",
            "discarded index [9, 6, 8, 0, 3, 5, 7, 2, 1, 4]\n",
            "10 [9 6 8 0 3 5 7 2 1 4]\n",
            "discarded index [9, 6, 8, 0, 3, 5, 7, 2, 1, 4]\n",
            "10 [9 6 8 0 3 5 7 2 1 4]\n",
            "discarded index [9, 6, 8, 0, 3, 5, 7, 2, 1, 4]\n",
            "10 [9 6 8 0 3 5 7 2 1 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 208, bulyan: at fang n_at 10 e 208 | val loss 2.0695 val acc 22.4635 best val_acc 40.685877\n",
            "discarded index [9, 6, 8, 3, 1, 2, 5, 7, 0, 4]\n",
            "10 [9 6 8 3 1 2 5 7 0 4]\n",
            "discarded index [9, 6, 8, 3, 1, 2, 5, 7, 0, 4]\n",
            "10 [9 6 8 3 1 2 5 7 0 4]\n",
            "discarded index [9, 6, 8, 3, 1, 2, 5, 7, 0, 4]\n",
            "10 [9 6 8 3 1 2 5 7 0 4]\n",
            "discarded index [9, 6, 8, 3, 1, 2, 5, 7, 0, 4]\n",
            "10 [9 6 8 3 1 2 5 7 0 4]\n",
            "discarded index [9, 6, 8, 3, 1, 2, 5, 7, 0, 4]\n",
            "10 [9 6 8 3 1 2 5 7 0 4]\n",
            "discarded index [9, 6, 8, 3, 1, 2, 5, 7, 0, 4]\n",
            "10 [9 6 8 3 1 2 5 7 0 4]\n",
            "discarded index [9, 6, 8, 3, 1, 2, 5, 7, 0, 4]\n",
            "10 [9 6 8 3 1 2 5 7 0 4]\n",
            "discarded index [9, 6, 8, 3, 1, 2, 5, 7, 0, 4]\n",
            "10 [9 6 8 3 1 2 5 7 0 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 209, bulyan: at fang n_at 10 e 209 | val loss 2.0339 val acc 23.8028 best val_acc 40.685877\n",
            "discarded index [9, 1, 6, 2, 0, 3, 8, 5, 4, 7]\n",
            "10 [9 1 6 2 0 3 8 5 4 7]\n",
            "discarded index [9, 1, 6, 2, 0, 3, 8, 5, 4, 7]\n",
            "10 [9 1 6 2 0 3 8 5 4 7]\n",
            "discarded index [9, 1, 6, 2, 0, 3, 8, 5, 4, 7]\n",
            "10 [9 1 6 2 0 3 8 5 4 7]\n",
            "discarded index [9, 1, 6, 2, 0, 3, 8, 5, 4, 7]\n",
            "10 [9 1 6 2 0 3 8 5 4 7]\n",
            "discarded index [9, 1, 6, 2, 0, 3, 8, 5, 4, 7]\n",
            "10 [9 1 6 2 0 3 8 5 4 7]\n",
            "discarded index [9, 1, 6, 2, 0, 3, 8, 5, 4, 7]\n",
            "10 [9 1 6 2 0 3 8 5 4 7]\n",
            "discarded index [9, 1, 6, 2, 0, 3, 8, 5, 4, 7]\n",
            "10 [9 1 6 2 0 3 8 5 4 7]\n",
            "discarded index [9, 1, 6, 2, 0, 3, 8, 5, 4, 7]\n",
            "10 [9 1 6 2 0 3 8 5 4 7]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 210, bulyan: at fang n_at 10 e 210 | val loss 2.0603 val acc 24.3709 best val_acc 40.685877\n",
            "discarded index [0, 5, 1, 8, 4, 7, 3, 6, 9, 2]\n",
            "10 [0 5 1 8 4 7 3 6 9 2]\n",
            "discarded index [0, 5, 1, 8, 4, 7, 3, 6, 9, 2]\n",
            "10 [0 5 1 8 4 7 3 6 9 2]\n",
            "discarded index [0, 5, 1, 8, 4, 7, 3, 6, 9, 2]\n",
            "10 [0 5 1 8 4 7 3 6 9 2]\n",
            "discarded index [0, 5, 1, 8, 4, 7, 3, 6, 9, 2]\n",
            "10 [0 5 1 8 4 7 3 6 9 2]\n",
            "discarded index [0, 5, 1, 8, 4, 7, 3, 6, 9, 2]\n",
            "10 [0 5 1 8 4 7 3 6 9 2]\n",
            "discarded index [0, 5, 1, 8, 4, 7, 3, 6, 9, 2]\n",
            "10 [0 5 1 8 4 7 3 6 9 2]\n",
            "discarded index [0, 5, 1, 8, 4, 7, 3, 6, 9, 2]\n",
            "10 [0 5 1 8 4 7 3 6 9 2]\n",
            "discarded index [0, 5, 1, 8, 4, 7, 3, 6, 9, 2]\n",
            "10 [0 5 1 8 4 7 3 6 9 2]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 211, bulyan: at fang n_at 10 e 211 | val loss 1.8863 val acc 30.1339 best val_acc 40.685877\n",
            "discarded index [0, 1, 6, 3, 2, 8, 4, 5, 9, 7]\n",
            "10 [0 1 6 3 2 8 4 5 9 7]\n",
            "discarded index [0, 1, 6, 3, 2, 8, 4, 5, 9, 7]\n",
            "10 [0 1 6 3 2 8 4 5 9 7]\n",
            "discarded index [0, 1, 6, 3, 2, 8, 4, 5, 9, 7]\n",
            "10 [0 1 6 3 2 8 4 5 9 7]\n",
            "discarded index [0, 1, 6, 3, 2, 8, 4, 5, 9, 7]\n",
            "10 [0 1 6 3 2 8 4 5 9 7]\n",
            "discarded index [0, 1, 6, 3, 2, 8, 4, 5, 9, 7]\n",
            "10 [0 1 6 3 2 8 4 5 9 7]\n",
            "discarded index [0, 1, 6, 3, 2, 8, 4, 5, 9, 7]\n",
            "10 [0 1 6 3 2 8 4 5 9 7]\n",
            "discarded index [0, 1, 6, 3, 2, 8, 4, 5, 9, 7]\n",
            "10 [0 1 6 3 2 8 4 5 9 7]\n",
            "discarded index [0, 1, 6, 3, 2, 8, 4, 5, 9, 7]\n",
            "10 [0 1 6 3 2 8 4 5 9 7]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 212, bulyan: at fang n_at 10 e 212 | val loss 1.7941 val acc 31.2500 best val_acc 40.685877\n",
            "discarded index [0, 4, 6, 3, 9, 8, 7, 2, 5, 1]\n",
            "10 [0 4 6 3 9 8 7 2 5 1]\n",
            "discarded index [0, 4, 6, 3, 9, 8, 7, 2, 5, 1]\n",
            "10 [0 4 6 3 9 8 7 2 5 1]\n",
            "discarded index [0, 4, 6, 3, 9, 8, 7, 2, 5, 1]\n",
            "10 [0 4 6 3 9 8 7 2 5 1]\n",
            "discarded index [0, 4, 6, 3, 9, 8, 7, 2, 5, 1]\n",
            "10 [0 4 6 3 9 8 7 2 5 1]\n",
            "discarded index [0, 4, 6, 3, 9, 8, 7, 2, 5, 1]\n",
            "10 [0 4 6 3 9 8 7 2 5 1]\n",
            "discarded index [0, 4, 6, 3, 9, 8, 7, 2, 5, 1]\n",
            "10 [0 4 6 3 9 8 7 2 5 1]\n",
            "discarded index [0, 4, 6, 3, 9, 8, 7, 2, 5, 1]\n",
            "10 [0 4 6 3 9 8 7 2 5 1]\n",
            "discarded index [0, 4, 6, 3, 9, 8, 7, 2, 5, 1]\n",
            "10 [0 4 6 3 9 8 7 2 5 1]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 213, bulyan: at fang n_at 10 e 213 | val loss 1.7776 val acc 34.7200 best val_acc 40.685877\n",
            "discarded index [1, 6, 7, 8, 4, 3, 9, 5, 0, 2]\n",
            "10 [1 6 7 8 4 3 9 5 0 2]\n",
            "discarded index [1, 6, 7, 8, 4, 3, 9, 5, 0, 2]\n",
            "10 [1 6 7 8 4 3 9 5 0 2]\n",
            "discarded index [1, 6, 7, 8, 4, 3, 9, 5, 0, 2]\n",
            "10 [1 6 7 8 4 3 9 5 0 2]\n",
            "discarded index [1, 6, 7, 8, 4, 3, 9, 5, 0, 2]\n",
            "10 [1 6 7 8 4 3 9 5 0 2]\n",
            "discarded index [1, 6, 7, 8, 4, 3, 9, 5, 0, 2]\n",
            "10 [1 6 7 8 4 3 9 5 0 2]\n",
            "discarded index [1, 6, 7, 8, 4, 3, 9, 5, 0, 2]\n",
            "10 [1 6 7 8 4 3 9 5 0 2]\n",
            "discarded index [1, 6, 7, 8, 4, 3, 9, 5, 0, 2]\n",
            "10 [1 6 7 8 4 3 9 5 0 2]\n",
            "discarded index [1, 6, 7, 8, 4, 3, 9, 5, 0, 2]\n",
            "10 [1 6 7 8 4 3 9 5 0 2]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 214, bulyan: at fang n_at 10 e 214 | val loss 1.8374 val acc 33.1372 best val_acc 40.685877\n",
            "discarded index [3, 7, 0, 8, 2, 4, 5, 9, 6, 1]\n",
            "10 [3 7 0 8 2 4 5 9 6 1]\n",
            "discarded index [3, 7, 0, 8, 2, 4, 5, 9, 6, 1]\n",
            "10 [3 7 0 8 2 4 5 9 6 1]\n",
            "discarded index [3, 7, 0, 8, 2, 4, 5, 9, 6, 1]\n",
            "10 [3 7 0 8 2 4 5 9 6 1]\n",
            "discarded index [3, 7, 0, 8, 2, 4, 5, 9, 6, 1]\n",
            "10 [3 7 0 8 2 4 5 9 6 1]\n",
            "discarded index [3, 7, 0, 8, 2, 4, 5, 9, 6, 1]\n",
            "10 [3 7 0 8 2 4 5 9 6 1]\n",
            "discarded index [3, 7, 0, 8, 2, 4, 5, 9, 6, 1]\n",
            "10 [3 7 0 8 2 4 5 9 6 1]\n",
            "discarded index [3, 7, 0, 8, 2, 4, 5, 9, 6, 1]\n",
            "10 [3 7 0 8 2 4 5 9 6 1]\n",
            "discarded index [3, 7, 0, 8, 2, 4, 5, 9, 6, 1]\n",
            "10 [3 7 0 8 2 4 5 9 6 1]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 215, bulyan: at fang n_at 10 e 215 | val loss 1.8555 val acc 33.5836 best val_acc 40.685877\n",
            "discarded index [6, 5, 3, 2, 9, 1, 4, 0, 8, 7]\n",
            "10 [6 5 3 2 9 1 4 0 8 7]\n",
            "discarded index [6, 5, 3, 2, 9, 1, 4, 0, 8, 7]\n",
            "10 [6 5 3 2 9 1 4 0 8 7]\n",
            "discarded index [6, 5, 3, 2, 9, 1, 4, 0, 8, 7]\n",
            "10 [6 5 3 2 9 1 4 0 8 7]\n",
            "discarded index [6, 5, 3, 2, 9, 1, 4, 0, 8, 7]\n",
            "10 [6 5 3 2 9 1 4 0 8 7]\n",
            "discarded index [6, 5, 3, 2, 9, 1, 4, 0, 8, 7]\n",
            "10 [6 5 3 2 9 1 4 0 8 7]\n",
            "discarded index [6, 5, 3, 2, 9, 1, 4, 0, 8, 7]\n",
            "10 [6 5 3 2 9 1 4 0 8 7]\n",
            "discarded index [6, 5, 3, 2, 9, 1, 4, 0, 8, 7]\n",
            "10 [6 5 3 2 9 1 4 0 8 7]\n",
            "discarded index [6, 5, 3, 2, 9, 1, 4, 0, 8, 7]\n",
            "10 [6 5 3 2 9 1 4 0 8 7]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 216, bulyan: at fang n_at 10 e 216 | val loss 1.8858 val acc 32.3052 best val_acc 40.685877\n",
            "discarded index [0, 1, 6, 7, 4, 2, 9, 3, 8, 5]\n",
            "10 [0 1 6 7 4 2 9 3 8 5]\n",
            "discarded index [0, 1, 6, 7, 4, 2, 9, 3, 8, 5]\n",
            "10 [0 1 6 7 4 2 9 3 8 5]\n",
            "discarded index [0, 1, 6, 7, 4, 2, 9, 3, 8, 5]\n",
            "10 [0 1 6 7 4 2 9 3 8 5]\n",
            "discarded index [0, 1, 6, 7, 4, 2, 9, 3, 8, 5]\n",
            "10 [0 1 6 7 4 2 9 3 8 5]\n",
            "discarded index [0, 1, 6, 7, 4, 2, 9, 3, 8, 5]\n",
            "10 [0 1 6 7 4 2 9 3 8 5]\n",
            "discarded index [0, 1, 6, 7, 4, 2, 9, 3, 8, 5]\n",
            "10 [0 1 6 7 4 2 9 3 8 5]\n",
            "discarded index [0, 1, 6, 7, 4, 2, 9, 3, 8, 5]\n",
            "10 [0 1 6 7 4 2 9 3 8 5]\n",
            "discarded index [0, 1, 6, 7, 4, 2, 9, 3, 8, 5]\n",
            "10 [0 1 6 7 4 2 9 3 8 5]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 217, bulyan: at fang n_at 10 e 217 | val loss 1.7922 val acc 36.0187 best val_acc 40.685877\n",
            "discarded index [5, 1, 7, 0, 8, 3, 9, 2, 6, 4]\n",
            "10 [5 1 7 0 8 3 9 2 6 4]\n",
            "discarded index [5, 1, 7, 0, 8, 3, 9, 2, 6, 4]\n",
            "10 [5 1 7 0 8 3 9 2 6 4]\n",
            "discarded index [5, 1, 7, 0, 8, 3, 9, 2, 6, 4]\n",
            "10 [5 1 7 0 8 3 9 2 6 4]\n",
            "discarded index [5, 1, 7, 0, 8, 3, 9, 2, 6, 4]\n",
            "10 [5 1 7 0 8 3 9 2 6 4]\n",
            "discarded index [5, 1, 7, 0, 8, 3, 9, 2, 6, 4]\n",
            "10 [5 1 7 0 8 3 9 2 6 4]\n",
            "discarded index [5, 1, 7, 0, 8, 3, 9, 2, 6, 4]\n",
            "10 [5 1 7 0 8 3 9 2 6 4]\n",
            "discarded index [5, 1, 7, 0, 8, 3, 9, 2, 6, 4]\n",
            "10 [5 1 7 0 8 3 9 2 6 4]\n",
            "discarded index [5, 1, 7, 0, 8, 3, 9, 2, 6, 4]\n",
            "10 [5 1 7 0 8 3 9 2 6 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 218, bulyan: at fang n_at 10 e 218 | val loss 1.7086 val acc 38.1291 best val_acc 40.685877\n",
            "discarded index [3, 0, 6, 4, 9, 7, 5, 8, 2, 1]\n",
            "10 [3 0 6 4 9 7 5 8 2 1]\n",
            "discarded index [3, 0, 6, 4, 9, 7, 5, 8, 2, 1]\n",
            "10 [3 0 6 4 9 7 5 8 2 1]\n",
            "discarded index [3, 0, 6, 4, 9, 7, 5, 8, 2, 1]\n",
            "10 [3 0 6 4 9 7 5 8 2 1]\n",
            "discarded index [3, 0, 6, 4, 9, 7, 5, 8, 2, 1]\n",
            "10 [3 0 6 4 9 7 5 8 2 1]\n",
            "discarded index [3, 0, 6, 4, 9, 7, 5, 8, 2, 1]\n",
            "10 [3 0 6 4 9 7 5 8 2 1]\n",
            "discarded index [3, 0, 6, 4, 9, 7, 5, 8, 2, 1]\n",
            "10 [3 0 6 4 9 7 5 8 2 1]\n",
            "discarded index [3, 0, 6, 4, 9, 7, 5, 8, 2, 1]\n",
            "10 [3 0 6 4 9 7 5 8 2 1]\n",
            "discarded index [3, 0, 6, 4, 9, 7, 5, 8, 2, 1]\n",
            "10 [3 0 6 4 9 7 5 8 2 1]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 219, bulyan: at fang n_at 10 e 219 | val loss 1.6795 val acc 38.7987 best val_acc 40.685877\n",
            "discarded index [6, 9, 8, 7, 3, 1, 5, 4, 2, 0]\n",
            "10 [6 9 8 7 3 1 5 4 2 0]\n",
            "discarded index [6, 9, 8, 7, 3, 1, 5, 4, 2, 0]\n",
            "10 [6 9 8 7 3 1 5 4 2 0]\n",
            "discarded index [6, 9, 8, 7, 3, 1, 5, 4, 2, 0]\n",
            "10 [6 9 8 7 3 1 5 4 2 0]\n",
            "discarded index [6, 9, 8, 7, 3, 1, 5, 4, 2, 0]\n",
            "10 [6 9 8 7 3 1 5 4 2 0]\n",
            "discarded index [6, 9, 8, 7, 3, 1, 5, 4, 2, 0]\n",
            "10 [6 9 8 7 3 1 5 4 2 0]\n",
            "discarded index [6, 9, 8, 7, 3, 1, 5, 4, 2, 0]\n",
            "10 [6 9 8 7 3 1 5 4 2 0]\n",
            "discarded index [6, 9, 8, 7, 3, 1, 5, 4, 2, 0]\n",
            "10 [6 9 8 7 3 1 5 4 2 0]\n",
            "discarded index [6, 9, 8, 7, 3, 1, 5, 4, 2, 0]\n",
            "10 [6 9 8 7 3 1 5 4 2 0]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 220, bulyan: at fang n_at 10 e 220 | val loss 1.7386 val acc 36.5057 best val_acc 40.685877\n",
            "discarded index [0, 7, 1, 5, 8, 9, 4, 2, 6, 3]\n",
            "10 [0 7 1 5 8 9 4 2 6 3]\n",
            "discarded index [0, 7, 1, 5, 8, 9, 4, 2, 6, 3]\n",
            "10 [0 7 1 5 8 9 4 2 6 3]\n",
            "discarded index [0, 7, 1, 5, 8, 9, 4, 2, 6, 3]\n",
            "10 [0 7 1 5 8 9 4 2 6 3]\n",
            "discarded index [0, 7, 1, 5, 8, 9, 4, 2, 6, 3]\n",
            "10 [0 7 1 5 8 9 4 2 6 3]\n",
            "discarded index [0, 7, 1, 5, 8, 9, 4, 2, 6, 3]\n",
            "10 [0 7 1 5 8 9 4 2 6 3]\n",
            "discarded index [0, 7, 1, 5, 8, 9, 4, 2, 6, 3]\n",
            "10 [0 7 1 5 8 9 4 2 6 3]\n",
            "discarded index [0, 7, 1, 5, 8, 9, 4, 2, 6, 3]\n",
            "10 [0 7 1 5 8 9 4 2 6 3]\n",
            "discarded index [0, 7, 1, 5, 8, 9, 4, 2, 6, 3]\n",
            "10 [0 7 1 5 8 9 4 2 6 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 221, bulyan: at fang n_at 10 e 221 | val loss 1.8130 val acc 30.7021 best val_acc 40.685877\n",
            "discarded index [0, 7, 1, 8, 9, 2, 4, 3, 6, 5]\n",
            "10 [0 7 1 8 9 2 4 3 6 5]\n",
            "discarded index [0, 7, 1, 8, 9, 2, 4, 3, 6, 5]\n",
            "10 [0 7 1 8 9 2 4 3 6 5]\n",
            "discarded index [0, 7, 1, 8, 9, 2, 4, 3, 6, 5]\n",
            "10 [0 7 1 8 9 2 4 3 6 5]\n",
            "discarded index [0, 7, 1, 8, 9, 2, 4, 3, 6, 5]\n",
            "10 [0 7 1 8 9 2 4 3 6 5]\n",
            "discarded index [0, 7, 1, 8, 9, 2, 4, 3, 6, 5]\n",
            "10 [0 7 1 8 9 2 4 3 6 5]\n",
            "discarded index [0, 7, 1, 8, 9, 2, 4, 3, 6, 5]\n",
            "10 [0 7 1 8 9 2 4 3 6 5]\n",
            "discarded index [0, 7, 1, 8, 9, 2, 4, 3, 6, 5]\n",
            "10 [0 7 1 8 9 2 4 3 6 5]\n",
            "discarded index [0, 7, 1, 8, 9, 2, 4, 3, 6, 5]\n",
            "10 [0 7 1 8 9 2 4 3 6 5]\n",
            "discarded index [0, 7, 1, 8, 9, 2, 4, 3, 6, 5]\n",
            "10 [0 7 1 8 9 2 4 3 6 5]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 222, bulyan: at fang n_at 10 e 222 | val loss 1.8853 val acc 32.7922 best val_acc 40.685877\n",
            "discarded index [8, 9, 6, 3, 1, 7, 2, 0, 5, 4]\n",
            "10 [8 9 6 3 1 7 2 0 5 4]\n",
            "discarded index [8, 9, 6, 3, 1, 7, 2, 0, 5, 4]\n",
            "10 [8 9 6 3 1 7 2 0 5 4]\n",
            "discarded index [8, 9, 6, 3, 1, 7, 2, 0, 5, 4]\n",
            "10 [8 9 6 3 1 7 2 0 5 4]\n",
            "discarded index [8, 9, 6, 3, 1, 7, 2, 0, 5, 4]\n",
            "10 [8 9 6 3 1 7 2 0 5 4]\n",
            "discarded index [8, 9, 6, 3, 1, 7, 2, 0, 5, 4]\n",
            "10 [8 9 6 3 1 7 2 0 5 4]\n",
            "discarded index [8, 9, 6, 3, 1, 7, 2, 0, 5, 4]\n",
            "10 [8 9 6 3 1 7 2 0 5 4]\n",
            "discarded index [8, 9, 6, 3, 1, 7, 2, 0, 5, 4]\n",
            "10 [8 9 6 3 1 7 2 0 5 4]\n",
            "discarded index [8, 9, 6, 3, 1, 7, 2, 0, 5, 4]\n",
            "10 [8 9 6 3 1 7 2 0 5 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 223, bulyan: at fang n_at 10 e 223 | val loss 1.7873 val acc 34.8417 best val_acc 40.685877\n",
            "discarded index [6, 2, 1, 7, 8, 4, 9, 3, 0, 5]\n",
            "10 [6 2 1 7 8 4 9 3 0 5]\n",
            "discarded index [6, 2, 1, 7, 8, 4, 9, 3, 0, 5]\n",
            "10 [6 2 1 7 8 4 9 3 0 5]\n",
            "discarded index [6, 2, 1, 7, 8, 4, 9, 3, 0, 5]\n",
            "10 [6 2 1 7 8 4 9 3 0 5]\n",
            "discarded index [6, 2, 1, 7, 8, 4, 9, 3, 0, 5]\n",
            "10 [6 2 1 7 8 4 9 3 0 5]\n",
            "discarded index [6, 2, 1, 7, 8, 4, 9, 3, 0, 5]\n",
            "10 [6 2 1 7 8 4 9 3 0 5]\n",
            "discarded index [6, 2, 1, 7, 8, 4, 9, 3, 0, 5]\n",
            "10 [6 2 1 7 8 4 9 3 0 5]\n",
            "discarded index [6, 2, 1, 7, 8, 4, 9, 3, 0, 5]\n",
            "10 [6 2 1 7 8 4 9 3 0 5]\n",
            "discarded index [6, 2, 1, 7, 8, 4, 9, 3, 0, 5]\n",
            "10 [6 2 1 7 8 4 9 3 0 5]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 224, bulyan: at fang n_at 10 e 224 | val loss 1.7332 val acc 37.0739 best val_acc 40.685877\n",
            "discarded index [9, 5, 8, 0, 3, 7, 6, 1, 2, 4]\n",
            "10 [9 5 8 0 3 7 6 1 2 4]\n",
            "discarded index [9, 5, 8, 0, 3, 7, 6, 1, 2, 4]\n",
            "10 [9 5 8 0 3 7 6 1 2 4]\n",
            "discarded index [9, 5, 8, 0, 3, 7, 6, 1, 2, 4]\n",
            "10 [9 5 8 0 3 7 6 1 2 4]\n",
            "discarded index [9, 5, 8, 0, 3, 7, 6, 1, 2, 4]\n",
            "10 [9 5 8 0 3 7 6 1 2 4]\n",
            "discarded index [9, 5, 8, 0, 3, 7, 6, 1, 2, 4]\n",
            "10 [9 5 8 0 3 7 6 1 2 4]\n",
            "discarded index [9, 5, 8, 0, 3, 7, 6, 1, 2, 4]\n",
            "10 [9 5 8 0 3 7 6 1 2 4]\n",
            "discarded index [9, 5, 8, 0, 3, 7, 6, 1, 2, 4]\n",
            "10 [9 5 8 0 3 7 6 1 2 4]\n",
            "discarded index [9, 5, 8, 0, 3, 7, 6, 1, 2, 4]\n",
            "10 [9 5 8 0 3 7 6 1 2 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 225, bulyan: at fang n_at 10 e 225 | val loss 1.7704 val acc 35.2679 best val_acc 40.685877\n",
            "discarded index [0, 1, 7, 9, 2, 4, 5, 6, 8, 3]\n",
            "10 [0 1 7 9 2 4 5 6 8 3]\n",
            "discarded index [0, 1, 7, 9, 2, 4, 5, 6, 8, 3]\n",
            "10 [0 1 7 9 2 4 5 6 8 3]\n",
            "discarded index [0, 1, 7, 9, 2, 4, 5, 6, 8, 3]\n",
            "10 [0 1 7 9 2 4 5 6 8 3]\n",
            "discarded index [0, 1, 7, 9, 2, 4, 5, 6, 8, 3]\n",
            "10 [0 1 7 9 2 4 5 6 8 3]\n",
            "discarded index [0, 1, 7, 9, 2, 4, 5, 6, 8, 3]\n",
            "10 [0 1 7 9 2 4 5 6 8 3]\n",
            "discarded index [0, 1, 7, 9, 2, 4, 5, 6, 8, 3]\n",
            "10 [0 1 7 9 2 4 5 6 8 3]\n",
            "discarded index [0, 1, 7, 9, 2, 4, 5, 6, 8, 3]\n",
            "10 [0 1 7 9 2 4 5 6 8 3]\n",
            "discarded index [0, 1, 7, 9, 2, 4, 5, 6, 8, 3]\n",
            "10 [0 1 7 9 2 4 5 6 8 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 226, bulyan: at fang n_at 10 e 226 | val loss 1.9334 val acc 32.4472 best val_acc 40.685877\n",
            "discarded index [1, 3, 9, 8, 5, 2, 6, 0, 7, 4]\n",
            "10 [1 3 9 8 5 2 6 0 7 4]\n",
            "discarded index [1, 3, 9, 8, 5, 2, 6, 0, 7, 4]\n",
            "10 [1 3 9 8 5 2 6 0 7 4]\n",
            "discarded index [1, 3, 9, 8, 5, 2, 6, 0, 7, 4]\n",
            "10 [1 3 9 8 5 2 6 0 7 4]\n",
            "discarded index [1, 3, 9, 8, 5, 2, 6, 0, 7, 4]\n",
            "10 [1 3 9 8 5 2 6 0 7 4]\n",
            "discarded index [1, 3, 9, 8, 5, 2, 6, 0, 7, 4]\n",
            "10 [1 3 9 8 5 2 6 0 7 4]\n",
            "discarded index [1, 3, 9, 8, 5, 2, 6, 0, 7, 4]\n",
            "10 [1 3 9 8 5 2 6 0 7 4]\n",
            "discarded index [1, 3, 9, 8, 5, 2, 6, 0, 7, 4]\n",
            "10 [1 3 9 8 5 2 6 0 7 4]\n",
            "discarded index [1, 3, 9, 8, 5, 2, 6, 0, 7, 4]\n",
            "10 [1 3 9 8 5 2 6 0 7 4]\n",
            "discarded index [1, 3, 9, 8, 5, 2, 6, 0, 7, 4]\n",
            "10 [1 3 9 8 5 2 6 0 7 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 227, bulyan: at fang n_at 10 e 227 | val loss 1.9587 val acc 30.1339 best val_acc 40.685877\n",
            "discarded index [9, 0, 7, 8, 5, 6, 1, 2, 4, 3]\n",
            "10 [9 0 7 8 5 6 1 2 4 3]\n",
            "discarded index [9, 0, 7, 8, 5, 6, 1, 2, 4, 3]\n",
            "10 [9 0 7 8 5 6 1 2 4 3]\n",
            "discarded index [9, 0, 7, 8, 5, 6, 1, 2, 4, 3]\n",
            "10 [9 0 7 8 5 6 1 2 4 3]\n",
            "discarded index [9, 0, 7, 8, 5, 6, 1, 2, 4, 3]\n",
            "10 [9 0 7 8 5 6 1 2 4 3]\n",
            "discarded index [9, 0, 7, 8, 5, 6, 1, 2, 4, 3]\n",
            "10 [9 0 7 8 5 6 1 2 4 3]\n",
            "discarded index [9, 0, 7, 8, 5, 6, 1, 2, 4, 3]\n",
            "10 [9 0 7 8 5 6 1 2 4 3]\n",
            "discarded index [9, 0, 7, 8, 5, 6, 1, 2, 4, 3]\n",
            "10 [9 0 7 8 5 6 1 2 4 3]\n",
            "discarded index [9, 0, 7, 8, 5, 6, 1, 2, 4, 3]\n",
            "10 [9 0 7 8 5 6 1 2 4 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 228, bulyan: at fang n_at 10 e 228 | val loss 1.7982 val acc 34.6794 best val_acc 40.685877\n",
            "discarded index [1, 0, 6, 2, 4, 8, 3, 7, 5, 9]\n",
            "10 [1 0 6 2 4 8 3 7 5 9]\n",
            "discarded index [1, 0, 6, 2, 4, 8, 3, 7, 5, 9]\n",
            "10 [1 0 6 2 4 8 3 7 5 9]\n",
            "discarded index [1, 0, 6, 2, 4, 8, 3, 7, 5, 9]\n",
            "10 [1 0 6 2 4 8 3 7 5 9]\n",
            "discarded index [1, 0, 6, 2, 4, 8, 3, 7, 5, 9]\n",
            "10 [1 0 6 2 4 8 3 7 5 9]\n",
            "discarded index [1, 0, 6, 2, 4, 8, 3, 7, 5, 9]\n",
            "10 [1 0 6 2 4 8 3 7 5 9]\n",
            "discarded index [1, 0, 6, 2, 4, 8, 3, 7, 5, 9]\n",
            "10 [1 0 6 2 4 8 3 7 5 9]\n",
            "discarded index [1, 0, 6, 2, 4, 8, 3, 7, 5, 9]\n",
            "10 [1 0 6 2 4 8 3 7 5 9]\n",
            "discarded index [1, 0, 6, 2, 4, 8, 3, 7, 5, 9]\n",
            "10 [1 0 6 2 4 8 3 7 5 9]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 229, bulyan: at fang n_at 10 e 229 | val loss 1.7064 val acc 36.2622 best val_acc 40.685877\n",
            "discarded index [0, 1, 7, 2, 5, 6, 8, 4, 3, 9]\n",
            "10 [0 1 7 2 5 6 8 4 3 9]\n",
            "discarded index [0, 1, 7, 2, 5, 6, 8, 4, 3, 9]\n",
            "10 [0 1 7 2 5 6 8 4 3 9]\n",
            "discarded index [0, 1, 7, 2, 5, 6, 8, 4, 3, 9]\n",
            "10 [0 1 7 2 5 6 8 4 3 9]\n",
            "discarded index [0, 1, 7, 2, 5, 6, 8, 4, 3, 9]\n",
            "10 [0 1 7 2 5 6 8 4 3 9]\n",
            "discarded index [0, 1, 7, 2, 5, 6, 8, 4, 3, 9]\n",
            "10 [0 1 7 2 5 6 8 4 3 9]\n",
            "discarded index [0, 1, 7, 2, 5, 6, 8, 4, 3, 9]\n",
            "10 [0 1 7 2 5 6 8 4 3 9]\n",
            "discarded index [0, 1, 7, 2, 5, 6, 8, 4, 3, 9]\n",
            "10 [0 1 7 2 5 6 8 4 3 9]\n",
            "discarded index [0, 1, 7, 2, 5, 6, 8, 4, 3, 9]\n",
            "10 [0 1 7 2 5 6 8 4 3 9]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 230, bulyan: at fang n_at 10 e 230 | val loss 1.7565 val acc 33.2995 best val_acc 40.685877\n",
            "discarded index [1, 6, 8, 9, 7, 4, 2, 3, 5, 0]\n",
            "10 [1 6 8 9 7 4 2 3 5 0]\n",
            "discarded index [1, 6, 8, 9, 7, 4, 2, 3, 5, 0]\n",
            "10 [1 6 8 9 7 4 2 3 5 0]\n",
            "discarded index [1, 6, 8, 9, 7, 4, 2, 3, 5, 0]\n",
            "10 [1 6 8 9 7 4 2 3 5 0]\n",
            "discarded index [1, 6, 8, 9, 7, 4, 2, 3, 5, 0]\n",
            "10 [1 6 8 9 7 4 2 3 5 0]\n",
            "discarded index [1, 6, 8, 9, 7, 4, 2, 3, 5, 0]\n",
            "10 [1 6 8 9 7 4 2 3 5 0]\n",
            "discarded index [1, 6, 8, 9, 7, 4, 2, 3, 5, 0]\n",
            "10 [1 6 8 9 7 4 2 3 5 0]\n",
            "discarded index [1, 6, 8, 9, 7, 4, 2, 3, 5, 0]\n",
            "10 [1 6 8 9 7 4 2 3 5 0]\n",
            "discarded index [1, 6, 8, 9, 7, 4, 2, 3, 5, 0]\n",
            "10 [1 6 8 9 7 4 2 3 5 0]\n",
            "discarded index [1, 6, 8, 9, 7, 4, 2, 3, 5, 0]\n",
            "10 [1 6 8 9 7 4 2 3 5 0]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 231, bulyan: at fang n_at 10 e 231 | val loss 1.9402 val acc 29.4643 best val_acc 40.685877\n",
            "discarded index [1, 6, 5, 7, 2, 9, 8, 3, 4, 0]\n",
            "10 [1 6 5 7 2 9 8 3 4 0]\n",
            "discarded index [1, 6, 5, 7, 2, 9, 8, 3, 4, 0]\n",
            "10 [1 6 5 7 2 9 8 3 4 0]\n",
            "discarded index [1, 6, 5, 7, 2, 9, 8, 3, 4, 0]\n",
            "10 [1 6 5 7 2 9 8 3 4 0]\n",
            "discarded index [1, 6, 5, 7, 2, 9, 8, 3, 4, 0]\n",
            "10 [1 6 5 7 2 9 8 3 4 0]\n",
            "discarded index [1, 6, 5, 7, 2, 9, 8, 3, 4, 0]\n",
            "10 [1 6 5 7 2 9 8 3 4 0]\n",
            "discarded index [1, 6, 5, 7, 2, 9, 8, 3, 4, 0]\n",
            "10 [1 6 5 7 2 9 8 3 4 0]\n",
            "discarded index [1, 6, 5, 7, 2, 9, 8, 3, 4, 0]\n",
            "10 [1 6 5 7 2 9 8 3 4 0]\n",
            "discarded index [1, 6, 5, 7, 2, 9, 8, 3, 4, 0]\n",
            "10 [1 6 5 7 2 9 8 3 4 0]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 232, bulyan: at fang n_at 10 e 232 | val loss 1.9039 val acc 31.9805 best val_acc 40.685877\n",
            "discarded index [4, 2, 3, 0, 9, 5, 1, 7, 6, 8]\n",
            "10 [4 2 3 0 9 5 1 7 6 8]\n",
            "discarded index [4, 2, 3, 0, 9, 5, 1, 7, 6, 8]\n",
            "10 [4 2 3 0 9 5 1 7 6 8]\n",
            "discarded index [4, 2, 3, 0, 9, 5, 1, 7, 6, 8]\n",
            "10 [4 2 3 0 9 5 1 7 6 8]\n",
            "discarded index [4, 2, 3, 0, 9, 5, 1, 7, 6, 8]\n",
            "10 [4 2 3 0 9 5 1 7 6 8]\n",
            "discarded index [4, 2, 3, 0, 9, 5, 1, 7, 6, 8]\n",
            "10 [4 2 3 0 9 5 1 7 6 8]\n",
            "discarded index [4, 2, 3, 0, 9, 5, 1, 7, 6, 8]\n",
            "10 [4 2 3 0 9 5 1 7 6 8]\n",
            "discarded index [4, 2, 3, 0, 9, 5, 1, 7, 6, 8]\n",
            "10 [4 2 3 0 9 5 1 7 6 8]\n",
            "discarded index [4, 2, 3, 0, 9, 5, 1, 7, 6, 8]\n",
            "10 [4 2 3 0 9 5 1 7 6 8]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 233, bulyan: at fang n_at 10 e 233 | val loss 1.8543 val acc 31.4123 best val_acc 40.685877\n",
            "discarded index [4, 3, 2, 6, 8, 0, 1, 9, 7, 5]\n",
            "10 [4 3 2 6 8 0 1 9 7 5]\n",
            "discarded index [4, 3, 2, 6, 8, 0, 1, 9, 7, 5]\n",
            "10 [4 3 2 6 8 0 1 9 7 5]\n",
            "discarded index [4, 3, 2, 6, 8, 0, 1, 9, 7, 5]\n",
            "10 [4 3 2 6 8 0 1 9 7 5]\n",
            "discarded index [4, 3, 2, 6, 8, 0, 1, 9, 7, 5]\n",
            "10 [4 3 2 6 8 0 1 9 7 5]\n",
            "discarded index [4, 3, 2, 6, 8, 0, 1, 9, 7, 5]\n",
            "10 [4 3 2 6 8 0 1 9 7 5]\n",
            "discarded index [4, 3, 2, 6, 8, 0, 1, 9, 7, 5]\n",
            "10 [4 3 2 6 8 0 1 9 7 5]\n",
            "discarded index [4, 3, 2, 6, 8, 0, 1, 9, 7, 5]\n",
            "10 [4 3 2 6 8 0 1 9 7 5]\n",
            "discarded index [4, 3, 2, 6, 8, 0, 1, 9, 7, 5]\n",
            "10 [4 3 2 6 8 0 1 9 7 5]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 234, bulyan: at fang n_at 10 e 234 | val loss 1.8388 val acc 30.8239 best val_acc 40.685877\n",
            "discarded index [2, 5, 1, 3, 6, 4, 9, 8, 7, 0]\n",
            "10 [2 5 1 3 6 4 9 8 7 0]\n",
            "discarded index [2, 5, 1, 3, 6, 4, 9, 8, 7, 0]\n",
            "10 [2 5 1 3 6 4 9 8 7 0]\n",
            "discarded index [2, 5, 1, 3, 6, 4, 9, 8, 7, 0]\n",
            "10 [2 5 1 3 6 4 9 8 7 0]\n",
            "discarded index [2, 5, 1, 3, 6, 4, 9, 8, 7, 0]\n",
            "10 [2 5 1 3 6 4 9 8 7 0]\n",
            "discarded index [2, 5, 1, 3, 6, 4, 9, 8, 7, 0]\n",
            "10 [2 5 1 3 6 4 9 8 7 0]\n",
            "discarded index [2, 5, 1, 3, 6, 4, 9, 8, 7, 0]\n",
            "10 [2 5 1 3 6 4 9 8 7 0]\n",
            "discarded index [2, 5, 1, 3, 6, 4, 9, 8, 7, 0]\n",
            "10 [2 5 1 3 6 4 9 8 7 0]\n",
            "discarded index [2, 5, 1, 3, 6, 4, 9, 8, 7, 0]\n",
            "10 [2 5 1 3 6 4 9 8 7 0]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 235, bulyan: at fang n_at 10 e 235 | val loss 1.7503 val acc 35.9984 best val_acc 40.685877\n",
            "discarded index [0, 6, 1, 2, 8, 5, 9, 4, 3, 7]\n",
            "10 [0 6 1 2 8 5 9 4 3 7]\n",
            "discarded index [0, 6, 1, 2, 8, 5, 9, 4, 3, 7]\n",
            "10 [0 6 1 2 8 5 9 4 3 7]\n",
            "discarded index [0, 6, 1, 2, 8, 5, 9, 4, 3, 7]\n",
            "10 [0 6 1 2 8 5 9 4 3 7]\n",
            "discarded index [0, 6, 1, 2, 8, 5, 9, 4, 3, 7]\n",
            "10 [0 6 1 2 8 5 9 4 3 7]\n",
            "discarded index [0, 6, 1, 2, 8, 5, 9, 4, 3, 7]\n",
            "10 [0 6 1 2 8 5 9 4 3 7]\n",
            "discarded index [0, 6, 1, 2, 8, 5, 9, 4, 3, 7]\n",
            "10 [0 6 1 2 8 5 9 4 3 7]\n",
            "discarded index [0, 6, 1, 2, 8, 5, 9, 4, 3, 7]\n",
            "10 [0 6 1 2 8 5 9 4 3 7]\n",
            "discarded index [0, 6, 1, 2, 8, 5, 9, 4, 3, 7]\n",
            "10 [0 6 1 2 8 5 9 4 3 7]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 236, bulyan: at fang n_at 10 e 236 | val loss 1.6965 val acc 37.3174 best val_acc 40.685877\n",
            "discarded index [7, 0, 9, 3, 8, 1, 5, 4, 2, 6]\n",
            "10 [7 0 9 3 8 1 5 4 2 6]\n",
            "discarded index [7, 0, 9, 3, 8, 1, 5, 4, 2, 6]\n",
            "10 [7 0 9 3 8 1 5 4 2 6]\n",
            "discarded index [7, 0, 9, 3, 8, 1, 5, 4, 2, 6]\n",
            "10 [7 0 9 3 8 1 5 4 2 6]\n",
            "discarded index [7, 0, 9, 3, 8, 1, 5, 4, 2, 6]\n",
            "10 [7 0 9 3 8 1 5 4 2 6]\n",
            "discarded index [7, 0, 9, 3, 8, 1, 5, 4, 2, 6]\n",
            "10 [7 0 9 3 8 1 5 4 2 6]\n",
            "discarded index [7, 0, 9, 3, 8, 1, 5, 4, 2, 6]\n",
            "10 [7 0 9 3 8 1 5 4 2 6]\n",
            "discarded index [7, 0, 9, 3, 8, 1, 5, 4, 2, 6]\n",
            "10 [7 0 9 3 8 1 5 4 2 6]\n",
            "discarded index [7, 0, 9, 3, 8, 1, 5, 4, 2, 6]\n",
            "10 [7 0 9 3 8 1 5 4 2 6]\n",
            "discarded index [7, 0, 9, 3, 8, 1, 5, 4, 2, 6]\n",
            "10 [7 0 9 3 8 1 5 4 2 6]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 237, bulyan: at fang n_at 10 e 237 | val loss 1.8749 val acc 32.5893 best val_acc 40.685877\n",
            "discarded index [7, 9, 8, 0, 6, 5, 4, 1, 2, 3]\n",
            "10 [7 9 8 0 6 5 4 1 2 3]\n",
            "discarded index [7, 9, 8, 0, 6, 5, 4, 1, 2, 3]\n",
            "10 [7 9 8 0 6 5 4 1 2 3]\n",
            "discarded index [7, 9, 8, 0, 6, 5, 4, 1, 2, 3]\n",
            "10 [7 9 8 0 6 5 4 1 2 3]\n",
            "discarded index [7, 9, 8, 0, 6, 5, 4, 1, 2, 3]\n",
            "10 [7 9 8 0 6 5 4 1 2 3]\n",
            "discarded index [7, 9, 8, 0, 6, 5, 4, 1, 2, 3]\n",
            "10 [7 9 8 0 6 5 4 1 2 3]\n",
            "discarded index [7, 9, 8, 0, 6, 5, 4, 1, 2, 3]\n",
            "10 [7 9 8 0 6 5 4 1 2 3]\n",
            "discarded index [7, 9, 8, 0, 6, 5, 4, 1, 2, 3]\n",
            "10 [7 9 8 0 6 5 4 1 2 3]\n",
            "discarded index [7, 9, 8, 0, 6, 5, 4, 1, 2, 3]\n",
            "10 [7 9 8 0 6 5 4 1 2 3]\n",
            "discarded index [7, 9, 8, 0, 6, 5, 4, 1, 2, 3]\n",
            "10 [7 9 8 0 6 5 4 1 2 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 238, bulyan: at fang n_at 10 e 238 | val loss 1.8359 val acc 33.2386 best val_acc 40.685877\n",
            "discarded index [3, 0, 7, 9, 1, 2, 4, 6, 8, 5]\n",
            "10 [3 0 7 9 1 2 4 6 8 5]\n",
            "discarded index [3, 0, 7, 9, 1, 2, 4, 6, 8, 5]\n",
            "10 [3 0 7 9 1 2 4 6 8 5]\n",
            "discarded index [3, 0, 7, 9, 1, 2, 4, 6, 8, 5]\n",
            "10 [3 0 7 9 1 2 4 6 8 5]\n",
            "discarded index [3, 0, 7, 9, 1, 2, 4, 6, 8, 5]\n",
            "10 [3 0 7 9 1 2 4 6 8 5]\n",
            "discarded index [3, 0, 7, 9, 1, 2, 4, 6, 8, 5]\n",
            "10 [3 0 7 9 1 2 4 6 8 5]\n",
            "discarded index [3, 0, 7, 9, 1, 2, 4, 6, 8, 5]\n",
            "10 [3 0 7 9 1 2 4 6 8 5]\n",
            "discarded index [3, 0, 7, 9, 1, 2, 4, 6, 8, 5]\n",
            "10 [3 0 7 9 1 2 4 6 8 5]\n",
            "discarded index [3, 0, 7, 9, 1, 2, 4, 6, 8, 5]\n",
            "10 [3 0 7 9 1 2 4 6 8 5]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 239, bulyan: at fang n_at 10 e 239 | val loss 1.7081 val acc 38.7378 best val_acc 40.685877\n",
            "discarded index [9, 6, 3, 8, 0, 7, 4, 5, 2, 1]\n",
            "10 [9 6 3 8 0 7 4 5 2 1]\n",
            "discarded index [9, 6, 3, 8, 0, 7, 4, 5, 2, 1]\n",
            "10 [9 6 3 8 0 7 4 5 2 1]\n",
            "discarded index [9, 6, 3, 8, 0, 7, 4, 5, 2, 1]\n",
            "10 [9 6 3 8 0 7 4 5 2 1]\n",
            "discarded index [9, 6, 3, 8, 0, 7, 4, 5, 2, 1]\n",
            "10 [9 6 3 8 0 7 4 5 2 1]\n",
            "discarded index [9, 6, 3, 8, 0, 7, 4, 5, 2, 1]\n",
            "10 [9 6 3 8 0 7 4 5 2 1]\n",
            "discarded index [9, 6, 3, 8, 0, 7, 4, 5, 2, 1]\n",
            "10 [9 6 3 8 0 7 4 5 2 1]\n",
            "discarded index [9, 6, 3, 8, 0, 7, 4, 5, 2, 1]\n",
            "10 [9 6 3 8 0 7 4 5 2 1]\n",
            "discarded index [9, 6, 3, 8, 0, 7, 4, 5, 2, 1]\n",
            "10 [9 6 3 8 0 7 4 5 2 1]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 240, bulyan: at fang n_at 10 e 240 | val loss 1.6194 val acc 42.1875 best val_acc 42.187500\n",
            "discarded index [0, 1, 6, 3, 5, 2, 9, 8, 7, 4]\n",
            "10 [0 1 6 3 5 2 9 8 7 4]\n",
            "discarded index [0, 1, 6, 3, 5, 2, 9, 8, 7, 4]\n",
            "10 [0 1 6 3 5 2 9 8 7 4]\n",
            "discarded index [0, 1, 6, 3, 5, 2, 9, 8, 7, 4]\n",
            "10 [0 1 6 3 5 2 9 8 7 4]\n",
            "discarded index [0, 1, 6, 3, 5, 2, 9, 8, 7, 4]\n",
            "10 [0 1 6 3 5 2 9 8 7 4]\n",
            "discarded index [0, 1, 6, 3, 5, 2, 9, 8, 7, 4]\n",
            "10 [0 1 6 3 5 2 9 8 7 4]\n",
            "discarded index [0, 1, 6, 3, 5, 2, 9, 8, 7, 4]\n",
            "10 [0 1 6 3 5 2 9 8 7 4]\n",
            "discarded index [0, 1, 6, 3, 5, 2, 9, 8, 7, 4]\n",
            "10 [0 1 6 3 5 2 9 8 7 4]\n",
            "discarded index [0, 1, 6, 3, 5, 2, 9, 8, 7, 4]\n",
            "10 [0 1 6 3 5 2 9 8 7 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 241, bulyan: at fang n_at 10 e 241 | val loss 1.6552 val acc 38.9205 best val_acc 42.187500\n",
            "discarded index [0, 1, 7, 5, 4, 3, 9, 8, 6, 2]\n",
            "10 [0 1 7 5 4 3 9 8 6 2]\n",
            "discarded index [0, 1, 7, 5, 4, 3, 9, 8, 6, 2]\n",
            "10 [0 1 7 5 4 3 9 8 6 2]\n",
            "discarded index [0, 1, 7, 5, 4, 3, 9, 8, 6, 2]\n",
            "10 [0 1 7 5 4 3 9 8 6 2]\n",
            "discarded index [0, 1, 7, 5, 4, 3, 9, 8, 6, 2]\n",
            "10 [0 1 7 5 4 3 9 8 6 2]\n",
            "discarded index [0, 1, 7, 5, 4, 3, 9, 8, 6, 2]\n",
            "10 [0 1 7 5 4 3 9 8 6 2]\n",
            "discarded index [0, 1, 7, 5, 4, 3, 9, 8, 6, 2]\n",
            "10 [0 1 7 5 4 3 9 8 6 2]\n",
            "discarded index [0, 1, 7, 5, 4, 3, 9, 8, 6, 2]\n",
            "10 [0 1 7 5 4 3 9 8 6 2]\n",
            "discarded index [0, 1, 7, 5, 4, 3, 9, 8, 6, 2]\n",
            "10 [0 1 7 5 4 3 9 8 6 2]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 242, bulyan: at fang n_at 10 e 242 | val loss 1.7929 val acc 33.0966 best val_acc 42.187500\n",
            "discarded index [5, 2, 9, 1, 0, 8, 4, 6, 7, 3]\n",
            "10 [5 2 9 1 0 8 4 6 7 3]\n",
            "discarded index [5, 2, 9, 1, 0, 8, 4, 6, 7, 3]\n",
            "10 [5 2 9 1 0 8 4 6 7 3]\n",
            "discarded index [5, 2, 9, 1, 0, 8, 4, 6, 7, 3]\n",
            "10 [5 2 9 1 0 8 4 6 7 3]\n",
            "discarded index [5, 2, 9, 1, 0, 8, 4, 6, 7, 3]\n",
            "10 [5 2 9 1 0 8 4 6 7 3]\n",
            "discarded index [5, 2, 9, 1, 0, 8, 4, 6, 7, 3]\n",
            "10 [5 2 9 1 0 8 4 6 7 3]\n",
            "discarded index [5, 2, 9, 1, 0, 8, 4, 6, 7, 3]\n",
            "10 [5 2 9 1 0 8 4 6 7 3]\n",
            "discarded index [5, 2, 9, 1, 0, 8, 4, 6, 7, 3]\n",
            "10 [5 2 9 1 0 8 4 6 7 3]\n",
            "discarded index [5, 2, 9, 1, 0, 8, 4, 6, 7, 3]\n",
            "10 [5 2 9 1 0 8 4 6 7 3]\n",
            "discarded index [5, 2, 9, 1, 0, 8, 4, 6, 7, 3]\n",
            "10 [5 2 9 1 0 8 4 6 7 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 243, bulyan: at fang n_at 10 e 243 | val loss 1.9361 val acc 28.2670 best val_acc 42.187500\n",
            "discarded index [5, 0, 1, 7, 9, 4, 3, 8, 6, 2]\n",
            "10 [5 0 1 7 9 4 3 8 6 2]\n",
            "discarded index [5, 0, 1, 7, 9, 4, 3, 8, 6, 2]\n",
            "10 [5 0 1 7 9 4 3 8 6 2]\n",
            "discarded index [5, 0, 1, 7, 9, 4, 3, 8, 6, 2]\n",
            "10 [5 0 1 7 9 4 3 8 6 2]\n",
            "discarded index [5, 0, 1, 7, 9, 4, 3, 8, 6, 2]\n",
            "10 [5 0 1 7 9 4 3 8 6 2]\n",
            "discarded index [5, 0, 1, 7, 9, 4, 3, 8, 6, 2]\n",
            "10 [5 0 1 7 9 4 3 8 6 2]\n",
            "discarded index [5, 0, 1, 7, 9, 4, 3, 8, 6, 2]\n",
            "10 [5 0 1 7 9 4 3 8 6 2]\n",
            "discarded index [5, 0, 1, 7, 9, 4, 3, 8, 6, 2]\n",
            "10 [5 0 1 7 9 4 3 8 6 2]\n",
            "discarded index [5, 0, 1, 7, 9, 4, 3, 8, 6, 2]\n",
            "10 [5 0 1 7 9 4 3 8 6 2]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 244, bulyan: at fang n_at 10 e 244 | val loss 1.8759 val acc 30.9253 best val_acc 42.187500\n",
            "discarded index [0, 7, 6, 4, 5, 1, 2, 3, 8, 9]\n",
            "10 [0 7 6 4 5 1 2 3 8 9]\n",
            "discarded index [0, 7, 6, 4, 5, 1, 2, 3, 8, 9]\n",
            "10 [0 7 6 4 5 1 2 3 8 9]\n",
            "discarded index [0, 7, 6, 4, 5, 1, 2, 3, 8, 9]\n",
            "10 [0 7 6 4 5 1 2 3 8 9]\n",
            "discarded index [0, 7, 6, 4, 5, 1, 2, 3, 8, 9]\n",
            "10 [0 7 6 4 5 1 2 3 8 9]\n",
            "discarded index [0, 7, 6, 4, 5, 1, 2, 3, 8, 9]\n",
            "10 [0 7 6 4 5 1 2 3 8 9]\n",
            "discarded index [0, 7, 6, 4, 5, 1, 2, 3, 8, 9]\n",
            "10 [0 7 6 4 5 1 2 3 8 9]\n",
            "discarded index [0, 7, 6, 4, 5, 1, 2, 3, 8, 9]\n",
            "10 [0 7 6 4 5 1 2 3 8 9]\n",
            "discarded index [0, 7, 6, 4, 5, 1, 2, 3, 8, 9]\n",
            "10 [0 7 6 4 5 1 2 3 8 9]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 245, bulyan: at fang n_at 10 e 245 | val loss 1.7939 val acc 33.4619 best val_acc 42.187500\n",
            "discarded index [7, 5, 0, 2, 9, 1, 8, 3, 6, 4]\n",
            "10 [7 5 0 2 9 1 8 3 6 4]\n",
            "discarded index [7, 5, 0, 2, 9, 1, 8, 3, 6, 4]\n",
            "10 [7 5 0 2 9 1 8 3 6 4]\n",
            "discarded index [7, 5, 0, 2, 9, 1, 8, 3, 6, 4]\n",
            "10 [7 5 0 2 9 1 8 3 6 4]\n",
            "discarded index [7, 5, 0, 2, 9, 1, 8, 3, 6, 4]\n",
            "10 [7 5 0 2 9 1 8 3 6 4]\n",
            "discarded index [7, 5, 0, 2, 9, 1, 8, 3, 6, 4]\n",
            "10 [7 5 0 2 9 1 8 3 6 4]\n",
            "discarded index [7, 5, 0, 2, 9, 1, 8, 3, 6, 4]\n",
            "10 [7 5 0 2 9 1 8 3 6 4]\n",
            "discarded index [7, 5, 0, 2, 9, 1, 8, 3, 6, 4]\n",
            "10 [7 5 0 2 9 1 8 3 6 4]\n",
            "discarded index [7, 5, 0, 2, 9, 1, 8, 3, 6, 4]\n",
            "10 [7 5 0 2 9 1 8 3 6 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 246, bulyan: at fang n_at 10 e 246 | val loss 1.6951 val acc 37.9667 best val_acc 42.187500\n",
            "discarded index [7, 9, 3, 0, 6, 1, 5, 8, 4, 2]\n",
            "10 [7 9 3 0 6 1 5 8 4 2]\n",
            "discarded index [7, 9, 3, 0, 6, 1, 5, 8, 4, 2]\n",
            "10 [7 9 3 0 6 1 5 8 4 2]\n",
            "discarded index [7, 9, 3, 0, 6, 1, 5, 8, 4, 2]\n",
            "10 [7 9 3 0 6 1 5 8 4 2]\n",
            "discarded index [7, 9, 3, 0, 6, 1, 5, 8, 4, 2]\n",
            "10 [7 9 3 0 6 1 5 8 4 2]\n",
            "discarded index [7, 9, 3, 0, 6, 1, 5, 8, 4, 2]\n",
            "10 [7 9 3 0 6 1 5 8 4 2]\n",
            "discarded index [7, 9, 3, 0, 6, 1, 5, 8, 4, 2]\n",
            "10 [7 9 3 0 6 1 5 8 4 2]\n",
            "discarded index [7, 9, 3, 0, 6, 1, 5, 8, 4, 2]\n",
            "10 [7 9 3 0 6 1 5 8 4 2]\n",
            "discarded index [7, 9, 3, 0, 6, 1, 5, 8, 4, 2]\n",
            "10 [7 9 3 0 6 1 5 8 4 2]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 247, bulyan: at fang n_at 10 e 247 | val loss 1.6144 val acc 40.3612 best val_acc 42.187500\n",
            "discarded index [9, 2, 6, 8, 4, 5, 7, 1, 0, 3]\n",
            "10 [9 2 6 8 4 5 7 1 0 3]\n",
            "discarded index [9, 2, 6, 8, 4, 5, 7, 1, 0, 3]\n",
            "10 [9 2 6 8 4 5 7 1 0 3]\n",
            "discarded index [9, 2, 6, 8, 4, 5, 7, 1, 0, 3]\n",
            "10 [9 2 6 8 4 5 7 1 0 3]\n",
            "discarded index [9, 2, 6, 8, 4, 5, 7, 1, 0, 3]\n",
            "10 [9 2 6 8 4 5 7 1 0 3]\n",
            "discarded index [9, 2, 6, 8, 4, 5, 7, 1, 0, 3]\n",
            "10 [9 2 6 8 4 5 7 1 0 3]\n",
            "discarded index [9, 2, 6, 8, 4, 5, 7, 1, 0, 3]\n",
            "10 [9 2 6 8 4 5 7 1 0 3]\n",
            "discarded index [9, 2, 6, 8, 4, 5, 7, 1, 0, 3]\n",
            "10 [9 2 6 8 4 5 7 1 0 3]\n",
            "discarded index [9, 2, 6, 8, 4, 5, 7, 1, 0, 3]\n",
            "10 [9 2 6 8 4 5 7 1 0 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 248, bulyan: at fang n_at 10 e 248 | val loss 1.5932 val acc 41.7005 best val_acc 42.187500\n",
            "discarded index [0, 7, 1, 5, 2, 8, 4, 9, 3, 6]\n",
            "10 [0 7 1 5 2 8 4 9 3 6]\n",
            "discarded index [0, 7, 1, 5, 2, 8, 4, 9, 3, 6]\n",
            "10 [0 7 1 5 2 8 4 9 3 6]\n",
            "discarded index [0, 7, 1, 5, 2, 8, 4, 9, 3, 6]\n",
            "10 [0 7 1 5 2 8 4 9 3 6]\n",
            "discarded index [0, 7, 1, 5, 2, 8, 4, 9, 3, 6]\n",
            "10 [0 7 1 5 2 8 4 9 3 6]\n",
            "discarded index [0, 7, 1, 5, 2, 8, 4, 9, 3, 6]\n",
            "10 [0 7 1 5 2 8 4 9 3 6]\n",
            "discarded index [0, 7, 1, 5, 2, 8, 4, 9, 3, 6]\n",
            "10 [0 7 1 5 2 8 4 9 3 6]\n",
            "discarded index [0, 7, 1, 5, 2, 8, 4, 9, 3, 6]\n",
            "10 [0 7 1 5 2 8 4 9 3 6]\n",
            "discarded index [0, 7, 1, 5, 2, 8, 4, 9, 3, 6]\n",
            "10 [0 7 1 5 2 8 4 9 3 6]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 249, bulyan: at fang n_at 10 e 249 | val loss 1.5945 val acc 41.7614 best val_acc 42.187500\n",
            "discarded index [6, 4, 7, 8, 3, 0, 1, 5, 2, 9]\n",
            "10 [6 4 7 8 3 0 1 5 2 9]\n",
            "discarded index [6, 4, 7, 8, 3, 0, 1, 5, 2, 9]\n",
            "10 [6 4 7 8 3 0 1 5 2 9]\n",
            "discarded index [6, 4, 7, 8, 3, 0, 1, 5, 2, 9]\n",
            "10 [6 4 7 8 3 0 1 5 2 9]\n",
            "discarded index [6, 4, 7, 8, 3, 0, 1, 5, 2, 9]\n",
            "10 [6 4 7 8 3 0 1 5 2 9]\n",
            "discarded index [6, 4, 7, 8, 3, 0, 1, 5, 2, 9]\n",
            "10 [6 4 7 8 3 0 1 5 2 9]\n",
            "discarded index [6, 4, 7, 8, 3, 0, 1, 5, 2, 9]\n",
            "10 [6 4 7 8 3 0 1 5 2 9]\n",
            "discarded index [6, 4, 7, 8, 3, 0, 1, 5, 2, 9]\n",
            "10 [6 4 7 8 3 0 1 5 2 9]\n",
            "discarded index [6, 4, 7, 8, 3, 0, 1, 5, 2, 9]\n",
            "10 [6 4 7 8 3 0 1 5 2 9]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 250, bulyan: at fang n_at 10 e 250 | val loss 1.6456 val acc 39.8133 best val_acc 42.187500\n",
            "discarded index [0, 3, 7, 1, 9, 6, 4, 5, 8, 2]\n",
            "10 [0 3 7 1 9 6 4 5 8 2]\n",
            "discarded index [0, 3, 7, 1, 9, 6, 4, 5, 8, 2]\n",
            "10 [0 3 7 1 9 6 4 5 8 2]\n",
            "discarded index [0, 3, 7, 1, 9, 6, 4, 5, 8, 2]\n",
            "10 [0 3 7 1 9 6 4 5 8 2]\n",
            "discarded index [0, 3, 7, 1, 9, 6, 4, 5, 8, 2]\n",
            "10 [0 3 7 1 9 6 4 5 8 2]\n",
            "discarded index [0, 3, 7, 1, 9, 6, 4, 5, 8, 2]\n",
            "10 [0 3 7 1 9 6 4 5 8 2]\n",
            "discarded index [0, 3, 7, 1, 9, 6, 4, 5, 8, 2]\n",
            "10 [0 3 7 1 9 6 4 5 8 2]\n",
            "discarded index [0, 3, 7, 1, 9, 6, 4, 5, 8, 2]\n",
            "10 [0 3 7 1 9 6 4 5 8 2]\n",
            "discarded index [0, 3, 7, 1, 9, 6, 4, 5, 8, 2]\n",
            "10 [0 3 7 1 9 6 4 5 8 2]\n",
            "discarded index [0, 3, 7, 1, 9, 6, 4, 5, 8, 2]\n",
            "10 [0 3 7 1 9 6 4 5 8 2]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 251, bulyan: at fang n_at 10 e 251 | val loss 1.7926 val acc 34.6794 best val_acc 42.187500\n",
            "discarded index [7, 6, 0, 3, 5, 1, 2, 8, 9, 4]\n",
            "10 [7 6 0 3 5 1 2 8 9 4]\n",
            "discarded index [7, 6, 0, 3, 5, 1, 2, 8, 9, 4]\n",
            "10 [7 6 0 3 5 1 2 8 9 4]\n",
            "discarded index [7, 6, 0, 3, 5, 1, 2, 8, 9, 4]\n",
            "10 [7 6 0 3 5 1 2 8 9 4]\n",
            "discarded index [7, 6, 0, 3, 5, 1, 2, 8, 9, 4]\n",
            "10 [7 6 0 3 5 1 2 8 9 4]\n",
            "discarded index [7, 6, 0, 3, 5, 1, 2, 8, 9, 4]\n",
            "10 [7 6 0 3 5 1 2 8 9 4]\n",
            "discarded index [7, 6, 0, 3, 5, 1, 2, 8, 9, 4]\n",
            "10 [7 6 0 3 5 1 2 8 9 4]\n",
            "discarded index [7, 6, 0, 3, 5, 1, 2, 8, 9, 4]\n",
            "10 [7 6 0 3 5 1 2 8 9 4]\n",
            "discarded index [7, 6, 0, 3, 5, 1, 2, 8, 9, 4]\n",
            "10 [7 6 0 3 5 1 2 8 9 4]\n",
            "discarded index [7, 6, 0, 3, 5, 1, 2, 8, 9, 4]\n",
            "10 [7 6 0 3 5 1 2 8 9 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 252, bulyan: at fang n_at 10 e 252 | val loss 1.7175 val acc 37.1550 best val_acc 42.187500\n",
            "discarded index [7, 0, 5, 1, 2, 4, 6, 9, 8, 3]\n",
            "10 [7 0 5 1 2 4 6 9 8 3]\n",
            "discarded index [7, 0, 5, 1, 2, 4, 6, 9, 8, 3]\n",
            "10 [7 0 5 1 2 4 6 9 8 3]\n",
            "discarded index [7, 0, 5, 1, 2, 4, 6, 9, 8, 3]\n",
            "10 [7 0 5 1 2 4 6 9 8 3]\n",
            "discarded index [7, 0, 5, 1, 2, 4, 6, 9, 8, 3]\n",
            "10 [7 0 5 1 2 4 6 9 8 3]\n",
            "discarded index [7, 0, 5, 1, 2, 4, 6, 9, 8, 3]\n",
            "10 [7 0 5 1 2 4 6 9 8 3]\n",
            "discarded index [7, 0, 5, 1, 2, 4, 6, 9, 8, 3]\n",
            "10 [7 0 5 1 2 4 6 9 8 3]\n",
            "discarded index [7, 0, 5, 1, 2, 4, 6, 9, 8, 3]\n",
            "10 [7 0 5 1 2 4 6 9 8 3]\n",
            "discarded index [7, 0, 5, 1, 2, 4, 6, 9, 8, 3]\n",
            "10 [7 0 5 1 2 4 6 9 8 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 253, bulyan: at fang n_at 10 e 253 | val loss 1.6324 val acc 41.0714 best val_acc 42.187500\n",
            "discarded index [1, 0, 9, 7, 5, 6, 4, 8, 3, 2]\n",
            "10 [1 0 9 7 5 6 4 8 3 2]\n",
            "discarded index [1, 0, 9, 7, 5, 6, 4, 8, 3, 2]\n",
            "10 [1 0 9 7 5 6 4 8 3 2]\n",
            "discarded index [1, 0, 9, 7, 5, 6, 4, 8, 3, 2]\n",
            "10 [1 0 9 7 5 6 4 8 3 2]\n",
            "discarded index [1, 0, 9, 7, 5, 6, 4, 8, 3, 2]\n",
            "10 [1 0 9 7 5 6 4 8 3 2]\n",
            "discarded index [1, 0, 9, 7, 5, 6, 4, 8, 3, 2]\n",
            "10 [1 0 9 7 5 6 4 8 3 2]\n",
            "discarded index [1, 0, 9, 7, 5, 6, 4, 8, 3, 2]\n",
            "10 [1 0 9 7 5 6 4 8 3 2]\n",
            "discarded index [1, 0, 9, 7, 5, 6, 4, 8, 3, 2]\n",
            "10 [1 0 9 7 5 6 4 8 3 2]\n",
            "discarded index [1, 0, 9, 7, 5, 6, 4, 8, 3, 2]\n",
            "10 [1 0 9 7 5 6 4 8 3 2]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 254, bulyan: at fang n_at 10 e 254 | val loss 1.6359 val acc 40.0974 best val_acc 42.187500\n",
            "discarded index [9, 6, 8, 7, 3, 2, 1, 5, 4, 0]\n",
            "10 [9 6 8 7 3 2 1 5 4 0]\n",
            "discarded index [9, 6, 8, 7, 3, 2, 1, 5, 4, 0]\n",
            "10 [9 6 8 7 3 2 1 5 4 0]\n",
            "discarded index [9, 6, 8, 7, 3, 2, 1, 5, 4, 0]\n",
            "10 [9 6 8 7 3 2 1 5 4 0]\n",
            "discarded index [9, 6, 8, 7, 3, 2, 1, 5, 4, 0]\n",
            "10 [9 6 8 7 3 2 1 5 4 0]\n",
            "discarded index [9, 6, 8, 7, 3, 2, 1, 5, 4, 0]\n",
            "10 [9 6 8 7 3 2 1 5 4 0]\n",
            "discarded index [9, 6, 8, 7, 3, 2, 1, 5, 4, 0]\n",
            "10 [9 6 8 7 3 2 1 5 4 0]\n",
            "discarded index [9, 6, 8, 7, 3, 2, 1, 5, 4, 0]\n",
            "10 [9 6 8 7 3 2 1 5 4 0]\n",
            "discarded index [9, 6, 8, 7, 3, 2, 1, 5, 4, 0]\n",
            "10 [9 6 8 7 3 2 1 5 4 0]\n",
            "discarded index [9, 6, 8, 7, 3, 2, 1, 5, 4, 0]\n",
            "10 [9 6 8 7 3 2 1 5 4 0]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 255, bulyan: at fang n_at 10 e 255 | val loss 1.7982 val acc 35.8360 best val_acc 42.187500\n",
            "discarded index [0, 9, 6, 7, 3, 2, 8, 4, 1, 5]\n",
            "10 [0 9 6 7 3 2 8 4 1 5]\n",
            "discarded index [0, 9, 6, 7, 3, 2, 8, 4, 1, 5]\n",
            "10 [0 9 6 7 3 2 8 4 1 5]\n",
            "discarded index [0, 9, 6, 7, 3, 2, 8, 4, 1, 5]\n",
            "10 [0 9 6 7 3 2 8 4 1 5]\n",
            "discarded index [0, 9, 6, 7, 3, 2, 8, 4, 1, 5]\n",
            "10 [0 9 6 7 3 2 8 4 1 5]\n",
            "discarded index [0, 9, 6, 7, 3, 2, 8, 4, 1, 5]\n",
            "10 [0 9 6 7 3 2 8 4 1 5]\n",
            "discarded index [0, 9, 6, 7, 3, 2, 8, 4, 1, 5]\n",
            "10 [0 9 6 7 3 2 8 4 1 5]\n",
            "discarded index [0, 9, 6, 7, 3, 2, 8, 4, 1, 5]\n",
            "10 [0 9 6 7 3 2 8 4 1 5]\n",
            "discarded index [0, 9, 6, 7, 3, 2, 8, 4, 1, 5]\n",
            "10 [0 9 6 7 3 2 8 4 1 5]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 256, bulyan: at fang n_at 10 e 256 | val loss 1.6840 val acc 37.6015 best val_acc 42.187500\n",
            "discarded index [1, 6, 0, 5, 9, 7, 4, 2, 8, 3]\n",
            "10 [1 6 0 5 9 7 4 2 8 3]\n",
            "discarded index [1, 6, 0, 5, 9, 7, 4, 2, 8, 3]\n",
            "10 [1 6 0 5 9 7 4 2 8 3]\n",
            "discarded index [1, 6, 0, 5, 9, 7, 4, 2, 8, 3]\n",
            "10 [1 6 0 5 9 7 4 2 8 3]\n",
            "discarded index [1, 6, 0, 5, 9, 7, 4, 2, 8, 3]\n",
            "10 [1 6 0 5 9 7 4 2 8 3]\n",
            "discarded index [1, 6, 0, 5, 9, 7, 4, 2, 8, 3]\n",
            "10 [1 6 0 5 9 7 4 2 8 3]\n",
            "discarded index [1, 6, 0, 5, 9, 7, 4, 2, 8, 3]\n",
            "10 [1 6 0 5 9 7 4 2 8 3]\n",
            "discarded index [1, 6, 0, 5, 9, 7, 4, 2, 8, 3]\n",
            "10 [1 6 0 5 9 7 4 2 8 3]\n",
            "discarded index [1, 6, 0, 5, 9, 7, 4, 2, 8, 3]\n",
            "10 [1 6 0 5 9 7 4 2 8 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 257, bulyan: at fang n_at 10 e 257 | val loss 1.6647 val acc 37.6623 best val_acc 42.187500\n",
            "discarded index [0, 7, 2, 5, 9, 8, 6, 1, 3, 4]\n",
            "10 [0 7 2 5 9 8 6 1 3 4]\n",
            "discarded index [0, 7, 2, 5, 9, 8, 6, 1, 3, 4]\n",
            "10 [0 7 2 5 9 8 6 1 3 4]\n",
            "discarded index [0, 7, 2, 5, 9, 8, 6, 1, 3, 4]\n",
            "10 [0 7 2 5 9 8 6 1 3 4]\n",
            "discarded index [0, 7, 2, 5, 9, 8, 6, 1, 3, 4]\n",
            "10 [0 7 2 5 9 8 6 1 3 4]\n",
            "discarded index [0, 7, 2, 5, 9, 8, 6, 1, 3, 4]\n",
            "10 [0 7 2 5 9 8 6 1 3 4]\n",
            "discarded index [0, 7, 2, 5, 9, 8, 6, 1, 3, 4]\n",
            "10 [0 7 2 5 9 8 6 1 3 4]\n",
            "discarded index [0, 7, 2, 5, 9, 8, 6, 1, 3, 4]\n",
            "10 [0 7 2 5 9 8 6 1 3 4]\n",
            "discarded index [0, 7, 2, 5, 9, 8, 6, 1, 3, 4]\n",
            "10 [0 7 2 5 9 8 6 1 3 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 258, bulyan: at fang n_at 10 e 258 | val loss 1.6630 val acc 39.5089 best val_acc 42.187500\n",
            "discarded index [6, 1, 7, 4, 0, 9, 5, 8, 2, 3]\n",
            "10 [6 1 7 4 0 9 5 8 2 3]\n",
            "discarded index [6, 1, 7, 4, 0, 9, 5, 8, 2, 3]\n",
            "10 [6 1 7 4 0 9 5 8 2 3]\n",
            "discarded index [6, 1, 7, 4, 0, 9, 5, 8, 2, 3]\n",
            "10 [6 1 7 4 0 9 5 8 2 3]\n",
            "discarded index [6, 1, 7, 4, 0, 9, 5, 8, 2, 3]\n",
            "10 [6 1 7 4 0 9 5 8 2 3]\n",
            "discarded index [6, 1, 7, 4, 0, 9, 5, 8, 2, 3]\n",
            "10 [6 1 7 4 0 9 5 8 2 3]\n",
            "discarded index [6, 1, 7, 4, 0, 9, 5, 8, 2, 3]\n",
            "10 [6 1 7 4 0 9 5 8 2 3]\n",
            "discarded index [6, 1, 7, 4, 0, 9, 5, 8, 2, 3]\n",
            "10 [6 1 7 4 0 9 5 8 2 3]\n",
            "discarded index [6, 1, 7, 4, 0, 9, 5, 8, 2, 3]\n",
            "10 [6 1 7 4 0 9 5 8 2 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 259, bulyan: at fang n_at 10 e 259 | val loss 1.6250 val acc 41.0917 best val_acc 42.187500\n",
            "discarded index [9, 8, 6, 2, 4, 3, 5, 7, 0, 1]\n",
            "10 [9 8 6 2 4 3 5 7 0 1]\n",
            "discarded index [9, 8, 6, 2, 4, 3, 5, 7, 0, 1]\n",
            "10 [9 8 6 2 4 3 5 7 0 1]\n",
            "discarded index [9, 8, 6, 2, 4, 3, 5, 7, 0, 1]\n",
            "10 [9 8 6 2 4 3 5 7 0 1]\n",
            "discarded index [9, 8, 6, 2, 4, 3, 5, 7, 0, 1]\n",
            "10 [9 8 6 2 4 3 5 7 0 1]\n",
            "discarded index [9, 8, 6, 2, 4, 3, 5, 7, 0, 1]\n",
            "10 [9 8 6 2 4 3 5 7 0 1]\n",
            "discarded index [9, 8, 6, 2, 4, 3, 5, 7, 0, 1]\n",
            "10 [9 8 6 2 4 3 5 7 0 1]\n",
            "discarded index [9, 8, 6, 2, 4, 3, 5, 7, 0, 1]\n",
            "10 [9 8 6 2 4 3 5 7 0 1]\n",
            "discarded index [9, 8, 6, 2, 4, 3, 5, 7, 0, 1]\n",
            "10 [9 8 6 2 4 3 5 7 0 1]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 260, bulyan: at fang n_at 10 e 260 | val loss 1.5911 val acc 42.1063 best val_acc 42.187500\n",
            "discarded index [9, 6, 4, 3, 2, 8, 1, 0, 7, 5]\n",
            "10 [9 6 4 3 2 8 1 0 7 5]\n",
            "discarded index [9, 6, 4, 3, 2, 8, 1, 0, 7, 5]\n",
            "10 [9 6 4 3 2 8 1 0 7 5]\n",
            "discarded index [9, 6, 4, 3, 2, 8, 1, 0, 7, 5]\n",
            "10 [9 6 4 3 2 8 1 0 7 5]\n",
            "discarded index [9, 6, 4, 3, 2, 8, 1, 0, 7, 5]\n",
            "10 [9 6 4 3 2 8 1 0 7 5]\n",
            "discarded index [9, 6, 4, 3, 2, 8, 1, 0, 7, 5]\n",
            "10 [9 6 4 3 2 8 1 0 7 5]\n",
            "discarded index [9, 6, 4, 3, 2, 8, 1, 0, 7, 5]\n",
            "10 [9 6 4 3 2 8 1 0 7 5]\n",
            "discarded index [9, 6, 4, 3, 2, 8, 1, 0, 7, 5]\n",
            "10 [9 6 4 3 2 8 1 0 7 5]\n",
            "discarded index [9, 6, 4, 3, 2, 8, 1, 0, 7, 5]\n",
            "10 [9 6 4 3 2 8 1 0 7 5]\n",
            "discarded index [9, 6, 4, 3, 2, 8, 1, 0, 7, 5]\n",
            "10 [9 6 4 3 2 8 1 0 7 5]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 261, bulyan: at fang n_at 10 e 261 | val loss 1.7282 val acc 39.2248 best val_acc 42.187500\n",
            "discarded index [0, 9, 1, 5, 3, 2, 4, 6, 7, 8]\n",
            "10 [0 9 1 5 3 2 4 6 7 8]\n",
            "discarded index [0, 9, 1, 5, 3, 2, 4, 6, 7, 8]\n",
            "10 [0 9 1 5 3 2 4 6 7 8]\n",
            "discarded index [0, 9, 1, 5, 3, 2, 4, 6, 7, 8]\n",
            "10 [0 9 1 5 3 2 4 6 7 8]\n",
            "discarded index [0, 9, 1, 5, 3, 2, 4, 6, 7, 8]\n",
            "10 [0 9 1 5 3 2 4 6 7 8]\n",
            "discarded index [0, 9, 1, 5, 3, 2, 4, 6, 7, 8]\n",
            "10 [0 9 1 5 3 2 4 6 7 8]\n",
            "discarded index [0, 9, 1, 5, 3, 2, 4, 6, 7, 8]\n",
            "10 [0 9 1 5 3 2 4 6 7 8]\n",
            "discarded index [0, 9, 1, 5, 3, 2, 4, 6, 7, 8]\n",
            "10 [0 9 1 5 3 2 4 6 7 8]\n",
            "discarded index [0, 9, 1, 5, 3, 2, 4, 6, 7, 8]\n",
            "10 [0 9 1 5 3 2 4 6 7 8]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 262, bulyan: at fang n_at 10 e 262 | val loss 1.7024 val acc 39.0219 best val_acc 42.187500\n",
            "discarded index [1, 5, 2, 6, 3, 8, 4, 7, 9, 0]\n",
            "10 [1 5 2 6 3 8 4 7 9 0]\n",
            "discarded index [1, 5, 2, 6, 3, 8, 4, 7, 9, 0]\n",
            "10 [1 5 2 6 3 8 4 7 9 0]\n",
            "discarded index [1, 5, 2, 6, 3, 8, 4, 7, 9, 0]\n",
            "10 [1 5 2 6 3 8 4 7 9 0]\n",
            "discarded index [1, 5, 2, 6, 3, 8, 4, 7, 9, 0]\n",
            "10 [1 5 2 6 3 8 4 7 9 0]\n",
            "discarded index [1, 5, 2, 6, 3, 8, 4, 7, 9, 0]\n",
            "10 [1 5 2 6 3 8 4 7 9 0]\n",
            "discarded index [1, 5, 2, 6, 3, 8, 4, 7, 9, 0]\n",
            "10 [1 5 2 6 3 8 4 7 9 0]\n",
            "discarded index [1, 5, 2, 6, 3, 8, 4, 7, 9, 0]\n",
            "10 [1 5 2 6 3 8 4 7 9 0]\n",
            "discarded index [1, 5, 2, 6, 3, 8, 4, 7, 9, 0]\n",
            "10 [1 5 2 6 3 8 4 7 9 0]\n",
            "discarded index [1, 5, 2, 6, 3, 8, 4, 7, 9, 0]\n",
            "10 [1 5 2 6 3 8 4 7 9 0]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 263, bulyan: at fang n_at 10 e 263 | val loss 1.7091 val acc 36.2216 best val_acc 42.187500\n",
            "discarded index [0, 9, 6, 5, 8, 7, 2, 3, 4, 1]\n",
            "10 [0 9 6 5 8 7 2 3 4 1]\n",
            "discarded index [0, 9, 6, 5, 8, 7, 2, 3, 4, 1]\n",
            "10 [0 9 6 5 8 7 2 3 4 1]\n",
            "discarded index [0, 9, 6, 5, 8, 7, 2, 3, 4, 1]\n",
            "10 [0 9 6 5 8 7 2 3 4 1]\n",
            "discarded index [0, 9, 6, 5, 8, 7, 2, 3, 4, 1]\n",
            "10 [0 9 6 5 8 7 2 3 4 1]\n",
            "discarded index [0, 9, 6, 5, 8, 7, 2, 3, 4, 1]\n",
            "10 [0 9 6 5 8 7 2 3 4 1]\n",
            "discarded index [0, 9, 6, 5, 8, 7, 2, 3, 4, 1]\n",
            "10 [0 9 6 5 8 7 2 3 4 1]\n",
            "discarded index [0, 9, 6, 5, 8, 7, 2, 3, 4, 1]\n",
            "10 [0 9 6 5 8 7 2 3 4 1]\n",
            "discarded index [0, 9, 6, 5, 8, 7, 2, 3, 4, 1]\n",
            "10 [0 9 6 5 8 7 2 3 4 1]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 264, bulyan: at fang n_at 10 e 264 | val loss 1.5929 val acc 40.9700 best val_acc 42.187500\n",
            "discarded index [0, 1, 6, 4, 3, 9, 8, 7, 2, 5]\n",
            "10 [0 1 6 4 3 9 8 7 2 5]\n",
            "discarded index [0, 1, 6, 4, 3, 9, 8, 7, 2, 5]\n",
            "10 [0 1 6 4 3 9 8 7 2 5]\n",
            "discarded index [0, 1, 6, 4, 3, 9, 8, 7, 2, 5]\n",
            "10 [0 1 6 4 3 9 8 7 2 5]\n",
            "discarded index [0, 1, 6, 4, 3, 9, 8, 7, 2, 5]\n",
            "10 [0 1 6 4 3 9 8 7 2 5]\n",
            "discarded index [0, 1, 6, 4, 3, 9, 8, 7, 2, 5]\n",
            "10 [0 1 6 4 3 9 8 7 2 5]\n",
            "discarded index [0, 1, 6, 4, 3, 9, 8, 7, 2, 5]\n",
            "10 [0 1 6 4 3 9 8 7 2 5]\n",
            "discarded index [0, 1, 6, 4, 3, 9, 8, 7, 2, 5]\n",
            "10 [0 1 6 4 3 9 8 7 2 5]\n",
            "discarded index [0, 1, 6, 4, 3, 9, 8, 7, 2, 5]\n",
            "10 [0 1 6 4 3 9 8 7 2 5]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 265, bulyan: at fang n_at 10 e 265 | val loss 1.5608 val acc 41.7411 best val_acc 42.187500\n",
            "discarded index [0, 1, 8, 6, 9, 4, 3, 5, 2, 7]\n",
            "10 [0 1 8 6 9 4 3 5 2 7]\n",
            "discarded index [0, 1, 8, 6, 9, 4, 3, 5, 2, 7]\n",
            "10 [0 1 8 6 9 4 3 5 2 7]\n",
            "discarded index [0, 1, 8, 6, 9, 4, 3, 5, 2, 7]\n",
            "10 [0 1 8 6 9 4 3 5 2 7]\n",
            "discarded index [0, 1, 8, 6, 9, 4, 3, 5, 2, 7]\n",
            "10 [0 1 8 6 9 4 3 5 2 7]\n",
            "discarded index [0, 1, 8, 6, 9, 4, 3, 5, 2, 7]\n",
            "10 [0 1 8 6 9 4 3 5 2 7]\n",
            "discarded index [0, 1, 8, 6, 9, 4, 3, 5, 2, 7]\n",
            "10 [0 1 8 6 9 4 3 5 2 7]\n",
            "discarded index [0, 1, 8, 6, 9, 4, 3, 5, 2, 7]\n",
            "10 [0 1 8 6 9 4 3 5 2 7]\n",
            "discarded index [0, 1, 8, 6, 9, 4, 3, 5, 2, 7]\n",
            "10 [0 1 8 6 9 4 3 5 2 7]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 266, bulyan: at fang n_at 10 e 266 | val loss 1.6364 val acc 39.9554 best val_acc 42.187500\n",
            "discarded index [2, 3, 9, 8, 1, 0, 6, 5, 7, 4]\n",
            "10 [2 3 9 8 1 0 6 5 7 4]\n",
            "discarded index [2, 3, 9, 8, 1, 0, 6, 5, 7, 4]\n",
            "10 [2 3 9 8 1 0 6 5 7 4]\n",
            "discarded index [2, 3, 9, 8, 1, 0, 6, 5, 7, 4]\n",
            "10 [2 3 9 8 1 0 6 5 7 4]\n",
            "discarded index [2, 3, 9, 8, 1, 0, 6, 5, 7, 4]\n",
            "10 [2 3 9 8 1 0 6 5 7 4]\n",
            "discarded index [2, 3, 9, 8, 1, 0, 6, 5, 7, 4]\n",
            "10 [2 3 9 8 1 0 6 5 7 4]\n",
            "discarded index [2, 3, 9, 8, 1, 0, 6, 5, 7, 4]\n",
            "10 [2 3 9 8 1 0 6 5 7 4]\n",
            "discarded index [2, 3, 9, 8, 1, 0, 6, 5, 7, 4]\n",
            "10 [2 3 9 8 1 0 6 5 7 4]\n",
            "discarded index [2, 3, 9, 8, 1, 0, 6, 5, 7, 4]\n",
            "10 [2 3 9 8 1 0 6 5 7 4]\n",
            "discarded index [2, 3, 9, 8, 1, 0, 6, 5, 7, 4]\n",
            "10 [2 3 9 8 1 0 6 5 7 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 267, bulyan: at fang n_at 10 e 267 | val loss 1.7053 val acc 38.8393 best val_acc 42.187500\n",
            "discarded index [6, 9, 7, 8, 0, 4, 5, 2, 1, 3]\n",
            "10 [6 9 7 8 0 4 5 2 1 3]\n",
            "discarded index [6, 9, 7, 8, 0, 4, 5, 2, 1, 3]\n",
            "10 [6 9 7 8 0 4 5 2 1 3]\n",
            "discarded index [6, 9, 7, 8, 0, 4, 5, 2, 1, 3]\n",
            "10 [6 9 7 8 0 4 5 2 1 3]\n",
            "discarded index [6, 9, 7, 8, 0, 4, 5, 2, 1, 3]\n",
            "10 [6 9 7 8 0 4 5 2 1 3]\n",
            "discarded index [6, 9, 7, 8, 0, 4, 5, 2, 1, 3]\n",
            "10 [6 9 7 8 0 4 5 2 1 3]\n",
            "discarded index [6, 9, 7, 8, 0, 4, 5, 2, 1, 3]\n",
            "10 [6 9 7 8 0 4 5 2 1 3]\n",
            "discarded index [6, 9, 7, 8, 0, 4, 5, 2, 1, 3]\n",
            "10 [6 9 7 8 0 4 5 2 1 3]\n",
            "discarded index [6, 9, 7, 8, 0, 4, 5, 2, 1, 3]\n",
            "10 [6 9 7 8 0 4 5 2 1 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 268, bulyan: at fang n_at 10 e 268 | val loss 1.5966 val acc 41.4773 best val_acc 42.187500\n",
            "discarded index [6, 1, 0, 8, 3, 2, 4, 9, 7, 5]\n",
            "10 [6 1 0 8 3 2 4 9 7 5]\n",
            "discarded index [6, 1, 0, 8, 3, 2, 4, 9, 7, 5]\n",
            "10 [6 1 0 8 3 2 4 9 7 5]\n",
            "discarded index [6, 1, 0, 8, 3, 2, 4, 9, 7, 5]\n",
            "10 [6 1 0 8 3 2 4 9 7 5]\n",
            "discarded index [6, 1, 0, 8, 3, 2, 4, 9, 7, 5]\n",
            "10 [6 1 0 8 3 2 4 9 7 5]\n",
            "discarded index [6, 1, 0, 8, 3, 2, 4, 9, 7, 5]\n",
            "10 [6 1 0 8 3 2 4 9 7 5]\n",
            "discarded index [6, 1, 0, 8, 3, 2, 4, 9, 7, 5]\n",
            "10 [6 1 0 8 3 2 4 9 7 5]\n",
            "discarded index [6, 1, 0, 8, 3, 2, 4, 9, 7, 5]\n",
            "10 [6 1 0 8 3 2 4 9 7 5]\n",
            "discarded index [6, 1, 0, 8, 3, 2, 4, 9, 7, 5]\n",
            "10 [6 1 0 8 3 2 4 9 7 5]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 269, bulyan: at fang n_at 10 e 269 | val loss 1.5990 val acc 41.7005 best val_acc 42.187500\n",
            "discarded index [7, 3, 9, 1, 2, 8, 6, 4, 5, 0]\n",
            "10 [7 3 9 1 2 8 6 4 5 0]\n",
            "discarded index [7, 3, 9, 1, 2, 8, 6, 4, 5, 0]\n",
            "10 [7 3 9 1 2 8 6 4 5 0]\n",
            "discarded index [7, 3, 9, 1, 2, 8, 6, 4, 5, 0]\n",
            "10 [7 3 9 1 2 8 6 4 5 0]\n",
            "discarded index [7, 3, 9, 1, 2, 8, 6, 4, 5, 0]\n",
            "10 [7 3 9 1 2 8 6 4 5 0]\n",
            "discarded index [7, 3, 9, 1, 2, 8, 6, 4, 5, 0]\n",
            "10 [7 3 9 1 2 8 6 4 5 0]\n",
            "discarded index [7, 3, 9, 1, 2, 8, 6, 4, 5, 0]\n",
            "10 [7 3 9 1 2 8 6 4 5 0]\n",
            "discarded index [7, 3, 9, 1, 2, 8, 6, 4, 5, 0]\n",
            "10 [7 3 9 1 2 8 6 4 5 0]\n",
            "discarded index [7, 3, 9, 1, 2, 8, 6, 4, 5, 0]\n",
            "10 [7 3 9 1 2 8 6 4 5 0]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 270, bulyan: at fang n_at 10 e 270 | val loss 1.6687 val acc 37.0333 best val_acc 42.187500\n",
            "discarded index [6, 0, 1, 3, 5, 7, 9, 8, 4, 2]\n",
            "10 [6 0 1 3 5 7 9 8 4 2]\n",
            "discarded index [6, 0, 1, 3, 5, 7, 9, 8, 4, 2]\n",
            "10 [6 0 1 3 5 7 9 8 4 2]\n",
            "discarded index [6, 0, 1, 3, 5, 7, 9, 8, 4, 2]\n",
            "10 [6 0 1 3 5 7 9 8 4 2]\n",
            "discarded index [6, 0, 1, 3, 5, 7, 9, 8, 4, 2]\n",
            "10 [6 0 1 3 5 7 9 8 4 2]\n",
            "discarded index [6, 0, 1, 3, 5, 7, 9, 8, 4, 2]\n",
            "10 [6 0 1 3 5 7 9 8 4 2]\n",
            "discarded index [6, 0, 1, 3, 5, 7, 9, 8, 4, 2]\n",
            "10 [6 0 1 3 5 7 9 8 4 2]\n",
            "discarded index [6, 0, 1, 3, 5, 7, 9, 8, 4, 2]\n",
            "10 [6 0 1 3 5 7 9 8 4 2]\n",
            "discarded index [6, 0, 1, 3, 5, 7, 9, 8, 4, 2]\n",
            "10 [6 0 1 3 5 7 9 8 4 2]\n",
            "discarded index [6, 0, 1, 3, 5, 7, 9, 8, 4, 2]\n",
            "10 [6 0 1 3 5 7 9 8 4 2]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 271, bulyan: at fang n_at 10 e 271 | val loss 1.8663 val acc 32.1023 best val_acc 42.187500\n",
            "discarded index [1, 2, 3, 0, 8, 6, 9, 5, 4, 7]\n",
            "10 [1 2 3 0 8 6 9 5 4 7]\n",
            "discarded index [1, 2, 3, 0, 8, 6, 9, 5, 4, 7]\n",
            "10 [1 2 3 0 8 6 9 5 4 7]\n",
            "discarded index [1, 2, 3, 0, 8, 6, 9, 5, 4, 7]\n",
            "10 [1 2 3 0 8 6 9 5 4 7]\n",
            "discarded index [1, 2, 3, 0, 8, 6, 9, 5, 4, 7]\n",
            "10 [1 2 3 0 8 6 9 5 4 7]\n",
            "discarded index [1, 2, 3, 0, 8, 6, 9, 5, 4, 7]\n",
            "10 [1 2 3 0 8 6 9 5 4 7]\n",
            "discarded index [1, 2, 3, 0, 8, 6, 9, 5, 4, 7]\n",
            "10 [1 2 3 0 8 6 9 5 4 7]\n",
            "discarded index [1, 2, 3, 0, 8, 6, 9, 5, 4, 7]\n",
            "10 [1 2 3 0 8 6 9 5 4 7]\n",
            "discarded index [1, 2, 3, 0, 8, 6, 9, 5, 4, 7]\n",
            "10 [1 2 3 0 8 6 9 5 4 7]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 272, bulyan: at fang n_at 10 e 272 | val loss 1.8597 val acc 31.4935 best val_acc 42.187500\n",
            "discarded index [7, 6, 0, 2, 5, 9, 8, 4, 1, 3]\n",
            "10 [7 6 0 2 5 9 8 4 1 3]\n",
            "discarded index [7, 6, 0, 2, 5, 9, 8, 4, 1, 3]\n",
            "10 [7 6 0 2 5 9 8 4 1 3]\n",
            "discarded index [7, 6, 0, 2, 5, 9, 8, 4, 1, 3]\n",
            "10 [7 6 0 2 5 9 8 4 1 3]\n",
            "discarded index [7, 6, 0, 2, 5, 9, 8, 4, 1, 3]\n",
            "10 [7 6 0 2 5 9 8 4 1 3]\n",
            "discarded index [7, 6, 0, 2, 5, 9, 8, 4, 1, 3]\n",
            "10 [7 6 0 2 5 9 8 4 1 3]\n",
            "discarded index [7, 6, 0, 2, 5, 9, 8, 4, 1, 3]\n",
            "10 [7 6 0 2 5 9 8 4 1 3]\n",
            "discarded index [7, 6, 0, 2, 5, 9, 8, 4, 1, 3]\n",
            "10 [7 6 0 2 5 9 8 4 1 3]\n",
            "discarded index [7, 6, 0, 2, 5, 9, 8, 4, 1, 3]\n",
            "10 [7 6 0 2 5 9 8 4 1 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 273, bulyan: at fang n_at 10 e 273 | val loss 1.7619 val acc 36.0795 best val_acc 42.187500\n",
            "discarded index [4, 5, 1, 3, 9, 6, 8, 2, 0, 7]\n",
            "10 [4 5 1 3 9 6 8 2 0 7]\n",
            "discarded index [4, 5, 1, 3, 9, 6, 8, 2, 0, 7]\n",
            "10 [4 5 1 3 9 6 8 2 0 7]\n",
            "discarded index [4, 5, 1, 3, 9, 6, 8, 2, 0, 7]\n",
            "10 [4 5 1 3 9 6 8 2 0 7]\n",
            "discarded index [4, 5, 1, 3, 9, 6, 8, 2, 0, 7]\n",
            "10 [4 5 1 3 9 6 8 2 0 7]\n",
            "discarded index [4, 5, 1, 3, 9, 6, 8, 2, 0, 7]\n",
            "10 [4 5 1 3 9 6 8 2 0 7]\n",
            "discarded index [4, 5, 1, 3, 9, 6, 8, 2, 0, 7]\n",
            "10 [4 5 1 3 9 6 8 2 0 7]\n",
            "discarded index [4, 5, 1, 3, 9, 6, 8, 2, 0, 7]\n",
            "10 [4 5 1 3 9 6 8 2 0 7]\n",
            "discarded index [4, 5, 1, 3, 9, 6, 8, 2, 0, 7]\n",
            "10 [4 5 1 3 9 6 8 2 0 7]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 274, bulyan: at fang n_at 10 e 274 | val loss 1.6632 val acc 38.2305 best val_acc 42.187500\n",
            "discarded index [0, 7, 1, 4, 5, 8, 6, 3, 9, 2]\n",
            "10 [0 7 1 4 5 8 6 3 9 2]\n",
            "discarded index [0, 7, 1, 4, 5, 8, 6, 3, 9, 2]\n",
            "10 [0 7 1 4 5 8 6 3 9 2]\n",
            "discarded index [0, 7, 1, 4, 5, 8, 6, 3, 9, 2]\n",
            "10 [0 7 1 4 5 8 6 3 9 2]\n",
            "discarded index [0, 7, 1, 4, 5, 8, 6, 3, 9, 2]\n",
            "10 [0 7 1 4 5 8 6 3 9 2]\n",
            "discarded index [0, 7, 1, 4, 5, 8, 6, 3, 9, 2]\n",
            "10 [0 7 1 4 5 8 6 3 9 2]\n",
            "discarded index [0, 7, 1, 4, 5, 8, 6, 3, 9, 2]\n",
            "10 [0 7 1 4 5 8 6 3 9 2]\n",
            "discarded index [0, 7, 1, 4, 5, 8, 6, 3, 9, 2]\n",
            "10 [0 7 1 4 5 8 6 3 9 2]\n",
            "discarded index [0, 7, 1, 4, 5, 8, 6, 3, 9, 2]\n",
            "10 [0 7 1 4 5 8 6 3 9 2]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 275, bulyan: at fang n_at 10 e 275 | val loss 1.6562 val acc 38.9205 best val_acc 42.187500\n",
            "discarded index [5, 3, 4, 8, 7, 6, 2, 0, 1, 9]\n",
            "10 [5 3 4 8 7 6 2 0 1 9]\n",
            "discarded index [5, 3, 4, 8, 7, 6, 2, 0, 1, 9]\n",
            "10 [5 3 4 8 7 6 2 0 1 9]\n",
            "discarded index [5, 3, 4, 8, 7, 6, 2, 0, 1, 9]\n",
            "10 [5 3 4 8 7 6 2 0 1 9]\n",
            "discarded index [5, 3, 4, 8, 7, 6, 2, 0, 1, 9]\n",
            "10 [5 3 4 8 7 6 2 0 1 9]\n",
            "discarded index [5, 3, 4, 8, 7, 6, 2, 0, 1, 9]\n",
            "10 [5 3 4 8 7 6 2 0 1 9]\n",
            "discarded index [5, 3, 4, 8, 7, 6, 2, 0, 1, 9]\n",
            "10 [5 3 4 8 7 6 2 0 1 9]\n",
            "discarded index [5, 3, 4, 8, 7, 6, 2, 0, 1, 9]\n",
            "10 [5 3 4 8 7 6 2 0 1 9]\n",
            "discarded index [5, 3, 4, 8, 7, 6, 2, 0, 1, 9]\n",
            "10 [5 3 4 8 7 6 2 0 1 9]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 276, bulyan: at fang n_at 10 e 276 | val loss 1.5890 val acc 42.6136 best val_acc 42.613636\n",
            "discarded index [5, 7, 0, 2, 1, 8, 4, 3, 6, 9]\n",
            "10 [5 7 0 2 1 8 4 3 6 9]\n",
            "discarded index [5, 7, 0, 2, 1, 8, 4, 3, 6, 9]\n",
            "10 [5 7 0 2 1 8 4 3 6 9]\n",
            "discarded index [5, 7, 0, 2, 1, 8, 4, 3, 6, 9]\n",
            "10 [5 7 0 2 1 8 4 3 6 9]\n",
            "discarded index [5, 7, 0, 2, 1, 8, 4, 3, 6, 9]\n",
            "10 [5 7 0 2 1 8 4 3 6 9]\n",
            "discarded index [5, 7, 0, 2, 1, 8, 4, 3, 6, 9]\n",
            "10 [5 7 0 2 1 8 4 3 6 9]\n",
            "discarded index [5, 7, 0, 2, 1, 8, 4, 3, 6, 9]\n",
            "10 [5 7 0 2 1 8 4 3 6 9]\n",
            "discarded index [5, 7, 0, 2, 1, 8, 4, 3, 6, 9]\n",
            "10 [5 7 0 2 1 8 4 3 6 9]\n",
            "discarded index [5, 7, 0, 2, 1, 8, 4, 3, 6, 9]\n",
            "10 [5 7 0 2 1 8 4 3 6 9]\n",
            "discarded index [5, 7, 0, 2, 1, 8, 4, 3, 6, 9]\n",
            "10 [5 7 0 2 1 8 4 3 6 9]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 277, bulyan: at fang n_at 10 e 277 | val loss 1.6643 val acc 41.8425 best val_acc 42.613636\n",
            "discarded index [0, 1, 9, 2, 7, 4, 6, 5, 8, 3]\n",
            "10 [0 1 9 2 7 4 6 5 8 3]\n",
            "discarded index [0, 1, 9, 2, 7, 4, 6, 5, 8, 3]\n",
            "10 [0 1 9 2 7 4 6 5 8 3]\n",
            "discarded index [0, 1, 9, 2, 7, 4, 6, 5, 8, 3]\n",
            "10 [0 1 9 2 7 4 6 5 8 3]\n",
            "discarded index [0, 1, 9, 2, 7, 4, 6, 5, 8, 3]\n",
            "10 [0 1 9 2 7 4 6 5 8 3]\n",
            "discarded index [0, 1, 9, 2, 7, 4, 6, 5, 8, 3]\n",
            "10 [0 1 9 2 7 4 6 5 8 3]\n",
            "discarded index [0, 1, 9, 2, 7, 4, 6, 5, 8, 3]\n",
            "10 [0 1 9 2 7 4 6 5 8 3]\n",
            "discarded index [0, 1, 9, 2, 7, 4, 6, 5, 8, 3]\n",
            "10 [0 1 9 2 7 4 6 5 8 3]\n",
            "discarded index [0, 1, 9, 2, 7, 4, 6, 5, 8, 3]\n",
            "10 [0 1 9 2 7 4 6 5 8 3]\n",
            "discarded index [0, 1, 9, 2, 7, 4, 6, 5, 8, 3]\n",
            "10 [0 1 9 2 7 4 6 5 8 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 2, 4, 6, 8, 1, 3, 5, 7, 9]\n",
            "epoch: 278, bulyan: at fang n_at 10 e 278 | val loss 1.6745 val acc 39.4886 best val_acc 42.613636\n",
            "discarded index [5, 7, 3, 9, 4, 1, 0, 6, 2, 8]\n",
            "10 [5 7 3 9 4 1 0 6 2 8]\n",
            "discarded index [5, 7, 3, 9, 4, 1, 0, 6, 2, 8]\n",
            "10 [5 7 3 9 4 1 0 6 2 8]\n",
            "discarded index [5, 7, 3, 9, 4, 1, 0, 6, 2, 8]\n",
            "10 [5 7 3 9 4 1 0 6 2 8]\n",
            "discarded index [5, 7, 3, 9, 4, 1, 0, 6, 2, 8]\n",
            "10 [5 7 3 9 4 1 0 6 2 8]\n",
            "discarded index [5, 7, 3, 9, 4, 1, 0, 6, 2, 8]\n",
            "10 [5 7 3 9 4 1 0 6 2 8]\n",
            "discarded index [5, 7, 3, 9, 4, 1, 0, 6, 2, 8]\n",
            "10 [5 7 3 9 4 1 0 6 2 8]\n",
            "discarded index [5, 7, 3, 9, 4, 1, 0, 6, 2, 8]\n",
            "10 [5 7 3 9 4 1 0 6 2 8]\n",
            "discarded index [5, 7, 3, 9, 4, 1, 0, 6, 2, 8]\n",
            "10 [5 7 3 9 4 1 0 6 2 8]\n",
            "discarded index [5, 7, 3, 9, 4, 1, 0, 6, 2, 8]\n",
            "10 [5 7 3 9 4 1 0 6 2 8]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 279, bulyan: at fang n_at 10 e 279 | val loss 1.7184 val acc 37.2362 best val_acc 42.613636\n",
            "discarded index [0, 9, 2, 5, 1, 4, 8, 6, 3, 7]\n",
            "10 [0 9 2 5 1 4 8 6 3 7]\n",
            "discarded index [0, 9, 2, 5, 1, 4, 8, 6, 3, 7]\n",
            "10 [0 9 2 5 1 4 8 6 3 7]\n",
            "discarded index [0, 9, 2, 5, 1, 4, 8, 6, 3, 7]\n",
            "10 [0 9 2 5 1 4 8 6 3 7]\n",
            "discarded index [0, 9, 2, 5, 1, 4, 8, 6, 3, 7]\n",
            "10 [0 9 2 5 1 4 8 6 3 7]\n",
            "discarded index [0, 9, 2, 5, 1, 4, 8, 6, 3, 7]\n",
            "10 [0 9 2 5 1 4 8 6 3 7]\n",
            "discarded index [0, 9, 2, 5, 1, 4, 8, 6, 3, 7]\n",
            "10 [0 9 2 5 1 4 8 6 3 7]\n",
            "discarded index [0, 9, 2, 5, 1, 4, 8, 6, 3, 7]\n",
            "10 [0 9 2 5 1 4 8 6 3 7]\n",
            "discarded index [0, 9, 2, 5, 1, 4, 8, 6, 3, 7]\n",
            "10 [0 9 2 5 1 4 8 6 3 7]\n",
            "discarded index [0, 9, 2, 5, 1, 4, 8, 6, 3, 7]\n",
            "10 [0 9 2 5 1 4 8 6 3 7]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 280, bulyan: at fang n_at 10 e 280 | val loss 1.6904 val acc 37.9058 best val_acc 42.613636\n",
            "discarded index [1, 0, 5, 6, 4, 3, 2, 7, 8, 9]\n",
            "10 [1 0 5 6 4 3 2 7 8 9]\n",
            "discarded index [1, 0, 5, 6, 4, 3, 2, 7, 8, 9]\n",
            "10 [1 0 5 6 4 3 2 7 8 9]\n",
            "discarded index [1, 0, 5, 6, 4, 3, 2, 7, 8, 9]\n",
            "10 [1 0 5 6 4 3 2 7 8 9]\n",
            "discarded index [1, 0, 5, 6, 4, 3, 2, 7, 8, 9]\n",
            "10 [1 0 5 6 4 3 2 7 8 9]\n",
            "discarded index [1, 0, 5, 6, 4, 3, 2, 7, 8, 9]\n",
            "10 [1 0 5 6 4 3 2 7 8 9]\n",
            "discarded index [1, 0, 5, 6, 4, 3, 2, 7, 8, 9]\n",
            "10 [1 0 5 6 4 3 2 7 8 9]\n",
            "discarded index [1, 0, 5, 6, 4, 3, 2, 7, 8, 9]\n",
            "10 [1 0 5 6 4 3 2 7 8 9]\n",
            "discarded index [1, 0, 5, 6, 4, 3, 2, 7, 8, 9]\n",
            "10 [1 0 5 6 4 3 2 7 8 9]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 281, bulyan: at fang n_at 10 e 281 | val loss 1.7153 val acc 35.9984 best val_acc 42.613636\n",
            "discarded index [7, 6, 9, 5, 4, 8, 2, 3, 1, 0]\n",
            "10 [7 6 9 5 4 8 2 3 1 0]\n",
            "discarded index [7, 6, 9, 5, 4, 8, 2, 3, 1, 0]\n",
            "10 [7 6 9 5 4 8 2 3 1 0]\n",
            "discarded index [7, 6, 9, 5, 4, 8, 2, 3, 1, 0]\n",
            "10 [7 6 9 5 4 8 2 3 1 0]\n",
            "discarded index [7, 6, 9, 5, 4, 8, 2, 3, 1, 0]\n",
            "10 [7 6 9 5 4 8 2 3 1 0]\n",
            "discarded index [7, 6, 9, 5, 4, 8, 2, 3, 1, 0]\n",
            "10 [7 6 9 5 4 8 2 3 1 0]\n",
            "discarded index [7, 6, 9, 5, 4, 8, 2, 3, 1, 0]\n",
            "10 [7 6 9 5 4 8 2 3 1 0]\n",
            "discarded index [7, 6, 9, 5, 4, 8, 2, 3, 1, 0]\n",
            "10 [7 6 9 5 4 8 2 3 1 0]\n",
            "discarded index [7, 6, 9, 5, 4, 8, 2, 3, 1, 0]\n",
            "10 [7 6 9 5 4 8 2 3 1 0]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 282, bulyan: at fang n_at 10 e 282 | val loss 1.7138 val acc 37.8044 best val_acc 42.613636\n",
            "discarded index [2, 6, 7, 9, 0, 3, 5, 1, 8, 4]\n",
            "10 [2 6 7 9 0 3 5 1 8 4]\n",
            "discarded index [2, 6, 7, 9, 0, 3, 5, 1, 8, 4]\n",
            "10 [2 6 7 9 0 3 5 1 8 4]\n",
            "discarded index [2, 6, 7, 9, 0, 3, 5, 1, 8, 4]\n",
            "10 [2 6 7 9 0 3 5 1 8 4]\n",
            "discarded index [2, 6, 7, 9, 0, 3, 5, 1, 8, 4]\n",
            "10 [2 6 7 9 0 3 5 1 8 4]\n",
            "discarded index [2, 6, 7, 9, 0, 3, 5, 1, 8, 4]\n",
            "10 [2 6 7 9 0 3 5 1 8 4]\n",
            "discarded index [2, 6, 7, 9, 0, 3, 5, 1, 8, 4]\n",
            "10 [2 6 7 9 0 3 5 1 8 4]\n",
            "discarded index [2, 6, 7, 9, 0, 3, 5, 1, 8, 4]\n",
            "10 [2 6 7 9 0 3 5 1 8 4]\n",
            "discarded index [2, 6, 7, 9, 0, 3, 5, 1, 8, 4]\n",
            "10 [2 6 7 9 0 3 5 1 8 4]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 283, bulyan: at fang n_at 10 e 283 | val loss 1.6998 val acc 37.3985 best val_acc 42.613636\n",
            "discarded index [1, 0, 6, 9, 8, 4, 5, 2, 3, 7]\n",
            "10 [1 0 6 9 8 4 5 2 3 7]\n",
            "discarded index [1, 0, 6, 9, 8, 4, 5, 2, 3, 7]\n",
            "10 [1 0 6 9 8 4 5 2 3 7]\n",
            "discarded index [1, 0, 6, 9, 8, 4, 5, 2, 3, 7]\n",
            "10 [1 0 6 9 8 4 5 2 3 7]\n",
            "discarded index [1, 0, 6, 9, 8, 4, 5, 2, 3, 7]\n",
            "10 [1 0 6 9 8 4 5 2 3 7]\n",
            "discarded index [1, 0, 6, 9, 8, 4, 5, 2, 3, 7]\n",
            "10 [1 0 6 9 8 4 5 2 3 7]\n",
            "discarded index [1, 0, 6, 9, 8, 4, 5, 2, 3, 7]\n",
            "10 [1 0 6 9 8 4 5 2 3 7]\n",
            "discarded index [1, 0, 6, 9, 8, 4, 5, 2, 3, 7]\n",
            "10 [1 0 6 9 8 4 5 2 3 7]\n",
            "discarded index [1, 0, 6, 9, 8, 4, 5, 2, 3, 7]\n",
            "10 [1 0 6 9 8 4 5 2 3 7]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 284, bulyan: at fang n_at 10 e 284 | val loss 1.6053 val acc 41.1526 best val_acc 42.613636\n",
            "discarded index [0, 7, 2, 5, 8, 1, 9, 3, 4, 6]\n",
            "10 [0 7 2 5 8 1 9 3 4 6]\n",
            "discarded index [0, 7, 2, 5, 8, 1, 9, 3, 4, 6]\n",
            "10 [0 7 2 5 8 1 9 3 4 6]\n",
            "discarded index [0, 7, 2, 5, 8, 1, 9, 3, 4, 6]\n",
            "10 [0 7 2 5 8 1 9 3 4 6]\n",
            "discarded index [0, 7, 2, 5, 8, 1, 9, 3, 4, 6]\n",
            "10 [0 7 2 5 8 1 9 3 4 6]\n",
            "discarded index [0, 7, 2, 5, 8, 1, 9, 3, 4, 6]\n",
            "10 [0 7 2 5 8 1 9 3 4 6]\n",
            "discarded index [0, 7, 2, 5, 8, 1, 9, 3, 4, 6]\n",
            "10 [0 7 2 5 8 1 9 3 4 6]\n",
            "discarded index [0, 7, 2, 5, 8, 1, 9, 3, 4, 6]\n",
            "10 [0 7 2 5 8 1 9 3 4 6]\n",
            "discarded index [0, 7, 2, 5, 8, 1, 9, 3, 4, 6]\n",
            "10 [0 7 2 5 8 1 9 3 4 6]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 285, bulyan: at fang n_at 10 e 285 | val loss 1.5125 val acc 45.4140 best val_acc 45.413961\n",
            "discarded index [1, 0, 6, 7, 5, 2, 3, 4, 8, 9]\n",
            "10 [1 0 6 7 5 2 3 4 8 9]\n",
            "discarded index [1, 0, 6, 7, 5, 2, 3, 4, 8, 9]\n",
            "10 [1 0 6 7 5 2 3 4 8 9]\n",
            "discarded index [1, 0, 6, 7, 5, 2, 3, 4, 8, 9]\n",
            "10 [1 0 6 7 5 2 3 4 8 9]\n",
            "discarded index [1, 0, 6, 7, 5, 2, 3, 4, 8, 9]\n",
            "10 [1 0 6 7 5 2 3 4 8 9]\n",
            "discarded index [1, 0, 6, 7, 5, 2, 3, 4, 8, 9]\n",
            "10 [1 0 6 7 5 2 3 4 8 9]\n",
            "discarded index [1, 0, 6, 7, 5, 2, 3, 4, 8, 9]\n",
            "10 [1 0 6 7 5 2 3 4 8 9]\n",
            "discarded index [1, 0, 6, 7, 5, 2, 3, 4, 8, 9]\n",
            "10 [1 0 6 7 5 2 3 4 8 9]\n",
            "discarded index [1, 0, 6, 7, 5, 2, 3, 4, 8, 9]\n",
            "10 [1 0 6 7 5 2 3 4 8 9]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 286, bulyan: at fang n_at 10 e 286 | val loss 1.4999 val acc 45.7183 best val_acc 45.718344\n",
            "discarded index [0, 1, 6, 5, 7, 4, 2, 8, 3, 9]\n",
            "10 [0 1 6 5 7 4 2 8 3 9]\n",
            "discarded index [0, 1, 6, 5, 7, 4, 2, 8, 3, 9]\n",
            "10 [0 1 6 5 7 4 2 8 3 9]\n",
            "discarded index [0, 1, 6, 5, 7, 4, 2, 8, 3, 9]\n",
            "10 [0 1 6 5 7 4 2 8 3 9]\n",
            "discarded index [0, 1, 6, 5, 7, 4, 2, 8, 3, 9]\n",
            "10 [0 1 6 5 7 4 2 8 3 9]\n",
            "discarded index [0, 1, 6, 5, 7, 4, 2, 8, 3, 9]\n",
            "10 [0 1 6 5 7 4 2 8 3 9]\n",
            "discarded index [0, 1, 6, 5, 7, 4, 2, 8, 3, 9]\n",
            "10 [0 1 6 5 7 4 2 8 3 9]\n",
            "discarded index [0, 1, 6, 5, 7, 4, 2, 8, 3, 9]\n",
            "10 [0 1 6 5 7 4 2 8 3 9]\n",
            "discarded index [0, 1, 6, 5, 7, 4, 2, 8, 3, 9]\n",
            "10 [0 1 6 5 7 4 2 8 3 9]\n",
            "discarded index [0, 1, 6, 5, 7, 4, 2, 8, 3, 9]\n",
            "10 [0 1 6 5 7 4 2 8 3 9]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 287, bulyan: at fang n_at 10 e 287 | val loss 1.6017 val acc 41.9034 best val_acc 45.718344\n",
            "discarded index [2, 1, 0, 3, 5, 6, 7, 4, 9, 8]\n",
            "10 [2 1 0 3 5 6 7 4 9 8]\n",
            "discarded index [2, 1, 0, 3, 5, 6, 7, 4, 9, 8]\n",
            "10 [2 1 0 3 5 6 7 4 9 8]\n",
            "discarded index [2, 1, 0, 3, 5, 6, 7, 4, 9, 8]\n",
            "10 [2 1 0 3 5 6 7 4 9 8]\n",
            "discarded index [2, 1, 0, 3, 5, 6, 7, 4, 9, 8]\n",
            "10 [2 1 0 3 5 6 7 4 9 8]\n",
            "discarded index [2, 1, 0, 3, 5, 6, 7, 4, 9, 8]\n",
            "10 [2 1 0 3 5 6 7 4 9 8]\n",
            "discarded index [2, 1, 0, 3, 5, 6, 7, 4, 9, 8]\n",
            "10 [2 1 0 3 5 6 7 4 9 8]\n",
            "discarded index [2, 1, 0, 3, 5, 6, 7, 4, 9, 8]\n",
            "10 [2 1 0 3 5 6 7 4 9 8]\n",
            "discarded index [2, 1, 0, 3, 5, 6, 7, 4, 9, 8]\n",
            "10 [2 1 0 3 5 6 7 4 9 8]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 288, bulyan: at fang n_at 10 e 288 | val loss 1.6017 val acc 41.5787 best val_acc 45.718344\n",
            "discarded index [0, 6, 9, 7, 1, 2, 5, 8, 4, 3]\n",
            "10 [0 6 9 7 1 2 5 8 4 3]\n",
            "discarded index [0, 6, 9, 7, 1, 2, 5, 8, 4, 3]\n",
            "10 [0 6 9 7 1 2 5 8 4 3]\n",
            "discarded index [0, 6, 9, 7, 1, 2, 5, 8, 4, 3]\n",
            "10 [0 6 9 7 1 2 5 8 4 3]\n",
            "discarded index [0, 6, 9, 7, 1, 2, 5, 8, 4, 3]\n",
            "10 [0 6 9 7 1 2 5 8 4 3]\n",
            "discarded index [0, 6, 9, 7, 1, 2, 5, 8, 4, 3]\n",
            "10 [0 6 9 7 1 2 5 8 4 3]\n",
            "discarded index [0, 6, 9, 7, 1, 2, 5, 8, 4, 3]\n",
            "10 [0 6 9 7 1 2 5 8 4 3]\n",
            "discarded index [0, 6, 9, 7, 1, 2, 5, 8, 4, 3]\n",
            "10 [0 6 9 7 1 2 5 8 4 3]\n",
            "discarded index [0, 6, 9, 7, 1, 2, 5, 8, 4, 3]\n",
            "10 [0 6 9 7 1 2 5 8 4 3]\n",
            "discarded index [0, 6, 9, 7, 1, 2, 5, 8, 4, 3]\n",
            "10 [0 6 9 7 1 2 5 8 4 3]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 289, bulyan: at fang n_at 10 e 289 | val loss 1.8067 val acc 32.5487 best val_acc 45.718344\n",
            "discarded index [2, 8, 9, 6, 0, 1, 3, 4, 5, 7]\n",
            "10 [2 8 9 6 0 1 3 4 5 7]\n",
            "discarded index [2, 8, 9, 6, 0, 1, 3, 4, 5, 7]\n",
            "10 [2 8 9 6 0 1 3 4 5 7]\n",
            "discarded index [2, 8, 9, 6, 0, 1, 3, 4, 5, 7]\n",
            "10 [2 8 9 6 0 1 3 4 5 7]\n",
            "discarded index [2, 8, 9, 6, 0, 1, 3, 4, 5, 7]\n",
            "10 [2 8 9 6 0 1 3 4 5 7]\n",
            "discarded index [2, 8, 9, 6, 0, 1, 3, 4, 5, 7]\n",
            "10 [2 8 9 6 0 1 3 4 5 7]\n",
            "discarded index [2, 8, 9, 6, 0, 1, 3, 4, 5, 7]\n",
            "10 [2 8 9 6 0 1 3 4 5 7]\n",
            "discarded index [2, 8, 9, 6, 0, 1, 3, 4, 5, 7]\n",
            "10 [2 8 9 6 0 1 3 4 5 7]\n",
            "discarded index [2, 8, 9, 6, 0, 1, 3, 4, 5, 7]\n",
            "10 [2 8 9 6 0 1 3 4 5 7]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 290, bulyan: at fang n_at 10 e 290 | val loss 1.6622 val acc 40.3003 best val_acc 45.718344\n",
            "discarded index [9, 3, 1, 5, 7, 4, 2, 6, 0, 8]\n",
            "10 [9 3 1 5 7 4 2 6 0 8]\n",
            "discarded index [9, 3, 1, 5, 7, 4, 2, 6, 0, 8]\n",
            "10 [9 3 1 5 7 4 2 6 0 8]\n",
            "discarded index [9, 3, 1, 5, 7, 4, 2, 6, 0, 8]\n",
            "10 [9 3 1 5 7 4 2 6 0 8]\n",
            "discarded index [9, 3, 1, 5, 7, 4, 2, 6, 0, 8]\n",
            "10 [9 3 1 5 7 4 2 6 0 8]\n",
            "discarded index [9, 3, 1, 5, 7, 4, 2, 6, 0, 8]\n",
            "10 [9 3 1 5 7 4 2 6 0 8]\n",
            "discarded index [9, 3, 1, 5, 7, 4, 2, 6, 0, 8]\n",
            "10 [9 3 1 5 7 4 2 6 0 8]\n",
            "discarded index [9, 3, 1, 5, 7, 4, 2, 6, 0, 8]\n",
            "10 [9 3 1 5 7 4 2 6 0 8]\n",
            "discarded index [9, 3, 1, 5, 7, 4, 2, 6, 0, 8]\n",
            "10 [9 3 1 5 7 4 2 6 0 8]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 291, bulyan: at fang n_at 10 e 291 | val loss 1.6125 val acc 41.6193 best val_acc 45.718344\n",
            "discarded index [6, 1, 3, 0, 7, 2, 4, 5, 8, 9]\n",
            "10 [6 1 3 0 7 2 4 5 8 9]\n",
            "discarded index [6, 1, 3, 0, 7, 2, 4, 5, 8, 9]\n",
            "10 [6 1 3 0 7 2 4 5 8 9]\n",
            "discarded index [6, 1, 3, 0, 7, 2, 4, 5, 8, 9]\n",
            "10 [6 1 3 0 7 2 4 5 8 9]\n",
            "discarded index [6, 1, 3, 0, 7, 2, 4, 5, 8, 9]\n",
            "10 [6 1 3 0 7 2 4 5 8 9]\n",
            "discarded index [6, 1, 3, 0, 7, 2, 4, 5, 8, 9]\n",
            "10 [6 1 3 0 7 2 4 5 8 9]\n",
            "discarded index [6, 1, 3, 0, 7, 2, 4, 5, 8, 9]\n",
            "10 [6 1 3 0 7 2 4 5 8 9]\n",
            "discarded index [6, 1, 3, 0, 7, 2, 4, 5, 8, 9]\n",
            "10 [6 1 3 0 7 2 4 5 8 9]\n",
            "discarded index [6, 1, 3, 0, 7, 2, 4, 5, 8, 9]\n",
            "10 [6 1 3 0 7 2 4 5 8 9]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 292, bulyan: at fang n_at 10 e 292 | val loss 1.6512 val acc 40.4018 best val_acc 45.718344\n",
            "discarded index [0, 3, 1, 8, 9, 7, 6, 4, 2, 5]\n",
            "10 [0 3 1 8 9 7 6 4 2 5]\n",
            "discarded index [0, 3, 1, 8, 9, 7, 6, 4, 2, 5]\n",
            "10 [0 3 1 8 9 7 6 4 2 5]\n",
            "discarded index [0, 3, 1, 8, 9, 7, 6, 4, 2, 5]\n",
            "10 [0 3 1 8 9 7 6 4 2 5]\n",
            "discarded index [0, 3, 1, 8, 9, 7, 6, 4, 2, 5]\n",
            "10 [0 3 1 8 9 7 6 4 2 5]\n",
            "discarded index [0, 3, 1, 8, 9, 7, 6, 4, 2, 5]\n",
            "10 [0 3 1 8 9 7 6 4 2 5]\n",
            "discarded index [0, 3, 1, 8, 9, 7, 6, 4, 2, 5]\n",
            "10 [0 3 1 8 9 7 6 4 2 5]\n",
            "discarded index [0, 3, 1, 8, 9, 7, 6, 4, 2, 5]\n",
            "10 [0 3 1 8 9 7 6 4 2 5]\n",
            "discarded index [0, 3, 1, 8, 9, 7, 6, 4, 2, 5]\n",
            "10 [0 3 1 8 9 7 6 4 2 5]\n",
            "discarded index [0, 3, 1, 8, 9, 7, 6, 4, 2, 5]\n",
            "10 [0 3 1 8 9 7 6 4 2 5]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 293, bulyan: at fang n_at 10 e 293 | val loss 1.6496 val acc 40.8076 best val_acc 45.718344\n",
            "discarded index [5, 3, 2, 1, 7, 4, 0, 8, 6, 9]\n",
            "10 [5 3 2 1 7 4 0 8 6 9]\n",
            "discarded index [5, 3, 2, 1, 7, 4, 0, 8, 6, 9]\n",
            "10 [5 3 2 1 7 4 0 8 6 9]\n",
            "discarded index [5, 3, 2, 1, 7, 4, 0, 8, 6, 9]\n",
            "10 [5 3 2 1 7 4 0 8 6 9]\n",
            "discarded index [5, 3, 2, 1, 7, 4, 0, 8, 6, 9]\n",
            "10 [5 3 2 1 7 4 0 8 6 9]\n",
            "discarded index [5, 3, 2, 1, 7, 4, 0, 8, 6, 9]\n",
            "10 [5 3 2 1 7 4 0 8 6 9]\n",
            "discarded index [5, 3, 2, 1, 7, 4, 0, 8, 6, 9]\n",
            "10 [5 3 2 1 7 4 0 8 6 9]\n",
            "discarded index [5, 3, 2, 1, 7, 4, 0, 8, 6, 9]\n",
            "10 [5 3 2 1 7 4 0 8 6 9]\n",
            "discarded index [5, 3, 2, 1, 7, 4, 0, 8, 6, 9]\n",
            "10 [5 3 2 1 7 4 0 8 6 9]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 294, bulyan: at fang n_at 10 e 294 | val loss 1.5784 val acc 44.2370 best val_acc 45.718344\n",
            "discarded index [0, 1, 6, 8, 7, 9, 4, 5, 3, 2]\n",
            "10 [0 1 6 8 7 9 4 5 3 2]\n",
            "discarded index [0, 1, 6, 8, 7, 9, 4, 5, 3, 2]\n",
            "10 [0 1 6 8 7 9 4 5 3 2]\n",
            "discarded index [0, 1, 6, 8, 7, 9, 4, 5, 3, 2]\n",
            "10 [0 1 6 8 7 9 4 5 3 2]\n",
            "discarded index [0, 1, 6, 8, 7, 9, 4, 5, 3, 2]\n",
            "10 [0 1 6 8 7 9 4 5 3 2]\n",
            "discarded index [0, 1, 6, 8, 7, 9, 4, 5, 3, 2]\n",
            "10 [0 1 6 8 7 9 4 5 3 2]\n",
            "discarded index [0, 1, 6, 8, 7, 9, 4, 5, 3, 2]\n",
            "10 [0 1 6 8 7 9 4 5 3 2]\n",
            "discarded index [0, 1, 6, 8, 7, 9, 4, 5, 3, 2]\n",
            "10 [0 1 6 8 7 9 4 5 3 2]\n",
            "discarded index [0, 1, 6, 8, 7, 9, 4, 5, 3, 2]\n",
            "10 [0 1 6 8 7 9 4 5 3 2]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 295, bulyan: at fang n_at 10 e 295 | val loss 1.5719 val acc 42.2687 best val_acc 45.718344\n",
            "discarded index [9, 4, 7, 5, 0, 1, 2, 3, 6, 8]\n",
            "10 [9 4 7 5 0 1 2 3 6 8]\n",
            "discarded index [9, 4, 7, 5, 0, 1, 2, 3, 6, 8]\n",
            "10 [9 4 7 5 0 1 2 3 6 8]\n",
            "discarded index [9, 4, 7, 5, 0, 1, 2, 3, 6, 8]\n",
            "10 [9 4 7 5 0 1 2 3 6 8]\n",
            "discarded index [9, 4, 7, 5, 0, 1, 2, 3, 6, 8]\n",
            "10 [9 4 7 5 0 1 2 3 6 8]\n",
            "discarded index [9, 4, 7, 5, 0, 1, 2, 3, 6, 8]\n",
            "10 [9 4 7 5 0 1 2 3 6 8]\n",
            "discarded index [9, 4, 7, 5, 0, 1, 2, 3, 6, 8]\n",
            "10 [9 4 7 5 0 1 2 3 6 8]\n",
            "discarded index [9, 4, 7, 5, 0, 1, 2, 3, 6, 8]\n",
            "10 [9 4 7 5 0 1 2 3 6 8]\n",
            "discarded index [9, 4, 7, 5, 0, 1, 2, 3, 6, 8]\n",
            "10 [9 4 7 5 0 1 2 3 6 8]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 296, bulyan: at fang n_at 10 e 296 | val loss 1.5815 val acc 41.2338 best val_acc 45.718344\n",
            "discarded index [1, 4, 0, 3, 8, 7, 6, 2, 5, 9]\n",
            "10 [1 4 0 3 8 7 6 2 5 9]\n",
            "discarded index [1, 4, 0, 3, 8, 7, 6, 2, 5, 9]\n",
            "10 [1 4 0 3 8 7 6 2 5 9]\n",
            "discarded index [1, 4, 0, 3, 8, 7, 6, 2, 5, 9]\n",
            "10 [1 4 0 3 8 7 6 2 5 9]\n",
            "discarded index [1, 4, 0, 3, 8, 7, 6, 2, 5, 9]\n",
            "10 [1 4 0 3 8 7 6 2 5 9]\n",
            "discarded index [1, 4, 0, 3, 8, 7, 6, 2, 5, 9]\n",
            "10 [1 4 0 3 8 7 6 2 5 9]\n",
            "discarded index [1, 4, 0, 3, 8, 7, 6, 2, 5, 9]\n",
            "10 [1 4 0 3 8 7 6 2 5 9]\n",
            "discarded index [1, 4, 0, 3, 8, 7, 6, 2, 5, 9]\n",
            "10 [1 4 0 3 8 7 6 2 5 9]\n",
            "discarded index [1, 4, 0, 3, 8, 7, 6, 2, 5, 9]\n",
            "10 [1 4 0 3 8 7 6 2 5 9]\n",
            "discarded index [1, 4, 0, 3, 8, 7, 6, 2, 5, 9]\n",
            "10 [1 4 0 3 8 7 6 2 5 9]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 297, bulyan: at fang n_at 10 e 297 | val loss 1.6675 val acc 38.8799 best val_acc 45.718344\n",
            "discarded index [1, 5, 3, 7, 6, 2, 0, 4, 8, 9]\n",
            "10 [1 5 3 7 6 2 0 4 8 9]\n",
            "discarded index [1, 5, 3, 7, 6, 2, 0, 4, 8, 9]\n",
            "10 [1 5 3 7 6 2 0 4 8 9]\n",
            "discarded index [1, 5, 3, 7, 6, 2, 0, 4, 8, 9]\n",
            "10 [1 5 3 7 6 2 0 4 8 9]\n",
            "discarded index [1, 5, 3, 7, 6, 2, 0, 4, 8, 9]\n",
            "10 [1 5 3 7 6 2 0 4 8 9]\n",
            "discarded index [1, 5, 3, 7, 6, 2, 0, 4, 8, 9]\n",
            "10 [1 5 3 7 6 2 0 4 8 9]\n",
            "discarded index [1, 5, 3, 7, 6, 2, 0, 4, 8, 9]\n",
            "10 [1 5 3 7 6 2 0 4 8 9]\n",
            "discarded index [1, 5, 3, 7, 6, 2, 0, 4, 8, 9]\n",
            "10 [1 5 3 7 6 2 0 4 8 9]\n",
            "discarded index [1, 5, 3, 7, 6, 2, 0, 4, 8, 9]\n",
            "10 [1 5 3 7 6 2 0 4 8 9]\n",
            "discarded index [1, 5, 3, 7, 6, 2, 0, 4, 8, 9]\n",
            "10 [1 5 3 7 6 2 0 4 8 9]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 298, bulyan: at fang n_at 10 e 298 | val loss 1.6841 val acc 37.2362 best val_acc 45.718344\n",
            "discarded index [1, 9, 6, 3, 0, 2, 7, 5, 4, 8]\n",
            "10 [1 9 6 3 0 2 7 5 4 8]\n",
            "discarded index [1, 9, 6, 3, 0, 2, 7, 5, 4, 8]\n",
            "10 [1 9 6 3 0 2 7 5 4 8]\n",
            "discarded index [1, 9, 6, 3, 0, 2, 7, 5, 4, 8]\n",
            "10 [1 9 6 3 0 2 7 5 4 8]\n",
            "discarded index [1, 9, 6, 3, 0, 2, 7, 5, 4, 8]\n",
            "10 [1 9 6 3 0 2 7 5 4 8]\n",
            "discarded index [1, 9, 6, 3, 0, 2, 7, 5, 4, 8]\n",
            "10 [1 9 6 3 0 2 7 5 4 8]\n",
            "discarded index [1, 9, 6, 3, 0, 2, 7, 5, 4, 8]\n",
            "10 [1 9 6 3 0 2 7 5 4 8]\n",
            "discarded index [1, 9, 6, 3, 0, 2, 7, 5, 4, 8]\n",
            "10 [1 9 6 3 0 2 7 5 4 8]\n",
            "discarded index [1, 9, 6, 3, 0, 2, 7, 5, 4, 8]\n",
            "10 [1 9 6 3 0 2 7 5 4 8]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 299, bulyan: at fang n_at 10 e 299 | val loss 1.5981 val acc 41.0917 best val_acc 45.718344\n",
            "discarded index [6, 5, 3, 4, 2, 7, 9, 8, 0, 1]\n",
            "10 [6 5 3 4 2 7 9 8 0 1]\n",
            "discarded index [6, 5, 3, 4, 2, 7, 9, 8, 0, 1]\n",
            "10 [6 5 3 4 2 7 9 8 0 1]\n",
            "discarded index [6, 5, 3, 4, 2, 7, 9, 8, 0, 1]\n",
            "10 [6 5 3 4 2 7 9 8 0 1]\n",
            "discarded index [6, 5, 3, 4, 2, 7, 9, 8, 0, 1]\n",
            "10 [6 5 3 4 2 7 9 8 0 1]\n",
            "discarded index [6, 5, 3, 4, 2, 7, 9, 8, 0, 1]\n",
            "10 [6 5 3 4 2 7 9 8 0 1]\n",
            "discarded index [6, 5, 3, 4, 2, 7, 9, 8, 0, 1]\n",
            "10 [6 5 3 4 2 7 9 8 0 1]\n",
            "discarded index [6, 5, 3, 4, 2, 7, 9, 8, 0, 1]\n",
            "10 [6 5 3 4 2 7 9 8 0 1]\n",
            "discarded index [6, 5, 3, 4, 2, 7, 9, 8, 0, 1]\n",
            "10 [6 5 3 4 2 7 9 8 0 1]\n",
            "lamda < threshold\n",
            "discarded index [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "epoch: 300, bulyan: at fang n_at 10 e 300 | val loss 1.5060 val acc 45.2110 best val_acc 45.718344\n"
          ]
        }
      ],
      "source": [
        "batch_size=250\n",
        "resume=0\n",
        "\n",
        "schedule=[1000]\n",
        "\n",
        "gamma=.5\n",
        "opt = 'sgd'\n",
        "fed_lr=0.5\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "use_cuda = torch.cuda.is_available()\n",
        "\n",
        "aggregation='bulyan'\n",
        "multi_k = False\n",
        "candidates = []\n",
        "\n",
        "at_type='fang'\n",
        "n_attackers=[10]\n",
        "\n",
        "arch='alexnet'\n",
        "chkpt='./'+aggregation\n",
        "\n",
        "title = \"Fang attack on our defense\"\n",
        "\n",
        "for n_attacker in n_attackers:\n",
        "    epoch_num = 0\n",
        "    best_global_acc = 0\n",
        "    best_global_te_acc = 0\n",
        "    \n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    fed_model, _ = return_model(arch, 0.1, 0.9, parallel=False)\n",
        "    optimizer_fed = SGD(fed_model.parameters(), lr=fed_lr)\n",
        "\n",
        "    df = pd.DataFrame(columns = ['epoch', 'loss', 'validation accuracy', 'best validation accuracy'])\n",
        "\n",
        "    ####\n",
        "    history = torch.zeros((n_users, nepochs + 1), dtype=torch.float32).cuda()\n",
        "    ####\n",
        "    model_grads = []\n",
        "\n",
        "    while epoch_num <= nepochs:\n",
        "        user_grads=[]\n",
        "\n",
        "        # for i in range(n_attacker, nusers):\n",
        "        for i in range(n_users):\n",
        "            nbatches = user_tr_len[i]//batch_size\n",
        "\n",
        "            inputs = user_train_data_tensors[i][(epoch_num%nbatches)*batch_size:((epoch_num%nbatches) + 1) * batch_size]\n",
        "            targets = user_train_label_tensors[i][(epoch_num%nbatches)*batch_size:((epoch_num%nbatches) + 1) * batch_size]\n",
        "            targets = targets.type(torch.LongTensor)   \n",
        "            \n",
        "            inputs, targets = inputs.cuda(), targets.cuda()\n",
        "            inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
        "\n",
        "            outputs = fed_model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            fed_model.zero_grad()\n",
        "            loss.backward(retain_graph=True)\n",
        "\n",
        "            param_grad=[]\n",
        "            for param in fed_model.parameters():\n",
        "                param_grad=param.grad.data.view(-1) if not len(param_grad) else torch.cat((param_grad,param.grad.view(-1)))\n",
        "\n",
        "            user_grads=param_grad[None, :] if len(user_grads)==0 else torch.cat((user_grads,param_grad[None,:]), 0)\n",
        "\n",
        "        if epoch_num in schedule:\n",
        "            for param_group in optimizer_fed.param_groups:\n",
        "                param_group['lr'] *= gamma\n",
        "                print('New learnin rate ', param_group['lr'])\n",
        "\n",
        "        if n_attacker > 0:\n",
        "            agg_grads = torch.mean(user_grads, 0)\n",
        "            deviation = torch.sign(agg_grads)\n",
        "            mal_update = get_malicious_updates_fang(user_grads, agg_grads, deviation, n_attacker, history, epoch_num)\n",
        "\n",
        "            malicious_grads = torch.cat((torch.stack([mal_update] * n_attacker), user_grads[n_attacker:]), 0)\n",
        "\n",
        "        \n",
        "        if not (malicious_grads.shape[0]==50):\n",
        "            print(malicious_grads.shape)\n",
        "            sys.exit()\n",
        "            \n",
        "\n",
        "        if not (malicious_grads.shape[0]==50):\n",
        "            print(malicious_grads.shape)\n",
        "\n",
        "        updates_abs_mean = malicious_grads.abs().mean(dim=1, keepdim=True)\n",
        "\n",
        "        history[:, epoch_num] = updates_abs_mean.squeeze()\n",
        "        agg_grads, _ = our_mean_defense(malicious_grads, n_attacker, history)\n",
        "\n",
        "        del user_grads\n",
        "\n",
        "        start_idx=0\n",
        "\n",
        "        optimizer_fed.zero_grad()\n",
        "\n",
        "        model_grads=[]\n",
        "\n",
        "        for i, param in enumerate(fed_model.parameters()):\n",
        "            param_=agg_grads[start_idx:start_idx+len(param.data.view(-1))].reshape(param.data.shape)\n",
        "            start_idx=start_idx+len(param.data.view(-1))\n",
        "            param_=param_.cuda()\n",
        "            model_grads.append(param_)\n",
        "\n",
        "        optimizer_fed.step(model_grads)\n",
        "\n",
        "        val_loss, val_acc = test(val_data_tensor,val_label_tensor,fed_model,criterion,use_cuda)\n",
        "        te_loss, te_acc = test(te_data_tensor,te_label_tensor, fed_model, criterion, use_cuda)\n",
        "\n",
        "        is_best = best_global_acc < val_acc\n",
        "\n",
        "        best_global_acc = max(best_global_acc, val_acc)\n",
        "\n",
        "        if is_best:\n",
        "            best_global_te_acc = te_acc\n",
        "\n",
        "        \n",
        "        print('epoch: %d, %s: at %s n_at %d e %d | val loss %.4f val acc %.4f best val_acc %f'%(epoch_num, aggregation, at_type, n_attacker, epoch_num, val_loss, val_acc, best_global_acc))\n",
        "        new_row = pd.DataFrame([{\n",
        "            'epoch': epoch_num, \n",
        "            'loss': val_loss, \n",
        "            'validation accuracy': val_acc, \n",
        "            'best validation accuracy': best_global_acc\n",
        "            }])\n",
        "        df = pd.concat([df, new_row], ignore_index=True)\n",
        "        df.to_csv('fang_our-defense.csv', index=False)\n",
        "        epoch_num+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plotting the data\n",
        "for col in ['loss', 'validation accuracy', 'best validation accuracy']:\n",
        "    plt.plot(df['epoch'].tolist(), df[col].tolist())\n",
        "    plt.title(f\"{title} {col}\")\n",
        "    plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "ilTYNiZMlvp4",
        "8mZBn-_AaaTL"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
