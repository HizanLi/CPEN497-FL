{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMUR8ODgnrc3"
      },
      "source": [
        "# The notebook contains\n",
        "### Code for _Bulyan_ aggregation algorithm, *when gradient updates of benign clients are unknown to adversary*\n",
        "### Evaluation of all of the attacks (Fang, LIE, and our SOTA AGR-tailored and AGR-agnstic) on Bulyan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJu2Edmbnrc5"
      },
      "source": [
        "## Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "wGSIzpf_nrc5",
        "outputId": "5563fc08-740b-4522-8ba9-41e940ec060e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>.container { width:90% !important; }</style>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import display, HTML\n",
        "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "AAU3fosynrc6"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import argparse, os, sys, csv, shutil, time, random, operator, pickle, ast, math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.optim import Optimizer\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import pickle\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torch.multiprocessing as mp\n",
        "import math\n",
        "sys.path.insert(0,'./../utils/')\n",
        "from logger import *\n",
        "from eval import *\n",
        "from misc import *\n",
        "\n",
        "from cifar10_normal_train import *\n",
        "from cifar10_util import *\n",
        "from adam import Adam\n",
        "from sgd import SGD\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGABIvW6nrc6"
      },
      "source": [
        "## Load Data\n",
        "Divide cifar10 data among 50 clients in Non-IID fashion using Dirichlet distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1Nyn5Xlnrc6",
        "outputId": "2148c44a-9897-41f6-bf92-67d798026810"
      },
      "outputs": [],
      "source": [
        "n_users = 50\n",
        "user_tr_len = pickle.load(open('./data/user_tr_len.pkl','rb'))\n",
        "\n",
        "user_train_data_tensors = pickle.load(open('./data/user_train_data_tensors.pkl','rb'))\n",
        "user_train_label_tensors = pickle.load(open('./data/user_train_label_tensors.pkl','rb'))\n",
        "\n",
        "val_data_tensor = pickle.load(open('./data/val_data_tensor.pkl','rb'))\n",
        "val_label_tensor = pickle.load(open('./data/val_label_tensor.pkl','rb'))\n",
        "te_data_tensor = pickle.load(open('./data/te_data_tensor.pkl','rb'))\n",
        "te_label_tensor = pickle.load(open('./data/te_label_tensor.pkl','rb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOVMqc_9nrc8"
      },
      "source": [
        "## Our Aggregation Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "LMgKiRnynrc8"
      },
      "outputs": [],
      "source": [
        "def our_mean_defense(all_updates, n_attackers, history_updates):\n",
        "    discarded_history = get_discarded_index(n_attackers, history_updates)\n",
        "\n",
        "    mask = torch.ones(all_updates.size(0), dtype=torch.bool)\n",
        "    mask[discarded_history] = False\n",
        "    remaining_updates = all_updates[mask]\n",
        "\n",
        "    print('discarded index', discarded_history)\n",
        "\n",
        "    return torch.nanmean(remaining_updates, dim=0)\n",
        "\n",
        "####\n",
        "def euclidean_distance(row1, row2):\n",
        "    return torch.sqrt(torch.sum((row1 - row2) ** 2))\n",
        "####\n",
        "\n",
        "def get_discarded_index(n_attackers, history_updates):\n",
        "    n_users = history_updates.shape[0]\n",
        "\n",
        "    ####\n",
        "    distance_matrix = [[0 if i == j else euclidean_distance(history_updates[i, :], history_updates[j, :]) for j in range(n_users)] for i in range(n_users)]\n",
        "    ####\n",
        "\n",
        "    sum_of_distances = [sum(row) for row in distance_matrix]\n",
        "\n",
        "    discarded_history = []\n",
        "    for _ in range(n_attackers):\n",
        "        max_distance = max(sum_of_distances)\n",
        "        index_of_max_distance = sum_of_distances.index(max_distance)\n",
        "        discarded_history.append(index_of_max_distance)\n",
        "\n",
        "        for i in range(n_users):\n",
        "            sum_of_distances[i] -= distance_matrix[i][index_of_max_distance]\n",
        "        sum_of_distances[index_of_max_distance] = -1\n",
        "\n",
        "    return discarded_history\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yiHdOSknrc8"
      },
      "source": [
        "## Code for no defense aggregation algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "bDqjWvS-nrc8"
      },
      "outputs": [],
      "source": [
        "def no_defense_aggregation(user_grads):\n",
        "    return torch.nanmean(user_grads, dim=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eh9-2QXLnrc8"
      },
      "source": [
        "## our_attack_mean\n",
        "$ argmin_\\theta(\\ -L(\\theta_{attacker(s)}) + \\lambda_1 |\\bar{\\theta_{abs\\ mean\\ benige\\ users}} - \\bar{\\theta_{abs\\ attacker(s)}}|$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "22HIfqLWn0KR"
      },
      "outputs": [],
      "source": [
        "device = 'cuda:0'\n",
        "def check_condition(lambda1, prev_grad, loss_grad, history, all_updates, n_users, n_attacker, epoch_num):\n",
        "    loss_grad = loss_grad.to(device)\n",
        "    prev_grad = prev_grad.to(device)\n",
        "    new_grad = lambda1 * (loss_grad + prev_grad)\n",
        "\n",
        "    ####\n",
        "    mal_updates = torch.stack([new_grad.clone().detach() for _ in range(n_attacker)])\n",
        "    malicious_grads = torch.cat((mal_updates, all_updates[n_attacker:]), 0)\n",
        "\n",
        "    history_updates = history.clone().detach()\n",
        "    history_updates[:, epoch_num] = malicious_grads.abs().mean(dim=1, keepdim=True).squeeze()\n",
        "    ####\n",
        "\n",
        "    discarded_history = get_discarded_index(n_attacker+2, history_updates)\n",
        "\n",
        "    detected_mal = len([item for item in discarded_history if item < 10])\n",
        "    return detected_mal / len(discarded_history) <= n_attacker / n_users\n",
        "\n",
        "def find_upper_bound(lambda1, prev_grad, loss_grad, history, all_updates, n_users, n_attacker, epoch_num):\n",
        "    while check_condition(lambda1, prev_grad, loss_grad, history, all_updates, n_users, n_attacker, epoch_num):\n",
        "        lambda1 *= 2  # Exponentially increase lambda\n",
        "    return lambda1\n",
        "\n",
        "\n",
        "def projection(prev_grad, loss_grad, history, all_updates, n_users, n_attacker, epoch_num):\n",
        "    updates_abs_mean = all_updates.abs().mean(dim=1, keepdim=True)\n",
        "    median_value = torch.median(updates_abs_mean).item()\n",
        "\n",
        "    ####\n",
        "    history_updates = history.clone().detach()\n",
        "    history_updates[:, epoch_num] = updates_abs_mean.mean(dim=1, keepdim=True).squeeze()\n",
        "    ####\n",
        "\n",
        "    loss_grad = loss_grad.to(device)\n",
        "    prev_grad = prev_grad.to(device)\n",
        "\n",
        "    lambda_low = median_value/(prev_grad + loss_grad).abs().mean().item()\n",
        "    lambda_high = find_upper_bound(lambda_low, prev_grad, loss_grad, history_updates, all_updates, n_users, n_attacker, epoch_num)\n",
        "    if lambda_high < lambda_low:\n",
        "        lambda_high = lambda_low\n",
        "        print(\"SHOULD NEVER REACH THIS LINE\")\n",
        "        print('lambda_low: ', lambda_low, ' lambda_high: ', lambda_high)\n",
        "    tolerance = 1e-6\n",
        "\n",
        "    iterations_count = 0\n",
        "    while lambda_high - lambda_low > tolerance and iterations_count < 1:\n",
        "        lambda_mid = (lambda_low + lambda_high) / 2\n",
        "        if check_condition(lambda_mid, prev_grad, loss_grad, history_updates, all_updates, n_users, n_attacker, epoch_num):\n",
        "            lambda_low = lambda_mid\n",
        "        else:\n",
        "            lambda_high = lambda_mid\n",
        "        iterations_count += 1\n",
        "\n",
        "    lambda1 = lambda_low\n",
        "\n",
        "    return lambda1 * (prev_grad + loss_grad)\n",
        "\n",
        "def our_attack_mean(n_user, epoch_num, history_updates, all_updates, model_params, n_attacker, arch, criterion, user_train_data_tensors, user_train_label_tensors):\n",
        "    attacker_tr_data_tensor = user_train_data_tensors[0].cuda()\n",
        "    attacker_tr_label_tensor = user_train_label_tensors[0].cuda()\n",
        "\n",
        "    fed_model, _ = return_model(arch, 0.1, 0.9, parallel=False)\n",
        "    fed_model.eval()  # Ensure the model is in evaluation mode\n",
        "\n",
        "    new_grad = -all_updates[0].clone().detach().requires_grad_(True)\n",
        "    prev_grad = np.zeros(len(new_grad))\n",
        "    new_grad = projection(torch.from_numpy(prev_grad), new_grad, history_updates, all_updates, n_user, n_attacker, epoch_num)\n",
        "\n",
        "    for _ in range(10):\n",
        "        outputs = fed_model(attacker_tr_data_tensor)\n",
        "        loss = criterion(outputs, attacker_tr_label_tensor)\n",
        "\n",
        "        loss.backward(retain_graph=True)\n",
        "        param_grad = []\n",
        "        for param in fed_model.parameters():\n",
        "            param_grad.append(param.grad.view(-1).detach())\n",
        "\n",
        "        param_grad = torch.cat(param_grad)\n",
        "        prev_grad = new_grad\n",
        "        new_grad = projection(prev_grad, param_grad, history_updates, all_updates, n_user, n_attacker, epoch_num)\n",
        "\n",
        "        difference = torch.mean(torch.abs(new_grad - prev_grad)).item()\n",
        "        if difference < 1e-6:\n",
        "            # print(\"STOPPED! Difference is too small, stop finding best attack grad\")\n",
        "            break\n",
        "\n",
        "        fed_model.zero_grad()\n",
        "\n",
        "    result_attacker_grads = [new_grad.clone().detach() for _ in range(10)]\n",
        "    return torch.stack(result_attacker_grads).cuda()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CGm85rwnrc8"
      },
      "source": [
        "## Set number of epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "1umXispUnrc9"
      },
      "outputs": [],
      "source": [
        "nepochs= 300"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilTYNiZMlvp4"
      },
      "source": [
        "## our attack (10 attacker) + simple mean aggregation defense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "X5K48z4IdqBQ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Hizan\\Desktop\\CPEN497-FL\\attack-defense\\sgd.py:109: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\python_arg_parser.cpp:1630.)\n",
            "  p.data.add_(-group['lr'], d_p)\n",
            "C:\\Users\\Hizan\\AppData\\Local\\Temp\\ipykernel_21352\\3058707441.py:132: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df = pd.concat([df, new_row], ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 0, bulyan: at our-agr n_at 10 e 0 | val loss 2.3021 val acc 9.8620 best val_acc 9.862013\n",
            "epoch: 1, bulyan: at our-agr n_at 10 e 1 | val loss 2.3019 val acc 9.8620 best val_acc 9.862013\n",
            "epoch: 2, bulyan: at our-agr n_at 10 e 2 | val loss 2.3017 val acc 9.8620 best val_acc 9.862013\n",
            "epoch: 3, bulyan: at our-agr n_at 10 e 3 | val loss 2.3017 val acc 9.8620 best val_acc 9.862013\n",
            "epoch: 4, bulyan: at our-agr n_at 10 e 4 | val loss 2.3014 val acc 9.8620 best val_acc 9.862013\n",
            "epoch: 5, bulyan: at our-agr n_at 10 e 5 | val loss 2.3013 val acc 9.8620 best val_acc 9.862013\n",
            "epoch: 6, bulyan: at our-agr n_at 10 e 6 | val loss 2.3015 val acc 9.8620 best val_acc 9.862013\n",
            "epoch: 7, bulyan: at our-agr n_at 10 e 7 | val loss 2.3016 val acc 9.8620 best val_acc 9.862013\n",
            "epoch: 8, bulyan: at our-agr n_at 10 e 8 | val loss 2.3013 val acc 9.8620 best val_acc 9.862013\n",
            "epoch: 9, bulyan: at our-agr n_at 10 e 9 | val loss 2.3010 val acc 9.8620 best val_acc 9.862013\n",
            "epoch: 10, bulyan: at our-agr n_at 10 e 10 | val loss 2.3003 val acc 9.8620 best val_acc 9.862013\n",
            "epoch: 11, bulyan: at our-agr n_at 10 e 11 | val loss 2.2995 val acc 9.8620 best val_acc 9.862013\n",
            "epoch: 12, bulyan: at our-agr n_at 10 e 12 | val loss 2.2983 val acc 9.8620 best val_acc 9.862013\n",
            "epoch: 13, bulyan: at our-agr n_at 10 e 13 | val loss 2.2969 val acc 9.8620 best val_acc 9.862013\n",
            "epoch: 14, bulyan: at our-agr n_at 10 e 14 | val loss 2.2948 val acc 9.8620 best val_acc 9.862013\n",
            "epoch: 15, bulyan: at our-agr n_at 10 e 15 | val loss 2.2915 val acc 9.9229 best val_acc 9.922890\n"
          ]
        }
      ],
      "source": [
        "batch_size=250\n",
        "resume=0\n",
        "\n",
        "schedule=[1000]\n",
        "\n",
        "gamma=.5\n",
        "opt = 'sgd'\n",
        "fed_lr=0.5\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "use_cuda = torch.cuda.is_available()\n",
        "\n",
        "aggregation='bulyan'\n",
        "multi_k = False\n",
        "candidates = []\n",
        "\n",
        "at_type='our-agr'\n",
        "dev_type ='std'\n",
        "n_attackers=[10]\n",
        "\n",
        "arch='alexnet'\n",
        "chkpt='./'+aggregation\n",
        "\n",
        "past_mean = []\n",
        "past_abs_sum = []\n",
        "past_median = []\n",
        "past_lower_quartile = []\n",
        "past_upper_quartile = []\n",
        "past_std = []\n",
        "\n",
        "title = \"our attack (10 attacker) + simple mean aggregation defense\"\n",
        "\n",
        "for n_attacker in n_attackers:\n",
        "    epoch_num = 0\n",
        "    best_global_acc = 0\n",
        "    best_global_te_acc = 0\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    fed_model, _ = return_model(arch, 0.1, 0.9, parallel=False)\n",
        "    optimizer_fed = SGD(fed_model.parameters(), lr=fed_lr)\n",
        "\n",
        "    df = pd.DataFrame(columns = ['epoch', 'loss', 'validation accuracy', 'best validation accuracy'])\n",
        "\n",
        "    ####\n",
        "    history = torch.zeros((n_users, nepochs + 1), dtype=torch.float32).cuda()\n",
        "    ####\n",
        "\n",
        "    model_grads = []\n",
        "    flag = False\n",
        "    while epoch_num <= nepochs:\n",
        "        user_grads=[]\n",
        "\n",
        "        for i in range(n_users): # 50\n",
        "            nbatches = user_tr_len[i]//batch_size\n",
        "\n",
        "            inputs = user_train_data_tensors[i][(epoch_num%nbatches)*batch_size:((epoch_num%nbatches) + 1) * batch_size]\n",
        "            targets = user_train_label_tensors[i][(epoch_num%nbatches)*batch_size:((epoch_num%nbatches) + 1) * batch_size]\n",
        "\n",
        "            targets = targets.type(torch.LongTensor)\n",
        "\n",
        "            inputs, targets = inputs.cuda(), targets.cuda()\n",
        "            inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
        "\n",
        "            outputs = fed_model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            fed_model.zero_grad()\n",
        "            loss.backward(retain_graph=True)\n",
        "\n",
        "            param_grad=[]\n",
        "            for param in fed_model.parameters():\n",
        "                param_grad=param.grad.data.view(-1) if not len(param_grad) else torch.cat((param_grad,param.grad.view(-1)))\n",
        "\n",
        "\n",
        "            user_grads=param_grad[None, :] if len(user_grads)==0 else torch.cat((user_grads,param_grad[None,:]), 0)\n",
        "\n",
        "        if epoch_num in schedule:\n",
        "            for param_group in optimizer_fed.param_groups:\n",
        "                param_group['lr'] *= gamma\n",
        "                print('New learnin rate ', param_group['lr'])\n",
        "\n",
        "        updates_abs_mean = user_grads.abs().mean(dim=1, keepdim=True)\n",
        "\n",
        "        if n_attacker > 0:\n",
        "            model_params = torch.cat([p.data.view(-1) for p in fed_model.parameters()])\n",
        "            mal_updates = our_attack_mean(n_users, epoch_num, history, user_grads, model_params, n_attacker, arch, criterion, user_train_data_tensors, user_train_label_tensors)\n",
        "            malicious_grads = torch.cat((mal_updates, user_grads[n_attacker:]), 0) # torch.Size([50, 2472266])\n",
        "        else:   # No attack\n",
        "            malicious_grads = user_grads\n",
        "\n",
        "        if not (malicious_grads.shape[0]==50):\n",
        "            print(malicious_grads.shape)\n",
        "\n",
        "        updates_abs_mean = malicious_grads.abs().mean(dim=1, keepdim=True)\n",
        "\n",
        "        history[:, epoch_num] = updates_abs_mean.squeeze()\n",
        "        agg_grads = no_defense_aggregation(malicious_grads)\n",
        "\n",
        "        del user_grads\n",
        "\n",
        "        start_idx=0\n",
        "\n",
        "        optimizer_fed.zero_grad()\n",
        "\n",
        "        model_grads=[]\n",
        "\n",
        "        for i, param in enumerate(fed_model.parameters()):\n",
        "            param_=agg_grads[start_idx:start_idx+len(param.data.view(-1))].reshape(param.data.shape)\n",
        "            start_idx=start_idx+len(param.data.view(-1))\n",
        "            param_=param_.cuda()\n",
        "            model_grads.append(param_)\n",
        "\n",
        "        optimizer_fed.step(model_grads)\n",
        "\n",
        "        val_loss, val_acc = test(val_data_tensor,val_label_tensor,fed_model,criterion,use_cuda)\n",
        "        te_loss, te_acc = test(te_data_tensor,te_label_tensor, fed_model, criterion, use_cuda)\n",
        "\n",
        "        is_best = best_global_acc < val_acc\n",
        "\n",
        "        best_global_acc = max(best_global_acc, val_acc)\n",
        "\n",
        "        if is_best:\n",
        "            best_global_te_acc = te_acc\n",
        "\n",
        "\n",
        "        print('epoch: %d, %s: at %s n_at %d e %d | val loss %.4f val acc %.4f best val_acc %f'%(epoch_num, aggregation, at_type, n_attacker, epoch_num, val_loss, val_acc, best_global_acc))\n",
        "        new_row = pd.DataFrame([{\n",
        "            'epoch': epoch_num,\n",
        "            'loss': val_loss,\n",
        "            'validation accuracy': val_acc,\n",
        "            'best validation accuracy': best_global_acc\n",
        "            }])\n",
        "        df = pd.concat([df, new_row], ignore_index=True)\n",
        "        df.to_csv(f'{title}csv', index=False)\n",
        "\n",
        "        if val_loss > 1000:\n",
        "            print('val loss %f too high'%val_loss)\n",
        "            break\n",
        "\n",
        "        epoch_num+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PC6T3x8SdqBR"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plotting the data\n",
        "for col in ['loss', 'validation accuracy', 'best validation accuracy']:\n",
        "    plt.plot(df['epoch'].tolist(), df[col].tolist())\n",
        "    plt.title(f\"{title} {col}\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mZBn-_AaaTL"
      },
      "source": [
        "## No Attack + our defense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MbfPla_jaaTL",
        "outputId": "f5b8b21d-ec85-45ee-a02d-79260233ba13"
      },
      "outputs": [],
      "source": [
        "batch_size=250\n",
        "resume=0\n",
        "\n",
        "schedule=[1000]\n",
        "\n",
        "gamma=.5\n",
        "opt = 'sgd'\n",
        "fed_lr=0.5\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "use_cuda = torch.cuda.is_available()\n",
        "\n",
        "aggregation='bulyan'\n",
        "multi_k = False\n",
        "candidates = []\n",
        "\n",
        "at_type='our-agr'\n",
        "dev_type ='std'\n",
        "n_attackers=[0]\n",
        "\n",
        "arch='alexnet'\n",
        "chkpt='./'+aggregation\n",
        "\n",
        "past_mean = []\n",
        "past_abs_sum = []\n",
        "past_median = []\n",
        "past_lower_quartile = []\n",
        "past_upper_quartile = []\n",
        "past_std = []\n",
        "\n",
        "title = \"No Attack + our defense\"\n",
        "\n",
        "\n",
        "for n_attacker in n_attackers:\n",
        "    epoch_num = 0\n",
        "    best_global_acc = 0\n",
        "    best_global_te_acc = 0\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    fed_model, _ = return_model(arch, 0.1, 0.9, parallel=False)\n",
        "    optimizer_fed = SGD(fed_model.parameters(), lr=fed_lr)\n",
        "\n",
        "    df = pd.DataFrame(columns = ['epoch', 'loss', 'validation accuracy', 'best validation accuracy'])\n",
        "\n",
        "    ####\n",
        "    history = torch.zeros((n_users, nepochs + 1), dtype=torch.float32).cuda()\n",
        "    ####\n",
        "\n",
        "    model_grads = []\n",
        "    flag = False\n",
        "    while epoch_num <= nepochs:\n",
        "        user_grads=[]\n",
        "\n",
        "        for i in range(n_users): # 50\n",
        "            nbatches = user_tr_len[i]//batch_size\n",
        "\n",
        "            inputs = user_train_data_tensors[i][(epoch_num%nbatches)*batch_size:((epoch_num%nbatches) + 1) * batch_size]\n",
        "            targets = user_train_label_tensors[i][(epoch_num%nbatches)*batch_size:((epoch_num%nbatches) + 1) * batch_size]\n",
        "\n",
        "            targets = targets.type(torch.LongTensor)\n",
        "\n",
        "            inputs, targets = inputs.cuda(), targets.cuda()\n",
        "            inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
        "\n",
        "            outputs = fed_model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            fed_model.zero_grad()\n",
        "            loss.backward(retain_graph=True)\n",
        "\n",
        "            param_grad=[]\n",
        "            for param in fed_model.parameters():\n",
        "                param_grad=param.grad.data.view(-1) if not len(param_grad) else torch.cat((param_grad,param.grad.view(-1)))\n",
        "\n",
        "\n",
        "            user_grads=param_grad[None, :] if len(user_grads)==0 else torch.cat((user_grads,param_grad[None,:]), 0)\n",
        "\n",
        "        if epoch_num in schedule:\n",
        "            for param_group in optimizer_fed.param_groups:\n",
        "                param_group['lr'] *= gamma\n",
        "                print('New learnin rate ', param_group['lr'])\n",
        "\n",
        "        updates_abs_mean = user_grads.abs().mean(dim=1, keepdim=True)\n",
        "\n",
        "\n",
        "        malicious_grads = user_grads\n",
        "\n",
        "        if not (malicious_grads.shape[0]==50):\n",
        "            print(malicious_grads.shape)\n",
        "\n",
        "        updates_abs_mean = malicious_grads.abs().mean(dim=1, keepdim=True)\n",
        "\n",
        "        history[:, epoch_num] = updates_abs_mean.squeeze()\n",
        "        agg_grads = our_mean_defense(malicious_grads, n_attacker, history)\n",
        "\n",
        "        del user_grads\n",
        "\n",
        "        start_idx=0\n",
        "\n",
        "        optimizer_fed.zero_grad()\n",
        "\n",
        "        model_grads=[]\n",
        "\n",
        "        for i, param in enumerate(fed_model.parameters()):\n",
        "            param_=agg_grads[start_idx:start_idx+len(param.data.view(-1))].reshape(param.data.shape)\n",
        "            start_idx=start_idx+len(param.data.view(-1))\n",
        "            param_=param_.cuda()\n",
        "            model_grads.append(param_)\n",
        "\n",
        "        optimizer_fed.step(model_grads)\n",
        "\n",
        "        val_loss, val_acc = test(val_data_tensor,val_label_tensor,fed_model,criterion,use_cuda)\n",
        "        te_loss, te_acc = test(te_data_tensor,te_label_tensor, fed_model, criterion, use_cuda)\n",
        "\n",
        "        is_best = best_global_acc < val_acc\n",
        "\n",
        "        best_global_acc = max(best_global_acc, val_acc)\n",
        "\n",
        "        if is_best:\n",
        "            best_global_te_acc = te_acc\n",
        "\n",
        "\n",
        "        print('epoch: %d, %s: at %s n_at %d e %d | val loss %.4f val acc %.4f best val_acc %f'%(epoch_num, aggregation, at_type, n_attacker, epoch_num, val_loss, val_acc, best_global_acc))\n",
        "        new_row = pd.DataFrame([{\n",
        "            'epoch': epoch_num,\n",
        "            'loss': val_loss,\n",
        "            'validation accuracy': val_acc,\n",
        "            'best validation accuracy': best_global_acc\n",
        "            }])\n",
        "        df = pd.concat([df, new_row], ignore_index=True)\n",
        "        df.to_csv(f'{title}csv', index=False)\n",
        "\n",
        "        if val_loss > 1000:\n",
        "            print('val loss %f too high'%val_loss)\n",
        "            break\n",
        "\n",
        "        epoch_num+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "z7JTN4CMdlnF",
        "outputId": "40a9fef3-a67b-4f5a-c816-0913a8683b3f"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plotting the data\n",
        "for col in ['loss', 'validation accuracy', 'best validation accuracy']:\n",
        "    plt.plot(df['epoch'].tolist(), df[col].tolist())\n",
        "    plt.title(f\"{title} {col}\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_CfL1Rlnrc9"
      },
      "source": [
        "## our attack (10 attacker) + our defense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "cP82p47XdfjA",
        "outputId": "17756df2-bc6d-4138-d1b3-33441703fc33"
      },
      "outputs": [],
      "source": [
        "batch_size=250\n",
        "resume=0\n",
        "\n",
        "schedule=[1000]\n",
        "\n",
        "gamma=.5\n",
        "opt = 'sgd'\n",
        "fed_lr=0.5\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "use_cuda = torch.cuda.is_available()\n",
        "\n",
        "aggregation='bulyan'\n",
        "multi_k = False\n",
        "candidates = []\n",
        "\n",
        "at_type='our-agr'\n",
        "dev_type ='std'\n",
        "n_attackers=[10]\n",
        "\n",
        "arch='alexnet'\n",
        "chkpt='./'+aggregation\n",
        "\n",
        "past_mean = []\n",
        "past_abs_sum = []\n",
        "past_median = []\n",
        "past_lower_quartile = []\n",
        "past_upper_quartile = []\n",
        "past_std = []\n",
        "\n",
        "title = \"## our attack (10 attacker) + our defense\"\n",
        "\n",
        "for n_attacker in n_attackers:\n",
        "    epoch_num = 0\n",
        "    best_global_acc = 0\n",
        "    best_global_te_acc = 0\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    fed_model, _ = return_model(arch, 0.1, 0.9, parallel=False)\n",
        "    optimizer_fed = SGD(fed_model.parameters(), lr=fed_lr)\n",
        "\n",
        "    df = pd.DataFrame(columns = ['epoch', 'loss', 'validation accuracy', 'best validation accuracy'])\n",
        "\n",
        "    ####\n",
        "    history = torch.zeros((n_users, nepochs + 1), dtype=torch.float32).cuda()\n",
        "    ####\n",
        "\n",
        "    model_grads = []\n",
        "    flag = False\n",
        "    while epoch_num <= nepochs:\n",
        "        user_grads=[]\n",
        "\n",
        "        for i in range(n_users): # 50\n",
        "            nbatches = user_tr_len[i]//batch_size\n",
        "\n",
        "            inputs = user_train_data_tensors[i][(epoch_num%nbatches)*batch_size:((epoch_num%nbatches) + 1) * batch_size]\n",
        "            targets = user_train_label_tensors[i][(epoch_num%nbatches)*batch_size:((epoch_num%nbatches) + 1) * batch_size]\n",
        "\n",
        "            targets = targets.type(torch.LongTensor)\n",
        "\n",
        "            inputs, targets = inputs.cuda(), targets.cuda()\n",
        "            inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
        "\n",
        "            outputs = fed_model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            fed_model.zero_grad()\n",
        "            loss.backward(retain_graph=True)\n",
        "\n",
        "            param_grad=[]\n",
        "            for param in fed_model.parameters():\n",
        "                param_grad=param.grad.data.view(-1) if not len(param_grad) else torch.cat((param_grad,param.grad.view(-1)))\n",
        "\n",
        "\n",
        "            user_grads=param_grad[None, :] if len(user_grads)==0 else torch.cat((user_grads,param_grad[None,:]), 0)\n",
        "\n",
        "        if epoch_num in schedule:\n",
        "            for param_group in optimizer_fed.param_groups:\n",
        "                param_group['lr'] *= gamma\n",
        "                print('New learnin rate ', param_group['lr'])\n",
        "\n",
        "        updates_abs_mean = user_grads.abs().mean(dim=1, keepdim=True)\n",
        "\n",
        "        if n_attacker > 0:\n",
        "            model_params = torch.cat([p.data.view(-1) for p in fed_model.parameters()])\n",
        "            mal_updates = our_attack_mean(n_users, epoch_num, history, user_grads, model_params, n_attacker, arch, criterion, user_train_data_tensors, user_train_label_tensors)\n",
        "            malicious_grads = torch.cat((mal_updates, user_grads[n_attacker:]), 0) # torch.Size([50, 2472266])\n",
        "        else:   # No attack\n",
        "            malicious_grads = user_grads\n",
        "\n",
        "        if not (malicious_grads.shape[0]==50):\n",
        "            print(malicious_grads.shape)\n",
        "\n",
        "        updates_abs_mean = malicious_grads.abs().mean(dim=1, keepdim=True)\n",
        "\n",
        "        history[:, epoch_num] = updates_abs_mean.squeeze()\n",
        "        # agg_grads = no_defense_aggregation(malicious_grads)\n",
        "        agg_grads = our_mean_defense(malicious_grads, n_attacker, history)\n",
        "\n",
        "        del user_grads\n",
        "\n",
        "        start_idx=0\n",
        "\n",
        "        optimizer_fed.zero_grad()\n",
        "\n",
        "        model_grads=[]\n",
        "\n",
        "        for i, param in enumerate(fed_model.parameters()):\n",
        "            param_=agg_grads[start_idx:start_idx+len(param.data.view(-1))].reshape(param.data.shape)\n",
        "            start_idx=start_idx+len(param.data.view(-1))\n",
        "            param_=param_.cuda()\n",
        "            model_grads.append(param_)\n",
        "\n",
        "        optimizer_fed.step(model_grads)\n",
        "\n",
        "        val_loss, val_acc = test(val_data_tensor,val_label_tensor,fed_model,criterion,use_cuda)\n",
        "        te_loss, te_acc = test(te_data_tensor,te_label_tensor, fed_model, criterion, use_cuda)\n",
        "\n",
        "        is_best = best_global_acc < val_acc\n",
        "\n",
        "        best_global_acc = max(best_global_acc, val_acc)\n",
        "\n",
        "        if is_best:\n",
        "            best_global_te_acc = te_acc\n",
        "\n",
        "\n",
        "        print('epoch: %d, %s: at %s n_at %d e %d | val loss %.4f val acc %.4f best val_acc %f'%(epoch_num, aggregation, at_type, n_attacker, epoch_num, val_loss, val_acc, best_global_acc))\n",
        "        new_row = pd.DataFrame([{\n",
        "            'epoch': epoch_num,\n",
        "            'loss': val_loss,\n",
        "            'validation accuracy': val_acc,\n",
        "            'best validation accuracy': best_global_acc\n",
        "            }])\n",
        "        df = pd.concat([df, new_row], ignore_index=True)\n",
        "        df.to_csv('./our attack + 10 attacker + our defense.csv', index=False)\n",
        "\n",
        "        if val_loss > 1000:\n",
        "            print('val loss %f too high'%val_loss)\n",
        "            break\n",
        "\n",
        "        epoch_num+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "I72iJwnddqBQ",
        "outputId": "39cc82c9-7c4c-4d01-c5af-5cd9213d4f13"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plotting the data\n",
        "for col in ['loss', 'validation accuracy', 'best validation accuracy']:\n",
        "    plt.plot(df['epoch'].tolist(), df[col].tolist())\n",
        "    plt.title(f\"{title} {col}\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## LIE attack and our defense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def lie_attack(all_updates, z):\n",
        "    avg = torch.mean(all_updates, dim=0)\n",
        "    std = torch.std(all_updates, dim=0)\n",
        "    return avg + z * std"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size=250\n",
        "resume=0\n",
        "\n",
        "schedule=[1000]\n",
        "\n",
        "gamma=.5\n",
        "opt = 'sgd'\n",
        "fed_lr=0.5\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "use_cuda = torch.cuda.is_available()\n",
        "\n",
        "aggregation='bulyan'\n",
        "multi_k = False\n",
        "candidates = []\n",
        "\n",
        "dev_type ='std'\n",
        "n_attackers=[10]\n",
        "z_values={3:0.69847, 5:0.7054, 8:0.71904, 10:0.72575, 12:0.73891}\n",
        "\n",
        "arch='alexnet'\n",
        "chkpt='./'+aggregation\n",
        "\n",
        "past_mean = []\n",
        "past_abs_sum = []\n",
        "past_median = []\n",
        "past_lower_quartile = []\n",
        "past_upper_quartile = []\n",
        "past_std = []\n",
        "\n",
        "title = \"## LIE attack and our defense\"\n",
        "\n",
        "for n_attacker in n_attackers:\n",
        "    epoch_num = 0\n",
        "    best_global_acc = 0\n",
        "    best_global_te_acc = 0\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    fed_model, _ = return_model(arch, 0.1, 0.9, parallel=False)\n",
        "    optimizer_fed = SGD(fed_model.parameters(), lr=fed_lr)\n",
        "\n",
        "    df = pd.DataFrame(columns = ['epoch', 'loss', 'validation accuracy', 'best validation accuracy'])\n",
        "\n",
        "    ####\n",
        "    history = torch.zeros((n_users, nepochs + 1), dtype=torch.float32).cuda()\n",
        "    ####\n",
        "\n",
        "    model_grads = []\n",
        "    flag = False\n",
        "    while epoch_num <= nepochs:\n",
        "        user_grads=[]\n",
        "\n",
        "        for i in range(n_users): # 50\n",
        "            nbatches = user_tr_len[i]//batch_size\n",
        "\n",
        "            inputs = user_train_data_tensors[i][(epoch_num%nbatches)*batch_size:((epoch_num%nbatches) + 1) * batch_size]\n",
        "            targets = user_train_label_tensors[i][(epoch_num%nbatches)*batch_size:((epoch_num%nbatches) + 1) * batch_size]\n",
        "\n",
        "            targets = targets.type(torch.LongTensor)\n",
        "\n",
        "            inputs, targets = inputs.cuda(), targets.cuda()\n",
        "            inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
        "\n",
        "            outputs = fed_model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            fed_model.zero_grad()\n",
        "            loss.backward(retain_graph=True)\n",
        "\n",
        "            param_grad=[]\n",
        "            for param in fed_model.parameters():\n",
        "                param_grad=param.grad.data.view(-1) if not len(param_grad) else torch.cat((param_grad,param.grad.view(-1)))\n",
        "\n",
        "\n",
        "            user_grads=param_grad[None, :] if len(user_grads)==0 else torch.cat((user_grads,param_grad[None,:]), 0)\n",
        "\n",
        "        if epoch_num in schedule:\n",
        "            for param_group in optimizer_fed.param_groups:\n",
        "                param_group['lr'] *= gamma\n",
        "                print('New learnin rate ', param_group['lr'])\n",
        "\n",
        "        updates_abs_mean = user_grads.abs().mean(dim=1, keepdim=True)\n",
        "\n",
        "        if n_attacker > 0:\n",
        "            mal_update = lie_attack(malicious_grads, z_values[n_attacker])\n",
        "            malicious_grads = torch.cat((mal_updates, user_grads[n_attacker:]), 0) # torch.Size([50, 2472266])\n",
        "        else:   # No attack\n",
        "            malicious_grads = user_grads\n",
        "\n",
        "        if not (malicious_grads.shape[0]==50):\n",
        "            print(malicious_grads.shape)\n",
        "\n",
        "        updates_abs_mean = malicious_grads.abs().mean(dim=1, keepdim=True)\n",
        "\n",
        "        history[:, epoch_num] = updates_abs_mean.squeeze()\n",
        "        # agg_grads = no_defense_aggregation(malicious_grads)\n",
        "        agg_grads = our_mean_defense(malicious_grads, n_attacker, history)\n",
        "\n",
        "        del user_grads\n",
        "\n",
        "        start_idx=0\n",
        "\n",
        "        optimizer_fed.zero_grad()\n",
        "\n",
        "        model_grads=[]\n",
        "\n",
        "        for i, param in enumerate(fed_model.parameters()):\n",
        "            param_=agg_grads[start_idx:start_idx+len(param.data.view(-1))].reshape(param.data.shape)\n",
        "            start_idx=start_idx+len(param.data.view(-1))\n",
        "            param_=param_.cuda()\n",
        "            model_grads.append(param_)\n",
        "\n",
        "        optimizer_fed.step(model_grads)\n",
        "\n",
        "        val_loss, val_acc = test(val_data_tensor,val_label_tensor,fed_model,criterion,use_cuda)\n",
        "        te_loss, te_acc = test(te_data_tensor,te_label_tensor, fed_model, criterion, use_cuda)\n",
        "\n",
        "        is_best = best_global_acc < val_acc\n",
        "\n",
        "        best_global_acc = max(best_global_acc, val_acc)\n",
        "\n",
        "        if is_best:\n",
        "            best_global_te_acc = te_acc\n",
        "\n",
        "\n",
        "        print('epoch: %d, %s: at %s n_at %d e %d | val loss %.4f val acc %.4f best val_acc %f'%(epoch_num, aggregation, at_type, n_attacker, epoch_num, val_loss, val_acc, best_global_acc))\n",
        "        new_row = pd.DataFrame([{\n",
        "            'epoch': epoch_num,\n",
        "            'loss': val_loss,\n",
        "            'validation accuracy': val_acc,\n",
        "            'best validation accuracy': best_global_acc\n",
        "            }])\n",
        "        df = pd.concat([df, new_row], ignore_index=True)\n",
        "        df.to_csv('./our attack + 10 attacker + our defense.csv', index=False)\n",
        "\n",
        "        if val_loss > 1000:\n",
        "            print('val loss %f too high'%val_loss)\n",
        "            break\n",
        "\n",
        "        epoch_num+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plotting the data\n",
        "for col in ['loss', 'validation accuracy', 'best validation accuracy']:\n",
        "    plt.plot(df['epoch'].tolist(), df[col].tolist())\n",
        "    plt.title(f\"{title} {col}\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "ilTYNiZMlvp4",
        "8mZBn-_AaaTL"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
