{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The notebook contains\n",
    "### Code for data split iid and non-iid manner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse, os, sys, csv, shutil, time, random, operator, pickle, ast, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.optim import Optimizer\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import pickle\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torch.multiprocessing as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get cifar10 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "total data len:  60000\n",
      "(60000, 3, 32, 32)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "data_loc='/mnt/nfs/work1/amir/vshejwalkar/cifar10_data/'\n",
    "# load the train dataset\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "\n",
    "cifar10_train = datasets.CIFAR10(root=data_loc, train=True, download=True, transform=train_transform)\n",
    "\n",
    "cifar10_test = datasets.CIFAR10(root=data_loc, train=False, download=True, transform=train_transform)\n",
    "\n",
    "X=[]\n",
    "Y=[]\n",
    "for i in range(len(cifar10_train)):\n",
    "    X.append(cifar10_train[i][0].numpy())\n",
    "    Y.append(cifar10_train[i][1])\n",
    "\n",
    "for i in range(len(cifar10_test)):\n",
    "    X.append(cifar10_test[i][0].numpy())\n",
    "    Y.append(cifar10_test[i][1])\n",
    "\n",
    "X=np.array(X)\n",
    "Y=np.array(Y)\n",
    "\n",
    "print('total data len: ',len(X))\n",
    "\n",
    "if not os.path.isfile('./cifar10_shuffle.pkl'):\n",
    "    all_indices = np.arange(len(X))\n",
    "    np.random.shuffle(all_indices)\n",
    "    pickle.dump(all_indices,open('./cifar10_shuffle.pkl','wb'))\n",
    "else:\n",
    "    all_indices=pickle.load(open('./cifar10_shuffle.pkl','rb'))\n",
    "\n",
    "X=X[all_indices]\n",
    "Y=Y[all_indices]\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data len:  60000\n"
     ]
    }
   ],
   "source": [
    "nusers=50\n",
    "user_tr_len=1000\n",
    "\n",
    "total_tr_len=user_tr_len*nusers\n",
    "val_len=5000\n",
    "te_len=5000\n",
    "\n",
    "# data loading\n",
    "print('total data len: ',len(X))\n",
    "\n",
    "if not os.path.isfile('./cifar10_shuffle.pkl'):\n",
    "    all_indices = np.arange(len(X))\n",
    "    np.random.shuffle(all_indices)\n",
    "    pickle.dump(all_indices,open('./cifar10_shuffle.pkl','wb'))\n",
    "else:\n",
    "    all_indices=pickle.load(open('./cifar10_shuffle.pkl','rb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-iid split using Dirichlet distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide cifar10 data among 50 clients in Non-IID fashion (Christy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_tr_data_tensors = []\n",
    "user_tr_label_tensors = []\n",
    "\n",
    "# Group data by label\n",
    "num_classes = len(np.unique(Y))\n",
    "grouped_indices = [np.where(Y == i)[0] for i in range(num_classes)]\n",
    "\n",
    "# split training/ testing/ validation sets\n",
    "tr_indices = []\n",
    "te_indices = []\n",
    "val_indices = []\n",
    "\n",
    "for i in range(num_classes):\n",
    "    tr_indices.extend(grouped_indices[i][:5000])\n",
    "    te_indices.extend(grouped_indices[i][5000:5500])\n",
    "    val_indices.extend(grouped_indices[i][5500:])\n",
    "\n",
    "total_tr_data=X[tr_indices]\n",
    "total_tr_label=Y[tr_indices]\n",
    "\n",
    "val_data=X[te_indices]\n",
    "val_label=Y[te_indices]\n",
    "\n",
    "te_data=X[val_indices]\n",
    "te_label=Y[val_indices]\n",
    "\n",
    "total_tr_data_tensor=torch.from_numpy(total_tr_data).type(torch.FloatTensor)\n",
    "total_tr_label_tensor=torch.from_numpy(total_tr_label).type(torch.LongTensor)\n",
    "\n",
    "\n",
    "# users have data with a skewed distribution of two dominant classes\n",
    "\n",
    "grouped_indices = [np.where(total_tr_label == i)[0] for i in range(num_classes)]\n",
    "\n",
    "dominant_classes_num = 2\n",
    "labels = np.unique(Y)\n",
    "repetitions = dominant_classes_num * nusers / len(labels)\n",
    "number_pool = np.repeat(labels, repetitions)\n",
    "np.random.shuffle(number_pool)\n",
    "user_selections = [number_pool[i:i+dominant_classes_num] \n",
    "                   for i in range(0, len(number_pool), dominant_classes_num)]\n",
    "\n",
    "dominent_num = 300\n",
    "other_num = 50\n",
    "for i in range(nusers):\n",
    "    dominant_classes = user_selections[i]\n",
    "    indices = []\n",
    "    \n",
    "    for j in range(num_classes):\n",
    "        if j in dominant_classes:\n",
    "            indices.extend(grouped_indices[j][:dominent_num])\n",
    "            grouped_indices[j] = grouped_indices[j][dominent_num:]\n",
    "        else:\n",
    "            indices.extend(grouped_indices[j][:other_num])\n",
    "            grouped_indices[j] = grouped_indices[j][other_num:]\n",
    "\n",
    "\n",
    "    user_tr_data_tensor=torch.from_numpy(total_tr_data[indices]).type(torch.FloatTensor)\n",
    "    user_tr_label_tensor=torch.from_numpy(total_tr_label[indices]).type(torch.LongTensor)\n",
    "\n",
    "    user_tr_data_tensors.append(user_tr_data_tensor)\n",
    "    user_tr_label_tensors.append(user_tr_label_tensor)\n",
    "\n",
    "# dominant class=[i,i]\n",
    "final_user_tr_data_tensors = []\n",
    "final_user_tr_label_tensors = []\n",
    "indices = [item for sublist in grouped_indices for item in sublist]\n",
    "for data, label in zip(user_tr_data_tensors, user_tr_label_tensors):\n",
    "    userLen = 1000 - len(data)\n",
    "    if userLen>0:\n",
    "        i = indices[:userLen]\n",
    "        indices = indices[userLen:]\n",
    "        new_data_tensor=torch.from_numpy(total_tr_data[i]).type(torch.FloatTensor)\n",
    "        new_label_tensor = torch.from_numpy(total_tr_label[i]).type(torch.LongTensor)\n",
    "        data = torch.cat((data, new_data_tensor), dim=0)\n",
    "        label = torch.cat((label, new_label_tensor), dim=0)\n",
    "    final_user_tr_data_tensors.append(data)\n",
    "    final_user_tr_label_tensors.append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 3, 32, 32])\n",
      "torch.Size([1000])\n",
      "Number 0 occurs 50 times\n",
      "Number 1 occurs 50 times\n",
      "Number 2 occurs 50 times\n",
      "Number 3 occurs 50 times\n",
      "Number 4 occurs 300 times\n",
      "Number 5 occurs 50 times\n",
      "Number 6 occurs 50 times\n",
      "Number 7 occurs 50 times\n",
      "Number 8 occurs 300 times\n",
      "Number 9 occurs 50 times\n"
     ]
    }
   ],
   "source": [
    "print(final_user_tr_data_tensors[0].shape)\n",
    "print(final_user_tr_label_tensors[0].shape)\n",
    "\n",
    "tensor_int = final_user_tr_label_tensors[0].to(torch.int64)\n",
    "\n",
    "unique_numbers, counts = torch.unique(tensor_int, return_counts=True)\n",
    "\n",
    "for number, count in zip(unique_numbers, counts):\n",
    "    print(f\"Number {int(number)} occurs {int(count)} times\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide cifar10 data among 50 clients in Non-IID fashion (Linxin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user 0 tr len 1000, user_tr_data_tensor shape torch.Size([1000, 3, 32, 32]), user_tr_label_tensor shape torch.Size([1000])\n",
      "user 1 tr len 1000, user_tr_data_tensor shape torch.Size([1000, 3, 32, 32]), user_tr_label_tensor shape torch.Size([1000])\n",
      "user 2 tr len 1000, user_tr_data_tensor shape torch.Size([1000, 3, 32, 32]), user_tr_label_tensor shape torch.Size([1000])\n",
      "user 3 tr len 1000, user_tr_data_tensor shape torch.Size([1000, 3, 32, 32]), user_tr_label_tensor shape torch.Size([1000])\n",
      "user 4 tr len 1000, user_tr_data_tensor shape torch.Size([1000, 3, 32, 32]), user_tr_label_tensor shape torch.Size([1000])\n",
      "user 5 tr len 1000, user_tr_data_tensor shape torch.Size([1000, 3, 32, 32]), user_tr_label_tensor shape torch.Size([1000])\n",
      "user 6 tr len 1000, user_tr_data_tensor shape torch.Size([1000, 3, 32, 32]), user_tr_label_tensor shape torch.Size([1000])\n",
      "user 7 tr len 1000, user_tr_data_tensor shape torch.Size([1000, 3, 32, 32]), user_tr_label_tensor shape torch.Size([1000])\n",
      "user 8 tr len 1000, user_tr_data_tensor shape torch.Size([1000, 3, 32, 32]), user_tr_label_tensor shape torch.Size([1000])\n",
      "user 9 tr len 1000, user_tr_data_tensor shape torch.Size([1000, 3, 32, 32]), user_tr_label_tensor shape torch.Size([1000])\n",
      "user 10 tr len 1000, user_tr_data_tensor shape torch.Size([1000, 3, 32, 32]), user_tr_label_tensor shape torch.Size([1000])\n",
      "user 11 tr len 1000, user_tr_data_tensor shape torch.Size([1000, 3, 32, 32]), user_tr_label_tensor shape torch.Size([1000])\n",
      "user 12 tr len 1000, user_tr_data_tensor shape torch.Size([1000, 3, 32, 32]), user_tr_label_tensor shape torch.Size([1000])\n",
      "user 13 tr len 1000, user_tr_data_tensor shape torch.Size([1000, 3, 32, 32]), user_tr_label_tensor shape torch.Size([1000])\n",
      "user 14 tr len 1000, user_tr_data_tensor shape torch.Size([1000, 3, 32, 32]), user_tr_label_tensor shape torch.Size([1000])\n",
      "user 15 tr len 1000, user_tr_data_tensor shape torch.Size([1000, 3, 32, 32]), user_tr_label_tensor shape torch.Size([1000])\n",
      "user 16 tr len 1000, user_tr_data_tensor shape torch.Size([1000, 3, 32, 32]), user_tr_label_tensor shape torch.Size([1000])\n",
      "user 17 tr len 1000, user_tr_data_tensor shape torch.Size([1000, 3, 32, 32]), user_tr_label_tensor shape torch.Size([1000])\n",
      "user 18 tr len 1000, user_tr_data_tensor shape torch.Size([1000, 3, 32, 32]), user_tr_label_tensor shape torch.Size([1000])\n",
      "user 19 tr len 1000, user_tr_data_tensor shape torch.Size([1000, 3, 32, 32]), user_tr_label_tensor shape torch.Size([1000])\n",
      "user 20 tr len 1000, user_tr_data_tensor shape torch.Size([1000, 3, 32, 32]), user_tr_label_tensor shape torch.Size([1000])\n",
      "user 21 tr len 1000, user_tr_data_tensor shape torch.Size([1000, 3, 32, 32]), user_tr_label_tensor shape torch.Size([1000])\n",
      "user 22 tr len 1000, user_tr_data_tensor shape torch.Size([1000, 3, 32, 32]), user_tr_label_tensor shape torch.Size([1000])\n",
      "user 23 tr len 1000, user_tr_data_tensor shape torch.Size([1000, 3, 32, 32]), user_tr_label_tensor shape torch.Size([1000])\n",
      "user 24 tr len 1000, user_tr_data_tensor shape torch.Size([1000, 3, 32, 32]), user_tr_label_tensor shape torch.Size([1000])\n",
      "user 25 tr len 1000, user_tr_data_tensor shape torch.Size([1000, 3, 32, 32]), user_tr_label_tensor shape torch.Size([1000])\n",
      "user 26 tr len 1000, user_tr_data_tensor shape torch.Size([1000, 3, 32, 32]), user_tr_label_tensor shape torch.Size([1000])\n",
      "user 27 tr len 1000, user_tr_data_tensor shape torch.Size([1000, 3, 32, 32]), user_tr_label_tensor shape torch.Size([1000])\n",
      "user 28 tr len 1000, user_tr_data_tensor shape torch.Size([1000, 3, 32, 32]), user_tr_label_tensor shape torch.Size([1000])\n",
      "user 29 tr len 1000, user_tr_data_tensor shape torch.Size([1000, 3, 32, 32]), user_tr_label_tensor shape torch.Size([1000])\n",
      "user 30 tr len 1000, user_tr_data_tensor shape torch.Size([1000, 3, 32, 32]), user_tr_label_tensor shape torch.Size([1000])\n",
      "user 31 tr len 1000, user_tr_data_tensor shape torch.Size([1000, 3, 32, 32]), user_tr_label_tensor shape torch.Size([1000])\n",
      "user 32 tr len 1000, user_tr_data_tensor shape torch.Size([1000, 3, 32, 32]), user_tr_label_tensor shape torch.Size([1000])\n",
      "user 33 tr len 1000, user_tr_data_tensor shape torch.Size([1000, 3, 32, 32]), user_tr_label_tensor shape torch.Size([1000])\n",
      "user 34 tr len 1000, user_tr_data_tensor shape torch.Size([1000, 3, 32, 32]), user_tr_label_tensor shape torch.Size([1000])\n",
      "user 35 tr len 1000, user_tr_data_tensor shape torch.Size([1000, 3, 32, 32]), user_tr_label_tensor shape torch.Size([1000])\n",
      "user 36 tr len 1000, user_tr_data_tensor shape torch.Size([1000, 3, 32, 32]), user_tr_label_tensor shape torch.Size([1000])\n",
      "user 37 tr len 1000, user_tr_data_tensor shape torch.Size([1000, 3, 32, 32]), user_tr_label_tensor shape torch.Size([1000])\n",
      "user 38 tr len 1000, user_tr_data_tensor shape torch.Size([1000, 3, 32, 32]), user_tr_label_tensor shape torch.Size([1000])\n",
      "user 39 tr len 1000, user_tr_data_tensor shape torch.Size([1000, 3, 32, 32]), user_tr_label_tensor shape torch.Size([1000])\n",
      "user 40 tr len 1000, user_tr_data_tensor shape torch.Size([1000, 3, 32, 32]), user_tr_label_tensor shape torch.Size([1000])\n",
      "user 41 tr len 1000, user_tr_data_tensor shape torch.Size([1000, 3, 32, 32]), user_tr_label_tensor shape torch.Size([1000])\n",
      "user 42 tr len 1000, user_tr_data_tensor shape torch.Size([1000, 3, 32, 32]), user_tr_label_tensor shape torch.Size([1000])\n",
      "user 43 tr len 1000, user_tr_data_tensor shape torch.Size([1000, 3, 32, 32]), user_tr_label_tensor shape torch.Size([1000])\n",
      "user 44 tr len 1000, user_tr_data_tensor shape torch.Size([1000, 3, 32, 32]), user_tr_label_tensor shape torch.Size([1000])\n",
      "user 45 tr len 1000, user_tr_data_tensor shape torch.Size([1000, 3, 32, 32]), user_tr_label_tensor shape torch.Size([1000])\n",
      "user 46 tr len 1000, user_tr_data_tensor shape torch.Size([1000, 3, 32, 32]), user_tr_label_tensor shape torch.Size([1000])\n",
      "user 47 tr len 1000, user_tr_data_tensor shape torch.Size([1000, 3, 32, 32]), user_tr_label_tensor shape torch.Size([1000])\n",
      "user 48 tr len 1000, user_tr_data_tensor shape torch.Size([1000, 3, 32, 32]), user_tr_label_tensor shape torch.Size([1000])\n",
      "user 49 tr len 1000, user_tr_data_tensor shape torch.Size([1000, 3, 32, 32]), user_tr_label_tensor shape torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "user_tr_data_tensors = []\n",
    "user_tr_label_tensors = []\n",
    "\n",
    "total_tr_data_copy = np.copy(total_tr_data)\n",
    "total_tr_label_copy = np.copy(total_tr_label)\n",
    "\n",
    "for i in range(nusers):\n",
    "    # Generate random indices to extract\n",
    "    random_indices = np.random.choice(len(total_tr_data_copy), user_tr_len, replace=False)\n",
    "    \n",
    "    user_tr_data_tensor = torch.from_numpy(total_tr_data_copy[random_indices]).type(torch.FloatTensor)\n",
    "    user_tr_label_tensor = torch.from_numpy(total_tr_label_copy[random_indices]).type(torch.FloatTensor)\n",
    "\n",
    "    total_tr_data_copy = np.delete(total_tr_data_copy, random_indices, axis=0)\n",
    "    total_tr_label_copy = np.delete(total_tr_label_copy, random_indices, axis=0)\n",
    "\n",
    "    user_tr_data_tensors.append(user_tr_data_tensor)\n",
    "    user_tr_label_tensors.append(user_tr_label_tensor)\n",
    "    print('user %d tr len %d, user_tr_data_tensor shape %s, user_tr_label_tensor shape %s'%(i,len(user_tr_data_tensor), user_tr_data_tensor.shape, user_tr_label_tensor.shape))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 3, 32, 32])\n",
      "torch.Size([1000])\n",
      "Number 0 occurs 92 times\n",
      "Number 1 occurs 113 times\n",
      "Number 2 occurs 89 times\n",
      "Number 3 occurs 99 times\n",
      "Number 4 occurs 108 times\n",
      "Number 5 occurs 106 times\n",
      "Number 6 occurs 113 times\n",
      "Number 7 occurs 86 times\n",
      "Number 8 occurs 115 times\n",
      "Number 9 occurs 79 times\n"
     ]
    }
   ],
   "source": [
    "print(user_tr_data_tensors[0].shape)\n",
    "print(user_tr_label_tensors[0].shape)\n",
    "\n",
    "tensor_int = user_tr_label_tensors[35].to(torch.int64)\n",
    "\n",
    "unique_numbers, counts = torch.unique(tensor_int, return_counts=True)\n",
    "\n",
    "for number, count in zip(unique_numbers, counts):\n",
    "    print(f\"Number {int(number)} occurs {int(count)} times\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
