{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The notebook contains\n",
    "### Code for _Bulyan_ aggregation algorithm, *when gradient updates of benign clients are unknown to adversary*\n",
    "### Evaluation of all of the attacks (Fang, LIE, and our SOTA AGR-tailored and AGR-agnstic) on Bulyan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse, os, sys, csv, shutil, time, random, operator, pickle, ast, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.optim import Optimizer\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import pickle\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torch.multiprocessing as mp\n",
    "import math\n",
    "sys.path.insert(0,'./../utils/')\n",
    "from logger import *\n",
    "from eval import *\n",
    "from misc import *\n",
    "\n",
    "from cifar10_normal_train import *\n",
    "from cifar10_util import *\n",
    "from adam import Adam\n",
    "from sgd import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get cifar10 data and split it in IID fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "data_loc='/mnt/nfs/work1/amir/vshejwalkar/cifar10_data/'\n",
    "# load the train dataset\n",
    "\n",
    "X={}\n",
    "Y=[]\n",
    "\n",
    "\n",
    "if os.path.isfile('./X.pkl') and os.path.isfile('./Y.pkl'):\n",
    "    X = pickle.load(open('./X.pkl','rb'))\n",
    "    Y = pickle.load(open('./Y.pkl','rb'))\n",
    "\n",
    "    val_data_tensor = pickle.load(open('./val_data_tensor.pkl','rb'))\n",
    "    val_label_tensor = pickle.load(open('./val_label_tensor.pkl','rb'))\n",
    "    te_data_tensor = pickle.load(open('./te_data_tensor.pkl','rb'))\n",
    "    te_label_tensor = pickle.load(open('./te_label_tensor.pkl','rb'))\n",
    "\n",
    "    total_tr_len = 50000\n",
    "\n",
    "else:\n",
    "    train_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "        ])\n",
    "\n",
    "    cifar10_train = datasets.CIFAR10(root=data_loc, train=True, download=True, transform=train_transform)\n",
    "\n",
    "    cifar10_test = datasets.CIFAR10(root=data_loc, train=False, download=True, transform=train_transform)\n",
    "\n",
    "    total_tr_len = len(cifar10_train)\n",
    "    total_test_len = len(cifar10_test)\n",
    "\n",
    "\n",
    "    for i in range(len(cifar10_train)):\n",
    "        data = cifar10_train[i][0].numpy()\n",
    "        label = cifar10_train[i][1]\n",
    "        \n",
    "        if label not in Y:\n",
    "            Y.append(label)\n",
    "            X[label] = []\n",
    "\n",
    "        X[label].append(data)\n",
    "\n",
    "    for label in Y:\n",
    "        X[label] = np.array(X[label])\n",
    "\n",
    "    # testing and validation set-up\n",
    "    X_TV = []\n",
    "    Y_TV = []\n",
    "\n",
    "    for i in range(len(cifar10_test)): \n",
    "        X_TV.append(cifar10_train[i][0].numpy())\n",
    "        Y_TV.append(cifar10_train[i][1])\n",
    "\n",
    "    val_data = X_TV[0:5000]    \n",
    "    val_label = Y_TV[0:5000] \n",
    "\n",
    "    te_data = X_TV[5000:]    \n",
    "    te_label = Y_TV[5000:] \n",
    "\n",
    "\n",
    "    val_data_tensor=torch.from_numpy(np.array(val_data)).type(torch.FloatTensor)\n",
    "    val_label_tensor=torch.from_numpy(np.array(val_label)).type(torch.LongTensor)\n",
    "\n",
    "    te_data_tensor=torch.from_numpy(np.array(te_data)).type(torch.FloatTensor)\n",
    "    te_label_tensor=torch.from_numpy(np.array(te_label)).type(torch.LongTensor)\n",
    "\n",
    "        \n",
    "    pickle.dump(X,open('./X.pkl','wb'))\n",
    "    pickle.dump(Y,open('./Y.pkl','wb'))\n",
    "    pickle.dump(val_data_tensor,open('./val_data_tensor.pkl','wb'))\n",
    "    pickle.dump(val_label_tensor,open('./val_label_tensor.pkl','wb'))\n",
    "    pickle.dump(te_data_tensor,open('./te_data_tensor.pkl','wb'))\n",
    "    pickle.dump(te_label_tensor,open('./te_label_tensor.pkl','wb'))\n",
    "\n",
    "\n",
    "# for i in range(len(cifar10_test)):\n",
    "#     X.append(cifar10_test[i][0].numpy())\n",
    "#     Y.append(cifar10_test[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nusers=50\n",
    "user_tr_len= total_tr_len // nusers\n",
    "val_len=5000\n",
    "te_len=5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide cifar10 data among 50 clients in Non-IID fashion using Dirichlet distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "user 0 tr len 1000\n",
      "user 1 tr len 1000\n",
      "user 2 tr len 1000\n",
      "user 3 tr len 1000\n",
      "user 4 tr len 1000\n",
      "user 5 tr len 1000\n",
      "user 6 tr len 1000\n",
      "user 7 tr len 1000\n",
      "user 8 tr len 1000\n",
      "user 9 tr len 1000\n",
      "user 10 tr len 1000\n",
      "user 11 tr len 1000\n",
      "user 12 tr len 1000\n",
      "user 13 tr len 1000\n",
      "user 14 tr len 1000\n",
      "user 15 tr len 1000\n",
      "user 16 tr len 1000\n",
      "user 17 tr len 1000\n",
      "user 18 tr len 1000\n",
      "user 19 tr len 1000\n",
      "user 20 tr len 1000\n",
      "user 21 tr len 1000\n",
      "user 22 tr len 1000\n",
      "user 23 tr len 1000\n",
      "user 24 tr len 1000\n",
      "user 25 tr len 1000\n",
      "user 26 tr len 1000\n",
      "user 27 tr len 1000\n",
      "user 28 tr len 1000\n",
      "user 29 tr len 1000\n",
      "user 30 tr len 1000\n",
      "user 31 tr len 1000\n",
      "user 32 tr len 1000\n",
      "user 33 tr len 1000\n",
      "user 34 tr len 1000\n",
      "user 35 tr len 1000\n",
      "user 36 tr len 1000\n",
      "user 37 tr len 1000\n",
      "user 38 tr len 1000\n",
      "user 39 tr len 1000\n",
      "user 40 tr len 1000\n",
      "user 41 tr len 1000\n",
      "user 42 tr len 1000\n",
      "user 43 tr len 1000\n",
      "user 44 tr len 1000\n",
      "user 45 tr len 1000\n",
      "user 46 tr len 1000\n",
      "user 47 tr len 1000\n",
      "user 48 tr len 1000\n",
      "user 49 tr len 1000\n"
     ]
    }
   ],
   "source": [
    "user_tr_data_tensors=[]\n",
    "user_tr_label_tensors=[]\n",
    "\n",
    "alpha = 20\n",
    "n_class = 10\n",
    "\n",
    "print()\n",
    "\n",
    "for i in range(nusers):\n",
    "    alpha_list = [alpha for _ in range(n_class)]\n",
    "    probs = np.random.dirichlet(alpha_list)\n",
    "    \n",
    "    user_tr_data_tensor=[]\n",
    "    user_tr_label_tensor=[]\n",
    "\n",
    "    for j in range(n_class):\n",
    "        n_pair = math.ceil(probs[j] * user_tr_len)\n",
    "\n",
    "        random_indices = np.random.choice(len(X[j]), n_pair, replace=False)\n",
    "        user_tr_data_tensor.extend(X[j][random_indices])\n",
    "        user_tr_label_tensor.extend([j] * n_pair)\n",
    "\n",
    "    user_tr_data_tensor = torch.from_numpy(np.array(user_tr_data_tensor[0:1000])).type(torch.FloatTensor)\n",
    "    user_tr_label_tensor = torch.from_numpy(np.array(user_tr_label_tensor[0:1000])).type(torch.FloatTensor)\n",
    "\n",
    "    user_tr_data_tensors.append(user_tr_data_tensor)\n",
    "    user_tr_label_tensors.append(user_tr_label_tensor)\n",
    "    print('user %d tr len %d'%(i,len(user_tr_data_tensor)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide cifar10 data among 50 clients in IID fashion using Dirichlet distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "total data len:  60000\n",
      "total data len:  60000\n",
      "total tr len 50000 | val len 5000 | test len 5000\n",
      "user 0 tr len 1000\n",
      "user 1 tr len 1000\n",
      "user 2 tr len 1000\n",
      "user 3 tr len 1000\n",
      "user 4 tr len 1000\n",
      "user 5 tr len 1000\n",
      "user 6 tr len 1000\n",
      "user 7 tr len 1000\n",
      "user 8 tr len 1000\n",
      "user 9 tr len 1000\n",
      "user 10 tr len 1000\n",
      "user 11 tr len 1000\n",
      "user 12 tr len 1000\n",
      "user 13 tr len 1000\n",
      "user 14 tr len 1000\n",
      "user 15 tr len 1000\n",
      "user 16 tr len 1000\n",
      "user 17 tr len 1000\n",
      "user 18 tr len 1000\n",
      "user 19 tr len 1000\n",
      "user 20 tr len 1000\n",
      "user 21 tr len 1000\n",
      "user 22 tr len 1000\n",
      "user 23 tr len 1000\n",
      "user 24 tr len 1000\n",
      "user 25 tr len 1000\n",
      "user 26 tr len 1000\n",
      "user 27 tr len 1000\n",
      "user 28 tr len 1000\n",
      "user 29 tr len 1000\n",
      "user 30 tr len 1000\n",
      "user 31 tr len 1000\n",
      "user 32 tr len 1000\n",
      "user 33 tr len 1000\n",
      "user 34 tr len 1000\n",
      "user 35 tr len 1000\n",
      "user 36 tr len 1000\n",
      "user 37 tr len 1000\n",
      "user 38 tr len 1000\n",
      "user 39 tr len 1000\n",
      "user 40 tr len 1000\n",
      "user 41 tr len 1000\n",
      "user 42 tr len 1000\n",
      "user 43 tr len 1000\n",
      "user 44 tr len 1000\n",
      "user 45 tr len 1000\n",
      "user 46 tr len 1000\n",
      "user 47 tr len 1000\n",
      "user 48 tr len 1000\n",
      "user 49 tr len 1000\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "data_loc='/mnt/nfs/work1/amir/vshejwalkar/cifar10_data/'\n",
    "# load the train dataset\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "\n",
    "cifar10_train = datasets.CIFAR10(root=data_loc, train=True, download=True, transform=train_transform)\n",
    "\n",
    "cifar10_test = datasets.CIFAR10(root=data_loc, train=False, download=True, transform=train_transform)\n",
    "\n",
    "X=[]\n",
    "Y=[]\n",
    "for i in range(len(cifar10_train)):\n",
    "    X.append(cifar10_train[i][0].numpy())\n",
    "    Y.append(cifar10_train[i][1])\n",
    "\n",
    "for i in range(len(cifar10_test)):\n",
    "    X.append(cifar10_test[i][0].numpy())\n",
    "    Y.append(cifar10_test[i][1])\n",
    "\n",
    "X=np.array(X)\n",
    "Y=np.array(Y)\n",
    "\n",
    "print('total data len: ',len(X))\n",
    "\n",
    "\n",
    "all_indices = np.arange(len(X))\n",
    "np.random.shuffle(all_indices)\n",
    "pickle.dump(all_indices,open('./cifar10_shuffle.pkl','wb'))\n",
    "\n",
    "\n",
    "X=X[all_indices]\n",
    "Y=Y[all_indices]\n",
    "\n",
    "# data loading\n",
    "\n",
    "nusers=50\n",
    "user_tr_len=1000\n",
    "\n",
    "total_tr_len=user_tr_len*nusers\n",
    "val_len=5000\n",
    "te_len=5000\n",
    "\n",
    "print('total data len: ',len(X))\n",
    "\n",
    "if not os.path.isfile('./cifar10_shuffle.pkl'):\n",
    "    all_indices = np.arange(len(X))\n",
    "    np.random.shuffle(all_indices)\n",
    "    pickle.dump(all_indices,open('./cifar10_shuffle.pkl','wb'))\n",
    "else:\n",
    "    all_indices=pickle.load(open('./cifar10_shuffle.pkl','rb'))\n",
    "\n",
    "total_tr_data=X[:total_tr_len]\n",
    "total_tr_label=Y[:total_tr_len]\n",
    "\n",
    "val_data=X[total_tr_len:(total_tr_len+val_len)]\n",
    "val_label=Y[total_tr_len:(total_tr_len+val_len)]\n",
    "\n",
    "te_data=X[(total_tr_len+val_len):(total_tr_len+val_len+te_len)]\n",
    "te_label=Y[(total_tr_len+val_len):(total_tr_len+val_len+te_len)]\n",
    "\n",
    "total_tr_data_tensor=torch.from_numpy(total_tr_data).type(torch.FloatTensor)\n",
    "total_tr_label_tensor=torch.from_numpy(total_tr_label).type(torch.LongTensor)\n",
    "\n",
    "val_data_tensor=torch.from_numpy(val_data).type(torch.FloatTensor)\n",
    "val_label_tensor=torch.from_numpy(val_label).type(torch.LongTensor)\n",
    "\n",
    "te_data_tensor=torch.from_numpy(te_data).type(torch.FloatTensor)\n",
    "te_label_tensor=torch.from_numpy(te_label).type(torch.LongTensor)\n",
    "\n",
    "print('total tr len %d | val len %d | test len %d'%(len(total_tr_data_tensor),len(val_data_tensor),len(te_data_tensor)))\n",
    "\n",
    "#==============================================================================================================\n",
    "\n",
    "user_tr_data_tensors=[]\n",
    "user_tr_label_tensors=[]\n",
    "\n",
    "for i in range(nusers):\n",
    "    \n",
    "    user_tr_data_tensor=torch.from_numpy(total_tr_data[user_tr_len*i:user_tr_len*(i+1)]).type(torch.FloatTensor)\n",
    "    user_tr_label_tensor=torch.from_numpy(total_tr_label[user_tr_len*i:user_tr_len*(i+1)]).type(torch.LongTensor)\n",
    "\n",
    "    user_tr_data_tensors.append(user_tr_data_tensor)\n",
    "    user_tr_label_tensors.append(user_tr_label_tensor)\n",
    "    print('user %d tr len %d'%(i,len(user_tr_data_tensor)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for Multi-krum aggregation algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_krum(all_updates, n_attackers, multi_k=False):\n",
    "    print(\"all_updates.shape: \", all_updates.shape)\n",
    "    candidates = []\n",
    "    candidate_indices = []\n",
    "    remaining_updates = all_updates\n",
    "    all_indices = np.arange(len(all_updates))\n",
    "\n",
    "    while len(remaining_updates) > 2 * n_attackers + 2:\n",
    "        torch.cuda.empty_cache()\n",
    "        distances = []\n",
    "        for update in remaining_updates:\n",
    "            distance = []\n",
    "            for update_ in remaining_updates:\n",
    "                distance.append(torch.norm((update - update_)) ** 2)\n",
    "            distance = torch.Tensor(distance).float()\n",
    "            distances = distance[None, :] if not len(distances) else torch.cat((distances, distance[None, :]), 0)\n",
    "\n",
    "        distances = torch.sort(distances, dim=1)[0]\n",
    "        scores = torch.sum(distances[:, :len(remaining_updates) - 2 - n_attackers], dim=1)\n",
    "        indices = torch.argsort(scores)[:len(remaining_updates) - 2 - n_attackers]\n",
    "\n",
    "        candidate_indices.append(all_indices[indices[0].cpu().numpy()])\n",
    "        all_indices = np.delete(all_indices, indices[0].cpu().numpy())\n",
    "        candidates = remaining_updates[indices[0]][None, :] if not len(candidates) else torch.cat((candidates, remaining_updates[indices[0]][None, :]), 0)\n",
    "        remaining_updates = torch.cat((remaining_updates[:indices[0]], remaining_updates[indices[0] + 1:]), 0)\n",
    "        if not multi_k:\n",
    "            break\n",
    "    print(\"candidates\", len(candidates))\n",
    "\n",
    "    aggregate = torch.mean(candidates, dim=0)\n",
    "\n",
    "    return aggregate, np.array(candidate_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for Bulyan aggregation algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bulyan(all_updates, n_attackers):\n",
    "    nusers = all_updates.shape[0]\n",
    "    bulyan_cluster = []\n",
    "    candidate_indices = []\n",
    "    remaining_updates = all_updates\n",
    "    all_indices = np.arange(len(all_updates))\n",
    "\n",
    "    while len(bulyan_cluster) < (nusers - 2 * n_attackers):\n",
    "        torch.cuda.empty_cache()\n",
    "        distances = []\n",
    "        for update in remaining_updates:\n",
    "            distance = []\n",
    "            for update_ in remaining_updates:\n",
    "                distance.append(torch.norm((update - update_)) ** 2)\n",
    "            distance = torch.Tensor(distance).float()\n",
    "            distances = distance[None, :] if not len(distances) else torch.cat((distances, distance[None, :]), 0)\n",
    "        # print(distances)\n",
    "\n",
    "        distances = torch.sort(distances, dim=1)[0]\n",
    "\n",
    "        scores = torch.sum(distances[:, :len(remaining_updates) - 2 - n_attackers], dim=1)\n",
    "        indices = torch.argsort(scores)[:len(remaining_updates) - 2 - n_attackers]\n",
    "        if not len(indices):\n",
    "            break\n",
    "        candidate_indices.append(all_indices[indices[0].cpu().numpy()])\n",
    "        all_indices = np.delete(all_indices, indices[0].cpu().numpy())\n",
    "        bulyan_cluster = remaining_updates[indices[0]][None, :] if not len(bulyan_cluster) else torch.cat((bulyan_cluster, remaining_updates[indices[0]][None, :]), 0)\n",
    "        remaining_updates = torch.cat((remaining_updates[:indices[0]], remaining_updates[indices[0] + 1:]), 0)\n",
    "\n",
    "    # print('dim of bulyan cluster ', bulyan_cluster.shape)\n",
    "\n",
    "    n, d = bulyan_cluster.shape\n",
    "    param_med = torch.median(bulyan_cluster, dim=0)[0]\n",
    "    sort_idx = torch.argsort(torch.abs(bulyan_cluster - param_med), dim=0)\n",
    "    sorted_params = bulyan_cluster[sort_idx, torch.arange(d)[None, :]]\n",
    "\n",
    "    return torch.mean(sorted_params[:n - 2 * n_attackers], dim=0), np.array(candidate_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for our AGR-tailored attack on Bulyan\n",
    "* Note that our attacks on multi-krum and Bulyan aggregations are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def our_attack_mkrum(all_updates, model_re, n_attackers, dev_type='unit_vec'):\n",
    "\n",
    "    if dev_type == 'unit_vec':\n",
    "        deviation = model_re / torch.norm(model_re)\n",
    "    elif dev_type == 'sign':\n",
    "        deviation = torch.sign(model_re)\n",
    "    elif dev_type == 'std':\n",
    "        deviation = torch.std(all_updates, 0)\n",
    "\n",
    "    lamda = torch.Tensor([3.0]).cuda()\n",
    "\n",
    "    threshold_diff = 1e-5\n",
    "    lamda_fail = lamda\n",
    "    lamda_succ = 0\n",
    "\n",
    "    while torch.abs(lamda_succ - lamda) > threshold_diff:\n",
    "        mal_update = (model_re - lamda * deviation)\n",
    "        mal_updates = torch.stack([mal_update] * n_attackers)\n",
    "        print(\"mal_updates1: \",mal_updates.shape)\n",
    "        mal_updates = torch.cat((mal_updates, all_updates), 0)\n",
    "        print(\"mal_updates12: \",mal_updates.shape)\n",
    "        agg_grads, krum_candidate = multi_krum(mal_updates, n_attackers, multi_k=True)\n",
    "        if np.sum(krum_candidate < n_attackers) == n_attackers:\n",
    "            # print('successful lamda is ', lamda)\n",
    "            lamda_succ = lamda\n",
    "            lamda = lamda + lamda_fail / 2\n",
    "        else:\n",
    "            lamda = lamda - lamda_fail / 2\n",
    "\n",
    "        lamda_fail = lamda_fail / 2\n",
    "\n",
    "    mal_update = (model_re - lamda_succ * deviation)\n",
    "    print(mal_update.shape)\n",
    "    return mal_update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute our AGR-tailored attack on Bulyan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_attacker <class 'int'>\n",
      "n_attacker_ <class 'int'>\n",
      "mal_updates1:  torch.Size([2, 2472266])\n",
      "mal_updates12:  torch.Size([12, 2472266])\n",
      "all_updates.shape:  torch.Size([12, 2472266])\n",
      "candidates 6\n",
      "mal_updates1:  torch.Size([2, 2472266])\n",
      "mal_updates12:  torch.Size([12, 2472266])\n",
      "all_updates.shape:  torch.Size([12, 2472266])\n",
      "candidates 6\n",
      "mal_updates1:  torch.Size([2, 2472266])\n",
      "mal_updates12:  torch.Size([12, 2472266])\n",
      "all_updates.shape:  torch.Size([12, 2472266])\n",
      "candidates 6\n",
      "mal_updates1:  torch.Size([2, 2472266])\n",
      "mal_updates12:  torch.Size([12, 2472266])\n",
      "all_updates.shape:  torch.Size([12, 2472266])\n",
      "candidates 6\n",
      "mal_updates1:  torch.Size([2, 2472266])\n",
      "mal_updates12:  torch.Size([12, 2472266])\n",
      "all_updates.shape:  torch.Size([12, 2472266])\n",
      "candidates 6\n",
      "mal_updates1:  torch.Size([2, 2472266])\n",
      "mal_updates12:  torch.Size([12, 2472266])\n",
      "all_updates.shape:  torch.Size([12, 2472266])\n",
      "candidates 6\n",
      "mal_updates1:  torch.Size([2, 2472266])\n",
      "mal_updates12:  torch.Size([12, 2472266])\n",
      "all_updates.shape:  torch.Size([12, 2472266])\n",
      "candidates 6\n",
      "mal_updates1:  torch.Size([2, 2472266])\n",
      "mal_updates12:  torch.Size([12, 2472266])\n",
      "all_updates.shape:  torch.Size([12, 2472266])\n",
      "candidates 6\n",
      "mal_updates1:  torch.Size([2, 2472266])\n",
      "mal_updates12:  torch.Size([12, 2472266])\n",
      "all_updates.shape:  torch.Size([12, 2472266])\n",
      "candidates 6\n",
      "mal_updates1:  torch.Size([2, 2472266])\n",
      "mal_updates12:  torch.Size([12, 2472266])\n",
      "all_updates.shape:  torch.Size([12, 2472266])\n",
      "candidates 6\n",
      "mal_updates1:  torch.Size([2, 2472266])\n",
      "mal_updates12:  torch.Size([12, 2472266])\n",
      "all_updates.shape:  torch.Size([12, 2472266])\n",
      "candidates 6\n",
      "mal_updates1:  torch.Size([2, 2472266])\n",
      "mal_updates12:  torch.Size([12, 2472266])\n",
      "all_updates.shape:  torch.Size([12, 2472266])\n",
      "candidates 6\n",
      "mal_updates1:  torch.Size([2, 2472266])\n",
      "mal_updates12:  torch.Size([12, 2472266])\n",
      "all_updates.shape:  torch.Size([12, 2472266])\n",
      "candidates 6\n",
      "mal_updates1:  torch.Size([2, 2472266])\n",
      "mal_updates12:  torch.Size([12, 2472266])\n",
      "all_updates.shape:  torch.Size([12, 2472266])\n",
      "candidates 6\n",
      "mal_updates1:  torch.Size([2, 2472266])\n",
      "mal_updates12:  torch.Size([12, 2472266])\n",
      "all_updates.shape:  torch.Size([12, 2472266])\n",
      "candidates 6\n",
      "mal_updates1:  torch.Size([2, 2472266])\n",
      "mal_updates12:  torch.Size([12, 2472266])\n",
      "all_updates.shape:  torch.Size([12, 2472266])\n",
      "candidates 6\n",
      "mal_updates1:  torch.Size([2, 2472266])\n",
      "mal_updates12:  torch.Size([12, 2472266])\n",
      "all_updates.shape:  torch.Size([12, 2472266])\n",
      "candidates 6\n",
      "mal_updates1:  torch.Size([2, 2472266])\n",
      "mal_updates12:  torch.Size([12, 2472266])\n",
      "all_updates.shape:  torch.Size([12, 2472266])\n",
      "candidates 6\n",
      "mal_updates1:  torch.Size([2, 2472266])\n",
      "mal_updates12:  torch.Size([12, 2472266])\n",
      "all_updates.shape:  torch.Size([12, 2472266])\n",
      "candidates 6\n",
      "torch.Size([2472266])\n",
      "mal_updates1:  torch.Size([2, 2472266])\n",
      "mal_updates12:  torch.Size([12, 2472266])\n",
      "all_updates.shape:  torch.Size([12, 2472266])\n",
      "candidates 6\n",
      "mal_updates1:  torch.Size([2, 2472266])\n",
      "mal_updates12:  torch.Size([12, 2472266])\n",
      "all_updates.shape:  torch.Size([12, 2472266])\n",
      "candidates 6\n",
      "mal_updates1:  torch.Size([2, 2472266])\n",
      "mal_updates12:  torch.Size([12, 2472266])\n",
      "all_updates.shape:  torch.Size([12, 2472266])\n",
      "candidates 6\n",
      "mal_updates1:  torch.Size([2, 2472266])\n",
      "mal_updates12:  torch.Size([12, 2472266])\n",
      "all_updates.shape:  torch.Size([12, 2472266])\n",
      "candidates 6\n",
      "mal_updates1:  torch.Size([2, 2472266])\n",
      "mal_updates12:  torch.Size([12, 2472266])\n",
      "all_updates.shape:  torch.Size([12, 2472266])\n",
      "candidates 6\n",
      "mal_updates1:  torch.Size([2, 2472266])\n",
      "mal_updates12:  torch.Size([12, 2472266])\n",
      "all_updates.shape:  torch.Size([12, 2472266])\n",
      "candidates 6\n",
      "mal_updates1:  torch.Size([2, 2472266])\n",
      "mal_updates12:  torch.Size([12, 2472266])\n",
      "all_updates.shape:  torch.Size([12, 2472266])\n",
      "candidates 6\n",
      "mal_updates1:  torch.Size([2, 2472266])\n",
      "mal_updates12:  torch.Size([12, 2472266])\n",
      "all_updates.shape:  torch.Size([12, 2472266])\n",
      "candidates 6\n",
      "mal_updates1:  torch.Size([2, 2472266])\n",
      "mal_updates12:  torch.Size([12, 2472266])\n",
      "all_updates.shape:  torch.Size([12, 2472266])\n",
      "candidates 6\n",
      "mal_updates1:  torch.Size([2, 2472266])\n",
      "mal_updates12:  torch.Size([12, 2472266])\n",
      "all_updates.shape:  torch.Size([12, 2472266])\n",
      "candidates 6\n",
      "mal_updates1:  torch.Size([2, 2472266])\n",
      "mal_updates12:  torch.Size([12, 2472266])\n",
      "all_updates.shape:  torch.Size([12, 2472266])\n",
      "candidates 6\n",
      "mal_updates1:  torch.Size([2, 2472266])\n",
      "mal_updates12:  torch.Size([12, 2472266])\n",
      "all_updates.shape:  torch.Size([12, 2472266])\n",
      "candidates 6\n",
      "mal_updates1:  torch.Size([2, 2472266])\n",
      "mal_updates12:  torch.Size([12, 2472266])\n",
      "all_updates.shape:  torch.Size([12, 2472266])\n",
      "candidates 6\n",
      "mal_updates1:  torch.Size([2, 2472266])\n",
      "mal_updates12:  torch.Size([12, 2472266])\n",
      "all_updates.shape:  torch.Size([12, 2472266])\n",
      "candidates 6\n",
      "mal_updates1:  torch.Size([2, 2472266])\n",
      "mal_updates12:  torch.Size([12, 2472266])\n",
      "all_updates.shape:  torch.Size([12, 2472266])\n",
      "candidates 6\n",
      "mal_updates1:  torch.Size([2, 2472266])\n",
      "mal_updates12:  torch.Size([12, 2472266])\n",
      "all_updates.shape:  torch.Size([12, 2472266])\n",
      "candidates 6\n",
      "mal_updates1:  torch.Size([2, 2472266])\n",
      "mal_updates12:  torch.Size([12, 2472266])\n",
      "all_updates.shape:  torch.Size([12, 2472266])\n",
      "candidates 6\n",
      "mal_updates1:  torch.Size([2, 2472266])\n",
      "mal_updates12:  torch.Size([12, 2472266])\n",
      "all_updates.shape:  torch.Size([12, 2472266])\n",
      "candidates 6\n",
      "mal_updates1:  torch.Size([2, 2472266])\n",
      "mal_updates12:  torch.Size([12, 2472266])\n",
      "all_updates.shape:  torch.Size([12, 2472266])\n",
      "candidates 6\n",
      "torch.Size([2472266])\n",
      "tensor([-5.4761e-05, -8.1055e-05, -8.5149e-05,  ..., -2.0098e-02,\n",
      "        -1.5086e-02, -3.1792e-02], device='cuda:0')\n",
      "tensor([-5.4761e-05, -8.1055e-05, -8.5149e-05,  ..., -2.0098e-02,\n",
      "        -1.5086e-02, -3.1792e-02], device='cuda:0')\n",
      "True\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "batch_size=250\n",
    "resume=0\n",
    "\n",
    "nepochs=10\n",
    "schedule=[1000]\n",
    "nbatches = user_tr_len//batch_size\n",
    "\n",
    "gamma=.5\n",
    "opt = 'sgd'\n",
    "fed_lr=0.5\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "aggregation='bulyan'\n",
    "multi_k = False\n",
    "candidates = []\n",
    "\n",
    "at_type='our-agr'\n",
    "dev_type ='std'\n",
    "n_attackers=[10]\n",
    "\n",
    "arch='alexnet'\n",
    "chkpt='./'+aggregation\n",
    "\n",
    "past_mean = []\n",
    "past_abs_sum = []\n",
    "past_median = []\n",
    "past_lower_quartile = []\n",
    "past_upper_quartile = []\n",
    "past_std = []\n",
    "\n",
    "\n",
    "for n_attacker in n_attackers:\n",
    "    epoch_num = 0\n",
    "    best_global_acc = 0\n",
    "    best_global_te_acc = 0\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    r=np.arange(user_tr_len)\n",
    "\n",
    "    fed_model, _ = return_model(arch, 0.1, 0.9, parallel=False)\n",
    "    optimizer_fed = SGD(fed_model.parameters(), lr=fed_lr)\n",
    "\n",
    "    while epoch_num <= nepochs:\n",
    "        user_grads=[]\n",
    "        if not epoch_num and epoch_num%nbatches == 0:\n",
    "            np.random.shuffle(r)\n",
    "            for i in range(nusers):\n",
    "                user_tr_data_tensors[i]=user_tr_data_tensors[i][r]\n",
    "                user_tr_label_tensors[i]=user_tr_label_tensors[i][r]\n",
    "\n",
    "        for i in range(nusers): # 50\n",
    "\n",
    "            inputs = user_tr_data_tensors[i][(epoch_num%nbatches)*batch_size:((epoch_num%nbatches) + 1) * batch_size]\n",
    "            targets = user_tr_label_tensors[i][(epoch_num%nbatches)*batch_size:((epoch_num%nbatches) + 1) * batch_size]\n",
    "            targets = targets.type(torch.LongTensor)   \n",
    "            \n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "\n",
    "            outputs = fed_model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            fed_model.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "\n",
    "            param_grad=[]\n",
    "            for param in fed_model.parameters():\n",
    "                param_grad=param.grad.data.view(-1) if not len(param_grad) else torch.cat((param_grad,param.grad.view(-1)))\n",
    "\n",
    "            user_grads=param_grad[None, :] if len(user_grads)==0 else torch.cat((user_grads,param_grad[None,:]), 0)\n",
    "\n",
    "        if epoch_num in schedule:\n",
    "            for param_group in optimizer_fed.param_groups:\n",
    "                param_group['lr'] *= gamma\n",
    "                print('New learnin rate ', param_group['lr'])\n",
    "       \n",
    "        if n_attacker > 0:\n",
    "            print(\"n_attacker\", type(n_attacker))\n",
    "            n_attacker_ = max(1, n_attacker**2//nusers)\n",
    "            print(\"n_attacker_\", type(n_attacker_))\n",
    "\n",
    "            agg_grads = torch.mean(user_grads[:n_attacker], 0)\n",
    "\n",
    "            mal_update = our_attack_mkrum(user_grads[:n_attacker], agg_grads, n_attacker_, dev_type)\n",
    "\n",
    "            mal_updates = torch.stack([mal_update] * n_attacker) # n_attacker, should be 10 in this case\n",
    "            # print(\"mal_updates: \", mal_updates.shape) # torch.Size([10, 2472266])\n",
    "\n",
    "            malicious_grads = torch.cat((mal_updates, user_grads[n_attacker:]), 0) # 50\n",
    "            #print(malicious_grads.shape) # torch.Size([50, 2472266])\n",
    "            \n",
    "        if not (malicious_grads.shape[0]==50):\n",
    "            print(malicious_grads.shape)\n",
    "            sys.exit()\n",
    "        \n",
    "        # Store history of malicious_grads\n",
    "        average_tensor = malicious_grads.mean(dim=1, keepdim=True)\n",
    "        median_tensor = malicious_grads.median(dim=1, keepdim=True).values\n",
    "        lower_quartile = malicious_grads.quantile(0.25, dim=1, keepdim=True)\n",
    "        upper_quartile = malicious_grads.quantile(0.75, dim=1, keepdim=True)\n",
    "        std = malicious_grads.std(dim=1, keepdim=True)\n",
    "\n",
    "        mean_abs_tensor = malicious_grads.abs().sum(dim=1, keepdim=True)\n",
    "\n",
    "        past_abs_sum.append(mean_abs_tensor)\n",
    "        past_mean.append(average_tensor)\n",
    "        past_median.append(median_tensor)\n",
    "        past_lower_quartile.append(lower_quartile)\n",
    "        past_upper_quartile.append(upper_quartile)\n",
    "        past_std.append(std)\n",
    "\n",
    "\n",
    "        pickle.dump(past_abs_sum,open('./past_abs_sum.pkl','wb'))\n",
    "        pickle.dump(past_mean,open('./past_mean.pkl','wb'))\n",
    "        pickle.dump(past_median,open('./past_median.pkl','wb'))\n",
    "        pickle.dump(past_lower_quartile,open('./past_lower_quartile.pkl','wb'))\n",
    "        pickle.dump(past_upper_quartile,open('./past_upper_quartile.pkl','wb'))\n",
    "        pickle.dump(past_std,open('./past_std.pkl','wb'))\n",
    "\n",
    "        agg_grads, krum_candidate=bulyan(malicious_grads, n_attacker)\n",
    "\n",
    "        del user_grads\n",
    "\n",
    "        start_idx=0\n",
    "\n",
    "        optimizer_fed.zero_grad()\n",
    "\n",
    "        model_grads=[]\n",
    "\n",
    "        for i, param in enumerate(fed_model.parameters()):\n",
    "            param_=agg_grads[start_idx:start_idx+len(param.data.view(-1))].reshape(param.data.shape)\n",
    "            start_idx=start_idx+len(param.data.view(-1))\n",
    "            param_=param_.cuda()\n",
    "            model_grads.append(param_)\n",
    "\n",
    "        optimizer_fed.step(model_grads)\n",
    "\n",
    "        val_loss, val_acc = test(val_data_tensor,val_label_tensor,fed_model,criterion,use_cuda)\n",
    "        te_loss, te_acc = test(te_data_tensor,te_label_tensor, fed_model, criterion, use_cuda)\n",
    "\n",
    "        is_best = best_global_acc < val_acc\n",
    "\n",
    "        best_global_acc = max(best_global_acc, val_acc)\n",
    "\n",
    "        if is_best:\n",
    "            best_global_te_acc = te_acc\n",
    "\n",
    "        \n",
    "        print('epoch: %d, %s: at %s n_at %d n_mal_sel %d e %d | val loss %.4f val acc %.4f best val_acc %f'%(epoch_num, aggregation, at_type, n_attacker, np.sum(krum_candidate < n_attacker), epoch_num, val_loss, val_acc, best_global_acc))\n",
    "\n",
    "        if val_loss > 1000:\n",
    "            print('val loss %f too high'%val_loss)\n",
    "            break\n",
    "            \n",
    "        epoch_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[38.9730],\n",
      "        [38.9730],\n",
      "        [38.9730],\n",
      "        [38.9730],\n",
      "        [38.9730],\n",
      "        [38.9730],\n",
      "        [38.9730],\n",
      "        [38.9730],\n",
      "        [38.9730],\n",
      "        [38.9730],\n",
      "        [45.4803],\n",
      "        [44.6632],\n",
      "        [44.6549],\n",
      "        [44.2263],\n",
      "        [39.9464],\n",
      "        [38.1650],\n",
      "        [39.4315],\n",
      "        [40.9062],\n",
      "        [45.6001],\n",
      "        [38.3392],\n",
      "        [41.4701],\n",
      "        [40.2229],\n",
      "        [38.2768],\n",
      "        [44.2748],\n",
      "        [47.1865],\n",
      "        [47.1374],\n",
      "        [37.5192],\n",
      "        [35.2523],\n",
      "        [38.5023],\n",
      "        [43.3160],\n",
      "        [39.7284],\n",
      "        [42.1207],\n",
      "        [42.0800],\n",
      "        [36.7836],\n",
      "        [40.3979],\n",
      "        [41.0033],\n",
      "        [40.6315],\n",
      "        [41.0031],\n",
      "        [42.2689],\n",
      "        [39.5169],\n",
      "        [45.5636],\n",
      "        [39.1285],\n",
      "        [44.1024],\n",
      "        [39.8568],\n",
      "        [46.9433],\n",
      "        [37.5227],\n",
      "        [37.1470],\n",
      "        [40.5368],\n",
      "        [42.5046],\n",
      "        [39.5056]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# past_mean = []\n",
    "# past_abs_sum = []\n",
    "# past_median = []\n",
    "# past_lower_quartile = []\n",
    "# past_upper_quartile = []\n",
    "# past_std = []\n",
    "\n",
    "print(past_abs_sum[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50, 1]),\n",
       " [tensor([[-4.8672e-06],\n",
       "          [-4.8672e-06],\n",
       "          [-4.8672e-06],\n",
       "          [-4.8672e-06],\n",
       "          [-4.8672e-06],\n",
       "          [-4.8672e-06],\n",
       "          [-4.8672e-06],\n",
       "          [-4.8672e-06],\n",
       "          [-4.8672e-06],\n",
       "          [-4.8672e-06],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00]], device='cuda:0'),\n",
       "  tensor([[-5.1359e-06],\n",
       "          [-5.1359e-06],\n",
       "          [-5.1359e-06],\n",
       "          [-5.1359e-06],\n",
       "          [-5.1359e-06],\n",
       "          [-5.1359e-06],\n",
       "          [-5.1359e-06],\n",
       "          [-5.1359e-06],\n",
       "          [-5.1359e-06],\n",
       "          [-5.1359e-06],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00]], device='cuda:0'),\n",
       "  tensor([[-6.4831e-06],\n",
       "          [-6.4831e-06],\n",
       "          [-6.4831e-06],\n",
       "          [-6.4831e-06],\n",
       "          [-6.4831e-06],\n",
       "          [-6.4831e-06],\n",
       "          [-6.4831e-06],\n",
       "          [-6.4831e-06],\n",
       "          [-6.4831e-06],\n",
       "          [-6.4831e-06],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00]], device='cuda:0'),\n",
       "  tensor([[-7.4622e-06],\n",
       "          [-7.4622e-06],\n",
       "          [-7.4622e-06],\n",
       "          [-7.4622e-06],\n",
       "          [-7.4622e-06],\n",
       "          [-7.4622e-06],\n",
       "          [-7.4622e-06],\n",
       "          [-7.4622e-06],\n",
       "          [-7.4622e-06],\n",
       "          [-7.4622e-06],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00]], device='cuda:0'),\n",
       "  tensor([[-6.8625e-06],\n",
       "          [-6.8625e-06],\n",
       "          [-6.8625e-06],\n",
       "          [-6.8625e-06],\n",
       "          [-6.8625e-06],\n",
       "          [-6.8625e-06],\n",
       "          [-6.8625e-06],\n",
       "          [-6.8625e-06],\n",
       "          [-6.8625e-06],\n",
       "          [-6.8625e-06],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00]], device='cuda:0'),\n",
       "  tensor([[-6.9808e-06],\n",
       "          [-6.9808e-06],\n",
       "          [-6.9808e-06],\n",
       "          [-6.9808e-06],\n",
       "          [-6.9808e-06],\n",
       "          [-6.9808e-06],\n",
       "          [-6.9808e-06],\n",
       "          [-6.9808e-06],\n",
       "          [-6.9808e-06],\n",
       "          [-6.9808e-06],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00]], device='cuda:0'),\n",
       "  tensor([[-8.6318e-06],\n",
       "          [-8.6318e-06],\n",
       "          [-8.6318e-06],\n",
       "          [-8.6318e-06],\n",
       "          [-8.6318e-06],\n",
       "          [-8.6318e-06],\n",
       "          [-8.6318e-06],\n",
       "          [-8.6318e-06],\n",
       "          [-8.6318e-06],\n",
       "          [-8.6318e-06],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00]], device='cuda:0'),\n",
       "  tensor([[-9.7550e-06],\n",
       "          [-9.7550e-06],\n",
       "          [-9.7550e-06],\n",
       "          [-9.7550e-06],\n",
       "          [-9.7550e-06],\n",
       "          [-9.7550e-06],\n",
       "          [-9.7550e-06],\n",
       "          [-9.7550e-06],\n",
       "          [-9.7550e-06],\n",
       "          [-9.7550e-06],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00]], device='cuda:0'),\n",
       "  tensor([[-9.5675e-06],\n",
       "          [-9.5675e-06],\n",
       "          [-9.5675e-06],\n",
       "          [-9.5675e-06],\n",
       "          [-9.5675e-06],\n",
       "          [-9.5675e-06],\n",
       "          [-9.5675e-06],\n",
       "          [-9.5675e-06],\n",
       "          [-9.5675e-06],\n",
       "          [-9.5675e-06],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00]], device='cuda:0'),\n",
       "  tensor([[-9.0270e-06],\n",
       "          [-9.0270e-06],\n",
       "          [-9.0270e-06],\n",
       "          [-9.0270e-06],\n",
       "          [-9.0270e-06],\n",
       "          [-9.0270e-06],\n",
       "          [-9.0270e-06],\n",
       "          [-9.0270e-06],\n",
       "          [-9.0270e-06],\n",
       "          [-9.0270e-06],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00]], device='cuda:0'),\n",
       "  tensor([[-1.1818e-05],\n",
       "          [-1.1818e-05],\n",
       "          [-1.1818e-05],\n",
       "          [-1.1818e-05],\n",
       "          [-1.1818e-05],\n",
       "          [-1.1818e-05],\n",
       "          [-1.1818e-05],\n",
       "          [-1.1818e-05],\n",
       "          [-1.1818e-05],\n",
       "          [-1.1818e-05],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00]], device='cuda:0')])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "past_median[3].shape, past_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
