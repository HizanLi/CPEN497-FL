{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse, os, sys, csv, shutil, time, random, operator, pickle, ast, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.optim import Optimizer\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import pickle\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torch.multiprocessing as mp\n",
    "import math\n",
    "sys.path.insert(0,'./../utils/')\n",
    "from logger import *\n",
    "from eval import *\n",
    "from misc import *\n",
    "\n",
    "from cifar10_normal_train import *\n",
    "from cifar10_util import *\n",
    "from adam import Adam\n",
    "from sgd import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "data_loc='/mnt/nfs/work1/amir/vshejwalkar/cifar10_data/'\n",
    "# load the train dataset\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "\n",
    "cifar10_train = datasets.CIFAR10(root=data_loc, train=True, download=True, transform=train_transform)\n",
    "\n",
    "cifar10_test = datasets.CIFAR10(root=data_loc, train=False, download=True, transform=train_transform)\n",
    "\n",
    "total_tr_len = len(cifar10_train)\n",
    "\n",
    "X={}\n",
    "Y=[]\n",
    "for i in range(len(cifar10_train)):\n",
    "    data = cifar10_train[i][0].numpy()\n",
    "    label = cifar10_train[i][1]\n",
    "\n",
    "    if label in X:\n",
    "        X[label].append(data)\n",
    "    else:\n",
    "        X[label] = []\n",
    "        X[label].append(data)\n",
    "        Y.append(label)\n",
    "\n",
    "for i in range(len(cifar10_test)):\n",
    "    data = cifar10_test[i][0].numpy()\n",
    "    label = cifar10_test[i][1]\n",
    "\n",
    "    if label in X:\n",
    "        X[label].append(data)\n",
    "    else:\n",
    "        X[label] = []\n",
    "        X[label].append(data)\n",
    "        Y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "n_users=50\n",
    "\n",
    "print(type(X[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{6: 6000, 9: 6000, 4: 6000, 1: 6000, 2: 6000, 7: 6000, 8: 6000, 3: 6000, 5: 6000, 0: 6000}\n",
      "user 0 has 895 train data\n",
      "user 1 has 894 train data\n",
      "user 2 has 896 train data\n",
      "user 3 has 895 train data\n",
      "user 4 has 894 train data\n",
      "user 5 has 895 train data\n",
      "user 6 has 894 train data\n",
      "user 7 has 896 train data\n",
      "user 8 has 894 train data\n",
      "user 9 has 895 train data\n",
      "user 10 has 896 train data\n",
      "user 11 has 895 train data\n",
      "user 12 has 894 train data\n",
      "user 13 has 894 train data\n",
      "user 14 has 895 train data\n",
      "user 15 has 895 train data\n",
      "user 16 has 896 train data\n",
      "user 17 has 894 train data\n",
      "user 18 has 894 train data\n",
      "user 19 has 895 train data\n",
      "user 20 has 895 train data\n",
      "user 21 has 895 train data\n",
      "user 22 has 895 train data\n",
      "user 23 has 893 train data\n",
      "user 24 has 894 train data\n",
      "user 25 has 894 train data\n",
      "user 26 has 894 train data\n",
      "user 27 has 897 train data\n",
      "user 28 has 895 train data\n",
      "user 29 has 896 train data\n",
      "user 30 has 895 train data\n",
      "user 31 has 895 train data\n",
      "user 32 has 896 train data\n",
      "user 33 has 894 train data\n",
      "user 34 has 894 train data\n",
      "user 35 has 896 train data\n",
      "user 36 has 894 train data\n",
      "user 37 has 895 train data\n",
      "user 38 has 895 train data\n",
      "user 39 has 896 train data\n",
      "user 40 has 894 train data\n",
      "user 41 has 895 train data\n",
      "user 42 has 895 train data\n",
      "user 43 has 894 train data\n",
      "user 44 has 896 train data\n",
      "user 45 has 895 train data\n",
      "user 46 has 895 train data\n",
      "user 47 has 895 train data\n",
      "user 48 has 895 train data\n",
      "user 49 has 895 train data\n",
      "6 1499\n",
      "9 1682\n",
      "4 407\n",
      "1 1463\n",
      "2 1413\n",
      "7 1698\n",
      "8 1610\n",
      "3 2393\n",
      "5 1328\n",
      "0 1764\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "def get_label_with_most_sample(labels:list, taken_index:list, initial_num_data_per_label:dict, data:dict):\n",
    "    max_fraction = -9.99\n",
    "    result_label = None\n",
    "\n",
    "    for label in labels:\n",
    "        \n",
    "        if label in taken_index: \n",
    "            continue\n",
    "        \n",
    "        full = initial_num_data_per_label[label]\n",
    "        current = len(data[label])\n",
    "\n",
    "        if full == current:\n",
    "            return label\n",
    "        else:\n",
    "            unused_fraction = current / full \n",
    "            if unused_fraction > max_fraction:\n",
    "                max_fraction = unused_fraction\n",
    "                result_label = label\n",
    "\n",
    "    return result_label\n",
    "\n",
    "\n",
    "def split_data_dirichelt(num_user:int, num_class:int, num_data_per_user:int, alpha:int, data:dict):\n",
    "    \n",
    "    initial_num_data_per_label = {}\n",
    "    labels = []\n",
    "\n",
    "    for label in data:\n",
    "        initial_num_data_per_label[label] = len(data[label])\n",
    "        labels.append(label)\n",
    "\n",
    "    print(initial_num_data_per_label)\n",
    "\n",
    "    for i in range(num_user):\n",
    "        alpha_list = [alpha for _ in range(num_class)]\n",
    "        probs = np.random.dirichlet(alpha_list)\n",
    "\n",
    "        user_train_data_tensor=[]\n",
    "        user_train_label_tensor=[]\n",
    "\n",
    "        taken_index = []\n",
    "\n",
    "        for prob in probs:\n",
    "            n_sample = math.floor(prob * num_data_per_user[i])\n",
    "\n",
    "            # print(\"n_sample: \", n_sample)\n",
    "            result_label = get_label_with_most_sample(labels, taken_index, initial_num_data_per_label, data)\n",
    "\n",
    "            taken_index.append(result_label)\n",
    "            # print(f\"before label {result_label} in data has: \", len(data[result_label]))\n",
    "\n",
    "            if n_sample > len(data[result_label]):\n",
    "                sys.exit(f\"not enough data for user {num_user}, running out of data with label {label}\")\n",
    "\n",
    "            user_train_data_tensor.extend(data[result_label][:n_sample])\n",
    "            user_train_label_tensor.extend([result_label] * n_sample)\n",
    "            \n",
    "            data[result_label]= data[result_label][n_sample:]\n",
    "\n",
    "\n",
    "            # print(f\"after label {result_label} in data has: \", len(data[result_label]))\n",
    "\n",
    "        print(f\"user {i} has {len(user_train_data_tensor)} train data\")\n",
    "    \n",
    "    for label in data:\n",
    "        print(label, len(data[label]))\n",
    "        \n",
    "\n",
    "user_train_len= total_tr_len // n_users\n",
    "split_data_dirichelt(n_users, len(Y), [user_train_len - 100] * n_users, 1, X.copy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpen333",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
